{"meta":{"title":"Coding | Harrison's Blog","subtitle":"上善若水任方猿","description":"上善若水任方猿","author":"Chen Harrison","url":"https://ostenant.coding.me"},"pages":[{"title":"","date":"2018-05-08T02:49:46.087Z","updated":"2018-05-08T02:49:46.087Z","comments":true,"path":"404.html","permalink":"https://ostenant.coding.me/404.html","excerpt":"","text":"404 | HelloDog"}],"posts":[{"title":"单元测试利器Mockito","slug":"单元测试\b利器Mockito","date":"2018-05-31T15:30:00.000Z","updated":"2018-06-01T09:58:45.023Z","comments":true,"path":"2018/05/31/单元测试\b利器Mockito/","link":"","permalink":"https://ostenant.coding.me/2018/05/31/单元测试\b利器Mockito/","excerpt":"\b前言Mockito 是当前最流行的 单元测试 Mock 框架。采用 Mock 框架，我们可以 虚拟 出一个 外部依赖，降低测试 组件 之间的 耦合度，只注重代码的 流程与结果，真正地实现测试目的。","text":"\b前言Mockito 是当前最流行的 单元测试 Mock 框架。采用 Mock 框架，我们可以 虚拟 出一个 外部依赖，降低测试 组件 之间的 耦合度，只注重代码的 流程与结果，真正地实现测试目的。 正文什么是MockMock 的中文译为仿制的，模拟的，虚假的。对于测试框架来说，即构造出一个模拟/虚假的对象，使我们的测试能顺利进行下去。 Mock 测试就是在测试过程中，对于某些 不容易构造（如 HttpServletRequest 必须在 Servlet 容器中才能构造出来）或者不容易获取 比较复杂 的对象（如 JDBC 中的 ResultSet 对象），用一个 虚拟 的对象（Mock 对象）来创建，以便测试方法。 为什么使用Mock测试单元测试 是为了验证我们的代码运行正确性，我们注重的是代码的流程以及结果的正确与否。 对比真实运行代码，可能其中有一些 外部依赖 的构建步骤相对麻烦，如果我们还是按照真实代码的构建规则构造出外部依赖，会大大增加单元测试的工作，代码也会参杂太多非测试部分的内容，测试用例显得复杂难懂。 采用 Mock 框架，我们可以 虚拟 出一个 外部依赖，只注重代码的 流程与结果，真正地实现测试目的。 Mock测试框架的好处 可以很简单的虚拟出一个复杂对象（比如虚拟出一个接口的实现类）； 可以配置 mock 对象的行为； 可以使测试用例只注重测试流程与结果； 减少外部类、系统和依赖给单元测试带来的耦合。 Mockito的流程 如图所示，使用 Mockito 的大致流程如下: 创建 外部依赖 的 Mock 对象, 然后将此 Mock 对象注入到 测试类 中； 执行 测试代码； 校验 测试代码 是否执行正确。 Mockito的使用在 Module 的 build.gradle 中添加如下内容： 123456dependencies &#123; //Mockito for unit tests testImplementation \"org.mockito:mockito-core:2.+\" //Mockito for Android tests androidTestImplementation 'org.mockito:mockito-android:2.+'&#125; 这里稍微解释下： mockito-core: 用于 本地单元测试，其测试代码路径位于 module-name/src/test/java/ mockito-android: 用于 设备测试，即需要运行 android 设备进行测试，其测试代码路径位于 module-name/src/androidTest/java/ mockito-core最新版本可以在 Maven 中查询：mockito-core。mockito-android最新版本可以在 Maven 中查询：mockito-android Mockito的使用示例普通单元测试使用 mockito（mockito-core），路径：module-name/src/test/java/ 这里摘用官网的 Demo: 检验调对象相关行为是否被调用123456789101112import static org.mockito.Mockito.*;// Mock creationList mockedList = mock(List.class);// Use mock object - it does not throw any \"unexpected interaction\" exceptionmockedList.add(\"one\"); //调用了add(\"one\")行为mockedList.clear(); //调用了clear()行为// Selective, explicit, highly readable verificationverify(mockedList).add(\"one\"); // 检验add(\"one\")是否已被调用verify(mockedList).clear(); // 检验clear()是否已被调用 这里 mock 了一个 List（这里只是为了用作 Demo 示例，通常对于 List 这种简单的类对象创建而言，直接 new 一个真实的对象即可，无需进行 mock），verify() 会检验对象是否在前面已经执行了相关行为，这里 mockedList 在 verify 之前已经执行了 add(&quot;one&quot;) 和 clear() 行为，所以verify() 会通过。 配置/方法行为12345678// you can mock concrete classes, not only interfacesLinkedList mockedList = mock(LinkedList.class);// stubbing appears before the actual executionwhen(mockedList.get(0)).thenReturn(\"first\");// the following prints \"first\"System.out.println(mockedList.get(0));// the following prints \"null\" because get(999) was not stubbedSystem.out.println(mockedList.get(999)); 这里对几个比较重要的点进行解析： when(mockedList.get(0)).thenReturn(“first”) 这句话 Mockito 会解析为：当对象 mockedList 调用 get()方法，并且参数为 0 时，返回结果为&quot;first&quot;，这相当于定制了我们 mock 对象的行为结果（mock LinkedList 对象为 mockedList，指定其行为 get(0)，则返回结果为 &quot;first&quot;)。 mockedList.get(999) 由于 mockedList 没有指定 get(999) 的行为，所以其结果为 null。因为 Mockito 的底层原理是使用 cglib 动态生成一个 代理类对象，因此，mock 出来的对象其实质就是一个 代理，该代理在 没有配置/指定行为 的情况下，默认返回 空值。 上面的 Demo 使用的是 静态方法 mock() 模拟出一个实例，我们还可以通过注解 @Mock 也模拟出一个实例： 123456789101112131415161718@Mockprivate Intent mIntent;@Rulepublic MockitoRule mockitoRule = MockitoJUnit.rule();@Testpublic void mockAndroid()&#123; Intent intent = mockIntent(); assertThat(intent.getAction()).isEqualTo(\"com.yn.test.mockito\"); assertThat(intent.getStringExtra(\"Name\")).isEqualTo(\"Whyn\");&#125;private Intent mockIntent()&#123; when(mIntent.getAction()).thenReturn(\"com.yn.test.mockito\"); when(mIntent.getStringExtra(\"Name\")).thenReturn(\"Whyn\"); return mIntent;&#125; 对于标记有 @Mock, @Spy, @InjectMocks 等注解的成员变量的 初始化 到目前为止有 2 种方法： 对 JUnit 测试类添加 @RunWith(MockitoJUnitRunner.class) 在标示\b有 @Before 方法内调用初始化方法：MockitoAnnotations.initMocks(Object) 上面的测试用例，对于 @Mock 等注解的成员变量的初始化又多了一种方式 MockitoRule。规则 MockitoRule 会自动帮我们调用 MockitoAnnotations.initMocks(this) 去 实例化 出 注解 的成员变量，我们就无需手动进行初始化了。 Mockito的重要方法实例化虚拟对象123456789101112131415161718// You can mock concrete classes, not just interfacesLinkedList mockedList = mock(LinkedList.class);// Stubbingwhen(mockedList.get(0)).thenReturn(\"first\");when(mockedList.get(1)).thenThrow(new RuntimeException());// Following prints \"first\"System.out.println(mockedList.get(0));// Following throws runtime exceptionSystem.out.println(mockedList.get(1));// Following prints \"null\" because get(999) was not stubbedSystem.out.println(mockedList.get(999));// Although it is possible to verify a stubbed invocation, usually it's just redundant// If your code cares what get(0) returns, then something else breaks (often even before verify() gets executed).// If your code doesn't care what get(0) returns, then it should not be stubbed. Not convinced? See here.verify(mockedList).get(0); 对于所有方法，mock 对象默认返回 null，原始类型/原始类型包装类 默认值，或者 空集合。比如对于 int/Integer 类型，则返回 0，对于 boolean/Boolean 则返回 false。 行为配置（stub）是可以被复写的：比如通常的对象行为是具有一定的配置，但是测试方法可以复写这个行为。请谨记行为复写可能表明潜在的行为太多了。 一旦配置了行为，方法总是会返回 配置值，无论该方法被调用了多少次。 最后一次行为配置是更加重要的，当你为一个带有相同参数的相同方法配置了很多次，最后一次起作用。 参数匹配Mockito 通过参数对象的 equals() 方法来验证参数是否一致，当需要更多的灵活性时，可以使用参数匹配器： 12345678910// Stubbing using built-in anyInt() argument matcherwhen(mockedList.get(anyInt())).thenReturn(\"element\");// Stubbing using custom matcher (let's say isValid() returns your own matcher implementation):when(mockedList.contains(argThat(isValid()))).thenReturn(\"element\");// Following prints \"element\"System.out.println(mockedList.get(999));// You can also verify using an argument matcherverify(mockedList).get(anyInt());// Argument matchers can also be written as Java 8 Lambdasverify(mockedList).add(argThat(someString -&gt; someString.length() &gt; 5)); 参数匹配器 允许更加灵活的 验证 和 行为配置。更多 内置匹配器 和 自定义参数匹配器 例子请参考：ArgumentMatchers，MockitoHamcrest 注意：如果使用了参数匹配器，那么所有的参数都需要提供一个参数匹配器。 1234verify(mock).someMethod(anyInt(), anyString(), eq(\"third argument\"));// Above is correct - eq() is also an argument matcherverify(mock).someMethod(anyInt(), anyString(), \"third argument\");// Above is incorrect - exception will be thrown because third argument is given without an argument matcher. 类似 anyObject()，eq() 这类匹配器并不返回匹配数值。他们内部记录一个 匹配器堆栈 并返回一个空值（通常为 null）。这个实现是为了匹配 java 编译器的 静态类型安全，这样做的后果就是你不能在 检验/配置方法 外使用 anyObject()，eq() 等方法。 校验次数123456789101112131415161718192021222324LinkedList mockedList = mock(LinkedList.class);// Use mockmockedList.add(\"once\");mockedList.add(\"twice\");mockedList.add(\"twice\");mockedList.add(\"three times\");mockedList.add(\"three times\");mockedList.add(\"three times\");// Follow two verifications work exactly the same - times(1) is used by defaultverify(mockedList).add(\"once\");verify(mockedList, times(1)).add(\"once\");// Exact number of invocations verificationverify(mockedList, times(2)).add(\"twice\");verify(mockedList, times(3)).add(\"three times\");// Verification using never(). never() is an alias to times(0)verify(mockedList, never()).add(\"never happened\");// Verification using atLeast()/atMost()verify(mockedList, atLeastOnce()).add(\"three times\");verify(mockedList, atLeast(2)).add(\"three times\");verify(mockedList, atMost(5)).add(\"three times\"); 校验次数方法常用的有如下几个： Method Meaning times(n) 次数为n，默认为1（times(1)） never() 次数为0，相当于times(0) atLeast(n) 最少n次 atLeastOnce() 最少一次 atMost(n) 最多n次 抛出异常123doThrow(new RuntimeException()).when(mockedList).clear();// following throws RuntimeExceptionmockedList.clear(); 按顺序校验有时对于一些行为，有先后顺序之分，所以，当我们在校验时，就需要考虑这个行为的先后顺序： 12345678910111213141516171819202122// A. Single mock whose methods must be invoked in a particular orderList singleMock = mock(List.class);// Use a single mocksingleMock.add(\"was added first\");singleMock.add(\"was added second\");// Create an inOrder verifier for a single mockInOrder inOrder = inOrder(singleMock);// Following will make sure that add is first called with \"was added first, then with \"was added second\"inOrder.verify(singleMock).add(\"was added first\");inOrder.verify(singleMock).add(\"was added second\");// B. Multiple mocks that must be used in a particular orderList firstMock = mock(List.class);List secondMock = mock(List.class);// Use mocksfirstMock.add(\"was called first\");secondMock.add(\"was called second\");// Create inOrder object passing any mocks that need to be verified in orderInOrder inOrder = inOrder(firstMock, secondMock);// Following will make sure that firstMock was called before secondMockinOrder.verify(firstMock).add(\"was called first\");inOrder.verify(secondMock).add(\"was called second\"); 存根连续调用对于同一个方法，如果我们想让其在 多次调用 中分别 返回不同 的数值，那么就可以使用存根连续调用： 12345678910when(mock.someMethod(\"some arg\")) .thenThrow(new RuntimeException()) .thenReturn(\"foo\");// First call: throws runtime exception:mock.someMethod(\"some arg\");// Second call: prints \"foo\"System.out.println(mock.someMethod(\"some arg\"));// Any consecutive call: prints \"foo\" as well (last stubbing wins).System.out.println(mock.someMethod(\"some arg\")); 也可以使用下面更简洁的存根连续调用方法： 1when(mock.someMethod(\"some arg\")).thenReturn(\"one\", \"two\", \"three\"); 注意：存根连续调用要求必须使用链式调用，如果使用的是同个方法的多个存根配置，那么只有最后一个起作用（覆盖前面的存根配置）。 123// All mock.someMethod(\"some arg\") calls will return \"two\"when(mock.someMethod(\"some arg\").thenReturn(\"one\")when(mock.someMethod(\"some arg\").thenReturn(\"two\") 无返回值函数对于 返回类型 为 void 的方法，存根要求使用另一种形式的 when(Object) 函数，因为编译器要求括号内不能存在 void 方法。 例如，存根一个返回类型为 void 的方法，要求调用时抛出一个异常： 123doThrow(new RuntimeException()).when(mockedList).clear();// Following throws RuntimeException:mockedList.clear(); 监视真实对象前面使用的都是 mock 出来一个对象。这样，当 没有配置/存根 其具体行为的话，结果就会返回 空类型。而如果使用 特务对象（spy），那么对于 没有存根 的行为，它会调用 原来对象 的方法。可以把 spy 想象成局部 mock。 12345678910111213141516List list = new LinkedList();List spy = spy(list);// Optionally, you can stub out some methods:when(spy.size()).thenReturn(100);// Use the spy calls *real* methodsspy.add(\"one\");spy.add(\"two\");// Prints \"one\" - the first element of a listSystem.out.println(spy.get(0));// Size() method was stubbed - 100 is printedSystem.out.println(spy.size());// Optionally, you can verifyverify(spy).add(\"one\");verify(spy).add(\"two\"); 注意：由于 spy 是局部 mock，所以有时候使用 when(Object) 时，无法做到存根作用。此时，就可以考虑使用 doReturn() | Answer() | Throw() 这类方法进行存根： 123456List list = new LinkedList();List spy = spy(list);// Impossible: real method is called so spy.get(0) throws IndexOutOfBoundsException (the list is yet empty)when(spy.get(0)).thenReturn(\"foo\");// You have to use doReturn() for stubbingdoReturn(\"foo\").when(spy).get(0); spy 并不是 真实对象 的 代理。相反的，它对传递过来的 真实对象 进行 克隆。所以，对 真实对象 的任何操作，spy 对象并不会感知到。同理，对 spy 对象的任何操作，也不会影响到 真实对象。 当然，如果使用 mock 进行对象的 局部 mock，通过 doCallRealMethod() | thenCallRealMethod() 方法也是可以的： 12345// You can enable partial mock capabilities selectively on mocks:Foo mock = mock(Foo.class);// Be sure the real implementation is 'safe'.// If real implementation throws exceptions or depends on specific state of the object then you're in trouble.when(mock.someMethod()).thenCallRealMethod(); 测试驱动开发以 行为驱动开发 的格式使用 //given //when //then 注释为测试用法基石编写测试用例，这正是 Mockito 官方编写测试用例方法，强烈建议使用这种方式测试编写。 12345678910111213import static org.mockito.BDDMockito.*;Seller seller = mock(Seller.class);Shop shop = new Shop(seller);public void shouldBuyBread() throws Exception &#123; // Given given(seller.askForBread()).willReturn(new Bread()); // When Goods goods = shop.buyBread(); // Then assertThat(goods, containBread());&#125; 自定义错误校验输出信息1234// Will print a custom message on verification failureverify(mock, description(\"This will print on failure\")).someMethod();// Will work with any verification modeverify(mock, times(2).description(\"someMethod should be called twice\")).someMethod(); @InjectMock构造器，方法，成员变量依赖注入使用 @InjectMock 注解时，Mockito 会检查 类构造器，方法 或 成员变量，依据它们的 类型 进行自动 mock。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class InjectMockTest &#123; @Mock private User user; @Mock private ArticleDatabase database; @InjectMocks private ArticleManager manager; @Rule public MockitoRule mockitoRule = MockitoJUnit.rule(); @Test public void testInjectMock() &#123; // Calls addListener with an instance of ArticleListener manager.initialize(); // Validate that addListener was called verify(database).addListener(any(ArticleListener.class)); &#125; public static class ArticleManager &#123; private User user; private ArticleDatabase database; public ArticleManager(User user, ArticleDatabase database) &#123; super(); this.user = user; this.database = database; &#125; public void initialize() &#123; database.addListener(new ArticleListener()); &#125; &#125; public static class User &#123; &#125; public static class ArticleListener &#123; &#125; public static class ArticleDatabase &#123; public void addListener(ArticleListener listener) &#123; &#125; &#125;&#125; 成员变量 manager 类型为 ArticleManager，它的上面标识别了 @InjectMocks。这意味着要 mock 出 manager，Mockito 需要先自动 mock 出 ArticleManager 所需的 构造参数（即：user 和 database），最终 mock 得到一个 ArticleManager，赋值给 manager。 参数捕捉ArgumentCaptor 允许在 verify 的时候获取 方法参数内容，这使得我们能在 测试过程 中能对 调用方法参数 进行 捕捉 并 测试。 1234567891011121314@Rulepublic MockitoRule mockitoRule = MockitoJUnit.rule();@Captorprivate ArgumentCaptor&lt;List&lt;String&gt;&gt; captor;@Testpublic void testArgumentCaptor()&#123; List&lt;String&gt; asList = Arrays.asList(\"someElement_test\", \"someElement\"); final List&lt;String&gt; mockedList = mock(List.class); mockedList.addAll(asList); verify(mockedList).addAll(captor.capture()); // When verify,you can capture the arguments of the calling method final List&lt;String&gt; capturedArgument = captor.getValue(); assertThat(capturedArgument, hasItem(\"someElement\"));&#125; Mocktio的局限 不能 mock 静态方法； 不能 mock 构造器； 不能 mock equals() 和 hashCode() 方法。 欢迎扫码关注公众号：零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"测试框架系列","slug":"测试框架系列","permalink":"https://ostenant.coding.me/categories/测试框架系列/"}],"tags":[{"name":"Mockito","slug":"Mockito","permalink":"https://ostenant.coding.me/tags/Mockito/"}]},{"title":"2018\b服务端架构师技术图谱","slug":"2018服务端架构师技术图谱","date":"2018-05-30T14:46:00.000Z","updated":"2018-05-31T05:26:34.199Z","comments":true,"path":"2018/05/30/2018服务端架构师技术图谱/","link":"","permalink":"https://ostenant.coding.me/2018/05/30/2018服务端架构师技术图谱/","excerpt":"\b本文摘自 github 上的一篇长约 10 万字\b服务端架构师技术总结归纳文档，覆盖广度包括数据结构、算法、并发、操作系统、设计模式、运维、中间件、网络、数据库、搜索引擎、性能、大数据、安全、常见开源框架、分布式、设计思想、项目管理和技术资源等。\b","text":"\b本文摘自 github 上的一篇长约 10 万字\b服务端架构师技术总结归纳文档，覆盖广度包括数据结构、算法、并发、操作系统、设计模式、运维、中间件、网络、数据库、搜索引擎、性能、大数据、安全、常见开源框架、分布式、设计思想、项目管理和技术资源等。\b 目录 数据结构 队列 集合 链表、数组 字典、关联数组 栈 树 二叉树 完全二叉树 平衡二叉树 二叉查找树（BST） 红黑树 B-，B+，B*树 LSM 树 BitSet 常用算法 排序、查找算法 选择排序 冒泡排序 插入排序 快速排序 归并排序 希尔排序 堆排序 计数排序 桶排序 基数排序 二分查找 Java 中的排序工具 布隆过滤器 字符串比较 KMP 算法 深度优先、广度优先 贪心算法 回溯算法 剪枝算法 动态规划 朴素贝叶斯 推荐算法 最小生成树算法 最短路径算法 并发 多线程 线程安全 一致性、事务 事务 ACID 特性 事务的隔离级别 MVCC 锁 Java中的锁和同步类 公平锁 &amp; 非公平锁 悲观锁 乐观锁 &amp; CAS ABA 问题 CopyOnWrite容器 RingBuffer 可重入锁 &amp; 不可重入锁 互斥锁 &amp; 共享锁 死锁 操作系统 计算机原理 CPU 多级缓存 进程 线程 协程 Linux 设计模式 设计模式的六大原则 23种常见设计模式 应用场景 单例模式 责任链模式 MVC IOC AOP UML 微服务思想 康威定律 运维 &amp; 统计 &amp; 技术支持 常规监控 APM 统计分析 持续集成(CI/CD) Jenkins 环境分离 自动化运维 Ansible puppet chef 测试 TDD 理论 单元测试 压力测试 全链路压测 A/B 、灰度、蓝绿测试 虚拟化 KVM Xen OpenVZ 容器技术 Docker 云技术 OpenStack DevOps 文档管理 中间件 Web Server Nginx OpenResty Apache Httpd Tomcat 架构原理 调优方案 Jetty 缓存 本地缓存 客户端缓存 服务端缓存 Web缓存 Memcached Redis 架构 回收策略 Tair 消息队列 消息总线 消息的顺序 RabbitMQ RocketMQ ActiveMQ Kafka Redis 消息推送 ZeroMQ 定时调度 单机定时调度 分布式定时调度 RPC Dubbo Thrift gRPC 数据库中间件 Sharding Jdbc 日志系统 日志搜集 配置中心 API 网关 网络 协议 OSI 七层协议 TCP/IP HTTP HTTP2.0 HTTPS 网络模型 Epoll Java NIO kqueue 连接和短连接 框架 零拷贝（Zero-copy） 序列化(二进制协议) Hessian Protobuf 数据库 基础理论 数据库设计的三大范式 MySQL 原理 InnoDB 优化 索引 聚集索引, 非聚集索引 复合索引 自适应哈希索引(AHI) explain NoSQL MongoDB Hbase 搜索引擎 搜索引擎原理 Lucene Elasticsearch Solr sphinx 性能 性能优化方法论 容量评估 CDN 网络 连接池 性能调优 大数据 流式计算 Storm Flink Kafka Stream 应用场景 Hadoop HDFS MapReduce Yarn Spark 安全 web 安全 XSS CSRF SQL 注入 Hash Dos 脚本注入 漏洞扫描工具 验证码 DDoS 防范 用户隐私信息保护 序列化漏洞 加密解密 对称加密 哈希算法 非对称加密 服务器安全 数据安全 数据备份 网络隔离 内外网分离 登录跳板机 授权、认证 RBAC OAuth2.0 双因素认证（2FA） 单点登录(SSO) 常用开源框架 开源协议 日志框架 Log4j、Log4j2 Logback ORM 网络框架 Web 框架 Spring 家族 工具框架 分布式设计 扩展性设计 稳定性 &amp; 高可用 硬件负载均衡 软件负载均衡 限流 应用层容灾 跨机房容灾 容灾演练流程 平滑启动 数据库扩展 读写分离模式 分片模式 服务治理 服务注册与发现 服务路由控制 分布式一致 CAP 与 BASE 理论 分布式锁 分布式一致性算法 PAXOS Zab Raft Gossip 两阶段提交、多阶段提交 幂等 分布式一致方案 分布式 Leader 节点选举 TCC(Try/Confirm/Cancel) 柔性事务 分布式文件系统 唯一ID 生成 全局唯一ID 一致性Hash算法 设计思想 &amp; 开发模式 DDD(Domain-driven Design - 领域驱动设计) 命令查询职责分离(CQRS) 贫血，充血模型 Actor 模式 响应式编程 Reactor RxJava Vert.x DODAF2.0 Serverless Service Mesh 项目管理 架构评审 重构 代码规范 代码 Review RUP 看板管理 SCRUM 敏捷开发 极限编程（XP） 结对编程 FMEA管理模式 通用业务术语 技术趋势 政策、法规 法律 严格遵守刑法253法条 架构师素质 团队管理 招聘 资讯 行业资讯 公众号列表 博客 团队博客 个人博客 综合门户、社区 问答、讨论类社区 行业数据分析 专项网站 其他类 推荐参考书 在线电子书 纸质书 开发方面 架构方面 技术管理方面 基础理论 工具方面 大数据方面 技术资源 开源资源 手册、文档、教程 在线课堂 会议、活动 常用APP 找工作 工具 代码托管 文件服务 \b正文数据结构队列 《java队列——queue详细分析》 非阻塞队列：ConcurrentLinkedQueue(无界线程安全)，采用CAS机制（compareAndSwapObject原子操作）。 阻塞队列：ArrayBlockingQueue(有界)、LinkedBlockingQueue（无界）、DelayQueue、PriorityBlockingQueue，采用锁机制；使用 ReentrantLock 锁。 《LinkedList、ConcurrentLinkedQueue、LinkedBlockingQueue对比分析》 集合 《Java Set集合的详解》 链表、数组 《Java集合详解–什么是List》 字典、关联数组 《Java map 详解 - 用法、遍历、排序、常用API等》 栈 《java数据结构与算法之栈（Stack）设计与实现》 《Java Stack 类》 《java stack的详细实现分析》 Stack 是线程安全的。 内部使用数组保存数据，不够时翻倍。 树二叉树每个节点最多有两个叶子节点。 《二叉树》 完全二叉树 《完全二叉树》 叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。 平衡二叉树左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 《浅谈数据结构-平衡二叉树》 《浅谈算法和数据结构: 八 平衡查找树之2-3树》 二叉查找树（BST）二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree）。 《浅谈算法和数据结构: 七 二叉查找树》 红黑树 《最容易懂得红黑树》 添加阶段后，左旋或者右旋从而再次达到平衡。 《浅谈算法和数据结构: 九 平衡查找树之红黑树》 B-，B+，B*树MySQL是基于B+树聚集索引组织表 《B-树，B+树，B*树详解》 《B-树，B+树与B*树的优缺点比较》 B+ 树的叶子节点链表结构相比于 B- 树便于扫库，和范围检索。LSM 树 LSM（Log-Structured Merge-Trees）和 B+ 树相比，是牺牲了部分读的性能来换取写的性能(通过批量写入)，实现读写之间的。Hbase、LevelDB、Tair（Long DB）、nessDB 采用 LSM 树的结构。LSM可以快速建立索引。 《LSM树 VS B+树》 B+ 树读性能好，但由于需要有序结构，当key比较分散时，磁盘寻道频繁，造成写性能。 LSM 是将一个大树拆分成N棵小树，先写到内存（无寻道问题，性能高），在内存中构建一颗有序小树（有序树），随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历（二分查找）所有的小树，但在每颗小树内部数据是有序的。 《LSM树（Log-Structured Merge Tree）存储引擎》 极端的说，基于LSM树实现的HBase的写性能比MySQL高了一个数量级，读性能低了一个数量级。 优化方式：Bloom filter 替代二分查找；compact 小数位大树，提高查询性能。 Hbase 中，内存中达到一定阈值后，整体flush到磁盘上、形成一个文件（B+数），HDFS不支持update操作，所以Hbase做整体flush而不是merge update。flush到磁盘上的小树，定期会合并成一个大树。 BitSet经常用于大规模数据的排重检查。 《Java Bitset类》 《Java BitSet（位集）》 常用算法 《常见排序算法及对应的时间复杂度和空间复杂度》 排序、查找算法 《常见排序算法及对应的时间复杂度和空间复杂度》 选择排序 《Java中的经典算法之选择排序（SelectionSort）》 每一趟从待排序的记录中选出最小的元素，顺序放在已排好序的序列最后，直到全部记录排序完毕。 冒泡排序 《冒泡排序的2种写法》 相邻元素前后交换、把最大的排到最后。 时间复杂度 O(n²) 插入排序 《排序算法总结之插入排序》 快速排序 《坐在马桶上看算法：快速排序》 一侧比另外一次都大或小。 归并排序 《图解排序算法(四)之归并排序》 分而治之，分成小份排序，在合并(重建一个新空间进行复制)。 希尔排序TODO 堆排序 《图解排序算法(三)之堆排序》 排序过程就是构建最大堆的过程，最大堆：每个结点的值都大于或等于其左右孩子结点的值，堆顶元素是最大值。 计数排序 《计数排序和桶排序》 和桶排序过程比较像，差别在于桶的数量。 桶排序 《【啊哈！算法】最快最简单的排序——桶排序》 《排序算法（三）：计数排序与桶排序》 桶排序将[0,1)区间划分为n个相同的大小的子区间，这些子区间被称为桶。 每个桶单独进行排序，然后再遍历每个桶。 基数排序按照个位、十位、百位、…依次来排。 《排序算法系列：基数排序》 《基数排序》 二分查找 《二分查找(java实现)》 要求待查找的序列有序。 时间复杂度 O(logN)。 《java实现二分查找-两种方式》 while + 递归。Java 中的排序工具 《Arrays.sort和Collections.sort实现原理解析》 Collections.sort算法调用的是合并排序。 Arrays.sort() 采用了2种排序算法 – 基本类型数据使用快速排序法，对象数组使用归并排序。 布隆过滤器常用于大数据的排重，比如email，url 等。核心原理：将每条数据通过计算产生一个指纹（一个字节或多个字节，但一定比原始数据要少很多），其中每一位都是通过随机计算获得，在将指纹映射到一个大的按位存储的空间中。注意：会有一定的错误率。优点：空间和时间效率都很高。缺点：随着存入的元素数量增加，误算率随之增加。 《布隆过滤器 – 空间效率很高的数据结构》 《大量数据去重：Bitmap和布隆过滤器(Bloom Filter)》 《基于Redis的布隆过滤器的实现》 基于 Redis 的 Bitmap 数据结构。 《网络爬虫：URL去重策略之布隆过滤器(BloomFilter)的使用》 使用Java中的 BitSet 类 和 加权和hash算法。 字符串比较KMP 算法KMP：Knuth-Morris-Pratt算法（简称KMP）核心原理是利用一个“部分匹配表”，跳过已经匹配过的元素。 《字符串匹配的KMP算法》 深度优先、广度优先 《广度优先搜索BFS和深度优先搜索DFS》 贪心算法 《算法：贪婪算法基础》 《常见算法及问题场景——贪心算法》 回溯算法 《 五大常用算法之四：回溯法》 剪枝算法 《α-β剪枝算法》 动态规划 《详解动态规划——邹博讲动态规划》 《动态规划算法的个人理解》 朴素贝叶斯 《带你搞懂朴素贝叶斯分类算法》 P(B|A)=P(A|B)P(B)/P(A) 《贝叶斯推断及其互联网应用1》 《贝叶斯推断及其互联网应用2》 推荐算法 《推荐算法综述》 《TOP 10 开源的推荐系统简介》 最小生成树算法 《算法导论–最小生成树（Kruskal和Prim算法）》 最短路径算法 《Dijkstra算法详解》 并发Java 并发 Java 并发知识合集 JAVA并发知识图谱 多线程 《40个Java多线程问题总结》 线程安全 《Java并发编程——线程安全及解决机制简介》 一致性、事务事务 ACID 特性 《数据库事务ACID特性》 事务的隔离级别 未提交读：一个事务可以读取另一个未提交的数据，容易出现脏读的情况。 读提交：一个事务等另外一个事务提交之后才可以读取数据，但会出现不可重复读的情况（多次读取的数据不一致），读取过程中出现UPDATE操作，会多。（大多数数据库默认级别是RC，比如SQL Server，Oracle），读取的时候不可以修改。 可重复读： 同一个事务里确保每次读取的时候，获得的是同样的数据，但不保障原始数据被其他事务更新（幻读），Mysql InnoDB 就是这个级别。 序列化：所有事物串行处理（牺牲了效率） 《理解事务的4种隔离级别》 数据库事务的四大特性及事务隔离级别 《MySQL的InnoDB的幻读问题 》 幻读的例子非常清楚。 通过 SELECT … FOR UPDATE 解决。 《一篇文章带你读懂MySQL和InnoDB》 图解脏读、不可重复读、幻读问题。 MVCC 《【mysql】关于innodb中MVCC的一些理解》 innodb 中 MVCC 用在 Repeatable-Read 隔离级别。 MVCC 会产生幻读问题（更新时异常。） 《轻松理解MYSQL MVCC 实现机制》 通过隐藏版本列来实现 MVCC 控制，一列记录创建时间、一列记录删除时间，这里的时间 每次只操作比当前版本小（或等于）的 行。 锁Java中的锁和同步类 《Java中的锁分类》 主要包括 synchronized、ReentrantLock、和 ReadWriteLock。 《Java并发之AQS详解》 《Java中信号量 Semaphore》 有数量控制 申请用 acquire，申请不要则阻塞；释放用 release。 《java开发中的Mutex vs Semaphore》 简单的说 就是Mutex是排它的，只有一个可以获取到资源， Semaphore也具有排它性，但可以定义多个可以获取的资源的对象。 公平锁 &amp; 非公平锁公平锁的作用就是严格按照线程启动的顺序来执行的，不允许其他线程插队执行的；而非公平锁是允许插队的。 《公平锁与非公平锁》 默认情况下 ReentrantLock 和 synchronized 都是非公平锁。ReentrantLock 可以设置成公平锁。 悲观锁悲观锁如果使用不当（锁的条数过多），会引起服务大面积等待。推荐优先使用乐观锁+重试。 《【MySQL】悲观锁&amp;乐观锁》 乐观锁的方式：版本号+重试方式 悲观锁：通过 select … for update 进行行锁(不可读、不可写，share 锁可读不可写)。 《Mysql查询语句使用select.. for update导致的数据库死锁分析》 mysql的innodb存储引擎实务锁虽然是锁行，但它内部是锁索引的。 锁相同数据的不同索引条件可能会引起死锁。 《Mysql并发时经典常见的死锁原因及解决方法》 乐观锁 &amp; CAS 《乐观锁的一种实现方式——CAS》 和MySQL乐观锁方式相似，只不过是通过和原值进行比较。 ABA 问题由于高并发，在CAS下，更新后可能此A非彼A。通过版本号可以解决，类似于上文Mysql 中提到的的乐观锁。 《Java CAS 和ABA问题》 《Java 中 ABA问题及避免》 AtomicStampedReference 和 AtomicStampedReference。 CopyOnWrite容器可以对CopyOnWrite容器进行并发的读，而不需要加锁。CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，不适合需要数据强一致性的场景。 《JAVA中写时复制(Copy-On-Write)Map实现》 实现读写分离，读取发生在原始数据上，写入发生在副本上。 不用加锁，通过最终一致实现一致性。 《聊聊并发-Java中的Copy-On-Write容器》 RingBuffer 《线程安全的无锁RingBuffer的实现【一个读线程，一个写线程】》 可重入锁 &amp; 不可重入锁 《可重入锁和不可重入锁》 通过简单代码举例说明可重入锁和不可重入锁。 可重入锁指同一个线程可以再次获得之前已经获得的锁。 可重入锁可以用户避免死锁。 Java中的可重入锁：synchronized 和 java.util.concurrent.locks.ReentrantLock 《ReenTrantLock可重入锁（和synchronized的区别）总结》 synchronized 使用方便，编译器来加锁，是非公平锁。 ReenTrantLock 使用灵活，锁的公平性可以定制。 相同加锁场景下，推荐使用 synchronized。 互斥锁 &amp; 共享锁互斥锁：同时只能有一个线程获得锁。比如，ReentrantLock 是互斥锁，ReadWriteLock 中的写锁是互斥锁。共享锁：可以有多个线程同时或的锁。比如，Semaphore、CountDownLatch 是共享锁，ReadWriteLock 中的读锁是共享锁。 《ReadWriteLock场景应用》 死锁 《“死锁”四个必要条件的合理解释》 互斥、持有、不可剥夺、环形等待。 Java如何查看死锁？ JConsole 可以识别死锁。 java多线程系列：死锁及检测 jstack 可以显示死锁。 操作系统计算机原理 《操作系统基础知识——操作系统的原理，类型和结构》 CPU多级缓存典型的 CPU 有三级缓存，距离核心越近，速度越快，空间越小。L1 一般 32k，L2 一般 256k，L3 一般12M。内存速度需要200个 CPU 周期，CPU 缓存需要1个CPU周期。 《从Java视角理解CPU缓存和伪共享》 进程TODO 线程 《线程的生命周期及状态转换详解》 协程 《终结python协程—-从yield到actor模型的实现》 线程的调度是由操作系统负责，协程调度是程序自行负责 与线程相比，协程减少了无谓的操作系统切换. 实际上当遇到IO操作时做切换才更有意义，（因为IO操作不用占用CPU），如果没遇到IO操作，按照时间片切换. Linux 《Linux 命令大全》 设计模式设计模式的六大原则 《设计模式的六大原则》 开闭原则：对扩展开放,对修改关闭，多使用抽象类和接口。 里氏替换原则：基类可以被子类替换，使用抽象类继承,不使用具体类继承。 依赖倒转原则：要依赖于抽象,不要依赖于具体，针对接口编程,不针对实现编程。 接口隔离原则：使用多个隔离的接口,比使用单个接口好，建立最小的接口。 迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用，通过中间类建立联系。 合成复用原则：尽量使用合成/聚合,而不是使用继承。 23种常见设计模式 《设计模式》 《23种设计模式全解析》 应用场景 《细数JDK里的设计模式》 结构型模式： 适配器：用来把一个接口转化成另一个接口，如 java.util.Arrays#asList()。 桥接模式：这个模式将抽象和抽象操作的实现进行了解耦，这样使得抽象和实现可以独立地变化，如JDBC； 组合模式：使得客户端看来单个对象和对象的组合是同等的。换句话说，某个类型的方法同时也接受自身类型作为参数，如 Map.putAll，List.addAll、Set.addAll。 装饰者模式：动态的给一个对象附加额外的功能，这也是子类的一种替代方式，如 java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap。 享元模式：使用缓存来加速大量小对象的访问时间，如 valueOf(int)。 代理模式：代理模式是用一个简单的对象来代替一个复杂的或者创建耗时的对象，如 java.lang.reflect.Proxy 创建模式: 抽象工厂模式：抽象工厂模式提供了一个协议来生成一系列的相关或者独立的对象，而不用指定具体对象的类型，如 java.util.Calendar#getInstance()。 建造模式(Builder)：定义了一个新的类来构建另一个类的实例，以简化复杂对象的创建，如：java.lang.StringBuilder#append()。 工厂方法：就是 一个返* 回具体对象的方法，而不是多个，如 java.lang.Object#toString()、java.lang.Class#newInstance()。 原型模式：使得类的实例能够生成自身的拷贝、如：java.lang.Object#clone()。 单例模式：全局只有一个实例，如 java.lang.Runtime#getRuntime()。 行为模式： 责任链模式：通过把请求从一个对象传递到链条中下一个对象的方式，直到请求被处理完毕，以实现对象间的解耦。如 javax.servlet.Filter#doFilter()。 命令模式：将操作封装到对象内，以便存储，传递和返回，如：java.lang.Runnable。 解释器模式：定义了一个语言的语法，然后解析相应语法的语句，如，java.text.Format，java.text.Normalizer。 迭代器模式：提供一个一致的方法来顺序访问集合中的对象，如 java.util.Iterator。 中介者模式：通过使用一个中间对象来进行消息分发以及减少类之间的直接依赖，java.lang.reflect.Method#invoke()。 空对象模式：如 java.util.Collections#emptyList()。 观察者模式：它使得一个对象可以灵活的将消息发送给感兴趣的对象，如 java.util.EventListener。 模板方法模式：让子类可以重写方法的一部分，而不是整个重写，如 java.util.Collections#sort()。 《Spring-涉及到的设计模式汇总》 《Mybatis使用的设计模式》 单例模式 《单例模式的三种实现 以及各自的优缺点》 《单例模式－－反射－－防止序列化破坏单例模式》 使用枚举类型。 责任链模式TODO MVC 《MVC 模式》 模型(model)－视图(view)－控制器(controller) IOC 《理解 IOC》 《IOC 的理解与解释》 正向控制：传统通过new的方式。反向控制，通过容器注入对象。 作用：用于模块解耦。 DI：Dependency Injection，即依赖注入，只关心资源使用，不关心资源来源。 AOP 《轻松理解AOP(面向切面编程)》 《Spring AOP详解》 《Spring AOP的实现原理》 Spring AOP使用的动态代理，主要有两种方式：JDK动态代理和CGLIB动态代理。 《Spring AOP 实现原理与 CGLIB 应用》 Spring AOP 框架对 AOP 代理类的处理原则是：如果目标对象的实现类实现了接口，Spring AOP 将会采用 JDK 动态代理来生成 AOP 代理类；如果目标对象的实现类没有实现接口，Spring AOP 将会采用 CGLIB 来生成 AOP 代理类 UML 《UML教程》 微服务思想 《微服务架构设计》 《微服务架构技术栈选型手册》 康威定律 《微服务架构的理论基础 - 康威定律》 定律一：组织沟通方式会通过系统设计表达出来，就是说架构的布局和组织结构会有相似。 定律二：时间再多一件事情也不可能做的完美，但总有时间做完一件事情。一口气吃不成胖子，先搞定能搞定的。 定律三：线型系统和线型组织架构间有潜在的异质同态特性。种瓜得瓜，做独立自治的子系统减少沟通成本。 定律四：大的系统组织总是比小系统更倾向于分解。合久必分，分而治之。 《微服务架构核⼼20讲》 运维 &amp; 统计 &amp; 技术支持常规监控 《腾讯业务系统监控的修炼之路》 监控的方式：主动、被动、旁路(比如舆情监控) 监控类型： 基础监控、服务端监控、客户端监控、监控、用户端监控 监控的目标：全、块、准 核心指标：请求量、成功率、耗时 《开源还是商用？十大云运维监控工具横评》 Zabbix、Nagios、Ganglia、Zenoss、Open-falcon、监控宝、 360网站服务监控、阿里云监控、百度云观测、小蜜蜂网站监测等。 《监控报警系统搭建及二次开发经验》 命令行监控工具 《常用命令行监控工具》 top、sar、tsar、nload 《20个命令行工具监控 Linux 系统性能》 《JVM性能调优监控工具jps、jstack、jmap、jhat、jstat、hprof使用详解》 APMAPM — Application Performance Management 《Dapper，大规模分布式系统的跟踪系统》 CNCF OpenTracing，中文版 主要开源软件，按字母排序 Apache SkyWalking CAT CNCF jaeger Pinpoint Zipkin 《开源APM技术选型与实战》 主要基于 Google的Dapper（大规模分布式系统的跟踪系统） 思想。 统计分析 《流量统计的基础：埋点》 常用指标：访问与访客、停留时长、跳出率、退出率、转化率、参与度 《APP埋点常用的统计工具、埋点目标和埋点内容》 第三方统计：友盟、百度移动、魔方、App Annie、talking data、神策数据等。 《美团点评前端无痕埋点实践》 所谓无痕、即通过可视化工具配置采集节点，在前端自动解析配置并上报埋点数据，而非硬编码。 持续集成(CI/CD) 《持续集成是什么？》 《8个流行的持续集成工具》 Jenkins 《使用Jenkins进行持续集成》 环境分离开发、测试、生成环境分离。 《开发环境、生产环境、测试环境的基本理解和区》 自动化运维Ansible 《Ansible中文权威指南》 《Ansible基础配置和企业级项目实用案例》 puppet 《自动化运维工具——puppet详解》 chef 《Chef 的安装与使用》 测试TDD 理论 《深度解读 - TDD（测试驱动开发）》 基于测试用例编码功能代码，XP（Extreme Programming）的核心实践. 好处：一次关注一个点，降低思维负担；迎接需求变化或改善代码的设计；提前澄清需求；快速反馈； 单元测试 《Java单元测试之JUnit篇》 《JUnit 4 与 TestNG 对比》 TestNG 覆盖 JUnit 功能，适用于更复杂的场景。 《单元测试主要的测试功能点》 模块接口测试、局部数据结构测试、路径测试 、错误处理测试、边界条件测试 。 压力测试 《Apache ab 测试使用指南》 《大型网站压力测试及优化方案》 《10大主流压力/负载/性能测试工具推荐》 《真实流量压测工具 tcpcopy应用浅析》 《nGrinder 简易使用教程》 全链路压测 《京东618：升级全链路压测方案，打造军演机器人ForceBot》 《饿了么全链路压测的探索与实践》 《四大语言，八大框架｜滴滴全链路压测解决之道》 《全链路压测经验》 A/B 、灰度、蓝绿测试 《技术干货 | AB 测试和灰度发布探索及实践》 《nginx 根据IP 进行灰度发布》 《蓝绿部署、A/B 测试以及灰度发布》 虚拟化 《VPS的三种虚拟技术OpenVZ、Xen、KVM优缺点比较》 KVM 《KVM详解，太详细太深入了，经典》 《【图文】KVM 虚拟机安装详解》 Xen 《Xen虚拟化基本原理详解》 OpenVZ 《开源Linux容器 OpenVZ 快速上手指南》 容器技术Docker 《几张图帮你理解 docker 基本原理及快速入门》 《Docker 核心技术与实现原理》 《Docker 教程》 云技术OpenStack 《OpenStack构架知识梳理》 DevOps 《一分钟告诉你究竟DevOps是什么鬼？》 《DevOps详解》 文档管理 Confluence-收费文档管理系统 GitLab? Wiki 中间件Web ServerNginx 《Ngnix的基本学习-多进程和Apache的比较》 Nginx 通过异步非阻塞的事件处理机制实现高并发。Apache 每个请求独占一个线程，非常消耗系统资源。 事件驱动适合于IO密集型服务(Nginx)，多进程或线程适合于CPU密集型服务(Apache)，所以Nginx适合做反向代理，而非web服务器使用。 《nginx与Apache的对比以及优缺点》 nginx只适合静态和反向代理，不适合处理动态请求。 OpenResty 官方网站 《浅谈 OpenResty》 通过 Lua 模块可以在Nginx上进行开发。 Apache Httpd 官方网站 Tomcat架构原理 《TOMCAT原理详解及请求过程》 《Tomcat服务器原理详解》 《Tomcat 系统架构与设计模式,第 1 部分: 工作原理》 《四张图带你了解Tomcat系统架构》 《JBoss vs. Tomcat: Choosing A Java Application Server》 Tomcat 是轻量级的 Serverlet 容器，没有实现全部 JEE 特性（比如持久化和事务处理），但可以通过其他组件代替，比如Srping。 Jboss 实现全部了JEE特性，软件开源免费、文档收费。 调优方案 《Tomcat 调优方案》 启动NIO模式（或者APR）；调整线程池；禁用AJP连接器（Nginx+tomcat的架构，不需要AJP）； 《tomcat http协议与ajp协议》 《AJP与HTTP比较和分析》 AJP 协议（8009端口）用于降低和前端Server（如Apache，而且需要支持AJP协议）的连接数(前端)，通过长连接提高性能。 并发高时，AJP协议优于HTTP协议。 Jetty 《Jetty 的工作原理以及与 Tomcat 的比较》 《jetty和tomcat优势比较》 架构比较:Jetty的架构比Tomcat的更为简单。 性能比较：Jetty和Tomcat性能方面差异不大，Jetty默认采用NIO结束在处理I/O请求上更占优势，Tomcat默认采用BIO处理I/O请求，Tomcat适合处理少数非常繁忙的链接，处理静态资源时性能较差。 其他方面：Jetty的应用更加快速，修改简单，对新的Servlet规范的支持较好;Tomcat 对JEE和Servlet 支持更加全面。 缓存 《缓存失效策略（FIFO 、LRU、LFU三种算法的区别）》 本地缓存 《HashMap本地缓存》 《EhCache本地缓存》 堆内、堆外、磁盘三级缓存。 可按照缓存空间容量进行设置。 按照时间、次数等过期策略。 《Guava Cache》 简单轻量、无堆外、磁盘缓存。 《Nginx本地缓存》 《Pagespeed—懒人工具，服务器端加速》 客户端缓存 《浏览器端缓存》 主要是利用 Cache-Control 参数。 《H5 和移动端 WebView 缓存机制解析与实战》 服务端缓存Web缓存 nuster - nuster cache varnish - varnish cache squid - squid cache Memcached 《Memcached 教程》 《深入理解Memcached原理》 采用多路复用技术提高并发性。 slab分配算法： memcached给Slab分配内存空间，默认是1MB。分配给Slab之后 把slab的切分成大小相同的chunk，Chunk是用于缓存记录的内存空间，Chunk 的大小默认按照1.25倍的速度递增。好处是不会频繁申请内存，提高IO效率，坏处是会有一定的内存浪费。 《Memcached软件工作原理》 《Memcache技术分享：介绍、使用、存储、算法、优化、命中率》 《memcache 中 add 、 set 、replace 的区别》 区别在于当key存在还是不存在时，返回值是true和false的。 《memcached全面剖析》 Redis 《Redis 教程》 《redis底层原理》 使用 ziplist 存储链表，ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。 使用 skiplist(跳跃表)来存储有序集合对象、查找上先从高Level查起、时间复杂度和红黑树相当，实现容易，无锁、并发性好。 《Redis持久化方式》 RDB方式：定期备份快照，常用于灾难恢复。优点：通过fork出的进程进行备份，不影响主进程、RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。缺点：会丢数据。 AOF方式：保存操作日志方式。优点：恢复时数据丢失少，缺点：文件大，回复慢。 也可以两者结合使用。 《分布式缓存–序列3–原子操作与CAS乐观锁》 架构 《Redis单线程架构》 回收策略 《redis的回收策略》 Tair 官方网站 《Tair和Redis的对比》 特点：可以配置备份节点数目，通过异步同步到备份节点 一致性Hash算法。 架构：和Hadoop 的设计思想类似，有Configserver，DataServer，Configserver 通过心跳来检测，Configserver也有主备关系。 几种存储引擎: MDB，完全内存性，可以用来存储Session等数据。 Rdb（类似于Redis），轻量化，去除了aof之类的操作，支持Restfull操作 LDB（LevelDB存储引擎），持久化存储，LDB 作为rdb的持久化，google实现，比较高效，理论基础是LSM(Log-Structured-Merge Tree)算法，现在内存中修改数据，达到一定量时（和内存汇总的旧数据一同写入磁盘）再写入磁盘，存储更加高效，县比喻Hash算法。 Tair采用共享内存来存储数据，如果服务挂掉（非服务器），重启服务之后，数据亦然还在。 消息队列 《消息队列-推/拉模式学习 &amp; ActiveMQ及JMS学习》 RabbitMQ 消费者默认是推模式（也支持拉模式）。 Kafka 默认是拉模式。 Push方式：优点是可以尽可能快地将消息发送给消费者，缺点是如果消费者处理能力跟不上，消费者的缓冲区可能会溢出。 Pull方式：优点是消费端可以按处理能力进行拉去，缺点是会增加消息延迟。 《Kafka、RabbitMQ、RocketMQ等消息中间件的对比 —— 消息发送性能和区别》 消息总线消息总线相当于在消息队列之上做了一层封装，统一入口，统一管控、简化接入成本。 《消息总线VS消息队列》 消息的顺序 《如何保证消费者接收消息的顺序》 RabbitMQ支持事务，推拉模式都是支持、适合需要可靠性消息传输的场景。 《RabbitMQ的应用场景以及基本原理介绍》 《消息队列之 RabbitMQ》 《RabbitMQ之消息确认机制（事务+Confirm）》 RocketMQJava实现，推拉模式都是支持，吞吐量逊于Kafka。可以保证消息顺序。 《RocketMQ 实战之快速入门》 《RocketMQ 源码解析》 ActiveMQ纯Java实现，兼容JMS，可以内嵌于Java应用中。 《ActiveMQ消息队列介绍》 Kafka高吞吐量、采用拉模式。适合高IO场景，比如日志同步。 官方网站 《各消息队列对比，Kafka深度解析，众人推荐，精彩好文！》 《Kafka分区机制介绍与示例》 Redis 消息推送生产者、消费者模式完全是客户端行为，list 和 拉模式实现，阻塞等待采用 blpop 指令。 《Redis学习笔记之十：Redis用作消息队列》 ZeroMQ TODO 定时调度单机定时调度 《linux定时任务cron配置》 《Linux cron运行原理》 fork 进程 + sleep 轮询 《Quartz使用总结》 《Quartz源码解析 —- 触发器按时启动原理》 《quartz原理揭秘和源码解读》 定时调度在 QuartzSchedulerThread 代码中，while()无限循环，每次循环取出时间将到的trigger，触发对应的job，直到调度器线程被关闭。 分布式定时调度 《这些优秀的国产分布式任务调度系统，你用过几个？》 opencron、LTS、XXL-JOB、Elastic-Job、Uncode-Schedule、Antares 《Quartz任务调度的基本实现原理》 Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的 《Elastic-Job-Lite 源码解析》 《Elastic-Job-Cloud 源码解析》 RPC 《从零开始实现RPC框架 - RPC原理及实现》 核心角色：Server: 暴露服务的服务提供方、Client: 调用远程服务的服务消费方、Registry: 服务注册与发现的注册中心。 《分布式RPC框架性能大比拼 dubbo、motan、rpcx、gRPC、thrift的性能比较》 Dubbo 官方网站 dubbo实现原理简单介绍 SPITODO Thrift 官方网站 《Thrift RPC详解》 支持多语言，通过中间语言定义接口。 gRPC服务端可以认证加密，在外网环境下，可以保证数据安全。 官方网站 《你应该知道的RPC原理》 数据库中间件Sharding Jdbc 官网 日志系统日志搜集 《从零开始搭建一个ELKB日志收集系统》 《用ELK搭建简单的日志收集分析系统》 《日志收集系统-探究》 配置中心 Apollo - 携程开源的配置中心应用 Spring Boot 和 Spring Cloud 支持推、拉模式更新配置 支持多种语言 《基于zookeeper实现统一配置管理》 《 Spring Cloud Config 分布式配置中心使用教程》 servlet 3.0 异步特性可用于配置中心的客户端 《servlet3.0 新特性——异步处理》 API 网关主要职责：请求转发、安全认证、协议转换、容灾。 《API网关那些儿》 《谈API网关的背景、架构以及落地方案》 《使用Zuul构建API Gateway》 《Spring Cloud Gateway 源码解析》 《HTTP API网关选择之一Kong介绍》 网络协议OSI 七层协议 《OSI七层协议模型、TCP/IP四层模型学习笔记》 TCP/IP 《深入浅出 TCP/IP 协议》 《TCP协议中的三次握手和四次挥手》 HTTP 《http协议详解(超详细)》 HTTP2.0 《HTTP 2.0 原理详细分析》 《HTTP2.0的基本单位为二进制帧》 利用二进制帧负责传输。 多路复用。 HTTPS 《https原理通俗了解》 使用非对称加密协商加密算法 使用对称加密方式传输数据 使用第三方机构签发的证书，来加密公钥，用于公钥的安全传输、防止被中间人串改。 《八大免费SSL证书-给你的网站免费添加Https安全加密》 网络模型 《web优化必须了解的原理之I/o的五种模型和web的三种工作模式》 五种I/O模型：阻塞I/O，非阻塞I/O，I/O复用、事件(信号)驱动I/O、异步I/O，前四种I/O属于同步操作，I/O的第一阶段不同、第二阶段相同，最后的一种则属于异步操作。 三种 Web Server 工作方式：Prefork(多进程)、Worker方式(线程方式)、Event方式。 《select、poll、epoll之间的区别总结》 select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。 select 有打开文件描述符数量限制，默认1024（2048 for x64），100万并发，就要用1000个进程、切换开销大；poll采用链表结构，没有数量限制。 select，poll “醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，通过回调机制节省大量CPU时间；select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，而epoll只要一次拷贝。 poll会随着并发增加，性能逐渐下降，epoll采用红黑树结构，性能稳定，不会随着连接数增加而降低。 《select，poll，epoll比较 》 在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 《深入理解Java NIO》 NIO 是一种同步非阻塞的 IO 模型。同步是指线程不断轮询 IO 事件是否就绪，非阻塞是指线程在等待 IO 的时候，可以同时做其他任务 《BIO与NIO、AIO的区别》 《两种高效的服务器设计模型：Reactor和Proactor模型》 Epoll 《epoll使用详解（精髓）》 Java NIO 《深入理解Java NIO》 《Java NIO编写Socket服务器的一个例子》 kqueue 《kqueue用法简介》 连接和短连接 《TCP/IP系列——长连接与短连接的区别》 框架 《Netty原理剖析》 Reactor 模式介绍。 Netty 是 Reactor 模式的一种实现。 零拷贝（Zero-copy） 《对于 Netty ByteBuf 的零拷贝(Zero Copy) 的理解》 多个物理分离的buffer，通过逻辑上合并成为一个，从而避免了数据在内存之间的拷贝。 序列化(二进制协议)Hessian 《Hessian原理分析》Binary-RPC;不仅仅是序列化 Protobuf 《Protobuf协议的Java应用例子》Goolge出品、占用空间和效率完胜其他序列化类库，如Hessian；需要编写 .proto 文件。 《Protocol Buffers序列化协议及应用》 * 关于协议的解释；缺点：可读性差; 《简单的使用 protobuf 和 protostuff》 protostuff 的好处是不用写 .proto 文件，Java 对象直接就可以序列化。 数据库基础理论数据库设计的三大范式 《数据库的三大范式以及五大约束》 第一范式：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性； 第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情； 第三范式：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）； MySQL原理 《MySQL的InnoDB索引原理详解》 《MySQL存储引擎－－MyISAM与InnoDB区别》 两种类型最主要的差别就是Innodb 支持事务处理与外键和行级锁 《myisam和innodb索引实现的不同》 InnoDB 《一篇文章带你读懂Mysql和InnoDB》 优化 《MySQL36条军规》 《MYSQL性能优化的最佳20+条经验》 《SQL优化之道》 《mysql数据库死锁的产生原因及解决办法》 《导致索引失效的可能情况》 《 MYSQL分页limit速度太慢优化方法》 原则上就是缩小扫描范围。 索引聚集索引, 非聚集索引 《MySQL 聚集索引/非聚集索引简述》 《MyISAM和InnoDB的索引实现》 MyISAM 是非聚集，InnoDB 是聚集 复合索引 《复合索引的优点和注意事项》 自适应哈希索引(AHI) 《InnoDB存储引擎——自适应哈希索引》 explain 《MySQL 性能优化神器 Explain 使用分析》 NoSQLMongoDB MongoDB 教程 《Mongodb相对于关系型数据库的优缺点》 优点：弱一致性（最终一致），更能保证用户的访问速度；内置GridFS，支持大容量的存储；Schema-less 数据库，不用预先定义结构；内置Sharding；相比于其他NoSQL，第三方支持丰富；性能优越； 缺点：mongodb不支持事务操作；mongodb占用空间过大；MongoDB没有如MySQL那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方； Hbase 《简明 HBase 入门教程（开篇）》 《深入学习HBase架构原理》 《传统的行存储和（HBase）列存储的区别》 《Hbase与传统数据库的区别》 空数据不存储，节省空间，且适用于并发。 《HBase Rowkey设计》 rowkey 按照字典顺序排列，便于批量扫描。 通过散列可以避免热点。 搜索引擎搜索引擎原理 《倒排索引–搜索引擎入门》 Lucene 《Lucene入门简介》 Elasticsearch 《Elasticsearch学习，请先看这一篇！》 《Elasticsearch索引原理》 Solr 《 Apache Solr入门教程》 《elasticsearch与solr比较》 sphinx 《Sphinx 的介绍和原理探索》 性能性能优化方法论 《15天的性能优化工作，5方面的调优经验》 代码层面、业务层面、数据库层面、服务器层面、前端优化。 《系统性能优化的几个方面》 容量评估 《联网性能与容量评估的方法论和典型案例》 《互联网架构，如何进行容量设计？》 评估总访问量、评估平均访问量QPS、评估高峰QPS、评估系统、单机极限QPS CDN 网络 《CDN加速原理》 《国内有哪些比较好的 CDN？》 连接池 《主流Java数据库连接池比较与开发配置实战》 性能调优 《九大Java性能调试工具，必备至少一款》 大数据流式计算Storm 官方网站 《最详细的Storm入门教程》 Flink 《Flink之一 Flink基本原理介绍》 Kafka Stream 《Kafka Stream调研：一种轻量级流计算模式》 应用场景例如： 广告相关实时统计； 推荐系统用户画像标签实时更新； 线上服务健康状况实时监测； 实时榜单； 实时数据统计。 Hadoop 《用通俗易懂的话说下hadoop是什么,能做什么》 《史上最详细的Hadoop环境搭建》 HDFS 《【Hadoop学习】HDFS基本原理》 MapReduce 《用通俗易懂的大白话讲解Map/Reduce原理》 《 简单的map-reduce的java例子》 Yarn 《初步掌握Yarn的架构及原理》 Spark 《Spark(一): 基本架构及原理》 安全web 安全XSS 《xss攻击原理与解决方法》CSRF 《CSRF原理及防范》 SQL 注入 《SQL注入》 Hash Dos 《邪恶的JAVA HASH DOS攻击》 利用JsonObjet 上传大Json，JsonObject 底层使用HashMap；不同的数据产生相同的hash值，使得构建Hash速度变慢，耗尽CPU。 《一种高级的DoS攻击-Hash碰撞攻击》 《关于Hash Collision DoS漏洞：解析与解决方案》 脚本注入 《上传文件漏洞原理及防范》 漏洞扫描工具 《DVWA》 W3af OpenVAS详解 验证码 《验证码原理分析及实现》 《详解滑动验证码的实现原理》 滑动验证码是根据人在滑动滑块的响应时间，拖拽速度，时间，位置，轨迹，重试次数等来评估风险。 《淘宝滑动验证码研究》 DDoS 防范 《学习手册：DDoS的攻击方式及防御手段》 《免费DDoS攻击测试工具大合集》 用户隐私信息保护 用户密码非明文保存，加动态salt。 身份证号，手机号如果要显示，用 “*” 替代部分字符。 联系方式在的显示与否由用户自己控制。 TODO 《个人隐私包括哪些》 《在互联网上，隐私的范围包括哪些？》 《用户密码保存》 序列化漏洞 《Lib之过？Java反序列化漏洞通用利用分析》 加密解密对称加密 《常见对称加密算法》 DES、3DES、Blowfish、AES DES 采用 56位秘钥，Blowfish 采用1到448位变长秘钥，AES 128，192和256位长度的秘钥。 DES 秘钥太短（只有56位）算法目前已经被 AES 取代，并且 AES 有硬件加速，性能很好。 哈希算法 《常用的哈希算法》 MD5 和 SHA-1 已经不再安全，已被弃用。 目前 SHA-256 是比较安全的。 《基于Hash摘要签名的公网URL签名验证设计方案》 非对称加密 《常见非对称加密算法》 RSA、DSA、ECDSA(螺旋曲线加密算法) 和 RSA 不同的是 DSA 仅能用于数字签名，不能进行数据加密解密，其安全性和RSA相当，但其性能要比RSA快。 256位的ECC秘钥的安全性等同于3072位的RSA秘钥。 《区块链的加密技术》 服务器安全 《Linux强化论：15步打造一个安全的Linux服务器》 数据安全数据备份TODO 网络隔离内外网分离TODO 登录跳板机在内外环境中通过跳板机登录到线上主机。 《搭建简易堡垒机》 授权、认证RBAC 《基于组织角色的权限设计》 《权限系统与RBAC模型概述》 《Spring整合Shiro做权限控制模块详细案例分析》 OAuth2.0 《理解OAuth 2.0》 《一张图搞定OAuth2.0》 双因素认证（2FA）2FA - Two-factor authentication，用于加强登录验证 常用做法是 登录密码 + 手机验证码（或者令牌Key，类似于与网银的 USB key） 【《双因素认证（2FA）教程》】(http://www.ruanyifeng.com/blog/2017/11/2fa-tutorial.html) 单点登录(SSO) 《单点登录原理与简单实现》 CAS单点登录框架 常用开源框架开源协议 《开源协议的选择》 如何选择一个开源软件协议 日志框架Log4j、Log4j2 《log4j 详细讲解》 《log4j2 实际使用详解》 《Log4j1,Logback以及Log4j2性能测试对比》 Log4J 异步日志性能优异。 Logback 《最全LogBack 详解、含java案例和配置说明》 ORM 《ORM框架使用优缺点》 主要目的是为了提高开发效率。 MyBatis： 《mybatis缓存机制详解》 一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效 二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的；使用 LRU 机制清理缓存，通过 cacheEnabled 参数开启。 《MyBatis学习之代码生成器Generator》 网络框架TODO Web 框架Spring 家族Spring Spring 简明教程 Spring Boot 官方网站 《Spring Boot基础教程》 Spring Cloud Spring Boot 中文索引站 Spring Cloud 中文文档 《Spring Cloud基础教程》 工具框架 《Apache Commons 工具类介绍及简单使用》 《Google guava 中文教程》 分布式设计扩展性设计 《架构师不可不知的十大可扩展架构》 总结下来，通用的套路就是分布、缓存及异步处理。 《可扩展性设计之数据切分》 水平切分+垂直切分 利用中间件进行分片如，MySQL Proxy。 利用分片策略进行切分，如按照ID取模。 《说说如何实现可扩展性的大型网站架构》 分布式服务+消息队列。 《大型网站技术架构（七）–网站的可扩展性架构》 稳定性 &amp; 高可用 《系统设计：关于高可用系统的一些技术方案》 可扩展：水平扩展、垂直扩展。 通过冗余部署，避免单点故障。 隔离：避免单一业务占用全部资源。避免业务之间的相互影响 2. 机房隔离避免单点故障。 解耦：降低维护成本，降低耦合风险。减少依赖，减少相互间的影响。 限流：滑动窗口计数法、漏桶算法、令牌桶算法等算法。遇到突发流量时，保证系统稳定。 降级：紧急情况下释放非核心功能的资源。牺牲非核心业务，保证核心业务的高可用。 熔断：异常情况超出阈值进入熔断状态，快速失败。减少不稳定的外部依赖对核心服务的影响。 自动化测试：通过完善的测试，减少发布引起的故障。 灰度发布：灰度发布是速度与安全性作为妥协，能够有效减少发布故障。 《关于高可用的系统》 设计原则：数据不丢(持久化)；服务高可用(服务副本)；绝对的100%高可用很难，目标是做到尽可能多的9，如99.999%（全年累计只有5分钟）。 硬件负载均衡 《转！！负载均衡器技术Nginx和F5的优缺点对比》 主要是和F5对比。 《软/硬件负载均衡产品 你知多少？》 软件负载均衡 《几种负载均衡算法》 轮寻、权重、负载、最少连接、QoS 《DNS负载均衡》 配置简单，更新速度慢。 《Nginx负载均衡》 简单轻量、学习成本低；主要适用于web应用。 《借助LVS+Keepalived实现负载均衡 》 配置比较负载、只支持到4层，性能较高。 《HAProxy用法详解 全网最详细中文文档》 支持到七层（比如HTTP）、功能比较全面，性能也不错。 《Haproxy+Keepalived+MySQL实现读均衡负载》 主要是用户读请求的负载均衡。 《rabbitmq+haproxy+keepalived实现高可用集群搭建》 限流 《谈谈高并发系统的限流》 计数器：通过滑动窗口计数器，控制单位时间内的请求次数，简单粗暴。 漏桶算法：固定容量的漏桶，漏桶满了就丢弃请求，比较常用。 令牌桶算法：固定容量的令牌桶，按照一定速率添加令牌，处理请求前需要拿到令牌，拿不到令牌则丢弃请求，或进入丢队列，可以通过控制添加令牌的速率，来控制整体速度。Guava 中的 RateLimiter 是令牌桶的实现。 Nginx 限流：通过 limit_req 等模块限制并发连接数。 应用层容灾 《防雪崩利器：熔断器 Hystrix 的原理与使用》 雪崩效应原因：硬件故障、硬件故障、程序Bug、重试加大流量、用户大量请求。 雪崩的对策：限流、改进缓存模式(缓存预加载、同步调用改异步)、自动扩容、降级。 Hystrix设计原则： 资源隔离：Hystrix通过将每个依赖服务分配独立的线程池进行资源隔离, 从而避免服务雪崩。 熔断开关：服务的健康状况 = 请求失败数 / 请求总数，通过阈值设定和滑动窗口控制开关。 命令模式：通过继承 HystrixCommand 来包装服务调用逻辑。 《缓存穿透，缓存击穿，缓存雪崩解决方案分析》 《缓存击穿、失效以及热点key问题》 主要策略：失效瞬间：单机使用锁；使用分布式锁；不过期； 热点数据：热点数据单独存储；使用本地缓存；分成多个子key； 跨机房容灾 《“异地多活”多机房部署经验谈》 通过自研中间件进行数据同步。 《异地多活（异地双活）实践经验》 注意延迟问题，多次跨机房调用会将延时放大数倍。 建房间专线很大概率会出现问题，做好运维和程序层面的容错。 不能依赖于程序端数据双写，要有自动同步方案。 数据永不在高延迟和较差网络质量下，考虑同步质量问题。 核心业务和次要业务分而治之，甚至只考虑核心业务。 异地多活监控部署、测试也要跟上。 业务允许的情况下考虑用户分区，尤其是游戏、邮箱业务。 控制跨机房消息体大小，越小越好。 考虑使用docker容器虚拟化技术，提高动态调度能力。 容灾技术及建设经验介绍 容灾演练流程 《依赖治理、灰度发布、故障演练，阿里电商故障演练系统的设计与实战经验》 常见故障画像 案例：预案有效性、预案有效性、故障复现、架构容灾测试、参数调优、参数调优、故障突袭、联合演练。 平滑启动 平滑重启应用思路1.端流量（如vip层）、2. flush 数据(如果有)、3, 重启应用 《JVM安全退出（如何优雅的关闭java服务）》推荐推出方式：System.exit，Kill SIGTERM；不推荐 kill-9；用 Runtime.addShutdownHook 注册钩子。 《常见Java应用如何优雅关闭》Java、Srping、Dubbo 优雅关闭方式。 数据库扩展读写分离模式 《Mysql主从方案的实现》 《搭建MySQL主从复制经典架构》 《Haproxy+多台MySQL从服务器(Slave) 实现负载均衡》 《DRBD+Heartbeat+Mysql高可用读写分离架构》 DRDB 进行磁盘复制，避免单点问题。 《MySQL Cluster 方式》 分片模式 《分库分表需要考虑的问题及方案》 中间件： 轻量级：sharding-jdbc、TSharding；重量级：Atlas、MyCAT、Vitess等。 问题：事务、Join、迁移、扩容、ID、分页等。 事务补偿：对数据进行对帐检查;基于日志进行比对;定期同标准数据来源进行同步等。 分库策略：数值范围；取模；日期等。 分库数量：通常 MySQL 单库 5千万条、Oracle 单库一亿条需要分库。 《MySql分表和表分区详解》 分区：是MySQL内部机制，对客户端透明，数据存储在不同文件中，表面上看是同一个表。 分表：物理上创建不同的表、客户端需要管理分表路由。 服务治理服务注册与发现 《永不失联！如何实现微服务架构中的服务发现？》 客户端服务发现模式：客户端直接查询注册表，同时自己负责负载均衡。Eureka 采用这种方式。 服务器端服务发现模式：客户端通过负载均衡查询服务实例。 《SpringCloud服务注册中心比较:Consul vs Zookeeper vs Etcd vs Eureka》 CAP支持：Consul（CA）、zookeeper（cp）、etcd（cp） 、euerka（ap） 作者认为目前 Consul 对 Spring cloud 的支持比较好。 《基于Zookeeper的服务注册与发现》 优点：API简单、Pinterest，Airbnb 在用、多语言、通过watcher机制来实现配置PUSH，能快速响应配置变化。 服务路由控制 《分布式服务框架学习笔记4 服务路由》 原则：透明化路由 负载均衡策略：随机、轮询、服务调用延迟、一致性哈希、粘滞连接 本地路由有限策略：injvm(优先调用jvm内部的服务)，innative(优先使用相同物理机的服务),原则上找距离最近的服务。 配置方式：统一注册表；本地配置；动态下发。 分布式一致CAP 与 BASE 理论 《从分布式一致性谈到CAP理论、BASE理论》 一致性分类：强一致(立即一致)；弱一致(可在单位时间内实现一致，比如秒级)；最终一致(弱一致的一种，一定时间内最终一致) CAP：一致性、可用性、分区容错性(网络故障引起) BASE：Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性） BASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 分布式锁 《分布式锁的几种实现方式》 基于数据库的分布式锁：优点：操作简单、容易理解。缺点：存在单点问题、数据库性能够开销较大、不可重入； 基于缓存的分布式锁：优点：非阻塞、性能好。缺点：操作不好容易造成锁无法释放的情况。 Zookeeper 分布式锁：通过有序临时节点实现锁机制，自己对应的节点需要最小，则被认为是获得了锁。优点：集群可以透明解决单点问题，避免锁不被释放问题，同时锁可以重入。缺点：性能不如缓存方式，吞吐量会随着zk集群规模变大而下降。 《基于Zookeeper的分布式锁》 清楚的原理描述 + Java 代码示例。 《jedisLock—redis分布式锁实现》 基于 setnx(set if ont exists)，有则返回false，否则返回true。并支持过期时间。 《Memcached 和 Redis 分布式锁方案》 利用 memcached 的 add（有别于set）操作，当key存在时，返回false。 分布式一致性算法PAXOS 《分布式系列文章——Paxos算法原理与推导》 《Paxos–&gt;Fast Paxos–&gt;Zookeeper分析》 《【分布式】Zookeeper与Paxos》 Zab 《Zab：Zookeeper 中的分布式一致性协议介绍》 Raft 《Raft 为什么是更易理解的分布式一致性算法》 三种角色：Leader（领袖）、Follower（群众）、Candidate（候选人） 通过随机等待的方式发出投票，得票多的获胜。 Gossip 《Gossip算法》 两阶段提交、多阶段提交 《关于分布式事务、两阶段提交协议、三阶提交协议》 幂等 《分布式系统—幂等性设计》 幂等特性的作用：该资源具备幂等性，请求方无需担心重复调用会产生错误。 常见保证幂等的手段：MVCC（类似于乐观锁）、去重表(唯一索引)、悲观锁、一次性token、序列号方式。 分布式一致方案 《分布式系统事务一致性解决方案》 《保证分布式系统数据一致性的6种方案》 分布式 Leader 节点选举 《利用zookeeper实现分布式leader节点选举》 TCC(Try/Confirm/Cancel) 柔性事务 《传统事务与柔性事务》 基于BASE理论：基本可用、柔性状态、最终一致。 解决方案：记录日志+补偿（正向补充或者回滚）、消息重试(要求程序要幂等)；“无锁设计”、采用乐观锁机制。 分布式文件系统 说说分布式文件存储系统-基本架构 ？ 《各种分布式文件系统的比较》 ？ HDFS：大批量数据读写，用于高吞吐量的场景，不适合小文件。 FastDFS：轻量级、适合小文件。 唯一ID 生成全局唯一ID 《高并发分布式系统中生成全局唯一Id汇总》 Twitter 方案（Snowflake 算法）：41位时间戳+10位机器标识（比如IP，服务器名称等）+12位序列号(本地计数器) Flicker 方案：MySQL自增ID + “REPLACE INTO XXX:SELECT LAST_INSERT_ID();” UUID：缺点，无序，字符串过长，占用空间，影响检索性能。 MongoDB 方案：利用 ObjectId。缺点：不能自增。 《TDDL 在分布式下的SEQUENCE原理》 在数据库中创建 sequence 表，用于记录，当前已被占用的id最大值。 每台客户端主机取一个id区间（比如 1000~2000）缓存在本地，并更新 sequence 表中的id最大值记录。 客户端主机之间取不同的id区间，用完再取，使用乐观锁机制控制并发。 一致性Hash算法 《一致性哈希算法》 设计思想 &amp; 开发模式DDD(Domain-driven Design - 领域驱动设计) 《浅谈我对DDD领域驱动设计的理解》 概念：DDD 主要对传统软件开发流程(分析-设计-编码)中各阶段的割裂问题而提出，避免由于一开始分析不明或在软件开发过程中的信息流转不一致而造成软件无法交付（和需求方设想不一致）的问题。DDD 强调一切以领域（Domain）为中心，强调领域专家（Domain Expert）的作用，强调先定义好领域模型之后在进行开发，并且领域模型可以指导开发（所谓的驱动）。 过程：理解领域、拆分领域、细化领域，模型的准确性取决于模型的理解深度。 设计：DDD 中提出了建模工具，比如聚合、实体、值对象、工厂、仓储、领域服务、领域事件来帮助领域建模。 《领域驱动设计的基础知识总结》 领域（Doamin）本质上就是问题域，比如一个电商系统，一个论坛系统等。 界限上下文（Bounded Context）：阐述子域之间的关系，可以简单理解成一个子系统或组件模块。 领域模型（Domain Model）：DDD的核心是建立（用通用描述语言、工具—领域通用语言）正确的领域模型；反应业务需求的本质，包括实体和过程；其贯穿软件分析、设计、开发 的整个过程；常用表达领域模型的方式：图、代码或文字； 领域通用语言：领域专家、开发设计人员都能立即的语言或工具。 经典分层架构：用户界面/展示层、应用层、领域层、基础设施层，是四层架构模式。 使用的模式： 关联尽量少，尽量单项，尽量降低整体复杂度。 实体（Entity）：领域中的唯一标示，一个实体的属性尽量少，少则清晰。 值对象（Value Object）：没有唯一标识，且属性值不可变，小二简单的对象，比如Date。 领域服务（Domain Service）： 协调多个领域对象，只有方法没有状态(不存数据)；可以分为应用层服务，领域层服务、基础层服务。 聚合及聚合根（Aggregate，Aggregate Root）：聚合定义了一组具有内聚关系的相关对象的集合；聚合根是对聚合引用的唯一元素；当修改一个聚合时，必须在事务级别；大部分领域模型中，有70%的聚合通常只有一个实体，30%只有2~3个实体；如果一个聚合只有一个实体，那么这个实体就是聚合根；如果有多个实体，那么我们可以思考聚合内哪个对象有独立存在的意义并且可以和外部直接进行交互； 工厂（Factory）：类似于设计模式中的工厂模式。 仓储（Repository）：持久化到DB，管理对象，且只对聚合设计仓储。 《领域驱动设计(DDD)实现之路》 聚合：比如一辆汽车（Car）包含了引擎（Engine）、车轮（Wheel）和油箱（Tank）等组件，缺一不可。 《领域驱动设计系列（2）浅析VO、DTO、DO、PO的概念、区别和用处》 命令查询职责分离(CQRS)CQRS — Command Query Responsibility Seperation 《领域驱动设计系列 (六)：CQRS》 核心思想：读写分离（查询和更新在不同的方法中），不同的流程只是不同的设计方式，CQ代码分离，分布式环境中会有明显体现（有冗余数据的情况下），目的是为了高性能。 《DDD CQRS架构和传统架构的优缺点比较》 最终一致的设计理念；依赖于高可用消息中间件。 《CQRS架构简介》 一个实现 CQRS 的抽象案例。 《深度长文：我对CQRS/EventSourcing架构的思考》 CQRS 模式分析 + 12306 抢票案例 贫血，充血模型 《贫血，充血模型的解释以及一些经验》 失血模型：老子和儿子分别定义，相互不知道，二者实体定义中完全没有业务逻辑，通过外部Service进行关联。 贫血模型：老子知道儿子，儿子也知道老子；部分业务逻辑放到实体中；优点：各层单项依赖，结构清楚，易于维护；缺点：不符合OO思想，相比于充血模式，Service层较为厚重； 充血模型：和贫血模型类似，区别在于如何划分业务逻辑。优点：Service层比较薄，只充当Facade的角色，不和DAO打交道、复合OO思想；缺点：非单项依赖，DO和DAO之间双向依赖、和Service层的逻辑划分容易造成混乱。 肿胀模式：是一种极端情况，取消Service层、全部业务逻辑放在DO中；优点：符合OO思想、简化了分层；缺点：暴露信息过多、很多非DO逻辑也会强行并入DO。这种模式应该避免。 作者主张使用贫血模式。 Actor 模式TODO 响应式编程ReactorTODO RxJavaTODO Vert.xTODO DODAF2.0 《DODAF2.0方法论》 《DODAF2.0之能力视角如何落地》 Serverless无需过多关系服务器的服务架构理念。 《什么是Serverless无服务器架构？》 Serverless 不代表出去服务器，而是去除对服务器运行状态的关心。 Serverless 代表一思维方式的转变，从“构建一套服务在一台服务器上，对对个事件进行响应转变为构建一个为服务器，来响应一个事件”。 Serverless 不代表某个具体的框架。 《如何理解Serverless？》 依赖于 Baas （(Mobile) Backend as a Service） 和 Faas （Functions as a service） Service Mesh 《什么是Service Mesh？》 《初识 Service Mesh》 《什么是Service Mesh？》 项目管理架构评审 《架构设计之如何评审架构设计说明书》 《人人都是架构师：非功能性需求》 重构 《架构之重构的12条军规》 代码规范 《阿里巴巴Java开发手册》 代码 Review制度还是制度!另外，每个公司需要根据自己的需求和目标制定自己的 check list 《为什么你做不好 Code Review？》 代码 review 做的好，在于制度建设。 《从零开始Code Review》 《Code Review Checklist》 《Java Code Review Checklist》 《如何用 gitlab 做 code review》 RUP 《运用RUP 4+1视图方法进行软件架构设计》 看板管理 《说说看板在项目中的应用》 SCRUMSCRUM - 争球 3个角色:Product Owner(PO) 产品负责人;Scrum Master（SM），推动Scrum执行;Team 开发团队。 3个工件：Product Backlog 产品TODOLIST，含优先级;Sprint Backlog 功能开发 TODO LIST；燃尽图； 五个价值观：专注、勇气、公开、承诺、尊重。 《敏捷项目管理流程-Scrum框架最全总结！》 《敏捷其实很简单3—敏捷方法之scrum》 敏捷开发TODO 极限编程（XP）XP - eXtreme Programming 《主流敏捷开发方法：极限编程XP》 是一种指导开发人员的方法论。 4大价值： 沟通：鼓励口头沟通，提高效率。 简单：够用就好。 反馈：及时反馈、通知相关人。 勇气：提倡拥抱变化，敢于重构。 5个原则：快速反馈、简单性假设、逐步修改、提倡更改（小步快跑）、优质工作（保证质量的前提下保证小步快跑）。 5个工作：阶段性冲刺；冲刺计划会议；每日站立会议；冲刺后review；回顾会议。 结对编程边写码，边review。能够增强代码质量、减少bug。 《结对编程》 PDCA 循环质量管理P——PLAN 策划，D——DO 实施，C——CHECK 检查，A——ACT 改进 《PDCA》 FMEA管理模式TODO 通用业务术语TODO 技术趋势TODO 政策、法规TODO 法律严格遵守刑法253法条我国刑法第253条之一规定： 国家机关或者金融、电信、交通、教育、医疗等单位的工作人员，违反国家规定，将本单位在履行职责或者提供服务过程中获得的公民个人信息，出售或者非法提供给他人，情节严重的，处3年以下有期徒刑或者拘役，并处或者单处罚金。 窃取或者以其他方法非法获取上述信息，情节严重的，依照前款的规定处罚。 单位犯前两款罪的，对单位判处罚金，并对其直接负责的主管人员和其他直接责任人员，依照各该款的规定处罚。 最高人民法院、最高人民检察院关于执行《中华人民共和国刑法》确定罪名的补充规定（四）规定：触犯刑法第253条之一第1款之规定，构成“出售、非法提供公民个人信息罪”；触犯刑法第253条之一第2款之规定，构成“非法获取公民个人信息罪” 《非法获取公民个人信息罪》 架构师素质 《架构师画像》 业务理解和抽象能力 NB的代码能力 全面：1. 在面对业务问题上，架构师脑海里是否会浮现出多种技术方案；2. 在做系统设计时是否考虑到了足够多的方方面面；3. 在做系统设计时是否考虑到了足够多的方方面面； 全局：是否考虑到了对上下游的系统的影响。 权衡：权衡投入产出比；优先级和节奏控制； 《关于架构优化和设计，架构师必须知道的事情》 要去考虑的细节：模块化、轻耦合、无共享架构；减少各个组件之前的依赖、注意服务之间依赖所有造成的链式失败及影响等。 基础设施、配置、测试、开发、运维综合考虑。 考虑人、团队、和组织的影响。 《如何才能真正的提高自己，成为一名出色的架构师？》 《架构师的必备素质和成长途径》 素质：业务理解、技术广度、技术深度、丰富经验、沟通能力、动手能力、美学素养。 成长路径：2年积累知识、4年积累技能和组内影响力、7年积累部门内影响力、7年以上积累跨部门影响力。 《架构设计师—你在哪层楼？》 第一层的架构师看到的只是产品本身 第二层的架构师不仅看到自己的产品，还看到了整体的方案 第三层的架构师看到的是商业价值 团队管理TODO 招聘资讯行业资讯 36kr Techweb 公众号列表TODO 博客团队博客 阿里中间件博客 美团点评技术团队博客 个人博客 阮一峰的网络日志 酷壳 - COOLSHELL-陈皓 hellojava-阿里毕玄 Cm’s Blog 程序猿DD-翟永超-《Spring Cloud微服务实战》作者 综合门户、社区国内： CSDN 老牌技术社区、不必解释。 51cto.com ITeye 偏 Java 方向 博客园 ChinaUnix 偏 Linux 方向 开源中国社区 深度开源 伯乐在线 涵盖 IT职场、Web前端、后端、移动端、数据库等方面内容，偏技术端。 ITPUB 腾讯云— 云+社区 阿里云— 云栖社区 IBM DeveloperWorks 开发者头条 LinkedKeeper 国外： DZone Reddit 问答、讨论类社区 segmentfault 问答+专栏 知乎 stackoverflow 行业数据分析 艾瑞网 QUEST MOBILE 国家数据 TalkingData 专项网站 测试: 领测国际 测试窝 TesterHome 运维: * [运维派](http://www.yunweipai.com/) * [Abcdocker](https://www.abcdocker.com/) Java: ImportNew 专注于 Java 技术分享 HowToDoInJava 英文博客 安全 红黑联盟 FreeBuf 大数据 中国大数据 其他专题网站： DockerInfo 专注于 Docker 应用及咨询、教程的网站。 Linux公社 Linux 主题社区 其他类 程序员技能图谱 推荐参考书在线电子书 《深入理解Spring Cloud与微服务构建》 《阿里技术参考图册-研发篇》 《阿里技术参考图册-算法篇》 《2018美团点评技术年货（合辑）》70M InfoQ《架构师》月刊 《架构师之路》 纸质书开发方面 《阿里巴巴Java开发手册》京东 淘宝 架构方面 《软件架构师的12项修炼：技术技能篇》京东 淘宝 《架构之美》京东 淘宝 《分布式服务架构》京东 淘宝 《聊聊架构》 京东 淘宝 《云原生应用架构实践》京东 淘宝 《亿级流量网站架构核心技术》京东 淘宝 《淘宝技术这十年》京东 淘宝 《企业IT架构转型之道-中台战略思想与架构实战》 京东 淘宝 《高可用架构（第1卷）》京东 淘宝 技术管理方面 《CTO说》京东 淘宝 《技术管理之巅》京东 淘宝 《网易一千零一夜：互联网产品项目管理实战》京东 淘宝 基础理论 《数学之美》京东 淘宝 《编程珠玑》京东 淘宝 工具方面TODO 大数据方面技术资源开源资源 github Apache 软件基金会 手册、文档、教程国内： W3Cschool Runoob.com HTML 、 CSS、XML、Java、Python、PHP、设计模式等入门手册。 Love2.io 很多很多中文在线电子书，是一个全新的开源技术文档分享平台。 gitbook.cn 付费电子书。 ApacheCN AI、大数据方面系列中文文档。 国外： Quick Code 免费在线技术教程。 gitbook.com 有部分中文电子书。 Cheatography Cheat Sheets 大全，单页文档网站。 Tutorialspoint 知名教程网站，提供Java、Python、JS、SQL、大数据等高质量入门教程。 在线课堂 学徒无忧 极客时间 segmentfault 斯达克学院 牛客网 极客学院 51CTO学院 会议、活动 QCon ArchSummit GITC全球互联网技术大会 活动发布平台: 活动行 常用APP 极客时间 得到 找工作 Boss直聘 拉勾网 猎聘 100Offer 工具 极客搜索 技术文章搜索引擎。 代码托管 Coding 码云 文件服务 七牛 又拍云 综合云服务商 阿里云 腾讯云 百度云 新浪云 金山云 亚马逊云(AWS) 谷歌云 微软云","categories":[{"name":"技术知识图谱","slug":"技术知识图谱","permalink":"https://ostenant.coding.me/categories/技术知识图谱/"}],"tags":[]},{"title":"实战Spring Boot 2.0 Reactive编程系列(一) - WebFlux初体验","slug":"实战Spring Boot 2.0 Reactive编程系列(一) - WebFlux初体验","date":"2018-05-27T07:25:00.000Z","updated":"2018-05-28T08:20:00.333Z","comments":true,"path":"2018/05/27/实战Spring Boot 2.0 Reactive编程系列(一) - WebFlux初体验/","link":"","permalink":"https://ostenant.coding.me/2018/05/27/实战Spring Boot 2.0 Reactive编程系列(一) - WebFlux初体验/","excerpt":"前言上文引入了 反应式编程模型 相关概念，对 \bSpring Reactor \b的核心 API 进行了简单归纳。本文会对 Spring 5 WebFlux 进行相关介绍，\b包括引入 Servlet 3.1 +，各个功能组件 Router Functions、WebFlux 和 Reactive Streams 等，\b以及如何在 Spring Boot 2.0 中分别以 全局功能路由 和 MVC 控制器 的方式配置 HTTP 请求处理。","text":"前言上文引入了 反应式编程模型 相关概念，对 \bSpring Reactor \b的核心 API 进行了简单归纳。本文会对 Spring 5 WebFlux 进行相关介绍，\b包括引入 Servlet 3.1 +，各个功能组件 Router Functions、WebFlux 和 Reactive Streams 等，\b以及如何在 Spring Boot 2.0 中分别以 全局功能路由 和 MVC 控制器 的方式配置 HTTP 请求处理。 正文Spring 5 WebFlux介绍关于 Spring 5 的 WebFlux \b响应式编程，下图是传统 Spring Web MVC 结构以及Spring 5 中新增加的基于 Reactive Streams 的 Spring WebFlux 框架。可以使用 webFlux 模块来构建 异步的、非堵塞的、事件驱动 的服务，其在 伸缩性方面 表现非常好。 如图所示，WebFlux 模块从上到下依次是 Router Functions、WebFlux、Reactive Streams 三个新组件。 Servlet 3.1+ API介绍WebFlux 模块需要运行在实现了 Servlet 3.1+ 规范 的容器之上。Servlet 3.1 规范中新增了对 异步处理 的支持，在新的 Servlet 规范中，Servlet 线程不需要一直 阻塞等待 到业务处理完成。 在 Servlet 3.1 中，其请求处理的线程模型大致如下： Servlet 线程接收到新的请求后，不需要等待业务处理完成再进行结果输出，而是将这个请求委托给另外一个线程（业务线程）来完成。 Servlet 线程将委托完成之后变返回到容器中去接收新的请求。 Servlet 3.1 规范特别适用于那种 业务处理非常耗时 的场景之下，可以减少 服务器资源 的占用，并且提高 并发处理速度 ，而对于那些能 快速响应 的场景收益并不大。 所以 WebFlux 支持的容器有 Tomcat、Jetty 等 同步容器 ，也可以是 Netty 和 Undertow 这类 异步容器。在容器中 Spring WebFlux 会将 输入流 适配成 Mono 或 Flux 格式进行统一处理。 Spring WebFlux的功能模块下面介绍上图中 WebFlux 各个模块： 1. Router Functions对标准的 @Controller，@RequestMapping等的 Spring MVC 注解，提供一套 函数式风格 的 API，用于创建 Router、Handler 和Filter。 2. WebFlux核心组件，协调上下游各个组件提供 响应式编程 支持。 3. Reactive Streams一种支持 背压 (Backpressure) 的 异步数据流处理标准，主流实现有 RxJava 和 Reactor，Spring WebFlux 集成的是Reactor。 FluxFlux 和 Mono 属于 事件发布者，类似于 生产者，对消费者 提供订阅接口。当有事件发生的时候，Flux 或 Mono 会回调 消费者相应的方法来通知 消费者 相应的事件。 下面这张图是 Flux 的工作流程图： 关于 Flux 的工作模式，可以看出 Flux 可以 触发 (emit) 很多 item，而这些 item 可以经过若干 Operators 然后才被 subscribe，下面是使用 Flux 的一个例子： 12345678Flux.fromIterable(getSomeLongList()) .mergeWith(Flux.interval(100)) .doOnNext(serviceA::someObserver) .map(d -&gt; d * 2) .take(3) .onErrorResumeWith(errorHandler::fallback) .doAfterTerminate(serviceM::incrementTerminate) .subscribe(System.out::println); Mono下面的图片是 Mono 的处理流程，可以很直观的看出来 Mono 和 Flux 的区别： Mono 只能触发 (emit) 一个 item，下面是使用 Mono 的一个例子： 12345Mono.fromCallable(System::currentTimeMillis) .flatMap(time -&gt; Mono.first(serviceA.findRecent(time), serviceB.findRecent(time))) .timeout(Duration.ofSeconds(3), errorHandler::fallback) .doOnSuccess(r -&gt; serviceM.incrementSuccess()) .subscribe(System.out::println); \bSpring Boot 2.0 Reactive StackSpring Boot Webflux 就是基于 Reactor 实现的。Spring Boot 2.0 包括一个新的 spring-webflux 模块。该模块包含对 响应式 HTTP 和 WebSocket 客户端的支持，以及对 REST 、HTML 和 WebSocket 交互等程序 的支持。一般来说，Spring MVC 用于 同步处理，Spring Webflux 用于 异步处理。 如上图所示，从 Web 表现层到数据访问，再到容器，Spring Boot 2.0 同时提供了 同步阻塞式 和 异步非阻塞式 \b两套完整的 API Stack。 从上而下对比以下两者的区别: API Stack Sevlet Stack Reactive Stack \bWeb控制层 Spring MVC Spring WebFlux \b安全认证层 Spring Security Spring Security 数据访问层 Spring Data Repositories Spring Data Reactive Repositories 容器API Servlet API Reactive Streams Adapters 内嵌容器 Servlet Containers Netty, Servlet 3.1+ Containers 适用场景控制层一旦使用 Spring WebFlux，\b它下面的安全认证层、数据访问层都必须使用 Reactive API。其次，Spring Data Reactive Repositories 目前只支持 MongoDB、Redis 和 Couchbase 等几种不支持\b事务管理的 NOSQL。技术选型时一定要权衡这些弊端和风险\b，比如： Spring MVC 能满足场景的，就不需要更改为 Spring WebFlux。 要注意容器的支持，可以看看底层 内嵌容器 的支持。 微服务 体系结构，Spring WebFlux 和 Spring MVC 可以混合使用。尤其开发 IO 密集型 服务的时候，可以选择 Spring WebFlux 去实现。 编程模型Spring 5 Web 模块包含了 Spring WebFlux 的 HTTP 抽象。类似 Servlet API\b， WebFlux 提供了 WebHandler API 去定义 非阻塞 API 抽象接口。可以选择以下两种编程模型实现： 注解控制层: 和 MVC 保持一致，WebFlux 也支持 响应性 @RequestBody 注解。 功能性端点: 基于 lambda 轻量级编程模型，用来 建立路由 和 处理请求 的工具。和上面最大的区别就是，这种模型，全程 控制了 请求 - 响应 的生命流程 内嵌容器跟 Spring Boot 大框架一样启动应用，但 Spring WebFlux 默认是通过 Netty 启动，并且自动设置了 默认端口 为 8080。另外还提供了对 Jetty、Undertow 等容器的支持。开发者自行在添加对应的容器 Starter 组件依赖，即可配置并使用对应 内嵌容器实例。 注意: 必须是 Servlet 3.1+ 容器，如 Tomcat、Jetty；或者非 Servlet 容器，如 Netty 和 Undertow。 Starter 组件跟 Spring Boot 大框架一样，Spring Boot Webflux 提供了很多 开箱即用 的 Starter 组件。添加 spring-boot-starter-webflux 依赖，就可用于构建 响应式 API 服务，其包含了 WebFlux 和 Tomcat 内嵌容器 等。 快速开始Spring Initializr构建项目骨架利用 Spring Initializer 快速生成 Spring Boot 应用，配置\b项目信息并设置依赖。 配置Maven依赖12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; Spring Boot启动类123456@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 配置实体类1234567@Data@Builder@AllArgsConstructor@NoArgsConstructorpublic class Message &#123; String body;&#125; 1. MVC控制器方式1.1. 编写控制器1234567891011@RestController@RequestMappingpublic class MessageController &#123; @GetMapping public Flux&lt;Message&gt; allMessages()&#123; return Flux.just( Message.builder().body(\"hello Spring 5\").build(), Message.builder().body(\"hello Spring Boot 2\").build() ); &#125; &#125; 1.2. 编写\b测试类1234567891011@RunWith(SpringRunner.class)@WebFluxTest(controllers = MessageController.class)public class DemoApplicationTests &#123; @Autowired WebTestClient client; @Test public void getAllMessagesShouldBeOk() &#123; client.get().uri(\"/\").exchange().expectStatus().isOk(); &#125;&#125; 1.3. 查看启动日志12342018-05-27 17:37:23.550 INFO 67749 --- [ main] s.w.r.r.m.a.RequestMappingHandlerMapping : Mapped \"&#123;[],methods=[GET]&#125;\" onto reactor.core.publisher.Flux&lt;com.example.demo.Message&gt; com.example.demo.MessageController.allMessages()2018-05-27 17:37:23.998 INFO 67749 --- [ctor-http-nio-1] r.ipc.netty.tcp.BlockingNettyContext : Started HttpServer on /0:0:0:0:0:0:0:0:80802018-05-27 17:37:23.999 INFO 67749 --- [ main] o.s.b.web.embedded.netty.NettyWebServer : Netty started on port(s): 80802018-05-27 17:37:24.003 INFO 67749 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 1.6 seconds (JVM running for 2.274) 从日志里可以看出： 启动时 WebFlux 利用 MVC 原生的 RequestMappingHandlerMapping 将控制器里的 请求路径 和 MVC 中的 处理器 进行\b绑定。\b Spring WebFlux 默认采用 Netty 作为 内嵌容器，且启动端口默认为 8080。 访问 http://localhost:8080，返回结果如下： 2. 全局Router API方式2.1. 配置全局Router Bean12345678910111213141516@Configurationpublic class DemoRouterConfig &#123; @Bean public RouterFunction&lt;ServerResponse&gt; routes() &#123; return route(GET(\"/\"), (ServerRequest req)-&gt; ok() .body( BodyInserters.fromObject( Arrays.asList( Message.builder().body(\"hello Spring 5\").build(), Message.builder().body(\"hello Spring Boot 2\").build() ) ) ) ); &#125;&#125; 2.2. 编写测试类1234567891011@RunWith(SpringRunner.class)@WebFluxTestpublic class DemoApplicationTests &#123; @Autowired WebTestClient client; @Test public void getAllMessagesShouldBeOk() &#123; client.get().uri(\"/\").exchange().expectStatus().isOk(); &#125;&#125; \b2.3. 查看启动日志\b运行 Spring Boot 启动入口类，\b启动日志如下(不重要的省略)： 123452018-05-27 17:20:28.870 INFO 67696 --- [ main] o.s.w.r.f.s.s.RouterFunctionMapping : Mapped (GET &amp;&amp; /) -&gt; com.example.demo.DemoRouterConfig$$Lambda$213/1561745898@3381b4fc2018-05-27 17:20:28.931 INFO 67696 --- [ main] o.s.w.r.r.m.a.ControllerMethodResolver : Looking for @ControllerAdvice: org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@1460a8c0: startup date [Sun May 27 17:20:27 CST 2018]; root of context hierarchy2018-05-27 17:20:29.311 INFO 67696 --- [ctor-http-nio-1] r.ipc.netty.tcp.BlockingNettyContext : Started HttpServer on /0:0:0:0:0:0:0:0:80802018-05-27 17:20:29.312 INFO 67696 --- [ main] o.s.b.web.embedded.netty.NettyWebServer : Netty started on port(s): 80802018-05-27 17:20:29.316 INFO 67696 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 2.137 seconds (JVM running for 3.169) 从日志里可以看出：启动时 WebFlux 利用 RouterFunctionMapping 将 RouterFunction 里\b的 全局路径 和 请求处理 进行了映射和绑定。 访问 http://localhost:8080，返回结果如下： 可以看出，无论是使用 Fucntional Router 还是 MVC Controller，都可以产生相同的效果！ 开发运行环境 JDK 1.8 + : Spring Boot 2.x 要求 JDK 1.8 环境及以上版本。另外，Spring Boot 2.x 只兼容 Spring Framework 5.0 及以上版本。 Maven 3.2 + : 为 Spring Boot 2.x 提供了相关依赖构建工具是 Maven，版本需要 3.2 及以上版本。使用 Gradle 则需要 1.12 及以上版本。Maven 和 Gradle 大家各自挑选下喜欢的就好。 小结本文首先对 Spring 5 WebFlux 进行了单独介绍，\b包括引入 Servlet 3.1 +，各个功能组件 Router Functions、WebFlux 和 Reactive Streams 等。然后在 Spring Boot 2.0 详细地介绍了 Reactive Stack 和 Servlet Stack 的组成区别，并分别给出了 WebFlux 基于 全局功能路由 和 控制器 的配置和使用案例。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Spring Boot 2.0系列","slug":"Spring-Boot-2-0系列","permalink":"https://ostenant.coding.me/categories/Spring-Boot-2-0系列/"},{"name":"Spring Reactive编程系列","slug":"Spring-Boot-2-0系列/Spring-Reactive编程系列","permalink":"https://ostenant.coding.me/categories/Spring-Boot-2-0系列/Spring-Reactive编程系列/"}],"tags":[{"name":"Reactive Streams","slug":"Reactive-Streams","permalink":"https://ostenant.coding.me/tags/Reactive-Streams/"},{"name":"Spring WebFlux","slug":"Spring-WebFlux","permalink":"https://ostenant.coding.me/tags/Spring-WebFlux/"},{"name":"Spring Boot 2.0","slug":"Spring-Boot-2-0","permalink":"https://ostenant.coding.me/tags/Spring-Boot-2-0/"}]},{"title":"聊聊Spring Reactor反应式编程","slug":"聊聊Spring Reactor反应式编程","date":"2018-05-26T08:41:00.000Z","updated":"2018-05-27T10:03:31.352Z","comments":true,"path":"2018/05/26/聊聊Spring Reactor反应式编程/","link":"","permalink":"https://ostenant.coding.me/2018/05/26/聊聊Spring Reactor反应式编程/","excerpt":"前言为了应对 高并发环境下 的服务端编程，微软提出了一个实现 异步编程 的方案 - Reactive Programming，中文名称 反应式编程。随后，其它技术也迅速地跟上了脚步，像 ES6 通过 Promise 引入了类似的异步编程方式。Java 社区也没有落后很多，Netflix 和 TypeSafe 公司提供了 RxJava 和 Akka Stream 技术，让 Java 平台也有了能够实现反应式编程的框架。","text":"前言为了应对 高并发环境下 的服务端编程，微软提出了一个实现 异步编程 的方案 - Reactive Programming，中文名称 反应式编程。随后，其它技术也迅速地跟上了脚步，像 ES6 通过 Promise 引入了类似的异步编程方式。Java 社区也没有落后很多，Netflix 和 TypeSafe 公司提供了 RxJava 和 Akka Stream 技术，让 Java 平台也有了能够实现反应式编程的框架。 正文函数式编程函数式编程是种编程方式，它将计算机的运算视为函数的计算。函数编程语言最重要的基础是 λ演算 (lambda calculus)，而λ演算的函数可以接受函数当作 输入(参数) 和 输出(返回值)。lambda 表达式对与大多数程序员已经很熟悉了，jdk8 以及 es6都是引入的 lambda。 函数式编程的特点 惰性计算 函数是“第一等公民” 只使用表达式而不使用语句 没有副作用 反应式编程反应式编程 (reactive programming) 是一种基于 数据流 (data stream) 和 变化传递 (propagation of change) 的 声明式 (declarative) 的编程范式。 反应式编程的特点1. 事件驱动在一个 事件驱动 的应用程序中，组件之间的交互是通过松耦合的 生产者 (production)和 消费者 (consumption) 来实现的。这些事件是以 异步 和 非阻塞 的方式发送和接收的。 事件驱动 的系统依靠 推模式 而不是 拉模式 或 投票表决，即 生产者 是在有消息时才推送数据给 消费者，而不是通过一种浪费资源方式：让 消费者 不断地 轮询 或 等待数据。 2. 实时响应\b程序发起执行以后，\b应该 快速 返回存储 结果的\b上下文，把具体执行交给 后台线程。\b待处理完成\b以后，异步地将 真实返回值 封装在此 上下文 中，而不是 阻塞 程序的执行。\b实时响应\b是通过 异步 编程实现的，例如：发起调用\b后，快速返回类似 java8 中 CompletableFuture 对象。 3. 弹性\b机制事件驱动的 松散耦合 提供了组件在失败下，可以抓获 完全隔离 的上下文场景，作为 消息封装，发送到下游组件。在具体编程时可以 检查错误 ，比如：是否接收到，接收的命令是否可执行等，并决定如何应对。 Reactor简介Reactor 框架是 Pivotal 基于 Reactive Programming 思想实现的。它符合 Reactive Streams 规范 (Reactive Streams 是由 Netflix、TypeSafe、Pivotal 等公司发起的) 的一项技术。其名字有 反应堆 之意，反映了其背后的强大的 性能。 1. Reactive ProgrammingReactive Programming，中文称 反应式编程。Reactive Programming 是一种 非阻塞、事件驱动数据流 的开发方案，使用 函数式编程 的概念来操作数据流，系统中某部分的数据变动后会自动更新其他部分，而且成本极低。 其最早是由微软提出并引入到 .NET 平台中，随后 ES6 也引入了类似的技术。在 Java 平台上，较早采用反应式编程技术的是 Netflix 公司开源的 RxJava 框架。Hystrix 就是以 RxJava 为基础开发的。 反应式编程其实并不神秘，通过与我们熟悉的 迭代器模式 对比，便可了解其基本思想： 事件 Iterable (pull) Observable (push) 获取数据 T next() onNext(T) 发现异常 throws Exception onError(Exception) 处理完成 hasNext() onCompleted() 上面表格的中的 Observable 那一列便代表 反应式编程 的 API 的使用方式。它其实是 观察者模式 的一种延伸。 如果将 迭代器模式 看作是 拉模式，那 观察者模式 便是 推模式。 被订阅者 (Publisher) 主动推送数据给 订阅者 (Subscriber)，触发 onNext() 方法。异常和完成时触发另外两个方法。 \b\b\b被订阅者 (Publisher) 发生异常，则触发 订阅者 (Subscriber) 的 onError() 方法进行异常捕获处理。 被订阅者 (Publisher) 每次推送都会触发一次 onNext() 方法。所有的推送完成且无异常时，\bonCompleted() 方法将 在最后 触发一次。 如果 Publisher 发布消息太快了，超过了 Subscriber 的处理速度，那怎么办？这就是 Backpressure 的由来。Reactive Programming 框架需要提供 背压机制，使得 Subscriber 能够控制 消费消息 的速度。 2. Reactive Streams在 Java 平台上，Netflix（开发了 RxJava）、TypeSafe（开发了 Scala、Akka）、Pivatol（开发了 Spring、Reactor）共同制定了一个被称为 Reactive Streams 项目（规范），用于制定反应式编程相关的规范以及接口。 Reactive Streams 由以下几个组件组成： 发布者：发布元素到订阅者 订阅者：消费元素 订阅：在发布者中，订阅被创建时，将与订阅者共享 处理器：发布者与订阅者之间处理数据 其主要的接口有这三个： Publisher Subscriber Subcription 其中，Subcriber 中便包含了上面表格提到的 onNext、onError、onCompleted 这三个方法。对于 Reactive Streams，只需要理解其思想就可以，包括基本思想以及 Backpressure 等思想即可。 3. Reactor的主要模块Reactor 框架主要有两个主要的模块： reactor-core reactor-ipc 前者主要负责 Reactive Programming 相关的 核心 API 的实现，后者负责 高性能网络通信 的实现，目前是基于 Netty 实现的。 4. Reactor的核心类在 Reactor 中，经常使用的类并不是很多，主要有以下两个： Mono Mono 实现了 org.reactivestreams.Publisher 接口，代表 0 到 1 个元素的 发布者。 Flux Flux 同样实现了 org.reactivestreams.Publisher 接口，代表 0 到 N 个元素的发表者。 Scheduler 代表背后驱动反应式流的调度器，通常由各种线程池实现。 5. WebFluxSpring 5 引入的一个基于 Netty 而不是 Servlet 的高性能的 Web 框架 - Spring WebFlux ，但是使用方式并没有同传统的基于 Servlet 的 Spring MVC 有什么大的不同。 WebFlux 中 MVC 接口的示例： 12345678@RequestMapping(\"/webflux\")@RestControllerpublic class WebFluxTestController &#123; @GetMapping(\"/mono\") public Mono&lt;Foobar&gt; foobar() &#123; return Mono.just(new Foobar()); &#125;&#125; 最大的变化就是返回值从 Foobar 所表示的一个对象变为 Mono&lt;Foobar&gt; 或 Flux&lt;Foobar&gt;。 6. Reactive Streams、Reactor和WebFlux上面介绍了 反应式编程 的一些概念。可能读者看到这里有些乱，梳理一下三者的关系： Reactive Streams 是一套反应式编程 标准 和 规范； Reactor 是基于 Reactive Streams 一套 反应式编程框架； WebFlux 以 Reactor 为基础，实现 Web 领域的 反应式编程框架。 其实，对于业务开发人员来说，当编写反应式代码时，通常只会接触到 Publisher 这个接口，对应到 Reactor 便是 Mono 和 Flux。 对于 Subscriber 和 Subcription 这两个接口，Reactor 也有相应的实现。这些都是 Spring WebFlux 和 Spring Data Reactive 这样的框架用到的。如果 不开发中间件，开发人员是不会接触到的。 Reactor入门接下来介绍一下 Reactor 中 Mono 和 Flux 这两个类中的主要方法的使用。 如同 Java 8 所引入的 Stream 一样，Reactor 的使用方式基本上也是分三步： 开始阶段的创建 中间阶段的处理 最终阶段的消费 只不过创建和消费可能是通过像 Spring 5 这样框架完成的（比如通过 WebFlux 中的 WebClient 调用 HTTP 接口，返回值便是一个 Mono）。但我们还是需要基本了解这些阶段的开发方式。 1. 创建 Mono 和 Flux（开始阶段）使用 Reactor 编程的开始必然是先创建出 Mono 或 Flux。有些时候不需要我们自己创建，而是实现例如 WebFlux 中的 WebClient 或 Spring Data Reactive 得到一个 Mono 或 Flux。 使用 WebFlux WebClient 调用 HTTP 接口 123456789WebClient webClient = WebClient.create(\"http://localhost:8080\");public Mono&lt;User&gt; findById(Long userId) &#123; return webClient .get() .uri(\"/users/\" + userId) .accept(MediaType.APPLICATION_JSON) .exchange() .flatMap(cr -&gt; cr.bodyToMono(User.class));&#125; 使用 ReactiveMongoRepository 查询 User 123public interface UserRepository extends ReactiveMongoRepository&lt;User, Long&gt; &#123; Mono&lt;User&gt; findByUsername(String username);&#125; 但有些时候，我们也需要主动地创建一个 Mono 或 Flux。 普通的创建方式123Mono&lt;String&gt; helloWorld = Mono.just(\"Hello World\");Flux&lt;String&gt; fewWords = Flux.just(\"Hello\", \"World\");Flux&lt;String&gt; manyWords = Flux.fromIterable(words); 这样的创建方式在什么时候用呢？一般是用在经过一系列 非IO型 操作之后，得到了一个对象。接下来要基于这个对象运用 Reactor 进行 高性能 的 IO 操作时，可以用这种方式将之前得到的对象转换为 Mono 或 Flux。 文艺的创建方式上面是通过一个 同步调用 得到的结果创建出 Mono 或 Flux，但有时需要从一个 非 Reactive 的 异步调用 的结果创建出 Mono 或 Flux。 如果这个 异步方法 返回一个 CompletableFuture，那可以基于这个 CompletableFuture 创建一个 Mono： 1Mono.fromFuture(completableFuture); 如果这个 异步调用 不会返回 CompletableFuture，是有自己的 回调方法，那怎么创建 Mono 呢？\b可以使用 static &lt;T&gt; Mono&lt;T&gt; create(Consumer&lt;MonoSink&lt;T&gt;&gt; callback) 方法： 1234567891011121314Mono.create(sink -&gt; &#123; ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; entity = asyncRestTemplate.getForEntity(url, String.class); entity.addCallback(new ListenableFutureCallback&lt;ResponseEntity&lt;String&gt;&gt;() &#123; @Override public void onSuccess(ResponseEntity&lt;String&gt; result) &#123; sink.success(result.getBody()); &#125; @Override public void onFailure(Throwable ex) &#123; sink.error(ex); &#125; &#125;);&#125;); 在使用 WebFlux 之后，AsyncRestTemplate 已经不推荐使用，这里只是做演示。 2. 处理 Mono 和 Flux（中间阶段）中间阶段的 Mono 和 Flux 的方法主要有 filter、map、flatMap、then、zip、reduce 等。这些方法使用方法和 Stream 中的方法类似。 下面举几个 Reactor 开发实际项目的问题，帮大家理解这些方法的使用场景： 问题一: map、flatMap 和 then 在什么时候使用本段内容将涉及到如下类和方法： 方法：Mono.map() 方法：Mono.flatMap() 方法：Mono.then() 类：Function 在 Mono 和 Flux 中间环节的处理过程中，有三个有些类似的方法：map()、flatMap() 和 then()。这三个方法的使用频率很高。\b 传统的命令式编程 123Object result1 = doStep1(params);Object result2 = doStep2(result1);Object result3 = doStep3(result2); 对应的反应式编程 1234Mono.just(params) .flatMap(v -&gt; doStep1(v)) .flatMap(v -&gt; doStep2(v)) .flatMap(v -&gt; doStep3(v)); 从上面两段代码的对比就可以看出来 flatMap() 方法在其中起到的作用，map() 和 then() 方法也有类似的作用。但这些方法之间的区别是什么呢？我们先来看看这三个方法的签名（以 Mono 为例）： flatMap(Function&lt;? super T, ? extends Mono&lt;? extends R&gt;&gt; transformer) map(Function&lt;? super T, ? extends R&gt; mapper) then(Mono other) then()then() 看上去是下一步的意思，但它只表示执行顺序的下一步，不表示下一步依赖于上一步。then() 方法的参数只是一个 Mono，无从接受上一步的执行结果。而 flatMap() 和 map() 的参数都是一个 Function，入参是上一步的执行结果。 flatMap() 和 map()flatMap() 和 map() 的区别在于，flatMap() 中的入参 Function 的返回值要求是一个 Mono 对象，而 map 的入参 Function 只要求返回一个 普通对象。在业务处理中常需要调用 WebClient 或 ReactiveXxxRepository 中的方法，这些方法的 返回值 都是 Mono（或 Flux）。所以要将这些调用串联为一个整体 链式调用，就必须使用 flatMap()，而不是 map()。 问题二：如何实现并发执行本段内容将涉及到如下类和方法： 方法：Mono.zip() 类：Tuple2 类：BiFunction 并发执行 是常见的一个需求。Reactive Programming 虽然是一种 异步编程 方式，但是 异步 不代表就是 并发并行 的。 在 传统的命令式编程 中，并发执行 是通过 线程池 加 Future 的方式实现的。 1234567Future&lt;Result1&gt; result1Future = threadPoolExecutor.submit(() -&gt; doStep1(params));Future&lt;Result2&gt; result2Future = threadPoolExecutor.submit(() -&gt; doStep2(params));// Retrive resultResult1 result1 = result1Future.get();Result2 result2 = result2Future.get();// Do merge;return mergeResult; 上面的代码虽然实现了 \b异步调用，但 Future.get() 方法是 阻塞 的。在使用 Reactor 开发有 并发 执行场景的 反应式代码 时，不能用上面的方式。 这时应该使用 Mono 和 Flux 中的 zip() 方法，以 Mono 为例，代码如下： 12345678Mono&lt;CustomType1&gt; item1Mono = ...;Mono&lt;CustomType2&gt; item2Mono = ...;Mono.zip(items -&gt; &#123; CustomType1 item1 = CustomType1.class.cast(items[0]); CustomType2 item2 = CustomType2.class.cast(items[1]); // Do merge return mergeResult;&#125;, item1Mono, item2Mono); 上述代码中，产生 item1Mono 和 item2Mono 的过程是 并行 的。比如，调用一个 HTTP 接口的同时，执行一个 数据库查询 操作。这样就可以加快程序的执行。 但上述代码存在一个问题，就是 zip() 方法需要做 强制类型转换。而强制类型转换是 不安全的。好在 zip() 方法存在 多种重载 形式。除了最基本的形式以外，还有多种 类型安全 的形式： 123static &lt;T1, T2&gt; Mono&lt;Tuple2&lt;T1, T2&gt;&gt; zip(Mono&lt;? extends T1&gt; p1, Mono&lt;? extends T2&gt; p2);static &lt;T1, T2, O&gt; Mono&lt;O&gt; zip(Mono&lt;? extends T1&gt; p1, Mono&lt;? extends T2&gt; p2, BiFunction&lt;? super T1, ? super T2, ? extends O&gt; combinator); static &lt;T1, T2, T3&gt; Mono&lt;Tuple3&lt;T1, T2, T3&gt;&gt; zip(Mono&lt;? extends T1&gt; p1, Mono&lt;? extends T2&gt; p2, Mono&lt;? extends T3&gt; p3); 对于不超过 7 个元素的合并操作，都有 类型安全 的 zip() 方法可选。以两个元素的合并为例，介绍一下使用方法： 123456Mono.zip(item1Mono, item2Mono).map(tuple -&gt; &#123; CustomType1 item1 = tuple.getT1(); CustomType2 item2 = tuple.getT2(); // Do merge return mergeResult;&#125;); 上述代码中，map() 方法的参数是一个 Tuple2，表示一个 二元数组，相应的还有 Tuple3、Tuple4 等。 对于两个元素的并发执行，也可以通过 zip(Mono&lt;? extends T1&gt; p1, Mono&lt;? extends T2&gt; p2, BiFunction&lt;? super T1, ? super T2, ? extends O&gt; combinator) 方法直接将结果合并。方法是传递 BiFunction 实现 合并算法。 问题三：集合循环之后的汇聚本段内容将涉及到如下类和方法： 方法：Flux.fromIterable() 方法：Flux.reduce() 类：BiFunction 另外一个稍微复杂的场景，对一个对象中的一个类型为集合类的（List 、Set）进行处理之后，再对原本的对象进行处理。使用 迭代器模式 的代码很容易编写： 12345List&lt;SubData&gt; subDataList = data.getSubDataList();for (SubData item : subDataList) &#123; // Do something on data and item&#125;// Do something on data 当我们要用 Reactive 风格的代码实现上述逻辑时，就不是那么简单了。这里会用到 Flux 的 reduce() 方法。reduce() 方法的签名如下： &lt;A&gt; Mono&lt;A&gt; reduce(A initial, BiFunction&lt;A, ? super T, A&gt; accumulator); 可以看出，reduce() 方法的功能是将一个 Flux 聚合 成一个 Mono。 第一个参数: 返回值 Mono 中元素的 初始值。 第二个参数: 是一个 BiFunction，用来实现 聚合操作 的逻辑。对于泛型参数 &lt;A, ? super T, A&gt; 中： 第一个 A: 表示每次 聚合操作 之后的 结果的类型，它作为 BiFunction.apply() 方法的 第一个入参； 第二个 ? super T: 表示集合中的每个元素的类型，它作为 BiFunction.apply() 方法的 第二个入参； 第三个 A: 表示聚合操作的 结果，它作为 BiFunction.apply() 方法的 返回值。 接下来看一下示例： 1234567Data initData = ...;List&lt;SubData&gt; list = ...;Flux.fromIterable(list) .reduce(initData, (data, itemInList) -&gt; &#123; // Do something on data and itemInList return data; &#125;); 上面的示例代码中，initData 和 data 的类型相同。执行完上述代码之后，reduce() 方法会返回 Mono&lt;Data&gt;。 3. 消费 Mono 和 Flux（结束阶段）直接消费的 Mono 或 Flux 的方式就是调用 subscribe() 方法。如果在 WebFlux 接口中开发，直接返回 Mono 或 Flux 即可。WebFlux 框架会完成最后的 Response 输出工作。 小结本文介绍了反应式编程的一些概念和 Spring Reactor 框架的基本用法，还介绍了如何用 Reactor 解决一些稍微复杂一点的问题。Reactor 在 \bSpring 5 中有大量的应用，后面会给大家分享一些 Spring Reactor 实战\b系列的\b博客。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Spring Reactive编程系列","slug":"Spring-Reactive编程系列","permalink":"https://ostenant.coding.me/categories/Spring-Reactive编程系列/"}],"tags":[{"name":"Reactive Streams","slug":"Reactive-Streams","permalink":"https://ostenant.coding.me/tags/Reactive-Streams/"},{"name":"Spring WebFlux","slug":"Spring-WebFlux","permalink":"https://ostenant.coding.me/tags/Spring-WebFlux/"},{"name":"Reactor","slug":"Reactor","permalink":"https://ostenant.coding.me/tags/Reactor/"}]},{"title":"Android异步框架RxJava 1.x系列(三) - 线程调度器Scheduler","slug":"Android异步框架RxJava 1.x系列(三) - 线程调度器\bScheduler","date":"2018-05-23T12:22:00.000Z","updated":"2018-05-23T15:41:32.662Z","comments":true,"path":"2018/05/23/Android异步框架RxJava 1.x系列(三) - 线程调度器\bScheduler/","link":"","permalink":"https://ostenant.coding.me/2018/05/23/Android异步框架RxJava 1.x系列(三) - 线程调度器\bScheduler/","excerpt":"前言RxJava 事件的发出和消费都在同一个线程，基于同步的观察者模式。观察者模式的核心是后台处理，前台回调的异步机制。要实现异步，需要引入 RxJava 的另一个概念 - 线程调度器 Scheduler。","text":"前言RxJava 事件的发出和消费都在同一个线程，基于同步的观察者模式。观察者模式的核心是后台处理，前台回调的异步机制。要实现异步，需要引入 RxJava 的另一个概念 - 线程调度器 Scheduler。 正文在不指定线程的情况下，RxJava 遵循的是线程不变的原则。即在哪个线程调用 subscribe() 方法，就在哪个线程生产事件；在哪个线程生产事件，就在哪个线程消费事件。如果需要切换线程，就需要用到线程调度器 Scheduler。 1. 几种Scheduler介绍在 RxJava 中，Scheduler - 调度器，相当于线程控制器，RxJava 通过它来指定每一段代码应该运行在什么样的线程。RxJava 已经内置了几个 Scheduler ，它们已经适合大多数的使用场景： Schedulers.immediate() 直接在当前线程运行，相当于不指定线程。这是默认的 Scheduler。 Schedulers.newThread() 总是启用新线程，并在新线程执行操作。 Schedulers.io() I/O 操作（读写文件、读写数据库、网络信息交互等）所使用的 Scheduler。行为模式和 newThread() 差不多，区别在于 io() 内部采用的是一个无数量上限的线程池，可以重用空闲的线程。因此多数情况下 io() 比 newThread() 更有效率。 注意：不要把计算任务放在 io() 中，可以避免创建不必要的线程。 Schedulers.computation() 计算任务所使用的 Scheduler。这个计算指的是 CPU 密集型计算，即不会被 I/O 等操作限制性能的操作，例如图形的计算。这个 Scheduler 使用的固定的线程池，大小为 CPU 核数。 注意：不要把 I/O 操作放在 computation() 中，否则 I/O 操作的等待时间会浪费 CPU。 AndroidSchedulers.mainThread() Android 还有一个专用的 AndroidSchedulers.mainThread()，它指定的操作将在 Android 主线程运行。 2. Scheduler的线程切换2.1. 单次线程切换有了这几个 Scheduler，就可以使用 subscribeOn() 和 observeOn() 两个方法来对线程进行控制了。 subscribeOn(): 指定 subscribe() 所发生的线程，即 Observable.OnSubscribe 被激活时所处的线程，或者叫做事件产生的线程。 observeOn(): 指定 Subscriber 所运行在的线程，或者叫做事件消费的线程。 直接看代码： 123456789Observable.just(1, 2, 3, 4) .subscribeOn(Schedulers.io()) // 指定 subscribe() 发生在 IO 线程 .observeOn(AndroidSchedulers.mainThread()) // 指定 Subscriber 的回调发生在主线程 .subscribe(new Action1&lt;Integer&gt;() &#123; @Override public void call(Integer number) &#123; Log.d(tag, \"number:\" + number); &#125; &#125;); 上面这段代码中，由于 subscribeOn(Schedulers.io()) 的指定，被创建的事件的内容 1、2、3、4 将会在 IO 线程发出；由于 observeOn(AndroidScheculers.mainThread()) 的指定，因此 subscriber 数字的打印将发生在主线程。 事实上，这种使用方式非常常见，它适用于多数的 『后台线程取数据，主线程显示』的程序策略。 以下是一个完整的例子： 1234567891011121314151617181920212223242526272829int drawableRes = ...;ImageView imageView = ...;Observable.create(new OnSubscribe&lt;Drawable&gt;() &#123; @Override public void call(Subscriber&lt;? super Drawable&gt; subscriber) &#123; Drawable drawable = getTheme().getDrawable(drawableRes)); subscriber.onNext(drawable); subscriber.onCompleted(); &#125;&#125;)// 指定事件发出，即图片读取发生在 IO 线程.subscribeOn(Schedulers.io())// 指定事件消费 - 回调，即\b页面图片渲染发生在主线程.observeOn(AndroidSchedulers.mainThread()).subscribe(new Observer&lt;Drawable&gt;() &#123; @Override public void onNext(Drawable drawable) &#123; imageView.setImageDrawable(drawable); &#125; @Override public void onCompleted() &#123; &#125; @Override public void onError(Throwable e) &#123; Toast.makeText(activity, \"Error!\", Toast.LENGTH_SHORT).show(); &#125;&#125;); 这样的好处是，加载图片的过程发生在 IO 线程，而设置图片则\b发生\b在了主线程。这就意味着，即使加载图片耗费了几十甚至几百毫秒的时间，也不会造成界面上的丝毫卡顿。 2.2. 多次线程切换上面介绍\b到可以利用 subscribeOn() 结合 observeOn() 来实现线程控制，让事件的产生和消费发生在不同的线程。在了解了 map() 和 flatMap() 等变换方法后，一个问题就产生了 - 能不能多切换几次线程？ 因为 observeOn() 指定的是 Subscriber 的线程，而这个 Subscriber 并不是 subscribe() 参数中的 Subscriber ，而是 observeOn() 执行时，当前\b Observable 所对应的 Subscriber，即它的直接下级 Subscriber。 也就是说，observeOn() 指定的是它之后的操作所在的线程。因此如果有多次切换线程的需求，只要在每个想要切换线程的位置调用一次 observeOn() 即可。 直接查看示例代码： 123456789101112Observable.just(1, 2, 3, 4) // 事件发出的 IO 线程，由 subscribeOn() 指定 .subscribeOn(Schedulers.io()) // 新线程，由 observeOn() 指定 .observeOn(Schedulers.newThread()) .map(mapOperator) // IO 线程，由 observeOn() 指定 .observeOn(Schedulers.io()) .map(mapOperator2) // Android 主线程，由 observeOn() 指定 .observeOn(AndroidSchedulers.mainThread) .subscribe(subscriber); 上面的代码，通过 observeOn() 的多次调用，程序实现了线程的多次切换。不过，不同于 observeOn()的是，subscribeOn() 的位置放在哪里都可以，但它是只能调用一次的。 3. Scheduler的实现原理其实，subscribeOn() 和 observeOn() 的内部实现，也是用的 lift() (见上文)，具体看图（不同颜色的箭头表示不同的线程）： subscribeOn()的原理图 从图中可以看出，subscribeOn() 进行了线程切换的工作（图中的 schedule... 的位置）。 subscribeOn() 的线程切换发生在 OnSubscribe 中，即在它通知上一级 OnSubscribe 时，这时事件还没有开始发送，因此 subscribeOn() 的线程控制只能在事件发出的开端造成影响，即只允许一次线程切换。 observeOn()的原理图 从图中可以看出，和 observeOn() 进行了线程切换的工作（图中的 schedule... 的位置）。 observeOn() 的线程切换则发生在它内建的 Subscriber 中，即发生在它即将给下一级 Subscriber 发送事件时，因此 observeOn() 控制的是它后面的线程，允许多次线程切换。 混合切换原理图 最后用一张图来解释当多个 subscribeOn() 和 observeOn() 混合使用时，线程调度是怎么发生的： 图中共有 5 处对事件的操作，由图中可以看出: ① 和 ② 两处受第一个 subscribeOn() 影响，运行在红色线程； ③ 和 ④ 处受第一个 observeOn() 的影响，运行在绿色线程； ⑤ 处受第二个 onserveOn() 影响，运行在紫色线程； 而第二个 subscribeOn() ，由于在通知过程中线程就被第一个 subscribeOn() 截断，因此对整个流程并没有任何影响。 注意：当使用了多个 subscribeOn() 的时候，只有第一个 subscribeOn() 起作用。 4. \b延伸拓展虽然超过一个的 subscribeOn() 对事件处理的流程没有影响，但在流程之前却是有用的。在前面的文章介绍 Subscriber 的时候，提到过 Subscriber 的 onStart() 可以用作流程开始前的初始化处理。 由于 onStart() 在 subscribe() 发生时就被调用了，因此不能指定线程，而是只能执行在 subscribe() 被调用时的线程。这就导致如果 onStart() 中含有对线程有要求的代码（例如：在界面上显示一个 ProgressBar，这必须在主线程执行），将会有线程非法的风险，因为无法预测 subscribe() 会在什么线程执行。 与 Subscriber.onStart() 相对应的，有一个方法 Observable.doOnSubscribe()。它和 Subscriber.onStart() 同样是在 subscribe() 调用后而且在事件发送前执行，但区别在于它可以指定线程。默认情况下，doOnSubscribe() 执行在 subscribe() 发生的线程；而如果在 doOnSubscribe() 之后有 subscribeOn() 的话，它将执行在离它最近的 subscribeOn() 所指定的线程。 示例代码如下： 12345678910111213Observable.create(onSubscribe) .subscribeOn(Schedulers.io()) .doOnSubscribe(new Action0() &#123; @Override public void call() &#123; // 需要在主线程执行 progressBar.setVisibility(View.VISIBLE); &#125; &#125;) .subscribeOn(AndroidSchedulers.mainThread()) // 指定主线程 .observeOn(AndroidSchedulers.mainThread()) .subscribe(subscriber); 上面的代码，在 doOnSubscribe() 的后面跟一个 subscribeOn() ，就能指定特定工作的线程了！ 小结RxJava 的提供的各种事件及事件转换模型，以及基于转换的线程调度器，结合观察者模式，使得 RxJava 在异步编程体验、灵活性和运行效率上\b领先于其他的开源框架！ 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RxJava异步框架系列","slug":"RxJava异步框架系列","permalink":"https://ostenant.coding.me/categories/RxJava异步框架系列/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://ostenant.coding.me/tags/Android/"},{"name":"RxJava","slug":"RxJava","permalink":"https://ostenant.coding.me/tags/RxJava/"},{"name":"异步","slug":"异步","permalink":"https://ostenant.coding.me/tags/异步/"}]},{"title":"Android异步框架RxJava 1.x系列(二) - 事件及事件序列转换原理","slug":"Android异步框架RxJava 1.x系列(二) - 事件及事件序列转换原理","date":"2018-05-21T11:14:00.000Z","updated":"2018-05-21T15:30:10.905Z","comments":true,"path":"2018/05/21/Android异步框架RxJava 1.x系列(二) - 事件及事件序列转换原理/","link":"","permalink":"https://ostenant.coding.me/2018/05/21/Android异步框架RxJava 1.x系列(二) - 事件及事件序列转换原理/","excerpt":"前言在介绍 RxJava 1.x 线程调度器之前，首先引入一个重要的概念 - 事件序列转换。RxJava 提供了对事件序列进行转换的支持，这是它的核心功能之一。","text":"前言在介绍 RxJava 1.x 线程调度器之前，首先引入一个重要的概念 - 事件序列转换。RxJava 提供了对事件序列进行转换的支持，这是它的核心功能之一。 正文1. 事件序列转换定义所谓转换，就是将事件序列中的对象或整个序列进行加工处理，转换成不同的事件或事件序列，有点类似 Java 1.8 中的流处理。 2. 事件序列转换API首先看一个 map() 的例子： 12345678910111213Observable.just(\"images/logo.png\") // 输入类型 String .map(new Func1&lt;String, Bitmap&gt;() &#123; @Override public Bitmap call(String filePath) &#123; // 参数类型 String return getBitmapFromPath(filePath); // 返回类型 Bitmap &#125; &#125;) .subscribe(new Action1&lt;Bitmap&gt;() &#123; @Override public void call(Bitmap bitmap) &#123; // 参数类型 Bitmap showBitmap(bitmap); &#125; &#125;); 这里出现了一个叫 Func1 的类。它和 Action1 非常相似，也是 RxJava 的一个接口，用于包装含有一个参数的方法。 Func1 和 Action 的区别在于: Func1 包装的是有返回值的方法。另外，和 ActionX 一样，FuncX 也有多个，用于不同参数个数的方法。同理，FuncX 和 ActionX 的区别在 FuncX 包装的是有返回值的方法。 可以看到，map() 方法将参数中的 String 对象转换成一个 Bitmap 对象后返回，而在经过 map() 方法后，事件的参数类型也由 String 转为了 Bitmap。 这种直接转换对象并返回的，是最常见的也最容易理解的变换。不过 RxJava 的转换远不止这样，它不仅可以针对事件对象，还可以针对整个事件队列，这使得 RxJava 变得非常灵活。 下面给出几个示例： map()事件对象的直接变换，具体功能上面已经介绍过。它是 RxJava 最常用的变换。 map() 的示意图如下： flatMap()这是一个很有用但非常难理解的变换。首先假设这么一种需求：假设有一个数据结构『学生』，现在需要打印出一组学生的名字。实现方式很简单： 12345678910111213141516Student[] students = ...;Subscriber&lt;String&gt; subscriber = new Subscriber&lt;String&gt;() &#123; @Override public void onNext(String name) &#123; Log.d(tag, name); &#125;&#125;;Observable.from(students) .map(new Func1&lt;Student, String&gt;() &#123; @Override public String call(Student student) &#123; return student.getName(); &#125; &#125;) .subscribe(subscriber); 如果要打印出每个学生所需要修的所有课程的名称呢？需求的区别在于，每个学生只有一个名字，但却有多个课程，首先可以这样实现： 1234567891011121314Student[] students = ...;Subscriber&lt;Student&gt; subscriber = new Subscriber&lt;Student&gt;() &#123; @Override public void onNext(Student student) &#123; List&lt;Course&gt; courses = student.getCourses(); for (int i = 0; i &lt; courses.size(); i++) &#123; Course course = courses.get(i); Log.d(tag, course.getName()); &#125; &#125;&#125;;Observable.from(students) .subscribe(subscriber); 如果我不想在 Subscriber 中使用 for 循环，而是希望 Subscriber 中直接传入单个的 Course 对象呢（这对于代码复用很重要）？用 map() 显然是不行的，因为 map() 是一对一的转化，而现在需要一对多的转化。问题出现了：怎样把一个 Student 转化成多个 Course ？ 这个时候，flatMap() 就派上了用场： 12345678910111213141516Student[] students = ...;Subscriber&lt;Course&gt; subscriber = new Subscriber&lt;Course&gt;() &#123; @Override public void onNext(Course course) &#123; Log.d(tag, course.getName()); &#125;&#125;;Observable.from(students) .flatMap(new Func1&lt;Student, Observable&lt;Course&gt;&gt;() &#123; @Override public Observable&lt;Course&gt; call(Student student) &#123; return Observable.from(student.getCourses()); &#125; &#125;) .subscribe(subscriber); 从上面的代码可以看出，flatMap() 和 map() 有一个相同点：它也是把传入的参数转化之后返回另一个对象。 flatMap() 和 map() 不同的是，flatMap() 返回的是个 Observable 对象，并且这个 Observable 对象并不是被直接发送到 Subscriber 的回调方法中。 flatMap() 示意图如下： flatMap() 的原理是这样的： 使用传入的事件对象创建一个 Observable 对象； 并不立即发送这个 Observable, 而是将它激活，然后开始发送事件； 将每一个创建出来的 Observable 发送的事件，都被汇入同一个 Observable。 而这个 Observable 负责将这些事件统一交给 Subscriber 的回调方法。这三个步骤，把事件拆成了两级，通过一组新创建的 Observable 将初始的对象『铺平』之后通过统一路径分发了下去。而这个『铺平』就是 flatMap() 所谓的 flat。 3. 事件序列转换原理这些转换虽然功能各有不同，但实质上都是针对事件序列的处理和再发送。而在 RxJava 的内部，它们是基于同一个基础的转换方法：lift(Operator)。 lift()首先看一下 lift() 的内部实现（核心代码）： 12345678910public &lt;R&gt; Observable&lt;R&gt; lift(Operator&lt;? extends R, ? super T&gt; operator) &#123; return Observable.create(new OnSubscribe&lt;R&gt;() &#123; @Override public void call(Subscriber subscriber) &#123; Subscriber newSubscriber = operator.call(subscriber); newSubscriber.onStart(); onSubscribe.call(newSubscriber); &#125; &#125;);&#125; 这段代码实现的功能，简单来说就是创建了一个新的 Observable 并返回。如果看过上篇博客会发现有些蹊跷。重温一下 Observable.subscribe(Subscriber) 的实现(核心代码)： 12345public Subscription subscribe(Subscriber subscriber) &#123; subscriber.onStart(); onSubscribe.call(subscriber); return subscriber;&#125; 对比一下以上两段代码的方法体(忽略返回值)，会发现一行突兀的代码： 1Subscriber newSubscriber = operator.call(subscriber); 解释一下 lift() 方法完成的操作： 利用 Observable.create() 方法创建一个新的 Observable 对象，加上之前的原始 Observable，已经有两个 Observable。 创建 Observable 的同时创建一个新的 OnSubscribe 用于发出事件。 通过 lift() 传入的 Operator 函数的 call() 方法构造一个新的 Subscriber 对象，并将新 Subscriber 和原始 Subscriber 进行关联。 利用这个新 Subscriber 向原始 Observable 进行订阅，实现事件序列的转换。 这种实现基于代理模式，通过事件拦截和处理实现事件序列的变换。 在 Observable 执行了 lift(Operator) 方法之后，会返回一个新的 Observable，这个新的 Observable 会像一个代理一样，负责接收原始的 Observable 发出的事件，并在处理后发送给 Subscriber。 整个过程的思维导图如下： 或者可以看动图： 两次和多次的 lift() 同理，如下图： 举一个具体的 Operator 的实现。下面是一个将事件的 Integer 对象转换成 String 的例子，仅供参考： 12345678910111213141516171819202122observable.lift(new Observable.Operator&lt;String, Integer&gt;() &#123; @Override public Subscriber&lt;? super Integer&gt; call(final Subscriber&lt;? super String&gt; subscriber) &#123; // 将事件序列中的 Integer 对象转换为 String 对象 return new Subscriber&lt;Integer&gt;() &#123; @Override public void onNext(Integer integer) &#123; subscriber.onNext(\"\" + integer); &#125; @Override public void onCompleted() &#123; subscriber.onCompleted(); &#125; @Override public void onError(Throwable e) &#123; subscriber.onError(e); &#125; &#125;; &#125;&#125;); 学习 lift() 的原理只是为了更好地理解 RxJava ，从而可以更好地使用它。然而RxJava 不建议开发者自定义 Operator 来直接使用 lift()，而是尽量使用已有的 lift() 包装方法（如 map() flatMap() 等）进行组合。 compose()除了 lift() 之外，Observable 还有一个转方法叫做 compose()。它和 lift() 的区别在于，lift() 是针对事件项和事件序列的，而 compose() 是针对 Observable 自身进行转换。 举个例子，假设在程序中有多个 Observable 都需要应用一组相同的 lift() 进行转换，通常会这样写： 1234567891011121314151617181920212223observable1.lift1() .lift2() .lift3() .lift4() .subscribe(subscriber1);observable2.lift1() .lift2() .lift3() .lift4() .subscribe(subscriber2);observable3.lift1() .lift2() .lift3() .lift4() .subscribe(subscriber3);observable4.lift1() .lift2() .lift3() .lift4() .subscribe(subscriber1); 可以发现有太多重复代码，代码重构如下： 1234567891011private Observable liftAll(Observable observable) &#123; return observable.lift1() .lift2() .lift3() .lift4();&#125;liftAll(observable1).subscribe(subscriber1);liftAll(observable2).subscribe(subscriber2);liftAll(observable3).subscribe(subscriber3);liftAll(observable4).subscribe(subscriber4); 可读性、可维护性都提高了。可是 Observable 被一个方法包起来，这种方式对于 Observale 的灵活性进行了限制。怎么办？这个时候，就应该用 compose() 来解决了： 123456789101112131415public class LiftAllTransformer implements Observable.Transformer&lt;Integer, String&gt; &#123; @Override public Observable&lt;String&gt; call(Observable&lt;Integer&gt; observable) &#123; return observable.lift1() .lift2() .lift3() .lift4(); &#125;&#125;Transformer liftAll = new LiftAllTransformer();observable1.compose(liftAll).subscribe(subscriber1);observable2.compose(liftAll).subscribe(subscriber2);observable3.compose(liftAll).subscribe(subscriber3);observable4.compose(liftAll).subscribe(subscriber4); 如上，使用 compose() 方法，Observable 可以利用传入的 Transformer 对象的 call 方法直接对自身进行处理，而不是被包在方法的里面。 小结本文主要介绍了 RxJava 事件及事件序列转换原理，其中 lift() 方法的使用方法和实现原理是重点、难点。后续将会介绍的 RxJava 线程调度器底层也是基于它实现的。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RxJava异步框架系列","slug":"RxJava异步框架系列","permalink":"https://ostenant.coding.me/categories/RxJava异步框架系列/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://ostenant.coding.me/tags/Android/"},{"name":"RxJava","slug":"RxJava","permalink":"https://ostenant.coding.me/tags/RxJava/"},{"name":"异步","slug":"异步","permalink":"https://ostenant.coding.me/tags/异步/"}]},{"title":"Android异步框架RxJava 1.x系列(一) - 观察者模式及实现","slug":"Android异步框架RxJava 1.x系列(一) - 观察者模式及实现","date":"2018-05-20T10:14:00.000Z","updated":"2018-05-21T15:28:22.014Z","comments":true,"path":"2018/05/20/Android异步框架RxJava 1.x系列(一) - 观察者模式及实现/","link":"","permalink":"https://ostenant.coding.me/2018/05/20/Android异步框架RxJava 1.x系列(一) - 观察者模式及实现/","excerpt":"前言RxJava 是一款基于 Java VM 实现的响应式编程扩展库 - 基于观察者模式的异步和事件处理框架。RxJava 官方目前同时维护了两个版本，分别是 1.x 和 2.x，区别是它们使用不同的 group id 和 namespaces。","text":"前言RxJava 是一款基于 Java VM 实现的响应式编程扩展库 - 基于观察者模式的异步和事件处理框架。RxJava 官方目前同时维护了两个版本，分别是 1.x 和 2.x，区别是它们使用不同的 group id 和 namespaces。 版本 group id namespaces v1.x io.reactivex io.reactivex v2.x io.reactivex.rxjava2 rx 本系列的文章将针对 RxJava 1.x 进行介绍，先给出 Github 的地址： RxJava：https://github.com/ReactiveX/RxJava RxAndroid：https://github.com/ReactiveX/RxAndroid 通过 Gradle 引入相关依赖： 12compile 'io.reactivex:rxjava:1.0.14' compile 'io.reactivex:rxandroid:1.0.1' 正文1. RxJava的定义一个精准的解释如下：RxJava 是一个运行于 Java VM ，由可观测序列组成的，异步、基于事件的函数库。 2. RxJava的优点换句话说，『同样是做异步，为什么人们用它，而不用现成的 AsyncTask / Handler / XXX / … ？』 一个词：简洁。 异步操作很关键的一点是程序的简洁性，因为在调度过程比较复杂的情况下，异步代码经常会既难写也难被读懂。 Android 创造的 AsyncTask 和Handler，其实都是为了让异步代码更加简洁。RxJava 的优势也是简洁，但它的简洁的与众不同之处在于，随着程序逻辑变得越来越复杂，它依然能够保持简洁。 在 Android 开发中，假设有这样一个需求：界面上有一个自定义的视图 imageCollectorView ，它的作用是显示多张图片，并能使用 addImage(Bitmap) 方法来任意增加显示的图片。现在需要程序将一个给出的目录数组 File[] folders 中每个目录下的 png 图片都加载出来并显示在 imageCollectorView 中。 注意: 由于读取图片的过程较为耗时，需要放在后台执行，而图片的显示则必须在 UI 线程执行。 常用的实现方式有多种，这里给出其中一种： 1234567891011121314151617181920new Thread() &#123; @Override public void run() &#123; super.run(); for (File folder : folders) &#123; File[] files = folder.listFiles(); for (File file : files) &#123; if (file.getName().endsWith(\".png\")) &#123; final Bitmap bitmap = getBitmapFromFile(file); getActivity().runOnUiThread(new Runnable() &#123; @Override public void run() &#123; imageCollectorView.addImage(bitmap); &#125; &#125;); &#125; &#125; &#125; &#125;&#125;.start(); 而如果使用 RxJava，实现方式是这样的： 123456789101112131415161718192021222324252627Observable.from(folders) .flatMap(new Func1&lt;File, Observable&lt;File&gt;&gt;() &#123; @Override public Observable&lt;File&gt; call(File file) &#123; return Observable.from(file.listFiles()); &#125; &#125;) .filter(new Func1&lt;File, Boolean&gt;() &#123; @Override public Boolean call(File file) &#123; return file.getName().endsWith(\".png\"); &#125; &#125;) .map(new Func1&lt;File, Bitmap&gt;() &#123; @Override public Bitmap call(File file) &#123; return getBitmapFromFile(file); &#125; &#125;) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Action1&lt;Bitmap&gt;() &#123; @Override public void call(Bitmap bitmap) &#123; imageCollectorView.addImage(bitmap); &#125; &#125;); 可以发现，使用 RxJava 方式代码量明显大大增加，所谓简洁从何而来？ 这里说的简洁是指的逻辑上的。观察一下你会发现，RxJava 的这个实现，是一条从上到下的链式调用，没有任何嵌套，这在逻辑的简洁性上是具有优势的。当需求变得复杂时，这种优势将更加明显（试想如果还要求只选取前 10 张图片，常规方式要怎么办？如果有更多这样那样的要求呢？再试想，在这一大堆需求实现完两个月之后需要改功能，当你翻回这里看到自己当初写下的那一片迷之缩进，你能保证自己将迅速看懂，而不是对着代码重新捋一遍思路？）。 另外，如果你的 IDE 是 Android Studio，其实每次打开某个 Java 文件的时候，你会看到被自动 Lambda 化的预览，这将让你更加清晰地看到程序逻辑： 1234567Observable.from(folders) .flatMap((Func1) (folder) -&gt; &#123; Observable.from(file.listFiles()) &#125;) .filter((Func1) (file) -&gt; &#123; file.getName().endsWith(\".png\") &#125;) .map((Func1) (file) -&gt; &#123; getBitmapFromFile(file) &#125;) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe((Action1) (bitmap) -&gt; &#123; imageCollectorView.addImage(bitmap) &#125;); 所以，RxJava 有啥优点？就好在简洁，优点就是把复杂逻辑，通过函数式编程模型穿成一条线。 3. 观察者模式的扩展RxJava 的异步实现，是通过一种扩展的观察者模式来实现的。 3.1. 通用的观察者模式观察者模式面向的需求是：A 对象（观察者）对 B 对象（被观察者）的某种变化高度敏感，需要在 B 变化的一瞬间做出反应。 举个例子，新闻里喜闻乐见的警察抓小偷，警察需要在小偷伸手作案的时候实施抓捕。在这个例子里，警察是观察者，小偷是被观察者，警察需要时刻盯着小偷的一举一动，才能保证不会漏过任何瞬间。 程序的观察者模式略有不同，观察者不需要时刻盯着被观察者（例如 A 不需要每过 2ms 就检查一次 B 的状态），而是采用注册( Register )或者称为订阅(Subscribe)的方式，告诉被观察者：我需要你的某种状态，你要在它变化的时候通知我。 采取这样被动的观察方式，既省去了反复检索状态的资源消耗，也能够得到最高的反馈速度。 Android 开发中一个典型的例子是点击监听器 OnClickListener 。对设置 OnClickListener 来说，View 是被观察者，OnClickListener 是观察者，二者通过 setOnClickListener() 方法达成订阅关系。订阅之后用户点击按钮的瞬间，Android Framework 就会将点击事件发送给已注册的 OnClickListener 。 OnClickListener 的观察者模式大致如下图： 如图所示，通过 setOnClickListener() 方法，Button 持有 OnClickListener 的引用（这一过程没有在图上画出）。当用户点击时，Button 自动调用 OnClickListener 的 onClick() 方法。 按照观察者模式抽象出来的各个概念： Button: 被观察者 OnClickListener: 观察者 setOnClickListener(): 订阅 onClick(): 事件处理 就由专用的观察者模式转变成了通用的观察者模式，如下图： 3.2. RxJava的观察者模式RxJava 有四个基本概念： Observable: 可观察者，即被观察者 Observer: 观察者 Subscribe: 订阅 Event: 事件处理 Observable 和 Observer 通过 subscribe() 方法实现订阅关系，使得Observable 可以在需要的时候发出事件来通知 Observer。 与传统观察者模式不同，RxJava 的事件回调方法除了普通事件 onNext() （相当于 onClick()) 之外，还定义了两个特殊的事件：onCompleted() 和 onError()。 onCompleted(): 事件队列完结 RxJava 不仅把每个事件单独处理，还会把它们看做一个队列。RxJava规定，当不会再有新的 onNext() 发出时，需要触发 onCompleted() 方法作为事件完成标志。 onError(): 事件队列异常 在事件处理过程中出异常时，onError() 会被触发，同时队列自动终止，不允许再有事件发出。 在一个正确运行的事件序列中, onCompleted() 和 onError() 有且只有一个被调用，并且是事件序列中的最后一个执行。 RxJava 的观察者模式大致如下图： 4. RxJava的基本使用基于以上的概念，RxJava 的基本使用有 3 个步骤： 4.1. 创建ObseverObserver 即观察者，它决定事件触发的时候将有怎样的行为。 RxJava 中的 Observer 接口的声明方式： 12345678910111213141516Observer&lt;String&gt; observer = new Observer&lt;String&gt;() &#123; @Override public void onNext(String s) &#123; Log.d(tag, \"Item: \" + s); &#125; @Override public void onCompleted() &#123; Log.d(tag, \"Completed!\"); &#125; @Override public void onError(Throwable e) &#123; Log.d(tag, \"Error: \" + e.getMessage()); &#125;&#125;; 除了 Observer 接口之外，RxJava 还内置了一个实现了 Observer 的抽象类：Subscriber。 Subscriber 对 Observer 接口进行了一些扩展，但他们的基本使用方式是完全一样的： 12345678910111213141516Subscriber&lt;String&gt; subscriber = new Subscriber&lt;String&gt;() &#123; @Override public void onNext(String s) &#123; Log.d(tag, \"Item: \" + s); &#125; @Override public void onCompleted() &#123; Log.d(tag, \"Completed!\"); &#125; @Override public void onError(Throwable e) &#123; Log.d(tag, \"Error: \" + e.getMessage()); &#125;&#125;; 实质上，在 RxJava 的 subscribe 过程中，Observer 也总是会先被转换成一个 Subscriber 再使用。所以如果你只想使用基本功能，选择 Observer 和 Subscriber 是完全一样的。它们的区别对于使用者来说主要有两点： onStart() 这是 Subscriber 增加的方法。它会在 subscribe 刚开始，而事件还未发送之前被调用。可以用于做一些准备工作，例如数据的清零或重置。这是一个可选方法，默认情况下它的实现为空。 需要注意的是，如果对准备工作的线程有要求（例如: 弹出一个显示进度的对话框，这必须在主线程执行），onStart() 就不适用了。因为它总是在 subscribe 所发生的线程被调用，而不能指定线程。要在指定的线程来做准备工作，可以使用 doOnSubscribe() 方法，具体可以在后面的章节中看到。 unsubscribe() 这是 Subscriber 所实现的另一个接口 Subscription 的方法，用于取消订阅。在这个方法被调用后，Subscriber 将不再接收事件。一般在这个方法调用前，可以使用 isUnsubscribed() 先判断一下状态。 unsubscribe() 这个方法很重要，因为在 subscribe() 之后， Observable 会持有 Subscriber 的引用。这个引用如果不能及时被释放，将有内存泄露的风险。 注意：在不再使用的时候尽快在合适的地方（例如: onPause() 和 onStop() 等方法中）调用 unsubscribe() 来解除引用关系，以避免内存泄露的发生。 4.2. 创建Obsevable4.2.1. Obsevable.create()Observable 即被观察者，它决定什么时候触发事件以及触发怎样的事件。 RxJava 使用 create() 方法来创建一个 Observable ，并为它定义事件触发规则。示例如下： 123456789Observable observable = Observable.create(new Observable.OnSubscribe&lt;String&gt;() &#123; @Override public void call(Subscriber&lt;? super String&gt; subscriber) &#123; subscriber.onNext(\"Hello\"); subscriber.onNext(\"Hi\"); subscriber.onNext(\"Aloha\"); subscriber.onCompleted(); &#125;&#125;); 可以看到，这里传入了一个 OnSubscribe 对象作为参数。OnSubscribe 会被存储在返回的 Observable 对象中。 它的作用相当于一个计划表，当 Observable 被订阅的时候，OnSubscribe 的 call() 方法会自动被调用，事件序列就会依照设定依次触发（对于上面的代码，就是观察者Subscriber 将会被调用三次 onNext() 和一次 onCompleted()）。 这样，由被观察者调用了观察者的回调方法，就实现了由被观察者向观察者的事件传递，即观察者模式。 4.2.2. Obsevable.just(T…)create() 方法是 RxJava 最基本的创建事件序列的方法。基于这个方法，RxJava 还提供了一些方法用于快捷创建事件队列，例如 just() 方法： 12Observable observable = Observable.just(\"Hello\", \"Hi\", \"Aloha\");// 将会依次调用方法序列：onNext(\"Hello\") -&gt; onNext(\"Hi\") -&gt; onCompleted() 4.2.3. Obsevable.from(T[])和from(Iterable&lt;? extends T&gt;)将传入的数组或 Iterable 拆分成具体对象后，依次发送给观察者，示例如下： 123String[] words = &#123;\"Hello\", \"Hi\", \"Aloha\"&#125;;Observable observable = Observable.from(words);// 将会依次调用方法序列：onNext(\"Hello\") -&gt; onNext(\"Hi\") -&gt; onCompleted() 4.3. Subscribe关联创建了 Observable 和 Observer 之后，再用 subscribe() 方法将它们关联起来，整条链子就可以工作了。代码很简单： 123observable.subscribe(observer);// 或者observable.subscribe(subscriber); 可能会注意到，subscribe() 这个方法有点怪：它看起来是『observable 订阅了 observer / subscriber』，而不是『observer / subscriber 订阅了 observable』。这看起来就像『杂志订阅了读者』一样颠倒了对象关系。 这让人读起来有点别扭，不过如果把 API 设计成 『observer.subscribe(observable) / subscriber.subscribe(observable)』，虽然更加符合思维逻辑，但对流式 API 的设计就造成影响了，比较起来明显是得不偿失的。 Observable.subscribe(Subscriber) 的内部实现是这样的(核心代码): 12345public Subscription subscribe(Subscriber subscriber) &#123; subscriber.onStart(); onSubscribe.call(subscriber); return subscriber;&#125; 可以看到subscriber() 做了3件事： (a). 调用Subscriber.onStart() 这个方法在前面已经介绍过，是一个可选的准备方法。 (b). 调用Observable中的OnSubscribe.call(Subscriber) 事件发送的逻辑开始运行。从这也可以看出，在RxJava中，Observable并不是在创建的时候就立即开始发送事件，而是在它被订阅的时候，即当subscribe()方法执行的时候。 (c). 返回Subscription 将传入的Subscriber作为Subscription返回。这是为了方便后面的unsubscribe()。 整个过程中对象间的关系如下图： 或者可以看动图： 除了 subscribe(Observer) 和 subscribe(Subscriber) ，subscribe() 还支持不完整定义的回调，RxJava 会自动根据定义创建出 Subscriber。形式如下： 12345678910111213141516171819202122232425262728Action1&lt;String&gt; onNextAction = new Action1&lt;String&gt;() &#123; // onNext() @Override public void call(String s) &#123; Log.d(tag, s); &#125;&#125;;Action1&lt;Throwable&gt; onErrorAction = new Action1&lt;Throwable&gt;() &#123; // onError() @Override public void call(Throwable throwable) &#123; // Error handling &#125;&#125;;Action0 onCompletedAction = new Action0() &#123; // onCompleted() @Override public void call() &#123; Log.d(tag, \"completed\"); &#125;&#125;;// 自动创建 Subscriber ，并使用 onNextAction 来定义 onNext()observable.subscribe(onNextAction);// 自动创建 Subscriber ，并使用 onNextAction 和 onErrorAction 来定义 onNext() 和 onError()observable.subscribe(onNextAction, onErrorAction);// 自动创建 Subscriber ，并使用 onNextAction、 onErrorAction 和 onCompletedAction 来定义 onNext()、 onError() 和 onCompleted()observable.subscribe(onNextAction, onErrorAction, onCompletedAction); 简单解释一下这段代码中出现的 Action1 和 Action0。 Action0 Action0 是 RxJava 的一个接口，它只有一个方法 call()，这个方法是无参无返回值的。由于 onCompleted() 方法也是无参无返回值的，因此 Action0 可以被当成一个包装对象，将 onCompleted() 的内容打包起来将自己作为一个参数传入 subscribe() 以实现不完整定义的回调。 Action1 Action1 也是一个接口，它同样只有一个方法 call(T param)，这个方法也无返回值，但有一个参数。与 Action0 同理，由于 onNext(T obj) 和 onError(Throwable error) 也是单参数无返回值的，因此 Action1 可以将 onNext(obj) 和 onError(error) 打包起来传入 subscribe() 以实现不完整定义的回调。 事实上，虽然 Action0 和 Action1 在 API 中使用最广泛，但 RxJava 提供了多个 ActionX 形式的接口 (例如: Action2, Action3)，它们可以被用以包装不同的无返回值的方法。 4.4. 场景示例4.4.1. 打印字符串数组将字符串数组 names 中的所有字符串依次打印出来： 12345678String[] names = ...;Observable.from(names) .subscribe(new Action1&lt;String&gt;() &#123; @Override public void call(String name) &#123; Log.d(tag, name); &#125; &#125;); 4.4.2. 由ID取得图片显示12345678910111213141516171819202122232425int drawableRes = ...;ImageView imageView = ...;Observable.create(new OnSubscribe&lt;Drawable&gt;() &#123; @Override public void call(Subscriber&lt;? super Drawable&gt; subscriber) &#123; Drawable drawable = getTheme().getDrawable(drawableRes)); subscriber.onNext(drawable); subscriber.onCompleted(); &#125;&#125;).subscribe(new Observer&lt;Drawable&gt;() &#123; @Override public void onNext(Drawable drawable) &#123; imageView.setImageDrawable(drawable); &#125; @Override public void onCompleted() &#123; &#125; @Override public void onError(Throwable e) &#123; Toast.makeText(activity, \"Error!\", Toast.LENGTH_SHORT).show(); &#125;&#125;); 正如上面两个例子这样，创建出 Observable 和 Subscriber，再用 subscribe() 将它们串起来，一次 RxJava 的基本使用就完成了，非常简单！ 然而。 小结在 RxJava 的默认规则中，事件的发出和消费都是在同一个线程的。也就是说，如果只用上面的方法，实现出来的只是一个同步的观察者模式。观察者模式本身的目的就是『后台处理，前台回调』的异步机制，因此异步对于 RxJava 是至关重要的。而要实现异步，则需要用到 RxJava 的另一个核心的概念 Scheduler，后续将给出详细介绍。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RxJava异步框架系列","slug":"RxJava异步框架系列","permalink":"https://ostenant.coding.me/categories/RxJava异步框架系列/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://ostenant.coding.me/tags/Android/"},{"name":"RxJava","slug":"RxJava","permalink":"https://ostenant.coding.me/tags/RxJava/"},{"name":"异步","slug":"异步","permalink":"https://ostenant.coding.me/tags/异步/"}]},{"title":"分布式唯一ID的几种生成方案","slug":"分布式唯一ID的几种生成方案","date":"2018-05-13T23:46:00.000Z","updated":"2018-05-14T06:04:56.491Z","comments":true,"path":"2018/05/14/分布式唯一ID的几种生成方案/","link":"","permalink":"https://ostenant.coding.me/2018/05/14/分布式唯一ID的几种生成方案/","excerpt":"前言在互联网的业务系统中，涉及到各种各样的ID，如在支付系统中就会有支付ID、退款ID等。那一般生成ID都有哪些解决方案呢？特别是在复杂的分布式系统业务场景中，我们应该采用哪种适合自己的解决方案是十分重要的。下面我们一一来列举一下，不一定全部适合，这些解决方案仅供你参考，或许对你有用。","text":"前言在互联网的业务系统中，涉及到各种各样的ID，如在支付系统中就会有支付ID、退款ID等。那一般生成ID都有哪些解决方案呢？特别是在复杂的分布式系统业务场景中，我们应该采用哪种适合自己的解决方案是十分重要的。下面我们一一来列举一下，不一定全部适合，这些解决方案仅供你参考，或许对你有用。 正文分布式ID的特性 唯一性：确保生成的ID是全网唯一的。 有序递增性：确保生成的ID是对于某个用户或者业务是按一定的数字有序递增的。 高可用性：确保任何时候都能正确的生成ID。 带时间：ID里面包含时间，一眼扫过去就知道哪天的交易。 分布式ID的生成方案1. UUID算法的核心思想是结合机器的网卡、当地时间、一个随记数来生成UUID。 优点：本地生成，生成简单，性能好，没有高可用风险 缺点：长度过长，存储冗余，且无序不可读，查询效率低 2. 数据库自增ID使用数据库的id自增策略，如 MySQL 的 auto_increment。并且可以使用两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。 优点：数据库生成的ID绝对有序，高可用实现方式简单 缺点：需要独立部署数据库实例，成本高，有性能瓶颈 3. 批量生成ID一次按需批量生成多个ID，每次生成都需要访问数据库，将数据库修改为最大的ID值，并在内存中记录当前值及最大值。 优点：避免了每次生成ID都要访问数据库并带来压力，提高性能 缺点：属于本地生成策略，存在单点故障，服务重启造成ID不连续 4. Redis生成IDRedis的所有命令操作都是单线程的，本身提供像 incr 和 increby 这样的自增原子命令，所以能保证生成的 ID 肯定是唯一有序的。 优点：不依赖于数据库，灵活方便，且性能优于数据库；数字ID天然排序，对分页或者需要排序的结果很有帮助。 缺点：如果系统中没有Redis，还需要引入新的组件，增加系统复杂度；需要编码和配置的工作量比较大。 考虑到单节点的性能瓶颈，可以使用 Redis 集群来获取更高的吞吐量。假如一个集群中有5台 Redis。可以初始化每台 Redis 的值分别是1, 2, 3, 4, 5，然后步长都是 5。各个 Redis 生成的 ID 为： 12345A：1, 6, 11, 16, 21B：2, 7, 12, 17, 22C：3, 8, 13, 18, 23D：4, 9, 14, 19, 24E：5, 10, 15, 20, 25 随便负载到哪个机确定好，未来很难做修改。步长和初始值一定需要事先确定。使用 Redis 集群也可以方式单点故障的问题。 另外，比较适合使用 Redis 来生成每天从0开始的流水号。比如订单号 = 日期 + 当日自增长号。可以每天在 Redis 中生成一个 Key ，使用 INCR 进行累加。 5. Twitter的snowflake算法Twitter 利用 zookeeper 实现了一个全局ID生成的服务 Snowflake：https://github.com/twitter/snowflake 如上图的所示，Twitter 的 Snowflake 算法由下面几部分组成： 1位符号位： 由于 long 类型在 java 中带符号的，最高位为符号位，正数为 0，负数为 1，且实际系统中所使用的ID一般都是正数，所以最高位为 0。 41位时间戳（毫秒级）： 需要注意的是此处的 41 位时间戳并非存储当前时间的时间戳，而是存储时间戳的差值（当前时间戳 - 起始时间戳），这里的起始时间戳一般是ID生成器开始使用的时间戳，由程序来指定，所以41位毫秒时间戳最多可以使用 (1 &lt;&lt; 41) / (1000x60x60x24x365) = 69年。 10位数据机器位： 包括5位数据标识位和5位机器标识位，这10位决定了分布式系统中最多可以部署 1 &lt;&lt; 10 = 1024 s个节点。超过这个数量，生成的ID就有可能会冲突。 12位毫秒内的序列： 这 12 位计数支持每个节点每毫秒（同一台机器，同一时刻）最多生成 1 &lt;&lt; 12 = 4096个ID 加起来刚好64位，为一个Long型。 优点：高性能，低延迟，按时间有序，一般不会造成ID碰撞 缺点：需要独立的开发和部署，依赖于机器的时钟 简单实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class IdWorker &#123; /** * 起始时间戳 2017-04-01 */ private final long epoch = 1491004800000L; /** * 机器ID所占的位数 */ private final long workerIdBits = 5L; /** * 数据标识ID所占的位数 */ private final long dataCenterIdBits = 5L; /** * 支持的最大机器ID,结果是31 */ private final long maxWorkerId = ~(-1L &lt;&lt; workerIdBits); /** * 支持的最大数据标识ID,结果是31 */ private final long maxDataCenterId = ~(-1 &lt;&lt; dataCenterIdBits); /** * 毫秒内序列在id中所占的位数 */ private final long sequenceBits = 12L; /** * 机器ID向左移12位 */ private final long workerIdShift = sequenceBits; /** * 数据标识ID向左移17(12+5)位 */ private final long dataCenterIdShift = sequenceBits + workerIdBits; /** * 时间戳向左移22(12+5+5)位 */ private final long timestampShift = sequenceBits + workerIdBits + dataCenterIdBits; /** * 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */ private final long sequenceMask = ~(-1L &lt;&lt; sequenceBits); /** * 数据标识ID（0～31） */ private long dataCenterId; /** * 机器ID（0～31） */ private long workerId; /** * 毫秒内序列（0～4095） */ private long sequence; /** * 上次生成ID的时间戳 */ private long lastTimestamp = -1L; public IdWorker(long dataCenterId, long workerId) &#123; if (dataCenterId &gt; maxDataCenterId || dataCenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"dataCenterId can't be greater than %d or less than 0\", maxDataCenterId)); &#125; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId)); &#125; this.dataCenterId = dataCenterId; this.workerId = workerId; &#125; /** * 获得下一个ID (该方法是线程安全的) * @return snowflakeId */ public synchronized long nextId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳,说明系统时钟回退过,这个时候应当抛出异常 if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException(String.format(\"Clock moved backwards. Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp)); &#125; //如果是同一时间生成的，则进行毫秒内序列 if (timestamp == lastTimestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; //毫秒内序列溢出 if (sequence == 0) &#123; //阻塞到下一个毫秒,获得新的时间戳 timestamp = nextMillis(lastTimestamp); &#125; &#125; else &#123;//时间戳改变，毫秒内序列重置 sequence = 0L; &#125; lastTimestamp = timestamp; //移位并通过按位或运算拼到一起组成64位的ID return ((timestamp - epoch) &lt;&lt; timestampShift) | (dataCenterId &lt;&lt; dataCenterIdShift) | (workerId &lt;&lt; workerIdShift) | sequence; &#125; /** * 返回以毫秒为单位的当前时间 * @return 当前时间(毫秒) */ protected long timeGen() &#123; return System.currentTimeMillis(); &#125; /** * 阻塞到下一个毫秒，直到获得新的时间戳 * @param lastTimestamp 上次生成ID的时间截 * @return 当前时间戳 */ protected long nextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = lastTimestamp; &#125; return timestamp; &#125; &#125; 6. 百度UidGeneratorUidGenerator是百度开源的分布式ID生成器，基于于snowflake算法的实现，看起来感觉还行。不过，国内开源的项目维护性真是担忧。 具体可以参考官网说明：https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md 7. 美团LeafLeaf 是美团开源的分布式ID生成器，能保证全局唯一性、趋势递增、单调递增、信息安全，里面也提到了几种分布式方案的对比，但也需要依赖关系数据库、Zookeeper等中间件。 具体可以参考官网说明：https://tech.meituan.com/MT_Leaf.html 小结这篇文章和大家分享了全局id生成服务的几种常用方案，同时对比了各自的优缺点和适用场景。在实际工作中，大家可以结合自身业务和系统架构体系进行合理选型。 欢迎扫码关注公众号：零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"Unique ID","slug":"Unique-ID","permalink":"https://ostenant.coding.me/tags/Unique-ID/"}]},{"title":"蚂蚁金服SOFA-Boot整合SOFA-RPC(下篇)","slug":"蚂蚁金服SOFA-Boot整合SOFA-RPC(下篇)","date":"2018-05-12T12:12:00.000Z","updated":"2018-05-12T15:18:18.458Z","comments":true,"path":"2018/05/12/蚂蚁金服SOFA-Boot整合SOFA-RPC(下篇)/","link":"","permalink":"https://ostenant.coding.me/2018/05/12/蚂蚁金服SOFA-Boot整合SOFA-RPC(下篇)/","excerpt":"前言上文介绍了SOFA-RPC 的几种调用方式，包括单向调用、同步调用、Future调用、回调，引入了泛化调用和过滤器。本文将对 SOFA-RPC 的高级功能，包括参数配置、自定义线程池、预热权重和自动故障剔除等。","text":"前言上文介绍了SOFA-RPC 的几种调用方式，包括单向调用、同步调用、Future调用、回调，引入了泛化调用和过滤器。本文将对 SOFA-RPC 的高级功能，包括参数配置、自定义线程池、预热权重和自动故障剔除等。 正文1. 参数配置SOFABoot RPC Starter 提供了方便的参数设置方式。这些参数目前可以分为两个部分。一部分是如端口，注册中心地址等配置，这类配置在 application.properties 中。另一部分是如超时时间等配置，这类配置在 XML 中。 XML 配置 调用超时时间 如下是设置超时时间的方式，单位为 ms ，如果调用超过了这个时间则会抛出异常。服务端和客户端都可以设置，以客户端的超时时间设置优先。默认客户端为 3000 ，目前对 bolt，rest，dubbo 生效。 123&lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs timeout=\"5000\"/&gt;&lt;/sofa:binding.bolt&gt; 获取地址等待时间 如下是设置获取地址等待时间，单位为ms。在启动时如果服务引用方等待超过了这个时间则不会再等待地址，会继续启动。客户端设置，默认为-1，表示会一直等待到地址为止。目前对 bolt，rest 生效。 123&lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs address-wait-time=\"30000\"/&gt;&lt;/sofa:binding.bolt&gt; 建立连接超时时间 如下是设置建立连接超时时间，单位为 ms 。在建立连接时如果耗时超过了这个时间则会抛出异常。客户端设，默认为 5000。目前对 bolt，rest 生效。 123&lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs connect.timeout=\"30000\"&lt;/sofa:binding.bolt&gt; 权重 如下是设置权重。客户端在发起调用时，如果采用的算法是随机调用，则会根据该权重来进行随机。服务端设置，默认为 100。目前对 bolt 生效。 123&lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs weight=\"200\"/&gt;&lt;/sofa:binding.bolt&gt; lazy 连接 默认情况下客户端在注册中心推送地址到客户端时，就立即建立好连接，这个过程通常是在第一次调用之前进行的。如果设置服务引用的属性 lazy 为 true，客户端在第一次调用时才和所要调用的远程地址建立连接。默认为 false。 如下设置 lazy 连接方式，将 lazy 属性设为 true。目前支持 bolt 和 dubbo 协议。 12345&lt;sofa:reference id=\"lazyServiceReferenceBolt\" interface=\"com.ostenant.sofa.rpc.example.lazy.LazyService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs lazy=\"true\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; check 属性 默认情况下客户端在启动时，服务引用不要求存在可用的地址和连接。如果设置服务引用的属性 check 为 true，客户端在启动时，服务引用会检查是否存在对应的地址和连接，如果不存在会抛出异常。默认为 false。 如下设置 check 连接方式，将 check 属性设为 true。目前支持 bolt 和 dubbo 协议。 12345&lt;sofa:reference id=\"checkServiceReferenceBolt\" interface=\"com.ostenant.sofa.rpc.example.check.CheckService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs check=\"true\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 重试次数 重试次数，即在第一次调用失败后重试的最大次数，如果重试成功则不再继续重试。默认为 0。如下设置调用次数，利用 retries 属性指定重试次数。目前支持 bolt 和 dubbo 协议。 12345&lt;sofa:reference id=\"retriesServiceReferenceBolt\" interface=\"com.ostenant.sofa.rpc.example.retries.RetriesService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs retries=\"2\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 负载均衡 如下选择负载均衡的方式，利用 loadBalancer 属性指定调用时候使用的负载均衡策略，默认为 random。 目前支持 random，localPref，roundRobin，consistentHash，weightRoundRobin 五种负载均衡策略，具体可见 SOFARPC 负载均衡相关介绍。目前支持bolt协议。 12345&lt;sofa:reference id=\"loadBalancerServiceReference\" interface=\"com.ostenant.sofa.rpc.example.loadBalancer.LoadBalancerService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs loadBalancer=\"random\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 方法级别配置 如下，sofa:method 元素是方法级别的配置。方法级别的配置优先级比服务级别的更高。name 属性指定了方法的名字。支持调用超时时间，调用方式，回调类的设置。方法级别的配置与服务级别的配置所生效的协议一样。 123&lt;sofa:binding.bolt&gt; &lt;sofa:method name=\"sayMethod\" timeout=\"3000\" type=\"sync\" callback-ref=\"xxx\"/&gt;&lt;/sofa:binding.bolt&gt; Properties 配置 属性 描述 默认值 spring.application.name 应用名 logging.path 日志路径 logging.level.com.alipay.sofa.rpc.boot sofa-rpc-boot-start的日志级别(starter自身的日志) info logging.level.com.alipay.sofa.rpc sofa-rpc的日志级别(sofa-rpc核心日志基本在这里) info com.alipay.sofa.rpc.bolt.port bolt 端口 22000 com.alipay.sofa.rpc.bolt.io.thread.count bolt 的 io 线程数 com.alipay.sofa.rpc.bolt.executor.thread.count bolt 的业务线程最大值 200 com.alipay.sofa.rpc.bolt.accepts.count bolt 能够支持的最大长连接数 100000 com.alipay.sofa.rpc.rest.hostname rest 的 hostname com.alipay.sofa.rpc.rest.port rest 端口 8341 com.alipay.sofa.rpc.rest.io.thread.count rest 的 io 线程数 cpu 核数 * 2 com.alipay.sofa.rpc.rest.executor.thread.count rest 的业务线程数 200 com.alipay.sofa.rpc.rest.max.request.size rest 的最大 byte 请求长度 1024 1024 10 com.alipay.sofa.rpc.rest.telnet rest 是否支持 telnet true com.alipay.sofa.rpc.rest.daemon rest 是否支持 daemon true com.alipay.sofa.rpc.dubbo.port dubbo 的端口 20880 com.alipay.sofa.rpc.dubbo.io.thread.count dubbo 的 io 线程数 cpu 核数 + 1 com.alipay.sofa.rpc.dubbo.executor.thread.count dubbo 的业务线程数 100 com.alipay.sofa.rpc.dubbo.accepts.count dubbo能够支持的最大长连接数 0，表示不限制 2. 自定义线程池SOFA-RPC 支持自定义业务线程池。可以为指定服务设置一个独立的业务线程池，和 SOFA-RPC 自身的业务线程池是隔离的，多个服务可以共用一个独立的线程池。目前支持 bolt 协议。 在 SOFA-Boot 环境中可以为一个服务设置一个自定义线程池，配置如下： 声明自定义线程池 如下声明一个自定义线程池，class 必须为 com.alipay.sofa.rpc.server.UserThreadPool，这是 SOFA-RPC 提供的类，init-method=&quot;init&quot; 也必须声明以进行初始化。 123456&lt;bean id=\"customerThreadPool\" class=\"com.alipay.sofa.rpc.server.UserThreadPool\" init-method=\"init\"&gt; &lt;property name=\"corePoolSize\" value=\"10\"/&gt; &lt;property name=\"maximumPoolSize\" value=\"10\"/&gt; &lt;property name=\"queueSize\" value=\"5\"/&gt; &lt;property name=\"threadPoolName\" value=\"customerThreadPool_name\"/&gt;&lt;/bean&gt; 为服务设置自定义线程池 如下通过 sofa:global-attrs 元素的 thread-pool-ref 属性为该服务设置自定义线程池。customerThreadPool 是上面自定义线程池的 bean id。 123456&lt;bean id=\"threadPoolServiceImpl\" class=\"com.ostenant.sofa.rpc.example.threadpool.ThreadPoolServiceImpl\"/&gt;&lt;sofa:service ref=\"threadPoolServiceImpl\" interface=\"com.alipay.sofa.rpc.samples.threadpool.ThreadPoolService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs thread-pool-ref=\"customerThreadPool\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:service&gt; 3. 预热权重SOFA-RPC 提供了预热权重功能让客户端机器能够根据服务端的相应权重进行流量的分发。目前支持 bolt 协议。 SOFA-Boot 中提供了一系列参数属性，对指定服务进行预热配置。客户端机器能够自动解析这些参数，并按权重进行流量分发。 warm-up-time: 服务的预热时间 warm-up-weight: 服务设置预热期间权重 weight: 服务设置预热完后的权重 12345&lt;sofa:reference id=\"sampleRestFacadeReferenceBolt\" interface=\"com.alipay.sofa.endpoint.facade.SampleFacade\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs warm-up-time=\"10000\" warm-up-weight=\"10\" weight=\"100\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 上述配置中，该服务的预热期为10s，在预热期内权重为10，预热期结束后的正常权重为100。 如果该服务一共发布到A，B两个机器上。\bA机器正处于预热期内，使用上述配置；B已经完成预热，正常权重为200。那么客户端在调用的时候，此时流量分发的比重为10：200；A机器预热结束后，流量分发比重为100：200。 4. 自动故障剔除自动故障剔除会自动监控 RPC 调用的情况，对故障节点进行权重降级，并在节点恢复健康时进行权重恢复。目前支持 bolt 协议。 在 SOFA-Boot 中，只需要将自动故障剔除的参数配置到 application.properties 即可。只配置自己关心的参数，其余参数会取默认值。需要注意的是，rpc.aft.regulation.effective 是该功能的全局开关，如果关闭则该功能不会运行，其他参数也都不生效。 自动故障剔除的配置参数意义 属性 描述 默认值 com.alipay.sofa.rpc.aft.time.window 时间窗口大小：对统计信息计算的周期。 10s com.alipay.sofa.rpc.aft.least.window.count 时间窗口内最少调用数：只有在时间窗口内达到了该最低值的数据才会被加入到计算和调控中。 10次 com.alipay.sofa.rpc.aft.least.window.exception.rate.multiple 时间窗口内异常率与服务平均异常率的降级比值：在对统计信息进行计算的时候，会计算出该服务所有有效调用ip的平均异常率，如果某个ip的异常率大于等于了这个最低比值，则会被降级。 6倍 com.alipay.sofa.rpc.aft.weight.degrade.rate 降级比率：地址在进行权重降级时的降级比率。 1/20 com.alipay.sofa.rpc.aft.weight.recover.rate 恢复比率：地址在进行权重恢复时的恢复比率。 2倍 com.alipay.sofa.rpc.aft.degrade.effective 降级开关：如果应用打开了这个开关，则会对符合降级的地址进行降级，否则只会进行日志打印。 false(关闭) com.alipay.sofa.rpc.aft.degrade.least.weight 降级最小权重：地址权重被降级后的值如果小于这个最小权重，则会以该最小权重作为降级后的值。 0 com.alipay.sofa.rpc.aft.degrade.max.ip.count 降级的最大ip数：同一个服务被降级的ip数不能超过该值。 2 com.alipay.sofa.rpc.aft.regulation.effective 全局开关：如果应用打开了这个开关，则会开启整个单点故障自动剔除摘除功能，否则完全不进入该功能的逻辑。 false(关闭) 配置示例 123456789com.alipay.sofa.rpc.aft.time.window=20com.alipay.sofa.rpc.aft.least.window.count=30com.alipay.sofa.rpc.aft.least.window.exception.rate.multiple=6com.alipay.sofa.rpc.aft.weight.degrade.rate=0.5com.alipay.sofa.rpc.aft.weight.recover.rate=1.2com.alipay.sofa.rpc.aft.degrade.effective=turecom.alipay.sofa.rpc.aft.degrade.least.weight=1com.alipay.sofa.rpc.aft.degrade.max.ip.count=2com.alipay.sofa.rpc.aft.regulation.effective=true 上述配置中，默认打开了自动故障剔除功能和降级开关。当节点出现故障时会被进行权重降级，在恢复时会被进行权重恢复。 每隔 20s 进行一次节点健康状态的度量，20s 内调用次数超过 30 次的节点才被作为计算数据。 如果单个节点的异常率超过了所有节点的平均异常率的 6 倍，则对该节点进行权重降级，降级的比率为 0.5。权重最小降级到 1。如果单个节点的异常率低于了平均异常率的 6 倍，则对该节点进行权重恢复，恢复的比率为1.2。单个服务最多降级 2 个 IP。 小结本文介绍了 SOFA-RPC 的\b高级功能，包括参数配置，自定义线程池，服务预热和自动降级与权重恢复等用法。对于 SOFA-RPC \b提供的基本功能，以及整合 SOFA-Boot 的配置和用法就介绍完了。对此有了初步的认识后，有利于后续深入实现原理和\b剖析源码。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"SOFA-Boot","slug":"SOFA-Boot","permalink":"https://ostenant.coding.me/tags/SOFA-Boot/"},{"name":"SOFA_RPC","slug":"SOFA-RPC","permalink":"https://ostenant.coding.me/tags/SOFA-RPC/"}]},{"title":"蚂蚁金服SOFA-Boot整合SOFA-RPC(中篇)","slug":"蚂蚁金服SOFA-Boot整合SOFA-RPC(中篇)","date":"2018-05-09T07:08:00.000Z","updated":"2018-05-10T07:36:51.543Z","comments":true,"path":"2018/05/09/蚂蚁金服SOFA-Boot整合SOFA-RPC(中篇)/","link":"","permalink":"https://ostenant.coding.me/2018/05/09/蚂蚁金服SOFA-Boot整合SOFA-RPC(中篇)/","excerpt":"前言上篇文章简单地介绍了 SOFA-Boot 的功能特性，对 Readiness 健康检查的配置举例说明。重点介绍了如何在 SOFA-Boot 中引入 SOFA-RPC 中间件，给出了基于 bolt、rest 和 dubbo 等不同协议通道的服务发布与消费的全流程。","text":"前言上篇文章简单地介绍了 SOFA-Boot 的功能特性，对 Readiness 健康检查的配置举例说明。重点介绍了如何在 SOFA-Boot 中引入 SOFA-RPC 中间件，给出了基于 bolt、rest 和 dubbo 等不同协议通道的服务发布与消费的全流程。 本文将进一步介绍 SOFA-RPC 中间件提供的丰富而强大的功能，包括单向调用、同步调用、Future调用、回调，泛化调用，过滤器配置等。 正文1. 调用方式SOFA-RPC \b提供单向调用、同步调用、异步调用和回调四种调用机制。\b为了区分\b四者的不同\b之处，这里给出 SOFA 官方提供的原理图。 下面\b给出详细\b阐述和配置说明： 1.1. 单向方式当前线程发起调用后，不关心调用结果，不做超时控制，只要请求已经发出，就完成本次调用。目前支持 bolt 协议。 配置说明使用单向方式需要在服务引用的时候通过 sofa:global-attrs 元素的 type 属性声明调用方式为 oneway ，这样使用该服务引用发起调用时就是使用的单向方式了。 12345&lt;sofa:reference id=\"helloOneWayServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloOneWayService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs type=\"oneway\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 适用场景单向调用不保证成功，而且发起方无法知道调用结果。因此通常用于可以重试，或者定时通知类的场景，调用过程是有可能因为网络问题，机器故障等原因，导致请求失败。业务场景需要能接受这样的异常场景，才可以使用。 1.2. 同步方式当前线程发起调用后，需要在指定的超时时间内，等到响应结果，才能完成本次调用。如果超时时间内没有得到结果，那么会抛出超时异常。 配置说明服务接口与实现类\b SOFA-RPC 缺省采用的就是同步调用，可以省略 sofa:global-attrs 配置项。 \b服务端发布配置 1234&lt;bean id=\"helloSyncServiceImpl\" class=\"com.ostenant.sofa.rpc.example.invoke.HelloSyncServiceImpl\"/&gt;&lt;sofa:service ref=\"helloSyncServiceImpl\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloSyncService\"&gt; &lt;sofa:binding.bolt/&gt;&lt;/sofa:service&gt; 客户端引用配置\b 123&lt;sofa:reference id=\"helloSyncServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloSyncService\"&gt; &lt;sofa:binding.bolt/&gt;&lt;/sofa:reference&gt; 服务端启动入口 12SpringApplication springApplication = new SpringApplication(SyncServerApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端启动入口 12SpringApplication springApplication = new SpringApplication(SyncClientApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端调用 12HelloSyncService helloSyncServiceReference = (HelloSyncService) applicationContext.getBean(\"helloSyncServiceReference\");System.out.println(helloSyncServiceReference.saySync(\"sync\")); 适用场景同步调用是最常用的方式。注意要根据对端的处理能力，合理设置超时时间。 1.3. Future方式Future 方式下，客户端发起调用后不会等待服务端的结果，继续执行后面的业务逻辑。服务端返回的结果会被 SOFA-RPC 缓存，当客户端需要结果的时候，需要主动获取。目前支持 bolt 协议。 配置说明服务接口和实现类 HelloFutureService.java 123public interface HelloFutureService &#123; String sayFuture(String future);&#125; HelloFutureServiceImpl.java 123456public class HelloFutureServiceImpl implements HelloFutureService &#123; @Override public String sayFuture(String future) &#123; return future; &#125;&#125; 服务端发布配置 1234&lt;bean id=\"helloFutureServiceImpl\" class=\"com.ostenant.sofa.rpc.example.invoke.HelloFutureServiceImpl\"/&gt;&lt;sofa:service ref=\"helloFutureServiceImpl\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloFutureService\"&gt; &lt;sofa:binding.bolt/&gt;&lt;/sofa:service&gt; 客户端引用配置 使用 Future 方式需要在服务引用的时候通过 sofa:global-attrs 元素的 type 属性声明调用方式为 future。 12345&lt;sofa:reference id=\"helloFutureServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloFutureService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs type=\"future\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 这样使用该服务引用发起调用时就是使用的 Future 方式了。 服务端启动入口 12SpringApplication springApplication = new SpringApplication(FutureServerApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端启动入口 12SpringApplication springApplication = new SpringApplication(FutureClientApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端获取返回结果有两种方式： 其一，通过 SofaResponseFuture 直接获取结果。第一个参数是获取结果的超时时间，第二个参数表示是否清除线程上下文中的结果。 12345678910HelloFutureService helloFutureServiceReference = (HelloFutureService) applicationContext .getBean(\"helloFutureServiceReference\");helloFutureServiceReference.sayFuture(\"future\");try &#123; String result = (String)SofaResponseFuture.getResponse(1000, true); System.out.println(\"Future result: \" + result)&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; 其二，获取原生 Future。该种方式会获取 JDK 原生的 Future ，参数表示是否清除线程上下文中的结果。获取结果的方式就是 JDK Future 的获取方式。 1234567891011HelloFutureService helloFutureServiceReference = (HelloFutureService) applicationContext .getBean(\"helloFutureServiceReference\");helloFutureServiceReference.sayFuture(\"future\");try &#123; Future future = SofaResponseFuture.getFuture(true); String result = (String)future.get(1000, TimeUnit.MILLISECONDS); System.out.println(\"Future result: \" + result)&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; 适用场景Future 方式适用于非阻塞\b编程模式。对于客户端程序处理后，不需要\b立即获取返回结果，可以先完成后续程序代码执行，在后续业务中，主动从当前线程上下文获取调用返回结果。减少了网络 IO\b 等待造成的代码运行阻塞和延迟。 1.4. 回调方式当前线程发起调用，则本次调用马上结束，可以马上执行下一次调用。发起调用时需要注册一个回调，该回调需要分配一个异步线程池。待响应返回后，会在回调的异步线程池，来执行回调逻辑。 \b配置说明服务接口和实现类 HelloCallbackService.java 123public interface HelloCallbackService &#123; String sayCallback(String callback);&#125; HelloCallbackServiceImpl.java 123456public class HelloCallbackServiceImpl implements HelloCallbackService &#123; @Override public String sayCallback(String string) &#123; return string; &#125;&#125; 业务回调类 客户端回调类需要实现 com.alipay.sofa.rpc.core.invoke.SofaResponseCallback 接口。 CallbackImpl.java 1234567891011121314public class CallbackImpl implements SofaResponseCallback &#123; @Override public void onAppResponse(Object appResponse, String methodName, RequestBase request) &#123; System.out.println(\"callback client process:\" + appResponse); &#125; @Override public void onAppException(Throwable throwable, String methodName, RequestBase request) &#123; &#125; @Override public void onSofaException(SofaRpcException sofaException, String methodName, RequestBase request) &#123; &#125;&#125; SofaResponseCallback 接口提供了 3 个方法： onAppResponse: \b程序正常运行，则进入该回调方法。 onAppException: 服务端程序抛出异常，则进入\b该回调方法。 onSofaException: 框架内部出现错误，则进入该回调方法。 服务端发布配置 1234&lt;bean id=\"helloCallbackServiceImpl\" class=\"helloFutureServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloCallbackServiceImpl\"/&gt;&lt;sofa:service ref=\"helloCallbackServiceImpl\" interface=\"helloFutureServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloCallbackService\"&gt; &lt;sofa:binding.bolt/&gt;&lt;/sofa:service&gt; 客户端引用配置 在服务引用的时候通过 sofa:global-attrs 元素的 type 属性声明调用方式为 callback ，再通过 callback-ref 声明回调的实现类。 1234567&lt;bean id=\"callbackImpl\" class=\"com.ostenant.sofa.rpc.example.invoke.CallbackImpl\"/&gt;&lt;sofa:reference id=\"helloCallbackServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloCallbackService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs type=\"callback\" callback-ref=\"callbackImpl\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 这样使用该服务引用发起调用时，就是使用的回调方式了。在结果返回时，由 SOFA-RPC 自动调用该回调类的相应方法。 服务端启动入口 12SpringApplication springApplication = new SpringApplication(CallbackServerApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端启动入口 12SpringApplication springApplication = new SpringApplication(CallbackClientApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端发起调用 123456789HelloCallbackService helloCallbackServiceReference = (HelloCallbackService) applicationContext .getBean(\"helloCallbackServiceReference\");helloCallbackServiceReference.sayCallback(\"callback\");try &#123; Thread.sleep(3000);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; sayCallback() 的返回值不应该直接获取。在客户端注册的回调类中，返回值会以参数的形式传入正确的方法，\b以回调的形式\b完成后续逻辑处理。 适用场景Callback 方式适用于异步非阻塞\b编程模式。客户端\u001d程序所在线程发起调用后，\b继续执行后续操作，\b不需要主动去获取返回值。服务端程序处理完成，将返回值传回一个\b异步线程池，由子线程通过\b回调函数进行\b返回值处理。\b很大情况的减少了网络 IO 阻塞，解决了单线程的瓶颈，\b实现了异步编程。 2. 泛化调用泛化调用方式能够在客户端不依赖服务端的接口情况下发起调用，目前支持 bolt 协议。由于不知道服务端的接口，因此需要通过字符串的方式将服务端的接口，调用的方法，参数及结果类进行描述。 配置说明泛化参数类\b SampleGenericParamModel.java 123456789public class SampleGenericParamModel &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 泛化返回类 SampleGenericResultModel.java 12345678910111213141516public class SampleGenericResultModel &#123; private String name; private String value; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125;&#125; 服务接口和实现类 SampleGenericService.java 123public interface SampleGenericService &#123; SampleGenericResultModel sayGeneric(SampleGenericParamModel sampleGenericParamModel);&#125; SampleGenericParamModel：作为 sayGeneric() 的\b\b输入参数类型，有一个 name 成员变量，作为真正的方法入参。 SampleGenericResultModel：作为 sayGeneric() 的返回结果类型，\b声明了 name 和 value 两个成员变量，作为真实的返回值。 SampleGenericServiceImpl.java 12345678910public class SampleGenericServiceImpl implements SampleGenericService &#123; @Override public SampleGenericResultModel sayGeneric(SampleGenericParamModel sampleGenericParamModel) &#123; String name = sampleGenericParamModel.getName(); SampleGenericResultModel resultModel = new SampleGenericResultModel(); resultModel.setName(name); resultModel.setValue(\"sample generic value\"); return resultModel; &#125;&#125; 服务端发布配置 1234&lt;bean id=\"sampleGenericServiceImpl\" class=\"com.ostenant.sofa.rpc.example.generic.SampleGenericServiceImpl\"/&gt;&lt;sofa:service ref=\"sampleGenericServiceImpl\" interface=\"com.ostenant.sofa.rpc.example.generic.SampleGenericService\"&gt; &lt;sofa:binding.bolt/&gt;&lt;/sofa:service&gt; 客户端引用配置 12345&lt;sofa:reference id=\"sampleGenericServiceReference\" interface=\"com.alipay.sofa.rpc.api.GenericService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs generic-interface=\"com.ostenant.sofa.rpc.example.generic.SampleGenericService\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 在泛化调用过程中，客户端配置有两点需要注意： sofa:reference 指向的服务接口\b需要声明为 SOFA-RPC 提供的泛化接口 com.alipay.sofa.rpc.api.GenericService。 sofa:global-attrs 需要声明属性 generic-interface，value 为\b真实的服务接口名称。 服务端启动入口 12SpringApplication springApplication = new SpringApplication(SampleGenericServerApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端启动入口 12SpringApplication springApplication = new SpringApplication(SampleGenericClientApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端发起调用 获取服务的泛化引用 12GenericService sampleGenericServiceReference = (GenericService) applicationContext .getBean(\"sampleGenericServiceReference\"); 准备方法参数 由于客户端没有调用服务的参数类，因此通过 com.alipay.hessian.generic.model.GenericObjectGenericObject 进行描述。 1234// 准备方法参数GenericObject generic\bParam = new GenericObject( \"com.ostenant.sofa.rpc.example.generic.SampleGenericParamModel\");generic\bParam.putField(\"name\", \"Harrison\"); GenericObject 持有一个 Map&lt;String, Object&gt; 类型的变量，你能够通过 GenericObject 提供的 putField() 方法，将参数类的属性和值放到这个 Map 中，以此来描述参数类。 发起泛化调用 通过 GenericService 的 $genericInvoke(arg1, agr2, arg3) 方法可以发起服务的泛化调用，各个参数含义如下： 参数 含义 参数可选 arg1 目标方法名称 \b必填 arg2 参数类型的数组，要求\b严格遵循先后次序 必填 arg3 参数值的数组，要求与参数类型数组保持一致 必填 arg4 返回值的Class类型 可选 方式一： 123456789101112GenericObject genericResult = (GenericObject) sampleGenericServiceReference.$genericInvoke( // 目标方法名称 \"sayGeneric\", // 参数类型名称 new String[] &#123; \"com.ostenant.sofa.rpc.example.generic.SampleGenericParamModel\" &#125;, // \b参数\b的值 new Object[] &#123; generic\bParam &#125;);// 验证返回结果System.out.println(\"Type: \" + genericResult.getType());System.out.println(\"Name: \" + genericResult.getField(\"name\"));System.out.println(\"Value: \" + genericResult.getField(\"value\")); 方式二： 1234567891011121314SampleGenericResultModel sampleGenericResult = sampleGenericServiceReference.$genericInvoke( // 目标方法名称 \"sayGeneric\", // 参数类型名称 new String[] &#123; \"com.ostenant.sofa.rpc.example.generic.SampleGenericParamModel\" &#125;, // 参数\b的值 new Object[] &#123; genericParam &#125;, // 返回值的Class类型 SampleGenericResultModel.class);// 验证返回结果System.out.println(\"Type: \" + sampleGenericResult.getClass().getName());System.out.println(\"Name: \" + sampleGenericResult.getName());System.out.println(\"Value: \" + sampleGenericResult.getValue()); 查看控制台输出 两种方式输出如下： 123Type: com.ostenant.sofa.rpc.example.generic.SampleGenericResultModelName: HarrisonValue: sample generic value 3. 过滤器配置SOFA-RPC 通过过滤器 Filter 来实现对请求和响应的拦截处理。用户可以自定义 Filter 实现拦截扩展，目前支持 bolt 协议。开发人员通过继承 com.alipay.sofa.rpc.filter.Filter 实现过滤器的自定义。 配置说明服务接口与实现类\b FilterService.java 123public interface FilterService &#123; String sayFilter(String filter);&#125; FilterServiceImpl.java 123456public class FilterServiceImpl implements FilterService &#123; @Override public String sayFilter(String filter) &#123; return filters; &#125;&#125; 服务端过滤器 在 Filter 实现类中，invoke() 方法实现具体的拦截逻辑，通过 FilterInvoker.invoke(SofaRequest) 触发服务的调用，在该方法前后可以实现具体的拦截处理。\b 1234567891011public class SampleServerFilter extends Filter &#123; @Override public SofaResponse invoke(FilterInvoker invoker, SofaRequest request) throws SofaRpcException &#123; System.out.println(\"SampleFilter before server process\"); try &#123; return invoker.invoke(request); &#125; finally &#123; System.out.println(\"SampleFilter after server process\"); &#125; &#125;&#125; 服务端发布配置 服务端需要配置服务实现类、过滤器，\b然后在 sofa:service 的 sofa:global-attrs 标签配置 filter 属性，实现两者的绑定。 1234567&lt;bean id=\"sampleFilter\" class=\"com.ostenant.sofa.rpc.example.filter.SampleServerFilter\"/&gt;&lt;bean id=\"filterService\" class=\"com.ostenant.sofa.rpc.example.filter.FilterServiceImpl\"/&gt;&lt;sofa:service ref=\"filterService\" interface=\"com.ostenant.sofa.rpc.example.filter.FilterService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs filter=\"sampleFilter\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:service&gt; 客户端过滤器 1234567891011public class SampleClientFilter extends Filter &#123; @Override public SofaResponse invoke(FilterInvoker invoker, SofaRequest request) throws SofaRpcException &#123; System.out.println(\"SampleFilter before client invoke\"); try &#123; return invoker.invoke(request); &#125; finally &#123; System.out.println(\"SampleFilter after client invoke\"); &#125; &#125;&#125; 客户端引用配置 同样的，客户端过滤器需要在 sofa:reference 的 sofa:global-attrs 标签中配置 filter 属性，实现客户端引用\b类的调用拦截。 123456&lt;bean id=\"sampleFilter\" class=\"com.alipay.sofa.rpc.samples.filter.SampleClientFilter\"/&gt;&lt;sofa:reference id=\"filterServiceReference\" interface=\"\bcom.ostenant.sofa.rpc.example.filter.FilterService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs filter=\"sampleFilter\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 服务端启动类 12SpringApplication springApplication = new SpringApplication(FilterServerApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端启动类 12SpringApplication springApplication = new SpringApplication(FilterClientApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端调用 12345678910FilterService filterServiceReference = (FilterService) applicationContext.getBean(\"filterServiceReference\");try &#123; // sleep 5s, 便于观察过滤器效果 Thread.sleep(5000);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;String result = filterServiceReference.sayFilter(\"filter\");System.out.println(\"Invoke result: \" + result); 查看拦截\b输出\b 服务端打印输出 12SampleFilter before server processSampleFilter after server process 客户端打印输出 123SampleFilter before client invokeSampleFilter after client invokeInvoke result: filter \b过滤器配置生效，总结过滤器拦截先后次序如下： 客户端发起调用 -&gt; 客户端前置拦截\b -&gt; 服务端前置拦截 服务端方法执行 服务端后置拦截 -&gt; 客户端后置拦截 -&gt; 客户端接收返回值 小结本文介绍了 SOFA-RPC 的集中调用方式，包括单向调用、同步调用、Future调用、回调，引入了 SOFA-RPC 独有的泛化调用机制，同时对过滤器的配置进行了\b简单介绍。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"SOFA-Boot","slug":"SOFA-Boot","permalink":"https://ostenant.coding.me/tags/SOFA-Boot/"},{"name":"SOFA_RPC","slug":"SOFA-RPC","permalink":"https://ostenant.coding.me/tags/SOFA-RPC/"}]},{"title":"蚂蚁金服SOFA-Boot整合SOFA-RPC(上篇)","slug":"蚂蚁金服SOFA-Boot整合SOFA-RPC(上篇)","date":"2018-05-08T13:23:00.000Z","updated":"2018-05-09T06:28:50.824Z","comments":true,"path":"2018/05/08/蚂蚁金服SOFA-Boot整合SOFA-RPC(上篇)/","link":"","permalink":"https://ostenant.coding.me/2018/05/08/蚂蚁金服SOFA-Boot整合SOFA-RPC(上篇)/","excerpt":"前言上文介绍了 SOFARPC 的简单使用。在生产环境中，通常会将 SOFARPC 整合到 SpringBoot 中。蚂蚁金服提供了 SOFABoot 框架，SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等等能力。","text":"前言上文介绍了 SOFARPC 的简单使用。在生产环境中，通常会将 SOFARPC 整合到 SpringBoot 中。蚂蚁金服提供了 SOFABoot 框架，SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等等能力。 在增强了 Spring Boot 的同时，SOFABoot 提供了让用户可以在 Spring Boot 中非常方便地使用 SOFA 中间件的能力。当前 SOFABoot 的 2.3.1 版本是基于 Spring Boot 1.4.2.RELEASE 来构建的。 正文1. 功能描述SOFABoot 在 Spring Boot 的基础上，提供了以下能力： 1.1. 扩展 Spring Boot 的健康检查在 Spring Boot 健康检查能力的基础上，提供了 Readiness Check 的能力，保证应用实例安全上线。 1.2. 日志空间隔离能力中间件框架自动发现应用的日志实现依赖并独立打印日志，避免中间件和应用日志实现绑定，通过 sofa-common-tools 实现。 1.3. 提供类隔离的能力基于 SOFAArk 框架提供类隔离能力，方便使用者解决各种类冲突问题。 1.4. 中间件的集成管理统一管控、提供中间件统一易用的编程接口、每一个 SOFA 中间件都是独立可插拔的组件。 1.5. 完全兼容 Spring BootSOFABoot 基于 Spring Boot 的基础上进行构建，并且完全兼容 Spring Boot。 2. 快速开始2.1. 环境准备要使用 SOFABoot，需要先准备好基础环境，SOFABoot 依赖以下环境： JDK7 或 JDK8 需要采用 Apache Maven 3.2.5 或者以上的版本来编译 2.2. 创建工程SOFABoot 是直接构建在 Spring Boot 之上，因此可以使用 Spring Boot 的工程生成工具来生成。添加一个 Web 的依赖，以便最后在浏览器中查看效果。 2.3. 引入 SOFABoot在创建好一个 Spring Boot 的工程之后，接下来就需要引入 SOFABoot 的依赖。首先，需要将上文中生成的 Spring Boot 工程的 zip 包解压后，修改 maven 项目的配置文件 pom.xml。 替换 spring-boot-starter-parent 为相应版本的 sofaboot-dependencies，例如： 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt; 替换为： 12345&lt;parent&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;sofaboot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt;&lt;/parent&gt; 2.4. \bSOFABoot \b健康检查引入相关依赖添加 SOFABoot 健康检查扩展能力的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;healthcheck-sofa-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 最后，在工程的 application.properties 文件下添加一个 SOFABoot 必须要使用的参数。 spring.application.name：用于标示当前应用的名称 logging path：用于指定日志的输出目录 1234# Application Namespring.application.name=SOFABoot Example# logging pathlogging.path=./logs 运行 main() 方法，项目启动以后，控制台的日志输出如下： 123452018-05-09 09:56:48.305 INFO 15097 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)2018-05-09 09:56:48.309 INFO 15097 --- [ main] c.o.s.r.e.SofaBootExampleApplication : Started SofaBootExampleApplication in 2.551 seconds (JVM running for 3.046)2018-05-09 09:57:46.005 INFO 15097 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'2018-05-09 09:57:46.005 INFO 15097 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started2018-05-09 09:57:46.021 INFO 15097 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 16 ms 查看健康状态 \b在浏览器中输入 http://localhost:8080/sofaboot/versions 来查看当前 SOFABoot 中使用 Maven 插件生成的版本信息汇总，结果类似如下： 1234567891011[ &#123; \"GroupId\": \"com.alipay.sofa\", \"Doc-Url\": \"https://github.com/alipay/sofa-boot\", \"ArtifactId\": \"infra-sofa-boot-starter\", \"Bulit-Time\": \"2018-04-18T22:19:09+0800\", \"Commit-Time\": \"2018-04-18T22:07:52+0800\", \"Commit-Id\": \"466f0e039b250ff7b201dc693eec7fa07eb21ad7\", \"Version\": \"2.3.1\" &#125;] 在浏览器中输入 http://localhost:8080/health/readiness 查看应用 Readiness Check 的状况，类似如下： 123456789101112131415&#123; \"status\": \"UP\", \"sofaBootComponentHealthCheckInfo\": &#123; \"status\": \"UP\" &#125;, \"springContextHealthCheckInfo\": &#123; \"status\": \"UP\" &#125;, \"DiskSpaceHealthIndicator\": &#123; \"status\": \"UP\", \"total\": 250790436864, \"free\": 208612020224, \"threshold\": 10485760 &#125;&#125; status: &quot;UP&quot; 表示应用 Readiness Check 的就绪状态是健康的。 在浏览器中输入 http://localhost:8080/health 来查看应用的运行时健康状态（可能会随着时间发生变化,Spring Boot原生自带功能）。 123456789101112131415161718&#123; \"status\": \"UP\", \"sofaBootComponentHealthCheckInfo\": &#123; \"status\": \"UP\", \"Middleware\": &#123; &#125; &#125;, \"springContextHealthCheckInfo\": &#123; \"status\": \"UP\" &#125;, \"diskSpace\": &#123; \"status\": \"UP\", \"total\": 250790436864, \"free\": 208612528128, \"threshold\": 10485760 &#125;&#125; 查看日志在上面的 application.properties 里面，我们配置的日志打印目录是 ./logs 即当前应用的根目录（我们可以根据自己的实践需要配置），在当前工程的根目录下可以看到类似如下结构的日志文件： 12345678./logs├── health-check│ ├── sofaboot-common-default.log│ └── sofaboot-common-error.log├── infra│ ├── common-default.log│ └── common-error.log└── spring.log 如果应用启动失败或者健康检查返回失败，可以通过相应的日志文件找到错误的原因，有些需要关注 common-error.log 日志。 2.5. SOFA-RPC 环境准备引入相关依赖SOFABoot 使用一系列后缀为 -sofa-boot-starter 来标示一个中间件服务，如果想要使用某个中间件，直接添加对应的依赖即可。进一步引入 SOFA-RPC 的 starter \b依赖： 1234&lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;rpc-sofa-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 选择 Zookeeper 作为服务注册列表，在 pom.xml 文件中引入相关依赖： 12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;version&gt;0.10&lt;/version&gt;&lt;/dependency&gt; 注意将 zkclient 重复的依赖排除在外，以免引起冲突。 配置\b zookeeper 集群在 application.properties 中进一步配置 zookeeper 的地址信息。 12# zookeeper address listcom.alipay.sofa.rpc.registry.address=zookeeper://127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183?file=/home/admin/registry 为了方便起见，本地使用 docker 环境对 zookeeper 集群进行\u0001容器编排。多个 zookeeper 节点通过逗号分隔，file 参数指定当 zookeeper 不可用时，可以利用本地缓存文件进行服务发现。 编写 docker-compose.yml 文件如下： 1234567891011121314151617181920212223242526272829version: '2'services: zoo1: image: zookeeper:latest restart: always hostname: zoo1 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper:latest restart: always hostname: zoo2 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper:latest restart: always hostname: zoo3 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888 进入 docker-compose.yml 所在文件目录， \b运行 docker-compose up -d 启动3台 zookeeper 容器\b。启动完成后，运行 docker-compose ps 查看进程状态如下： 123456$ docker-compose ps Name Command State Ports ------------------------------------------------------------------------------------------------------zookeeper_zoo1_1 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2181-&gt;2181/tcp, 2888/tcp, 3888/tcpzookeeper_zoo2_1 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2182-&gt;2181/tcp, 2888/tcp, 3888/tcpzookeeper_zoo3_1 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2183-&gt;2181/tcp, 2888/tcp, 3888/tcp \b\bzookeeper 容器集群启动完成，如果想要查看集群 leader，可以运行 docker exec -it [container-id] /bin/bash 进入容器运行 zk\bServer.sh status 逐一查看。这里加以不累述！ XSD管理在要使用的 XML 配置文件中将头部 xsd 文件的声明设置为如下，这样就能够使用 SOFABoot 定义的 XML 元素进行开发。 12345678&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:sofa=\"http://sofastack.io/schema/sofaboot\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://sofastack.io/schema/sofaboot http://sofastack.io/schema/sofaboot.xsd\" default-autowire=\"byName\"&gt; 2.6. \bSOFA-\bBoot 整合 SOFA-RPC编写服务接口和实现类HelloSyncService.java 123public interface HelloSyncService &#123; String saySync(String string);&#125; HelloSyncServiceImpl.java 123456public class HelloSyncServiceImpl implements HelloSyncService &#123; @Override public String saySync(String sync) &#123; return sync; &#125;&#125; 编写服务提供方配置文件simple-server-example.xml 12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:sofa=\"http://sofastack.io/schema/sofaboot\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://sofastack.io/schema/sofaboot http://sofastack.io/schema/sofaboot.xsd\" default-autowire=\"byName\"&gt; &lt;bean id=\"helloSyncServiceImpl\" class=\"com.ostenant.sofa.rpc.example.simple.HelloSyncServiceImpl\"/&gt; &lt;!-- 以多种通信协议发布服务 --&gt; &lt;sofa:service ref=\"helloSyncServiceImpl\" interface=\"com.ostenant.sofa.rpc.example.simple.HelloSyncService\"&gt; &lt;sofa:binding.bolt/&gt; &lt;sofa:binding.rest/&gt; &lt;sofa:binding.dubbo/&gt; &lt;/sofa:service&gt;&lt;/beans&gt; 通过 sofa:service 元素将该服务发布，其中 ref 属性表示发布的服务实例，interface 属性表示该服务的接口。 sofa:binding.bolt: 服务通过 bolt 协协议通道发布，底层基于 Netty 实现。 sofa:binding.rest: 服务通过 \bhttp 协议发布。 sofa:binding.dubbo: 服务基于 dubbo 的协议通道发布。 编写服务提供方启动程序\bSimpleServerApplication.java 123456789@ImportResource(&#123; \"classpath:simple-server-example.xml\" &#125;)@SpringBootApplicationpublic class \bSimpleServerApplication &#123; public static void main(String[] args) &#123; SpringApplication springApplication = new SpringApplication(\bSimpleServerApplication.class); ApplicationContext applicationContext = springApplication.run(args); &#125;&#125; 编写服务消费方配置文件simple-client-example.xml 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:sofa=\"http://sofastack.io/schema/sofaboot\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://sofastack.io/schema/sofaboot http://sofastack.io/schema/sofaboot.xsd\" default-autowire=\"byName\"&gt; &lt;!-- bolt引用 --&gt; &lt;sofa:reference id=\"boltHelloSyncServiceReference\" interface=\"com.ostenant.sofa.rpc.example.simple.HelloSyncService\"&gt; &lt;sofa:binding.bolt/&gt; &lt;/sofa:reference&gt; &lt;!-- rest引用 --&gt; &lt;sofa:reference id=\"restHelloSyncServiceReference\" interface=\"com.ostenant.sofa.rpc.example.simple.HelloSyncService\"&gt; &lt;sofa:binding.rest/&gt; &lt;/sofa:reference&gt; &lt;!-- dubbo引用 --&gt; &lt;sofa:reference id=\"dubboHelloSyncServiceReference\" interface=\"com.ostenant.sofa.rpc.example.simple.HelloSyncService\"&gt; &lt;sofa:binding.dubbo/&gt; &lt;/sofa:reference&gt;&lt;/beans&gt; 编写服务提供方启动程序SimpleClientApplication.java 123456789101112131415161718@ImportResource(&#123; \"classpath:simple-client-example.xml\" &#125;)@SpringBootApplicationpublic class SimpleClientApplication &#123; public static void main(String[] args) &#123; System.setProperty(\"server.port\", \"8081\"); SpringApplication springApplication = new SpringApplication(SimpleClientApplication.class); ApplicationContext applicationContext = springApplication.run(args); HelloSyncService boltHelloSyncService = (HelloSyncService) applicationContext.getBean(\"boltHelloSyncServiceReference\"); HelloSyncService restHelloSyncService = (HelloSyncService) applicationContext.getBean(\"restHelloSyncServiceReference\"); HelloSyncService dubboHelloSyncService = (HelloSyncService) applicationContext.getBean(\"dubboHelloSyncServiceReference\"); System.out.println(\"Bolt result:\" + boltHelloSyncService.saySync(\"bolt\")); System.out.println(\"Rest result:\" + restHelloSyncService.saySync(\"rest\")); System.out.println(\"Dubbo result:\" + dubboHelloSyncService.saySync(\"dubbo\")); &#125;&#125; 分别启动服务端和客户端客户端控制台输出日志如下： 123Bolt result: boltRest result: restDubbo result: dubbo \b对于同一个服务，在服务发布方\b配置时，可在以 sofa:service 中通过 sofa:binding.xxx 提供多种协议通道配置；在服务消费方配置时，可以在 sofa:reference 中通过 sofa:binding.xxx 提供\b对不同通道服务的引用。 小结\b本文引入了 SOFA-Boot 框架，对 SOFA-Boot 的将康检查功能和\b\b日志管理的使用进行了简单说明，然后在 SOFA-Boot 环境中引入了 SOFA-RPC 框架，并提供了一个\b完整的服务发布和注册的示例程序。 关于 SOFA-\bRPC 更丰富、强大的功能\b介绍，\b下篇敬请期待！ 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"SOFA-RPC","slug":"SOFA-RPC","permalink":"https://ostenant.coding.me/tags/SOFA-RPC/"},{"name":"SOFA-Boot","slug":"SOFA-Boot","permalink":"https://ostenant.coding.me/tags/SOFA-Boot/"}]},{"title":"蚂蚁金服RPC框架SOFA-RPC - 初体验","slug":"蚂蚁金服RPC框架SOFA-RPC - 初体验","date":"2018-04-29T09:59:00.000Z","updated":"2018-05-09T06:21:43.934Z","comments":true,"path":"2018/04/29/蚂蚁金服RPC框架SOFA-RPC - 初体验/","link":"","permalink":"https://ostenant.coding.me/2018/04/29/蚂蚁金服RPC框架SOFA-RPC - 初体验/","excerpt":"前言SOFARPC 最早源于阿里内部的 HSF，是近期蚂蚁金服开源的一个高可扩展性、高性能、生产级的 Java RPC 框架。SOFA-RPC 在蚂蚁金服已经历了十多年的发展，致力于简化应用之间的 RPC 调用。为应用提供方便透明、稳定高效的点对点远程服务调用方案。","text":"前言SOFARPC 最早源于阿里内部的 HSF，是近期蚂蚁金服开源的一个高可扩展性、高性能、生产级的 Java RPC 框架。SOFA-RPC 在蚂蚁金服已经历了十多年的发展，致力于简化应用之间的 RPC 调用。为应用提供方便透明、稳定高效的点对点远程服务调用方案。 为了用户和开发者方便的进行功能扩展，SOFA-RPC 提供了丰富的模型抽象和可扩展接口，包括过滤器、路由、负载均衡等。同时围绕 SOFA-RPC 框架及其周边组件提供丰富的微服务治理方案。 正文1. 功能特性 透明化、高性能的远程服务调用 支持多种服务路由及负载均衡策略 支持多种注册中心的集成 支持 bolt、rest、dubbo 等多种通信协议 支持同步、单向、回调、泛化等多种调用方式 支持集群容错、服务预热、自动故障隔离 强大的扩展功能，可以按需扩展各个功能组件 2. 实现原理 a. 服务发布 当一个 SOFARPC 的应用启动的时候，如果发现当前应用需要发布 RPC 服务的话，那么 SOFARPC 会将这些服务注册到服务注册中心上。如图中 Service 指向 Registry。 b. 服务订阅 当引用这个服务的 SOFARPC 应用启动时，会从服务注册中心订阅到相应服务的元数据信息。服务注册中心收到订阅请求后，会将发布方的元数据列表实时推送给服务引用方。如图中 Registry 指向 Reference。 c. 服务调用 当服务引用方拿到地址以后，就可以从中选取地址发起调用了。如图中 Reference 指向 Service。 3. 快速开始3.1. 引入sofa-rpc依赖1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;sofa-rpc-all&lt;/artifactId&gt; &lt;version&gt;5.3.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3.2. 编写服务接口和服务实现类HelloService.java 123public interface HelloService &#123; String sayHello(String string);&#125; HelloServiceImpl.java 1234567public class HelloServiceImpl implements HelloService &#123; @Override public String sayHello(String string) &#123; System.out.println(\"Server receive: \" + string); return \"hello \" + string + \" ！\"; &#125;&#125; 3.3. 编写服务提供者启动类QuickStartServer.java 123456789101112131415public class QuickStartServer &#123; public static void main(String[] args) &#123; ServerConfig serverConfig = new ServerConfig() .setProtocol(\"bolt\") // 设置一个协议，默认bolt .setPort(9696) // 设置一个端口，默认12200 .setDaemon(false); // 非守护线程 ProviderConfig&lt;HelloService&gt; providerConfig = new ProviderConfig&lt;HelloService&gt;() .setInterfaceId(HelloService.class.getName()) // 指定接口 .setRef(new HelloServiceImpl()) // 指定实现 .setServer(serverConfig); // 指定服务端 providerConfig.export(); // 发布服务 &#125;&#125; 运行服务端提供方，日志输出如下： 12345Sofa-Middleware-Log SLF4J Warn : No log util is usable, Default app logger will be used.SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.Sofa-Middleware-Log SLF4J Warn : No log util is usable, Default app logger will be used. 3.4. 编写服务消费者启动类QuickStartClient.java 12345678910111213141516171819public class QuickStartClient &#123; public static void main(String[] args) &#123; ConsumerConfig&lt;HelloService&gt; consumerConfig = new ConsumerConfig&lt;HelloService&gt;() .setInterfaceId(HelloService.class.getName()) // 指定接口 .setProtocol(\"bolt\") // 指定协议 .setDirectUrl(\"bolt://127.0.0.1:9696\"); // 指定直连地址 HelloService helloService = consumerConfig.refer(); while (true) &#123; System.out.println(helloService.sayHello(\"world\")); try &#123; Thread.sleep(200); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 运行服务端消费方，调用服务提供方： 服务提供方日志输出如下： 1234Server receive: worldServer receive: worldServer receive: worldServer receive: world 服务消费方日志输出如下： 123456789SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.Sofa-Middleware-Log SLF4J Warn : No log util is usable, Default app logger will be used.Sofa-Middleware-Log SLF4J Warn : No log util is usable, Default app logger will be used.hello world ！hello world ！hello world ！hello world ！ 小结这是一个快速入门的例子！ 可以发现，在使用上，SOFA-RPC 与淘宝的 Dubbo，微博的 Motan 并无太大的区别。Dubbo 作为整套服务治理而存在，而 SOFA-RPC 只是一款轻量级的 RPC 框架，基于 HSF 框架改造，提供更加完善、强大的、多样化 RPC 编程 API。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"SOFA-RPC","slug":"SOFA-RPC","permalink":"https://ostenant.coding.me/tags/SOFA-RPC/"}]},{"title":"分布式理论(四) - 3PC协议","slug":"分布式理论(四) - 3PC协议","date":"2018-04-28T13:26:00.000Z","updated":"2018-05-08T02:49:46.095Z","comments":true,"path":"2018/04/28/分布式理论(四) - 3PC协议/","link":"","permalink":"https://ostenant.coding.me/2018/04/28/分布式理论(四) - 3PC协议/","excerpt":"前言由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷。所以，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。","text":"前言由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷。所以，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。 与两阶段提交不同的是，三阶段提交有两个改动点。 引入超时机制 - 同时在协调者和参与者中都引入超时机制。 在第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的。 正文1. 三阶段提交的定义三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。 所谓的三个阶段分别是：询问，然后再锁资源，最后真正提交。 第一阶段：CanCommit 第二阶段：PreCommit 第三阶段：Do Commit 2. 三阶段提交的过程2.1. 阶段一：CanCommit3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。 a. 事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。 b. 响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态；否则反馈No。 2.2. 阶段二：PreCommit协调者在得到所有参与者的响应之后，会根据结果执行2种操作：执行事务预提交，或者中断事务。 2.2.1. 执行事务预提交a. 发送预提交请求 协调者向所有参与者节点发出 preCommit 的请求，并进入 prepared 状态。 b. 事务预提交 参与者受到 preCommit 请求后，会执行事务操作，对应 2PC 准备阶段中的 “执行事务”，也会 Undo 和 Redo 信息记录到事务日志中。 c. 各参与者响应反馈 如果参与者成功执行了事务，就反馈 ACK 响应，同时等待指令：提交（commit） 或终止（abort）。 2.2.2. 中断事务a. 发送中断请求 协调者向所有参与者节点发出 abort 请求 。 b. 中断事务 参与者如果收到 abort 请求或者超时了，都会中断事务。 2.3. 阶段三：Do Commit该阶段进行真正的事务提交，也可以分为以下两种情况。 2.3.1. 执行提交a. 发送提交请求 协调者接收到各参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送 doCommit 请求。 b. 事务提交 参与者接收到 doCommit 请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。 c. 响应反馈 事务提交完之后，向协调者发送 ACK 响应。 d. 完成事务 协调者接收到所有参与者的 ACK 响应之后，完成事务。 2.3.2. 中断事务协调者没有接收到参与者发送的 ACK 响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。 a. 发送中断请求 协调者向所有参与者发送 abort 请求。 b. 事务回滚 参与者接收到 abort 请求之后，利用其在阶段二记录的 undo 信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。 c. 反馈结果 参与者完成事务回滚之后，向协调者发送 ACK 消息。 d. 中断事务 协调者接收到参与者反馈的 ACK 消息之后，完成事务的中断。 3. 小结3.1. 三阶段提交的优点相对于二阶段提交，三阶段提交主要解决的单点故障问题，并减少了阻塞的时间。 因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行 commit。而不会一直持有事务资源并处于阻塞状态。 3.2. 三阶段提交的缺点三阶段提交也会导致数据一致性问题。由于网络原因，协调者发送的 abort 响应没有及时被参与者接收到，那么参与者在等待超时之后执行了 commit 操作。 这样就和其他接到 abort 命令并执行回滚的参与者之间存在数据不一致的情况。 欢迎扫码关注公众号：零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://ostenant.coding.me/tags/分布式/"},{"name":"3PC","slug":"3PC","permalink":"https://ostenant.coding.me/tags/3PC/"}]},{"title":"分布式理论(三) - 2PC协议","slug":"分布式理论(三) - 2PC协议","date":"2018-04-25T14:22:00.000Z","updated":"2018-05-08T02:49:46.095Z","comments":true,"path":"2018/04/25/分布式理论(三) - 2PC协议/","link":"","permalink":"https://ostenant.coding.me/2018/04/25/分布式理论(三) - 2PC协议/","excerpt":"前言由于BASE理论需要在一致性和可用性方面做出权衡，因此涌现了很多关于一致性的算法和协议。其中比较著名的有二阶提交协议（2 Phase Commitment Protocol），三阶提交协议（3 Phase Commitment Protocol）和Paxos算法。","text":"前言由于BASE理论需要在一致性和可用性方面做出权衡，因此涌现了很多关于一致性的算法和协议。其中比较著名的有二阶提交协议（2 Phase Commitment Protocol），三阶提交协议（3 Phase Commitment Protocol）和Paxos算法。 本文要介绍的2PC协议，分为两个阶段提交一个事务。并通过协调者和各个参与者的配合，实现分布式一致性。 两个阶段事务提交协议，由协调者和参与者共同完成。 角色 XA概念 作用 协调者 事务管理器 协调各个参与者，对分布式事务进行提交或回滚 参与者 资源管理器 分布式集群中的节点 正文1. 分布式事务分布式事务是指会涉及到操作多个数据库的事务，其实就是将对同一库事务的概念扩大到了对多个库的事务。目的是为了保证分布式系统中的数据一致性。 分布式事务处理的关键是： 需要记录事务在任何节点所做的所有动作； 事务进行的所有操作要么全部提交，要么全部回滚。 2. XA规范2.1. XA规范的组成XA规范是由 X/Open组织（即现在的 Open Group ）定义的分布式事务处理模型。 X/Open DTP 模型（ 1994 ）包括： 应用程序（ AP ） 事务管理器（ TM ）：交易中间件等 资源管理器（ RM ）：关系型数据库等 通信资源管理器（ CRM ）：消息中间件等 2.2. XA规范的定义XA规范定义了交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。而XA接口函数由数据库厂商提供。 二阶提交协议和三阶提交协议就是基于XA规范提出的其中，二阶段提交就是实现XA分布式事务的关键。 2.3. XA规范编程规范 配置TM，给TM注册RM作为数据源。其中，一个TM可以注册多个RM。 AP向TM发起一个全局事务。这时，TM会发送一个XID（全局事务ID）通知各个RM。 AP从TM获取资源管理器的代理（例如：使用JTA接口，从TM管理的上下文中，获取出这个TM所管理的RM的JDBC连接或JMS连接）。 AP通过从TM中获取的连接，间接操作RM进行业务操作。TM在每次AP操作时把XID传递给RM，RM正是通过这个XID关联来操作和事务的关系的。 AP结束全局事务时，TM会通知RM全局事务结束。开始二段提交，也就是prepare - commit的过程。 XA规范的流程，大致如图所示： 3. 二阶段提交（2PC）3.1. 二阶段提交的定义二阶段提交的算法思路可以概括为：每个参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报，决定各参与者是否要提交操作还是中止操作。 所谓的两个阶段分别是： 第一阶段：准备阶段（投票阶段） 第二阶段：提交阶段（执行阶段） 3.1.1. 准备阶段准备阶段分为三个步骤： a. 事务询问 协调者向所有的参与者询问，是否准备好了执行事务，并开始等待各参与者的响应。 b. 执行事务 各参与者节点执行事务操作。如果本地事务成功，将Undo和Redo信息记入事务日志中，但不提交；否则，直接返回失败，退出执行。 c. 各参与者向协调者反馈事务询问的响应 如果参与者成功执行了事务操作，那么就反馈给协调者 Yes响应，表示事务可以执行提交；如果参与者没有成功执行事务，就返回No给协调者，表示事务不可以执行提交。 3.1.2. 提交阶段在提交阶段中，会根据准备阶段的投票结果执行2种操作：执行事务提交，中断事务。 提交事务过程如下： a. 发送提交请求 协调者向所有参与者发出commit请求。 b. 事务提交 参与者收到commit请求后，会正式执行事务提交操作，并在完成提交之后，释放整个事务执行期间占用的事务资源。 c. 反馈事务提交结果 参与者在完成事务提交之后，向协调者发送Ack信息。 d. 事务提交确认 协调者接收到所有参与者反馈的Ack信息后，完成事务。 中断事务过程如下： a. 发送回滚请求 协调者向所有参与者发出Rollback请求。 b. 事务回滚 参与者接收到Rollback请求后，会利用其在提交阶段种记录的Undo信息，来执行事务回滚操作。在完成回滚之后，释放在整个事务执行期间占用的资源。 c. 反馈事务回滚结果 参与者在完成事务回滚之后，想协调者发送Ack信息。 d. 事务中断确认 协调者接收到所有参与者反馈的Ack信息后，完成事务中断。 3.1. 二阶段提交的优缺点 优点：原理简单，实现方便。 缺点：同步阻塞，单点问题，数据不一致，容错性不好。 同步阻塞在二阶段提交的过程中，所有的节点都在等待其他节点的响应，无法进行其他操作。这种同步阻塞极大的限制了分布式系统的性能。 单点问题协调者在整个二阶段提交过程中很重要，如果协调者在提交阶段出现问题，那么整个流程将无法运转。更重要的是，其他参与者将会处于一直锁定事务资源的状态中，而无法继续完成事务操作。 数据不一致假设当协调者向所有的参与者发送commit请求之后，发生了局部网络异常，或者是协调者在尚未发送完所有 commit请求之前自身发生了崩溃，导致最终只有部分参与者收到了commit请求。这将导致严重的数据不一致问题。 容错性不好如果在二阶段提交的提交询问阶段中，参与者出现故障，导致协调者始终无法获取到所有参与者的确认信息，这时协调者只能依靠其自身的超时机制，判断是否需要中断事务。显然，这种策略过于保守。换句话说，二阶段提交协议没有设计较为完善的容错机制，任意一个节点是失败都会导致整个事务的失败。 小结对于2PC协议存在的同步阻塞、单点问题，将在下一篇文章的3PC协议中引入解决方案。 欢迎扫码关注公众号：零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://ostenant.coding.me/tags/分布式/"},{"name":"2PC","slug":"2PC","permalink":"https://ostenant.coding.me/tags/2PC/"}]},{"title":"分布式理论(二) - BASE理论","slug":"分布式理论(二) - BASE理论","date":"2018-04-24T12:41:00.000Z","updated":"2018-05-08T02:49:46.095Z","comments":true,"path":"2018/04/24/分布式理论(二) - BASE理论/","link":"","permalink":"https://ostenant.coding.me/2018/04/24/分布式理论(二) - BASE理论/","excerpt":"前言BASE理论是由eBay架构师提出的。BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网分布式系统实践的总结，是基于CAP定律逐步演化而来。其核心思想是即使无法做到强一致性，但每个应用都可以根据自身业务特点，才用适当的方式来使系统打到最终一致性。","text":"前言BASE理论是由eBay架构师提出的。BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网分布式系统实践的总结，是基于CAP定律逐步演化而来。其核心思想是即使无法做到强一致性，但每个应用都可以根据自身业务特点，才用适当的方式来使系统打到最终一致性。 正文1. CAP的3选2伪命题实际上，不是为了P（分区容错性），必须在C（一致性）和A（可用性）之间任选其一。分区的情况很少出现，CAP在大多时间能够同时满足C和A。 对于分区存在或者探知其影响的情况下，需要提供一种预备策略做出处理： 探知分区的发生； 进入显示的分区模式，限制某些操作； 启动恢复过程，恢复数据一致性，补偿分区发生期间的错误。 2. BASE理论简介BASE理论是Basically Available(基本可用)，Soft State（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。 其核心思想是： 既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 3. BASE理论的内容 基本可用（Basically Available） 软状态（Soft State） 最终一致性（Eventually Consistent） 下面展开讨论： 3.1. 基本可用什么是基本可用呢？假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言： 响应时间上的损失：正常情况下的搜索引擎0.5秒即返回给用户结果，而基本可用的搜索引擎可以在2秒作用返回结果。 功能上的损失：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单。但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 3.2. 软状态什么是软状态呢？相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种“硬状态”。 软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。 3.3. 最终一致性上面说软状态，然后不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。 而在实际工程实践中，最终一致性分为5种： 3.3.1. 因果一致性（Causal consistency）因果一致性指的是：如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。 3.3.2. 读己之所写（Read your writes）读己之所写指的是：节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。 3.3.3. 会话一致性（Session consistency）会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。 3.3.4. 单调读一致性（Monotonic read consistency）单调读一致性指的是：如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。 3.3.5. 单调写一致性（Monotonic write consistency）单调写一致性指的是：一个系统要能够保证来自同一个节点的写操作被顺序的执行。 在实际的实践中，这5种系统往往会结合使用，以构建一个具有最终一致性的分布式系统。 实际上，不只是分布式系统使用最终一致性，关系型数据库在某个功能上，也是使用最终一致性的。比如备份，数据库的复制过程是需要时间的，这个复制过程中，业务读取到的值就是旧的。当然，最终还是达成了数据一致性。这也算是一个最终一致性的经典案例。 小结总体来说BASE理论面向的是大型高可用、可扩展的分布式系统。与传统ACID特性相反，不同于ACID的强一致性模型，BASE提出通过牺牲强一致性来获得可用性，并允许数据段时间内的不一致，但是最终达到一致状态。同时，在实际分布式场景中，不同业务对数据的一致性要求不一样。因此在设计中，ACID和BASE理论往往又会结合使用。 欢迎扫码关注公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://ostenant.coding.me/tags/分布式/"},{"name":"BASE","slug":"BASE","permalink":"https://ostenant.coding.me/tags/BASE/"}]},{"title":"分布式理论(一) - CAP定理","slug":"分布式理论(一) - CAP定理","date":"2018-04-23T12:33:00.000Z","updated":"2018-05-08T02:49:46.094Z","comments":true,"path":"2018/04/23/分布式理论(一) - CAP定理/","link":"","permalink":"https://ostenant.coding.me/2018/04/23/分布式理论(一) - CAP定理/","excerpt":"前言CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性）这三个基本需求，最多只能同时满足其中的2个。","text":"前言CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性）这三个基本需求，最多只能同时满足其中的2个。 正文1. CAP原则简介 选项 描述 Consistency（一致性） 指数据在多个副本之间能够保持一致的特性（严格的一致性） Availability（可用性） 指系统提供的服务必须一直处于可用的状态，每次请求都能获取到非错的响应（不保证获取的数据为最新数据） Partition tolerance（分区容错性） 分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障 什么是分区？ 在分布式系统中，不同的节点分布在不同的子网络中，由于一些特殊的原因，这些子节点之间出现了网络不通的状态，但他们的内部子网络是正常的。从而导致了整个系统的环境被切分成了若干个孤立的区域，这就是分区。 2. CAP原则论证如图所示，是我们证明CAP的基本场景，网络中有两个节点N1和N2，可以简单的理解N1和N2分别是两台计算机，他们之间网络可以连通，N1中有一个应用程序A，和一个数据库V，N2也有一个应用程序B和一个数据库V。现在，A和B是分布式系统的两个部分，V是分布式系统的数据存储的两个子数据库。 在满足一致性的时候，N1和N2中的数据是一样的，V0=V0。 在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。 在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。 如图所示，这是分布式系统正常运转的流程，用户向N1机器请求数据更新，程序A更新数据库V0为V1。分布式系统将数据进行同步操作M，将V1同步的N2中V0，使得N2中的数据V0也更新为V1，N2中的数据再响应N2的请求。 根据CAP原则定义，系统的一致性、可用性和分区容错性细分如下： 一致性：N1和N2的数据库V之间的数据是否完全一样。 可用性：N1和N2的对外部的请求能否做出正常的响应。 分区容错性：N1和N2之间的网络是否互通。 这是正常运作的场景，也是理想的场景。作为一个分布式系统，它和单机系统的最大区别，就在于网络。现在假设一种极端情况，N1和N2之间的网络断开了，我们要支持这种网络异常。相当于要满足分区容错性，能不能同时满足一致性和可用性呢？还是说要对他们进行取舍？ 假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1。由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0。这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？ 这里有两种选择： 第一：牺牲数据一致性，保证可用性。响应旧的数据V0给用户。 第二：牺牲可用性，保证数据一致性。阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。 这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。 3. CAP原则权衡通过CAP理论，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？ 3.1. CA without P如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但其实分区不是你想不想的问题，而是始终会存在，因此CA的系统更多的是允许分区后各子系统依然保持CA。 3.2. CP without A如果不要求A（可用），相当于每个请求都需要在Server之间强一致，而P（分区）会导致同步时间无限延长，如此CP也是可以保证的。很多传统的数据库分布式事务都属于这种模式。 3.3. AP wihtout C要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的NoSQL都属于此类。 小结对于多数大型互联网应用的场景，主机众多、部署分散。而且现在的集群规模越来越大，所以节点故障、网络故障是常态。这种应用一般要保证服务可用性达到N个9，即保证P和A，只有舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。 对于涉及到钱财这样不能有一丝让步的场景，C必须保证。网络发生故障宁可停止服务，这是保证CA，舍弃P。貌似这几年国内银行业发生了不下10起事故，但影响面不大，报到也不多，广大群众知道的少。还有一种是保证CP，舍弃A，例如网络故障时只读不写。 孰优孰劣，没有定论，只能根据场景定夺，适合的才是最好的。 欢迎扫码关注公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://ostenant.coding.me/tags/分布式/"},{"name":"CAP","slug":"CAP","permalink":"https://ostenant.coding.me/tags/CAP/"}]},{"title":"基于Docker + Consul + Nginx + Consul-template的服务负载均衡实现","slug":"基于Docker + Consul + Nginx + Consul-template的服务负载均衡实现","date":"2018-02-08T03:03:00.000Z","updated":"2018-05-08T02:49:46.095Z","comments":true,"path":"2018/02/08/基于Docker + Consul + Nginx + Consul-template的服务负载均衡实现/","link":"","permalink":"https://ostenant.coding.me/2018/02/08/基于Docker + Consul + Nginx + Consul-template的服务负载均衡实现/","excerpt":"前言上一篇文章使用 Consul 和 Registrator 在 docker 的容器环境中搭建了服务注册和发现集群。在服务发现和注册的基础上，本文将引入 Nginx反向代理服务器和 Consul-template 组件，实现动态的服务负载均衡。","text":"前言上一篇文章使用 Consul 和 Registrator 在 docker 的容器环境中搭建了服务注册和发现集群。在服务发现和注册的基础上，本文将引入 Nginx反向代理服务器和 Consul-template 组件，实现动态的服务负载均衡。 正文1. 工具介绍1.1. Nginx一个高性能的 HTTP 和反向代理服务器，用于前端访问流量到后台应用服务器负载均衡和请求转发。 1.2. Consul-templateConsul-template 是 HashiCorp 基于 Consul 所提供的可扩展的工具，通过监听 Consul 中的数据变化，动态地修改一些配置文件中地模板。常用于在 Nginx、HAProxy 上动态配置健康状态下的客户端反向代理信息。 2. 实现原理 通过 Nginx 自身实现负载均衡和请求转发； 通过 Consul-template 的 config 功能实时监控 Consul 集群节点的服务和数据的变化； 实时的用 Consul 节点的信息替换 Nginx 配置文件的模板，并重新加载配置文件； Consul-template 和 nginx 必须安装在同一台机器上，因为 Consul-template 需要动态修改 nginx 的配置文件 nginx.conf，然后执行 nginx -s reload 命令进行路由更新，达到动态负载均衡的目的。 2.1. 传统负载均衡传统的负载均衡，就是 Client 支姐访问 Nginx，然后被转发到后端某一台 Web Server。如果后端有添加/删除 Web Server，运维需要手动改下 nginx.conf ，然后重新载入配置，就可以动态的调整负载均衡。 2.2. 自动负载均衡再看看基于服务自动发现和注册的负载均衡，负载均衡的方式没有变，只是多了一些外围组件，当然这些组件对 Client 是不可见的，client 依然只能看到 Nginx 入口，访问方式也没变化。 Nginx 的动态负载均衡实现流程如下： 以相同的 Consul 标签对 Web Server 进行服务标记和分类，新增或者删除 Web Server 服务器节点； Registrator 监控到 Web Server 的状态更新，自动在 Consul服务注册中心将它注册或者注销； Consul-template 订阅了 Consul 服务注册中心的服务消息，接收到 Consul 的消息推送，即 Web Server 服务节点状态发生改变。 Consul-template 自动去修改和替换 Nginx 服务器下的 nginx配置文件中的模板，并重新加载服务达到自动负载均衡的目的。 3. 环境准备3.1. 系统环境 软件 版本 操作系统 Ubuntu：16.04 x86_64，内核：4.8.0-58-generic docker Docker version 1.12.6, build 78d1802 docker-compose docker-compose version 1.8.0 3.2. 节点规划 主机IP 组件 192.168.1.181 Consul Server, Registrator, Nginx, Consul-template 192.168.1.186 Consul Server, Registrator, Nginx, Consul-template 192.168.1.182 Consul Client, Registrator, Client WebApp1, Server WebApp1, Server WebApp2 192.168.1.183 Consul Client, Registrator, Client WebApp2, Server WebApp3, Server WebApp4 192.168.1.185 Consul Client, Registrator, Client WebApp3, Server WebApp5, Server WebApp6 Client WebApp：提供基于Thrift的RPC客户端和基于Http协议的RESTful客户端，用于访问 Server 程序。 Server WebApp：提供基于Thrift的RPC服务端和基于Http协议的RESTful服务端，供 Client 程序调用。 这里的3台主机 - 192.168.1.182、192.168.1.183 和 192.168.1.185，每台主机部署两个 Client WebApp 容器和一个 Client Server 容器，用于模拟服务层的负载均衡。 3.3. 镜像构建 Consul：consul:latest Registrator：gliderlabs/registrator:latest Nginx和Consul-template：liberalman/nginx-consul-template:latest Client WebApp：test-client:latest Server WebApp：test-server:latest 这里先说说 test-client 和 test-server 的镜像构建： 克隆项目到本地项目环境： https://github.com/ostenant/spring-cloud-starter-thrift 切换到子模块 spring-cloud-starter-thrift-examples 下的 test 目录，执行命令 mvn clean package 进行程序打包。 分别将 test-client 和 test-server 项目根目录下的 Dockerfile 文件和target目录下的 target/*.jar程序拷贝到 192.168.1.182 、192.168.1.183 和 192.168.1.185 目录下。 进入客户端 Dockerfile 所在目录，对客户端程序 test-client 进行镜像构建，命令如下：docker build . -t test-client:latest 进入服务端 Dockerfile 所在目录，对服务端程序 test-server 进行镜像构建，命令如下：docker build . -t test-server:latest 构建完成后查看本地镜像库： 3.4. 部署模型五台主机，其中 192.168.1.181 和 192.168.1.186 两台主机的主要作用如下： 作为负载均衡转发器 (这里只是演示，可以通过 KeepAlived 实现 Nginx 的HA)，将前端访问流量经过负载算法一次转发到后台 Client WebApp 。 以 Server模式启动 Consul节点，其中一台作为整个服务发现与注册集群的 leader， 用于同步和持久化其余三台 Client 模式的 Consul 节点的数据和状态信息。 其余三台主机 - 192.168.1.182、192.168.1.183 和 192.168.1.185，充当的角色如下： 每台分别以 Client 模式部署 Consul 节点，用于注册和发现本机 docker 容器暴露的服务，同时和 Consul Server 的 leader 节点进行服务状态同步。 分别启动一个 Client WebApp 容器实例和两个 Server WebApp 容器实例，将 Client WebApp 的请求根据服务层的负载算法二次转发到 Server WebApp 中的任意一台上完成具体的业务处理。 这里有两次服务转发操作： 接入层的转发：两台 Nginx 服务器将客户流量，经由一次转发至三个 Client WebApp 服务实例中任意一个做处理。 服务层的转发：三个 Client WebApp服务实例其中之一，根据从服务注册中心拉取的健康的服务缓存列表，将请求二次转发至六个 Server WebApp服务实例其中之一做处理。 3.5. 开始搭建3.5.1. Consul Server主机(a). 分别编写 docker-compose.yml，注意 Registrator 需要配置各自的 IP地址。 主机：192.168.1.181 docker-compose.yml 123456789101112131415161718192021222324252627282930version: '2'services: load_balancer: image: liberalman/nginx-consul-template:latest hostname: lb links: - consul_server_master:consul ports: - \"80:80\" consul_server_master: image: consul:latest hostname: consul_server_master ports: - \"8300:8300\" - \"8301:8301\" - \"8302:8302\" - \"8400:8400\" - \"8500:8500\" - \"8600:8600\" command: consul agent -server -bootstrap-expect 1 -advertise 192.168.1.181 -node consul_server_master -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest hostname: registrator links: - consul_server_master:consul volumes: - \"/var/run/docker.sock:/tmp/docker.sock\" command: -ip 192.168.1.181 consul://192.168.1.181:8500 主机：192.168.1.186 docker-compose.yml 123456789101112131415161718192021222324252627282930version: '2'services: load_balancer: image: liberalman/nginx-consul-template:latest hostname: lb links: - consul_server_slave:consul ports: - \"80:80\" consul_server_slave: image: consul:latest hostname: consul_server_slave ports: - \"8300:8300\" - \"8301:8301\" - \"8302:8302\" - \"8400:8400\" - \"8500:8500\" - \"8600:8600\" command: consul agent -server -join=192.168.1.181 -advertise 192.168.1.186 -node consul_server_slave -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest hostname: registrator links: - consul_server_slave:consul volumes: - \"/var/run/docker.sock:/tmp/docker.sock\" command: -ip 192.168.1.186 consul://192.168.1.186:8500 (b). 在两台主机上分别通过 docker-compose 启动多容器应用，命令如下： 1docker-compose up -d 这是在主机 192.168.1.181 上运行启动命令时的输出，可以看到 docker-compose 启动时会先去检查目标镜像文件是否拉取到本地，然后依次创建并启动 docker-compose.yml 文件配置的容器实例。 (c). 查看正常启动的容器进程，观察Consul、Registrator 和 Nginx/Consul-template的容器都正常启动。 (d). 利用 docker-compose，以相同的方式在主机 192.168.1.186 上启动所配置的容器服务实例，查看启动状态如下： (e). 访问 http://IP:8500 查看 Consul Server 的节点信息和服务注册列表。 节点信息： 服务状态列表： 两台 Consul Server 主机上的容器服务实例均正常启动！ 3.5.2. Consul Client主机一般情况下，我们把 Consul 作为服务注册与发现中心，会使用它提供的服务定义 (Service Definition) 和健康检查定义 (Health Check Definition) 功能，相关配置说明参考如下： 服务定义 环境变量Key 环境变量Value 说明 SERVICE_ID web-001 可以为GUID或者可读性更强变量，保证不重复 SERVICE_NAME web 如果ID没有设置，Consul会将name作为id，则有可能注册失败 SERVICE_TAGS nodejs,web 服务的标签，用逗号分隔，开发者可以根据标签来查询一些信息 SERVICE_IP 内网IP 要使用Consul，可访问的IP SERVICE_PORT 50001 应用的IP, 如果应用监听了多个端口，理应被视为多个应用 SERVICE_IGNORE Boolean 是否忽略本Container，可以为一些不需要注册的Container添加此属性 服健康检查定义配置原则为: SERVICE_XXX_*。如果你的应用监听的是 5000 端口，则改为 SERVICE_5000_CHECK_HTTP，其它环境变量配置同理。 环境变量Key 环境变量Value 说明 — 以下为HTTP模式 — — SERVICE_80_CHECK_HTTP /path_to_health_check 你的健康状态检查的路径如 /status SERVICE_80_CHECK_INTERVAL 15s 15秒检查一次 SERVICE_80_CHECK_TIMEOUT 2s 状态检查超时时间 — 以下为HTTPS模式 — — SERVICE_443_CHECK_HTTPS /path_to_health_check 你的健康状态检查的路径如 /status SERVICE_443_CHECK_INTERVAL 15s 15秒检查一次 SERVICE_443_CHECK_TIMEOUT 2s 状态检查超时时间 — 以下为TCP模式 — — SERVICE_443_CHECK_TCP /path_to_health_check 你的健康状态检查的路径如 /status SERVICE_443_CHECK_INTERVAL 15s 15秒检查一次 SERVICE_443_CHECK_TIMEOUT 2s 状态检查超时时间 — 使用脚本检查 — — SERVICE_CHECK_SCRIPT curl –silent –fail example.com 如官方例子中的check_redis.py — 其他 — — SERVICE_CHECK_INITIAL_STATUS passing Consul默认注册后的服务为failed 配置说明(a). 分别编写 docker-compose.yml，同样注意 Registrator 需要配置各自的 IP 地址。test-server 和 test-client 的服务实例在配置时需要指定相关的环境变量。 主机：192.168.1.182 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465version: '2'services: consul_client_01: image: consul:latest ports: - \"8300:8300\" - \"8301:8301\" - \"8301:8301/udp\" - \"8302:8302\" - \"8302:8302/udp\" - \"8400:8400\" - \"8500:8500\" - \"8600:8600\" command: consul agent -retry-join 192.168.1.181 -advertise 192.168.1.182 -node consul_client_01 -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest volumes: - \"/var/run/docker.sock:/tmp/docker.sock\" command: -ip 192.168.1.182 consul://192.168.1.182:8500 test_server_1: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-01 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-01 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"16000:8080\" - \"30000:25000\" test_server_2: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-02 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-02 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"18000:8080\" - \"32000:25000\" test_client_1: image: test-client:latest environment: - SERVICE_8080_NAME=my-web-server - SERVICE_8080_TAGS=test-client-http-service-01 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/features ports: - \"80:8080\" 主机：192.168.1.183 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465version: '2'services: consul_client_02: image: consul:latest ports: - \"8300:8300\" - \"8301:8301\" - \"8301:8301/udp\" - \"8302:8302\" - \"8302:8302/udp\" - \"8400:8400\" - \"8500:8500\" - \"8600:8600\" command: consul agent -retry-join 192.168.1.181 -advertise 192.168.1.183 -node consul_client_02 -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest volumes: - \"/var/run/docker.sock:/tmp/docker.sock\" command: -ip 192.168.1.183 consul://192.168.1.183:8500 test_server_1: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-03 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-03 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"16000:8080\" - \"30000:25000\" test_server_2: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-04 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-04 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"18000:8080\" - \"32000:25000\" test_client_1: image: test-client:latest environment: - SERVICE_8080_NAME=my-web-server - SERVICE_8080_TAGS=test-client-http-service-02 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/features ports: - \"80:8080\" 主机：192.168.1.185 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465version: '2'services: consul_client_03: image: consul:latest ports: - \"8300:8300\" - \"8301:8301\" - \"8301:8301/udp\" - \"8302:8302\" - \"8302:8302/udp\" - \"8400:8400\" - \"8500:8500\" - \"8600:8600\" command: consul agent -retry-join 192.168.1.181 -advertise 192.168.1.185 -node consul_client_03 -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest volumes: - \"/var/run/docker.sock:/tmp/docker.sock\" command: -ip 192.168.1.185 consul://192.168.1.185:8500 test_server_1: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-05 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-05 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"16000:8080\" - \"30000:25000\" test_server_2: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-06 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-06 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"18000:8080\" - \"32000:25000\" test_client_1: image: test-client:latest environment: - SERVICE_8080_NAME=my-web-server - SERVICE_8080_TAGS=test-client-http-service-03 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/features ports: - \"80:8080\" 注意：我们使用的第三方镜像 liberalman/nginx-consul-template，Nginx 会把名称为 my-web-server的服务容器作为后台转发的目标服务器，因此，在 test-client 的配置项中，需要指定 SERVICE_XXX_NAME 为 my-web-server。当然你也可以自己制作镜像指定模板。 (b). 在三台主机上使用 docker-compose 启动多容器应用： 1docker-compose up -d 以主机 192.168.1.182 为例 (其余两台类似)，控制台日志显示，创建并启动 docker-compose.yml 文件配置的5个容器实例。 (c). 查看正常启动的容器进程，观察到 Consul、一台test-client 和 两台test-server的容器都正常启动。 (d). 在 b 操作中的控制台输出可以看到：docker-compose 并非按照 docker-compose.yml 文件中服务配置的先后顺序启动。 registrator 容器的启动依赖于 consul 容器，而此时 consul 还并未启动，就出现了 registrator 优先启动而异常退出的现象。解决方法是再运行一次 docker-compose up -d 命令。 (e). 再次查看容器进程，此时 Registrator 容器就已经正常启动了。 (f). 以相同的方式在其余两台主机上重复以上操作，再次访问 http://IP:8500 查看 Consul Server 的节点信息和服务注册列表。 Consul 集群节点信息，包括两台 Consul Server 节点和一台 Consul Client 节点，节点右侧可以看到所有的服务注册列表和相关的健康检查结果： nginx 服务状态列表，服务名称 nginx-consul-template，提供 http 服务，共有2个服务实例： test-client 服务状态列表，服务名称为 my-web-server，提供 http 服务，共有3个服务实例： test-server 服务状态列表，服务名称为 test-server-http-service 和 test-server-thrift-service，分别对应6个 http 服务实例和 6个 thrift 服务实例： 三台 Consul Client 主机上的容器服务实例均正常启动，服务注册和发现运行正常！ 4. 结果验证4.1. Nginx负载均衡4.1.1. 访问NginxNginx 默认访问端口号为80，任选一台 Nginx 访问，比如： http://192.168.1.181/swagger-ui.html。 请求转发至 Test Client 的 Swagger页面，表明 nginx配置文件 nginx.conf 被 Consul-template 成功修改。 4.1.2. 进入Nginx容器运行 docker ps 查看 nginx-consul-template 的容器 ID，比如这里是：4f2731a7e0cb。进入 nginx-consul-template 容器。 1docker-enter 4f2731a7e0cb 查看容器内部的进程列表： 特别留意以下一行进程命令，这里完成了三步重要的操作： 1consul-template -consul-addr=consul:8500 -template /etc/consul-templates/nginx.conf.ctmpl:/etc/nginx/conf.d/app.conf:nginx -s reload Consul-template 利用 Consul 上的服务信息对 Nginx 的配置文件模板 /etc/consul-templates/nginx.conf.ctmpl 进行重新解析和渲染。 渲染生成的 nginx 配置文件为 /etc/nginx/conf.d/app.conf。 进一步运行 nginx -s reload 重新加载 app.conf，更新路由转发列表。 查看 app.conf 的配置项，发现三个 test-client 节点的 IP:port 都加入了路由转发列表中。 退出并关闭主机 192.168.1.182 上的 test-client 容器。 再次查看 app.conf，可以发现路由节点 192.168.1.182:80 已经从 Nginx 的路由转发列表上剔除掉了。 同样的，重新启动 test-client 恢复容器，又可以发现 Nginx 的路由转发列表 再次自动将其添加! 4.2. 服务负载均衡4.2.1. 接口测试test-client 通过 http 通信方式请求任意一台 test-server，返回响应结果 (请求处理时间 ms )。 test-client 通过 thrift 通信方式请求任意一台 test-server，返回响应结果 (请求处理时间 ms )。 4.2.3. 日志分析服务的负载均衡并不是很好观察，这里直接截取了一段 test-client 的服务缓存列表动态定时刷新时打印的日志： 123456789101112131415161718192021222018-02-09 13:15:55.157 INFO 1 --- [erListUpdater-1] t.c.l.ThriftConsulServerListLoadBalancer : Refreshed thrift serverList: [test-server-thrift-service: [ ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-01], host='192.168.1.182', port=30000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-02], host='192.168.1.182', port=32000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-03], host='192.168.1.183', port=30000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-04], host='192.168.1.183', port=32000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-05], host='192.168.1.185', port=30000, address='192.168.1.185', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-06], host='192.168.1.185', port=32000, address='192.168.1.185', isHealth=true&#125;],test-server-http-service: [ ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-http-service', tags=[test-server-http-service-01], host='192.168.1.182', port=16000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-http-service', tags=[test-server-http-service-02], host='192.168.1.182', port=18000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-http-service', tags=[test-server-http-service-03], host='192.168.1.183', port=16000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-http-service', tags=[test-server-http-service-04], host='192.168.1.183', port=18000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-http-service', tags=[test-server-http-service-05], host='192.168.1.185', port=16000, address='192.168.1.185', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-http-service', tags=[test-server-http-service-06], host='192.168.1.185', port=18000, address='192.168.1.185', isHealth=true&#125;],my-web-server: [ ThriftServerNode&#123;node='consul_client_01', serviceId='my-web-server', tags=[test-client-http-service-01], host='192.168.1.182', port=80, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='my-web-server', tags=[test-client-http-service-02], host='192.168.1.183', port=80, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='my-web-server', tags=[test-client-http-service-03], host='192.168.1.185', port=80, address='192.168.1.185', isHealth=true&#125;]] 服务实例 test-server-http-service 所有健康的服务实例： 服务IP地址 服务端口 服务标签 192.168.1.182 16000 test-server-http-service-01 192.168.1.182 18000 test-server-http-service-02 192.168.1.183 16000 test-server-http-service-03 192.168.1.183 18000 test-server-http-service-04 192.168.1.185 16000 test-server-http-service-05 192.168.1.185 18000 test-server-http-service-06 test-server-thrift-service 所有健康的服务实例： 服务IP地址 服务端口 服务标签 192.168.1.182 30000 test-server-thrift-service-01 192.168.1.182 32000 test-server-thrift-service-02 192.168.1.183 30000 test-server-thrift-service-03 192.168.1.183 32000 test-server-thrift-service-04 192.168.1.185 30000 test-server-thrift-service-05 192.168.1.185 32000 test-server-thrift-service-06 my-web-server 所有健康的服务实例： 服务IP地址 服务端口 服务标签 192.168.1.182 80 test-client-http-service-01 192.168.1.183 80 test-client-http-service-02 192.168.1.185 80 test-client-http-service-03 spring-cloud-starter-thrift 采用的轮询的转发策略，也就是说 my-web-server 会按次序循环往来地将 http 或者 rpc 请求分发到各自的 6 个服务实例完成处理。 总结本文提供了一套基于微服务服务注册与发现体系和容器的高可用 (HA) 解决方案，引入了接入层和服务层的自动负载均衡的实现，详细给出了实践方案和技术手段！ 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"微服务系列","slug":"微服务系列","permalink":"https://ostenant.coding.me/categories/微服务系列/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://ostenant.coding.me/tags/Docker/"},{"name":"Consul","slug":"Consul","permalink":"https://ostenant.coding.me/tags/Consul/"},{"name":"Nginx","slug":"Nginx","permalink":"https://ostenant.coding.me/tags/Nginx/"},{"name":"Consul-template","slug":"Consul-template","permalink":"https://ostenant.coding.me/tags/Consul-template/"}]},{"title":"基于Docker + Consul + Registrator的服务注册与发现集群搭建","slug":"基于Docker + Consul + Registrator的服务注册与发现集群搭建","date":"2018-02-05T03:22:00.000Z","updated":"2018-05-08T02:49:46.096Z","comments":true,"path":"2018/02/05/基于Docker + Consul + Registrator的服务注册与发现集群搭建/","link":"","permalink":"https://ostenant.coding.me/2018/02/05/基于Docker + Consul + Registrator的服务注册与发现集群搭建/","excerpt":"前言近年微服务架构在互联网应用领域中愈来愈火，引入微服务主要解决了单体应用多个模块的紧耦合、无法扩展和运维困难等问题。微服务架构就是按照功能粒度将业务模块进行垂直拆分，对单体应用本身进行服务化和组件化，每个组件单独部署为小应用（从DB到UI）。微服务与微服务之间通过Service API进行交互，同时为了支持水平扩展、性能提升和服务可用性，单个服务允许同时部署一个或者多个服务实例。在运行时，每个实例通常是一个云虚拟机或者Docker容器。","text":"前言近年微服务架构在互联网应用领域中愈来愈火，引入微服务主要解决了单体应用多个模块的紧耦合、无法扩展和运维困难等问题。微服务架构就是按照功能粒度将业务模块进行垂直拆分，对单体应用本身进行服务化和组件化，每个组件单独部署为小应用（从DB到UI）。微服务与微服务之间通过Service API进行交互，同时为了支持水平扩展、性能提升和服务可用性，单个服务允许同时部署一个或者多个服务实例。在运行时，每个实例通常是一个云虚拟机或者Docker容器。 微服务系统内部多个服务的实例之间如何通信？如何感知到彼此的存在和销毁？生产者服务如何知道消费者服务的地址？如何实现服务与注册中心的解耦？这就需要一个第三方的服务注册中心，提供对生产者服务节点的注册管理和消费者服务节点的发现管理。 正文1. 服务发现与注册1.1. 具体流程 服务注册中心：作为整个架构中的核心，要支持分布式、持久化存储，注册信息变动实时通知消费者。 服务提供者：服务以 docker 容器化方式部署(实现服务端口的动态生成)，可以通过 docker-compose 的方式来管理。通过 Registrator 检测到 docker 进程信息以完成服务的自动注册。 服务消费者：要使用服务提供者提供的服务，和服务提供者往往是动态相互转位置的。 一个较为完整的服务注册与发现流程如下： 注册服务：服务提供者到注册中心注册； 订阅服务：服务消费者到注册中心订阅服务信息，对其进行监听； 缓存服务列表：本地缓存服务列表，减少与注册中心的网络通信； 调用服务：先查找本地缓存，找不到再去注册中心拉取服务地址，然后发送服务请求； 变更通知：服务节点变动时 (新增、删除等)，注册中心将通知监听节点，更新服务信息。 1.2. 相关组件一个服务发现系统主要由三部分组成： 注册器(registrator)：根据服务运行状态，注册/注销服务。主要要解决的问题是，何时发起注册/注销动作。 注册表(registry)：存储服务信息。常见的解决方案有zookeeper、etcd、cousul等。 发现机制(discovery)：从注册表读取服务信息，给用户封装访问接口。 1.3. 第三方实现对于第三方的服务注册与发现的实现，现有的工具主要有以下三种： zookeeper：一个高性能、分布式应用程序协调服务，用于名称服务、分布式锁定、共享资源同步和分布式配置管理。 Etcd：一个采用HTTP协议的健/值对存储系统，主要用于共享配置和服务发现，提供的功能相对Zookeeper和Consul相对简单。 Consul：一个分布式高可用的服务发现和配置共享的软件，支持服务发现与注册、多数据中心、健康检查和分布式键/值存储。 简单对比： 与Zookeeper和etcd不一样，Consul内嵌实现了服务发现系统，不需要构建自己的系统或使用第三方系统，客户只需要注册服务，并通过DNS或HTTP接口执行服务发现。 2. Consul和Registrator2.1. Consul简介Consul是什么 Consul 是一种分布式的、高可用、支持水平扩展的的服务注册与发现工具。它大致包括以下特性： 服务发现： Consul 通过 DNS 或者 HTTP 接口使服务注册和服务发现变的很容易。一些外部服务，例如 saas 提供的也可以一样注册； 健康检查：健康检测使 consul 可以快速的告警在集群中的操作。和服务发现的集成，可以防止服务转发到故障的服务上面； 键/值存储：一个用来存储动态配置的系统。提供简单的 HTTP 接口，可以在任何地方操作； 多数据中心：支持多数据中心以避免单点故障，内外网的服务采用不同的端口进行监听。而其部署则需要考虑网络延迟, 分片等情况等。zookeeper和etcd均不提供多数据中心功能的支持； 一致性算法：采用 Raft 一致性协议算法，比Paxos算法好用。 使用 GOSSIP 协议管理成员和广播消息, 并且支持 ACL 访问控制； 服务管理Dashboard：提供一个 Web UI 的服务注册于健康状态监控的管理页面。 Consul的几个概念 下图是Consul官方文档提供的架构设计图： 图中包含两个Consul数据中心，每个数据中心都是一个consul的集群。在数据中心1中，可以看出consul的集群是由N个SERVER，加上M个CLIENT组成的。而不管是SERVER还是CLIENT，都是consul集群的一个节点。所有的服务都可以注册到这些节点上，正是通过这些节点实现服务注册信息的共享。除了这两个，还有一些小细节 一一 简单介绍。 CLIENT CLIENT表示consul的client模式，就是客户端模式。是consul节点的一种模式，这种模式下，所有注册到当前节点的服务会被转发到SERVER节点，本身是不持久化这些信息。 SERVER SERVER表示consul的server模式，表明这个consul是个server节点。这种模式下，功能和CLIENT都一样，唯一不同的是，它会把所有的信息持久化的本地。这样遇到故障，信息是可以被保留的。 SERVER-LEADER 中间那个SERVER下面有LEADER的描述，表明这个SERVER节点是它们的老大。和其它SERVER不一样的一点是，它需要负责同步注册信息给其它的SERVER，同时也要负责各个节点的健康监测。 其它信息 其它信息包括各个节点之间的通信方式，还有一些协议信息、算法。它们是用于保证节点之间的数据同步、实时性要求等等一系列集群问题的解决。这些有兴趣的自己看看官方文档。 2.2. Registrator简介什么是RegistratorRegistrator是一个独立于服务注册表的自动服务注册/注销组件，一般以Docker container的方式进行部署。Registrator会自动侦测它所在的宿主机上的所有Docker容器状态（启用/销毁），并根据容器状态到对应的服务注册列表注册/注销服务。 事实上，Registrator通过读取同一台宿主机的其他容器Container的环境变量进行服务注册、健康检查定义等操作。 Registrator支持可插拔式的服务注册表配置，目前支持包括Consul, etcd和SkyDNS 2三种注册工具。 2.3. Docker安装Consul集群2.3.1. 集群节点规划我本地的使用的是Ubuntu16.04的虚拟机： 容器名称 容器IP地址 映射端口号 宿主机IP地址 服务运行模式 node1 172.17.0.2 8500 -&gt; 8500 192.168.127.128 Server Master node2 172.17.0.3 9500 -&gt; 8500 192.168.127.128 Server node3 172.17.0.4 10500 -&gt; 8500 192.168.127.128 Server node4 172.17.0.5 11500 -&gt; 8500 192.168.127.128 Client 2.3.2. Consul集群安装Consul的配置参数信息说明： 参数列表 参数的含义和使用场景说明 advertise 通知展现地址用来改变我们给集群中的其他节点展现的地址，一般情况下-bind地址就是展现地址 bootstrap 用来控制一个server是否在bootstrap模式，在一个datacenter中只能有一个server处于bootstrap模式，当一个server处于bootstrap模式时，可以自己选举为raft leader bootstrap-expect 在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导整个集群，该标记不能和bootstrap共用 bind 该地址用来在集群内部的通讯IP地址，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0 client consul绑定在哪个client地址上，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1 config-file 明确的指定要加载哪个配置文件 config-dir 配置文件目录，里面所有以.json结尾的文件都会被加载 data-dir 提供一个目录用来存放agent的状态，所有的agent允许都需要该目录，该目录必须是稳定的，系统重启后都继续存在 dc 该标记控制agent允许的datacenter的名称，默认是dc1 encrypt 指定secret key，使consul在通讯时进行加密，key可以通过consul keygen生成，同一个集群中的节点必须使用相同的key join 加入一个已经启动的agent的ip地址，可以多次指定多个agent的地址。如果consul不能加入任何指定的地址中，则agent会启动失败，默认agent启动时不会加入任何节点 retry-interval 两次join之间的时间间隔，默认是30s retry-max 尝试重复join的次数，默认是0，也就是无限次尝试 log-level consul agent启动后显示的日志信息级别。默认是info，可选：trace、debug、info、warn、err node 节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名 protocol consul使用的协议版本 rejoin 使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中 server 定义agent运行在server模式，每个集群至少有一个server，建议每个集群的server不要超过5个 syslog 开启系统日志功能，只在linux/osx上生效 pid-file 提供一个路径来存放pid文件，可以使用该文件进行SIGINT/SIGHUP(关闭/更新)agent 2.4. Docker安装Consul集群2.4.1. 拉取consul官方镜像1madison@ubuntu:~$ docker pull consul:latest 2.4.2. 启动Server节点运行consul镜像，启动Server Master节点node1： node1:12345678910111213madison@ubuntu:~$ docker run -d --name=node1 --restart=always \\ -e 'CONSUL_LOCAL_CONFIG=&#123;\"skip_leave_on_interrupt\": true&#125;' \\ -p 8300:8300 \\ -p 8301:8301 \\ -p 8301:8301/udp \\ -p 8302:8302/udp \\ -p 8302:8302 \\ -p 8400:8400 \\ -p 8500:8500 \\ -p 8600:8600 \\ -h node1 \\ consul agent -server -bind=172.17.0.2 -bootstrap-expect=3 -node=node1 \\ -data-dir=/tmp/data-dir -client 0.0.0.0 -ui 查看node1的日志，追踪运行情况： 现在集群中还没有选举leader节点，继续启动其余两台Server节点node2和node3： node2:123456789101112131415madison@ubuntu:~$ docker run -d --name=node2 --restart=always \\ -e 'CONSUL_LOCAL_CONFIG=&#123;\"skip_leave_on_interrupt\": true&#125;' \\ -p 9300:8300 \\ -p 9301:8301 \\ -p 9301:8301/udp \\ -p 9302:8302/udp \\ -p 9302:8302 \\ -p 9400:8400 \\ -p 9500:8500 \\ -p 9600:8600 \\ -h node2 \\ consul agent -server -bind=172.17.0.3 \\ -join=192.168.127.128 -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \\ -node=node2 \\ -data-dir=/tmp/data-dir -client 0.0.0.0 -ui 查看node2节点的进程启动日志： node3:123456789101112131415madison@ubuntu:~$ docker run -d --name=node3 --restart=always \\ -e 'CONSUL_LOCAL_CONFIG=&#123;\"skip_leave_on_interrupt\": true&#125;' \\ -p 10300:8300 \\ -p 10301:8301 \\ -p 10301:8301/udp \\ -p 10302:8302/udp \\ -p 10302:8302 \\ -p 10400:8400 \\ -p 10500:8500 \\ -p 10600:8600 \\ -h node2 \\ consul agent -server -bind=172.17.0.4 \\ -join=192.168.127.128 -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \\ -node=node3 \\ -data-dir=/tmp/data-dir -client 0.0.0.0 -ui 查看node3节点的进程启动日志： 当3个Server节点都启动并正常运行时，观察node2和node3的进程日志，可以发现node1被选举为leader节点，也就是这个数据中心的Server Master。 再次查看node1节点的进程启动日志： 观察日志发现，node2和node3都成功join到了node1所在的数据中心dc1。当集群中有3台Consul Server启动时，node1被选举为dc1中的主节点。然后，node1会通过心跳检查的方式，不断地对node2和node3进行健康检查。 2.4.4. 启动Client节点node4: 1234567891011121314madison@ubuntu:~$ docker run -d --name=node4 --restart=always \\ -e 'CONSUL_LOCAL_CONFIG=&#123;\"leave_on_terminate\": true&#125;' \\ -p 11300:8300 \\ -p 11301:8301 \\ -p 11301:8301/udp \\ -p 11302:8302/udp \\ -p 11302:8302 \\ -p 11400:8400 \\ -p 11500:8500 \\ -p 11600:8600 \\ -h node4 \\ consul agent -bind=172.17.0.5 -retry-join=192.168.127.128 \\ -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \\ -node=node4 -client 0.0.0.0 -ui 查看node4节点的进程启动日志: 可以发现：node4是以Client模式启动运行的。启动后完成后，把dc1数据中心中的以Server模式启动的节点node1、node2和node3都添加到本地缓存列表中。当客户端向node4发起服务发现的请求后，node4会通过RPC将请求转发给Server节点中的其中一台做处理。 2.4.5. 查看集群状态1madison@ubuntu:~$ docker exec -t node1 consul members dc1数据中心中的4个节点node1, node2, node3和node4分别成功启动，Status表示他们的状态，都为alive。node1, node2, node3以Server模式启动，而node4以Client模式启动。 2.5. Docker安装Registrator2.5.1. 拉取Registrator的镜像1madison@ubuntu:~$ docker pull gliderlabs/registrator:latest 2.5.2. 启动Registrator节点1234madison@ubuntu:~$ docker run -d --name=registrator \\ -v /var/run/docker.sock:/tmp/docker.sock \\ --net=host \\ gliderlabs/registrator -ip=\"192.168.127.128\" consul://192.168.127.128:8500 –net指定为host表明使用主机模式。 -ip用于指定宿主机的IP地址，用于健康检查的通信地址。 consul://192.168.127.128:8500: 使用Consul作为服务注册表，指定具体的Consul通信地址进行服务注册和注销（注意：8500是Consul对外暴露的HTTP通信端口）。 查看Registrator的容器进程启动日志： Registrator在启动过程完成了以下几步操作： 查看Consul数据中心的leader节点，作为服务注册表； 同步当前宿主机的启用容器，以及所有的服务端口； 分别将各个容器发布的服务地址/端口注册到Consul的服务注册列表。 2.5.3. 查看Consul的注册状态Consul提供了一个Web UI来可视化服务注册列表、通信节点、数据中心和键/值存储等，直接访问宿主机的8500端口。 服务注册列表： NODES节点下挂载着dc1数据中心中的所有的Consul节点，包括Consul Server和Client。 通信节点列表： 启动Registrator以后，宿主机中的所有容器把服务都注册到Consul的SERVICES上，测试完成！ 总结单数据中心的Consul集群的搭建就完成了！！！后续章节我会介绍如何使用Registrator进行服务注册的标签化。然后通过docker部署多实例的Web容器来实现基于HTTP的RESTful Service和基于TCP的RPC Service的服务注册和健康检查定义，并演示如何以标签标识一个服务的多个实例。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"微服务系列","slug":"微服务系列","permalink":"https://ostenant.coding.me/categories/微服务系列/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://ostenant.coding.me/tags/Docker/"},{"name":"Consul","slug":"Consul","permalink":"https://ostenant.coding.me/tags/Consul/"},{"name":"Registrator","slug":"Registrator","permalink":"https://ostenant.coding.me/tags/Registrator/"}]},{"title":"Spring Cloud整合Thrift RPC(二) - 应用案例","slug":"Spring Cloud整合Thrift RPC(二) - 应用案例","date":"2018-01-24T02:21:00.000Z","updated":"2018-05-08T02:49:46.092Z","comments":true,"path":"2018/01/24/Spring Cloud整合Thrift RPC(二) - 应用案例/","link":"","permalink":"https://ostenant.coding.me/2018/01/24/Spring Cloud整合Thrift RPC(二) - 应用案例/","excerpt":"前言上一篇简单的阐述了 spring-cloud-thrift-starter 这个插件的配置和使用，并引入了一个calculator的项目。本文将基于一个银行存款、取款的业务场景，给出一套thrift在生产环境的应用案例。","text":"前言上一篇简单的阐述了 spring-cloud-thrift-starter 这个插件的配置和使用，并引入了一个calculator的项目。本文将基于一个银行存款、取款的业务场景，给出一套thrift在生产环境的应用案例。 首先设计如下几张简单的数据库表：银行(bank)、分支(branch)、银行卡(deposit_card)、客户(customer)、存款历史纪录(deposit_history)、取款历史纪录(withdraw_history)。 正文项目结构如下，依然是由三个模块组成： deposit deposit-client deposit-iface deposit-server Thrift IDL编写关于 thrift更复杂的用法可以参考Apache Thrift基础学习系列，根据数据库表的设计编写 deposit.thrift。 deposit.thrift定义了以下四个部分：命名空间 (namespace)、枚举类型 (enum)、结构类型 (struct)和服务类型 (service)。 (a). 命名空间 (namespace) 12// 指定编译生成的源代码的包路径名称namespace java com.icekredit.rpc.thrift.examples.thrift (b). 枚举类型 (enum) 123456789101112131415161718192021222324// 通过枚举定义银行分支所属区域enum ThriftRegion &#123; NORTH = 1, CENTRAL = 2, SOUTH = 3, EAST = 4, SOUTHWEST = 5, NORTHWEST = 6, NORTHEAST = 7&#125;// 存款完成状态enum ThriftDepositStatus &#123; FINISHED = 1, PROCCEDING = 2, FAILED = 3&#125;// 取款完成状态enum ThriftWithdrawStatus &#123; FINISHED = 1, PROCCEDING = 2, FAILED = 3&#125; (c). 结构类型 (struct) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 银行struct ThriftBank &#123; 1: required i64 id, 2: required string code, 3: required string name, 4: optional string description, 5: optional map&lt;ThriftRegion, list&lt;ThriftBranch&gt;&gt; branches&#125;// 银行分支struct ThriftBranch &#123; 1: required i64 id, 2: required string code, 3: required string name, 4: required string address, 5: optional i32 staffs, 6: optional ThriftBank bank, 7: optional ThriftRegion region&#125;// 客户struct ThriftCustomer &#123; 1: required string IDNumber, 2: required string name, 3: required string birthday, 4: required i32 sex = 0, 5: required i32 age, 6: optional list&lt;string&gt; address, 7: optional set&lt;ThriftDepositCard&gt; depositCards&#125;// 银行卡struct ThriftDepositCard &#123; 1: required string id, 2: required bool isVip, 3: required string openingTime, 4: required double accountBalance, 5: optional double accountFlow, 6: optional ThriftBranch branch, 7: optional ThriftCustomer customer, 8: optional list&lt;ThriftDeposit&gt; depositHistory, 9: optional list&lt;ThriftWithdraw&gt; WithdrawHistory&#125;// 存款历史纪录struct ThriftDeposit &#123; 1: required string serialNumber, 2: required double transactionAmount, 3: required string submittedTime, 4: optional string finishedTime, 5: optional ThriftDepositStatus status, 6: optional ThriftDepositCard depositCard&#125;// 取款历史纪录struct ThriftWithdraw &#123; 1: required string serialNumber, 2: required double transactionAmount, 3: required string submittedTime, 4: optional string finishedTime, 5: optional ThriftWithdrawStatus status, 6: optional ThriftDepositCard depositCard&#125; (d). 服务类型 (service) 12345678910111213141516171819202122232425262728293031323334// 银行 - 业务服务定义service ThriftBankService &#123; void registerNewBank(ThriftBank bank); list&lt;ThriftBank&gt; queryAllBanks(); ThriftBank getBankById(i64 bankId); map&lt;ThriftRegion, list&lt;ThriftBranch&gt;&gt; queryAllBranchesByRegion(i64 bankId);&#125;// 银行分支 - 业务服务定义service ThriftBranchService &#123; void addNewBranch(i64 bankId, ThriftBranch branch); list&lt;ThriftBranch&gt; queryAllBranches(i64 bankId); ThriftBranch getBranchById(i64 branchId);&#125;// 客户 - 业务服务定义service ThriftCustomerService &#123; ThriftCustomer getCustomerById(string customerId); list&lt;ThriftCustomer&gt; queryAllCustomers(); void addNewUser(ThriftCustomer customer); void modifyUserById(string customerId, ThriftCustomer customer); i32 getTotalDepositCard(string customerId);&#125;// 银行卡 - 业务服务定义service ThriftDepositCardService &#123; set&lt;ThriftDepositCard&gt; queryAllDepositCards(string customerId); void addNewDepositCard(string customerId, ThriftDepositCard depositCard); ThriftDepositStatus depositMoney(string depositCardId, double money); ThriftWithdrawStatus withdrawMoney(string depositCardId, double money); list&lt;ThriftDeposit&gt; queryDepositHistorys(string depositCardId); list&lt;ThriftWithdraw&gt; queryWithdrawHistorys(string depositCardId);&#125; 进入src/main/thrift目录，编译生成所需的枚举类、结构类和业务服务类的源文件。 1thrift -gen java ./deposit.thrift 所有生成的源文件都位于同一个命名空间(包)下面：com.icekredit.rpc.thrift.examples.thrift 中间契约(deposit-iface)将上述源文件拷贝到 deposit-iface 模块中。 通过Mybatis逆向工程插件生成SQLMapper的XML和接口文件以及实体类。 友情提示：Mybatis逆向工程生成的实体类 (entity)，需要和Thrift编译生成器生成的结构类 (struct) 区分开来。而Thrift生成器生成的所有源文件，都一定程度封装了底层的通信方式和相关协议，开发人员是不应该动手脚的。 为了在Thrift中通过Mybatis完成数据持久化，必须在实体类 (entity)包装一层与结构类 (struct)相互转换的方法。在每个实体类中，根据业务添加以下两个方法，以DepositCard为例： toThrift()：将实体类对象转换为结构类对象。 1234567891011121314151617public ThriftDepositCard toThrift() &#123; ThriftDepositCard thriftDepositCard = new ThriftDepositCard(); thriftDepositCard.setId(this.getId()); thriftDepositCard.setAccountBalance(this.getAccountBalance()); thriftDepositCard.setAccountFlow(this.getAccountFlow()); thriftDepositCard.setIsVip(this.getIsVip()); thriftDepositCard.setOpeningTime(this.getOpeningTime()); ThriftBranch thriftBranch = new ThriftBranch(); thriftBranch.setId(this.getBranchId()); thriftDepositCard.setBranch(thriftBranch); ThriftCustomer thriftCustomer = new ThriftCustomer(); thriftCustomer.setIDNumber(this.getCustomerId()); thriftDepositCard.setCustomer(thriftCustomer); return thriftDepositCard;&#125; fromThrift()：静态方法，将结构类对象转换为实体类对象。 12345678910111213141516171819202122public static DepositCard fromThrift(ThriftDepositCard thriftDepositCard) &#123; DepositCard depositCard = new DepositCard(); depositCard.setId(thriftDepositCard.getId()); depositCard.setAccountBalance(thriftDepositCard.getAccountBalance()); depositCard.setAccountFlow(thriftDepositCard.getAccountFlow()); depositCard.setIsVip(thriftDepositCard.isIsVip()); ThriftCustomer thriftCustomer = thriftDepositCard.getCustomer(); if (thriftCustomer != null) &#123; String customerIDNumber = thriftCustomer.getIDNumber(); depositCard.setCustomerId(customerIDNumber); &#125; ThriftBranch thriftBranch = thriftDepositCard.getBranch(); if (thriftBranch != null) &#123; Long branchId = thriftBranch.getId(); depositCard.setBranchId(branchId); &#125; depositCard.setOpeningTime(thriftDepositCard.getOpeningTime()); return depositCard;&#125; 服务端(deposit-server)在服务端模块引入： spring-cloud-starter-thrift-server：thrift服务端的 starter程序。 calculator-iface：中间契约模块，这里作为服务端骨架(Skeleton)程序。 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;parent&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;deposit&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;deposit-server&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;dependencies&gt; &lt;!-- Thrift相关依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-thrift-server&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;deposit-iface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 数据库相关依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Swagger依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在application.yml中配置thrift服务端的运行参数、数据源连接池参数和Mybatis相关属性： application.yml 123456789101112131415161718192021222324252627282930313233343536373839404142server: port: 8080endpoints: actuator: sensitive: false enabled: truemanagement: security: enabled: falsespring: datasource: druid: url: jdbc:mysql://localhost:3306/deposit?useUnicode=true&amp;characterEncoding=utf-8 driver-class-name: com.mysql.jdbc.Driver username: root password: root thrift: server: service-id: deposit-server-rpc service-model: hsHa port: 25000 worker-queue-capacity: 1000 hs-ha: min-worker-threads: 5 max-worker-threads: 20 keep-alived-time: 3mybatis: mapper-locations: classpath:mapper/*.xml type-aliases-package: com.icekredit.rpc.thrift.examples.http.entitieslogging: level: root: INFO com: icekredit: rpc: thrift: examples: mapper: DEBUG 服务端程序启动入口类，设置 Swagger API所在的包路径名称。 Application.java 12345678910111213141516171819202122232425@SpringBootApplication@EnableSwagger2public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Bean public Docket createRestfulApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(\"com.icekredit.rpc.thrift.examples.service.http.controller\")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(\"Deposit Server\") .description(\"Deposit Server\") .version(\"1.0\") .build(); &#125;&#125; 编写服务端的Thrift的实现，以ThriftDepositCardService为例，由实现类ThriftDepositCardServiceImpl实现ThriftDepositCardService.Iface接口的方法： ThriftDepositCardServiceImpl.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106@ThriftService(name = \"thriftDepositCardService\")public class ThriftDepositCardServiceImpl implements ThriftDepositCardService.Iface &#123; private final BranchMapper branchMapper; private final DepositCardMapper depositCardMapper; private final CustomerMapper customerMapper; private final DepositHistoryMapper depositHistoryMapper; private final WithdrawHistoryMapper withdrawHistoryMapper; @Autowired public ThriftDepositCardServiceImpl(BranchMapper branchMapper, DepositCardMapper depositCardMapper, CustomerMapper customerMapper, DepositHistoryMapper depositHistoryMapper, WithdrawHistoryMapper withdrawHistoryMapper) &#123; this.branchMapper = branchMapper; this.depositCardMapper = depositCardMapper; this.customerMapper = customerMapper; this.depositHistoryMapper = depositHistoryMapper; this.withdrawHistoryMapper = withdrawHistoryMapper; &#125; @Override public Set&lt;ThriftDepositCard&gt; queryAllDepositCards(String customerId) throws TException &#123; List&lt;DepositCard&gt; depositCardList = depositCardMapper.queryAllDepositCards(customerId); // 查询客户持有的银行卡 return depositCardList.stream().map(depositCard -&gt; &#123; ThriftDepositCard thriftDepositCard = depositCard.toThrift(); Long branchId = depositCard.getBranchId(); if (Objects.nonNull(branchId) &amp;&amp; branchId &gt; 0L) &#123; Branch branch = branchMapper.findById(branchId); ThriftBranch thriftBranch = branch.toThrift(); ThriftBank thriftBank = new ThriftBank(); thriftBank.setId(branch.getBankId()); thriftBranch.setBank(thriftBank); thriftDepositCard.setBranch(thriftBranch); &#125; Customer customer = customerMapper.findById(customerId); ThriftCustomer thriftCustomer = customer.toThrift(); thriftDepositCard.setCustomer(thriftCustomer); return thriftDepositCard; &#125;).collect(Collectors.toSet()); &#125; @Override @Transactional public void addNewDepositCard(String customerId, ThriftDepositCard depositCard) throws TException &#123; DepositCard newDepositCard = DepositCard.fromThrift(depositCard); // 新增银行卡信息 depositCardMapper.save(newDepositCard); &#125; @Override @Transactional public ThriftDepositStatus depositMoney(String depositCardId, double money) throws TException &#123; SimpleDateFormat sf = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss\"); try &#123; DepositHistory depositHistory = new DepositHistory(); depositHistory.setSubmittedTime(sf.format(new Date())); depositCardMapper.incrementMoney(depositCardId, money); depositHistory.setFinishedTime(sf.format(new Date())); depositHistory.setSerialNumber(UUID.randomUUID().toString().replace(\"-\", \"\")); depositHistory.setTransactionAmount(money); depositHistory.setDepositCardId(depositCardId); depositHistory.setStatus(1); // 新增存款历史记录 depositHistoryMapper.save(depositHistory); return ThriftDepositStatus.FINISHED; &#125; catch (Exception e) &#123; e.printStackTrace(); return ThriftDepositStatus.FAILED; &#125; &#125; @Override @Transactional public ThriftWithdrawStatus withdrawMoney(String depositCardId, double money) throws TException &#123; SimpleDateFormat sf = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss\"); try &#123; WithdrawHistory withdrawHistory = new WithdrawHistory(); withdrawHistory.setSubmittedTime(sf.format(new Date())); depositCardMapper.decrementMoney(depositCardId, money); withdrawHistory.setFinishedTime(sf.format(new Date())); withdrawHistory.setSerialNumber(UUID.randomUUID().toString().replace(\"-\", \"\")); withdrawHistory.setTransactionAmount(money); withdrawHistory.setDepositCardId(depositCardId); withdrawHistory.setStatus(1); // 新增取款历史记录 withdrawHistoryMapper.save(withdrawHistory); return ThriftWithdrawStatus.FINISHED; &#125; catch (Exception e) &#123; e.printStackTrace(); return ThriftWithdrawStatus.FAILED; &#125; &#125; @Override public List&lt;ThriftDeposit&gt; queryDepositHistorys(String depositCardId) throws TException &#123; List&lt;DepositHistory&gt; depositHistory = depositHistoryMapper.queryDepositHistoryList(depositCardId); // 查询存款历史纪录 return depositHistory.stream().map(DepositHistory::toThrift).collect(Collectors.toList()); &#125; @Override public List&lt;ThriftWithdraw&gt; queryWithdrawHistorys(String depositCardId) throws TException &#123; List&lt;WithdrawHistory&gt; withdrawHistory = withdrawHistoryMapper.queryWithdrawHistoryList(depositCardId); // 查询取款历史纪录 return withdrawHistory.stream().map(WithdrawHistory::toThrift).collect(Collectors.toList()); &#125;&#125; Mybatis持久层，还是以DepositCardMapper为例： DepositCardMapper.java 123456789@Repository@Mapperpublic interface DepositCardMapper &#123; int save(DepositCard record); List&lt;DepositCard&gt; queryAllDepositCards(@Param(\"customerId\") String customerId); void decrementMoney(@Param(\"depositCardId\") String depositCardId, @Param(\"money\") Double money); void incrementMoney(@Param(\"depositCardId\") String depositCardId, @Param(\"money\") Double money); Long countRowsByCustomerId(@Param(\"customerId\") String customerId);&#125; DepositCardMapper.xml 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;insert id=\"save\" parameterType=\"com.icekredit.rpc.thrift.examples.http.entities.DepositCard\"&gt; INSERT INTO deposit_card (id, is_vip, opening_time, account_balance, account_flow, branch_id, customer_id) VALUES (#&#123;id,jdbcType=VARCHAR&#125;, #&#123;isVip,jdbcType=BIT&#125;, #&#123;openingTime,jdbcType=VARCHAR&#125;, #&#123;accountBalance,jdbcType=DOUBLE&#125;, #&#123;accountFlow,jdbcType=DOUBLE&#125;, #&#123;branchId,jdbcType=BIGINT&#125;, #&#123;customerId,jdbcType=VARCHAR&#125;)&lt;/insert&gt;&lt;select id=\"queryAllDepositCards\" resultMap=\"BaseResultMap\" parameterType=\"java.lang.String\"&gt; SELECT &lt;include refid=\"Base_Column_List\"/&gt; FROM deposit_card WHERE customer_id = #&#123;customerId&#125;&lt;/select&gt;&lt;select id=\"countRowsByCustomerId\" resultType=\"java.lang.Long\" parameterType=\"java.lang.String\"&gt; SELECT COUNT(id) FROM deposit_card WHERE customer_id = #&#123;customerId&#125;&lt;/select&gt;&lt;update id=\"decrementMoney\"&gt; UPDATE deposit_card &lt;set&gt; &lt;if test=\"money != null\"&gt; account_balance = account_balance - #&#123;money&#125;, &lt;/if&gt; &lt;/set&gt; WHERE id = #&#123;depositCardId&#125;&lt;/update&gt;&lt;update id=\"incrementMoney\"&gt; UPDATE deposit_card &lt;set&gt; &lt;if test=\"money != null\"&gt; account_balance = account_balance + #&#123;money&#125;, &lt;/if&gt; &lt;/set&gt; WHERE id = #&#123;depositCardId&#125;&lt;/update&gt; 客户端(deposit-client)同样，在客户端模块引入： spring-cloud-starter-thrift-client：thrift客户端的 starter程序。 deposit-iface：中间契约模块，这里作为客户端桩(Stub)程序。 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;parent&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;deposit&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;deposit-client&lt;/artifactId&gt;&lt;dependencies&gt; &lt;!-- Thrift相关依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-thrift-client&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;deposit-iface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud Consul服务注册与发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud声明式Restful客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Swagger依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在application.yml中配置thrift的客户端的的运行参数和 Consul 的服务注册与发现的参数： application.yml 12345678910111213141516171819202122232425262728293031323334server: port: 8080endpoints: actuator: sensitive: false enabled: truemanagement: security: enabled: falsespring: cloud: consul: host: 192.168.91.128 port: 8500 discovery: register: false register-health-check: true health-check-interval: 30s retry: max-attempts: 3 max-interval: 2000 thrift: client: package-to-scan: com.icekredit.rpc.thrift.examples.thrift.client service-model: hsHa pool: retry-times: 3 pool-max-total-per-key: 200 pool-min-idle-per-key: 10 pool-max-idle-per-key: 40 pool-max-wait: 10000 connect-timeout: 5000 客户端程序启动入口类，设置 Swagger API所在的包路径名称，同时允许自身作为注册程序注册到注册中心。 123456789101112131415161718192021222324252627@SpringBootApplication@EnableFeignClients@EnableDiscoveryClient@EnableSwagger2public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Bean public Docket createRestfulApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(\"com.icekredit.rpc.thrift.examples\")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(\"Deposit Client\") .description(\"Deposit Client\") .version(\"1.0\") .build(); &#125;&#125; 在客户端使用@ThriftClient注解标识服务端的thrift服务代理接口，代理服务ID为deposit-server-rpc，代理的目标类是ThriftDepositCardService。 DepositCardThriftClient.java 123@ThriftClient(serviceId = \"deposit-server-rpc\", refer = ThriftDepositCardService.class)public interface DepositCardThriftClient extends ThriftClientAware&lt;ThriftDepositCardService.Client&gt; &#123;&#125; BankThriftClient.java 123@ThriftClient(serviceId = \"deposit-server-rpc\", refer = ThriftBankService.class)public interface BankThriftClient extends ThriftClientAware&lt;ThriftBankService.Client&gt; &#123;&#125; 在客户端控制器中通过ThriftReferer注入需要使用的服务代理接口，通过 thriftClient.client()即可获取Thrift客户端桩对象，然后实现远程服务的调用。 DepositCardRpcController.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@RestController@RequestMapping(\"/rpc/deposit\")public class DepositCardRpcController &#123; @ThriftReferer private DepositCardThriftClient thriftClient; @GetMapping(\"/queryAllDepositCards\") public List&lt;DepositCard&gt; queryAllDepositCards(@RequestParam(\"customerId\") String customerId) throws Exception &#123; return thriftClient.client().queryAllDepositCards(customerId) .stream().map(DepositCard::fromThrift) .collect(Collectors.toList()); &#125; @PostMapping(\"/addNewDepositCard\") public void addNewDepositCard(DepositCard depositCard) throws Exception &#123; thriftClient.client().addNewDepositCard(depositCard.getCustomerId(), depositCard.toThrift()); &#125; @GetMapping(\"/depositMoney\") public ThriftDepositStatus depositMoney(@RequestParam(\"depositCardId\") String depositCardId, @RequestParam(\"money\") double money) throws Exception &#123; return thriftClient.client().depositMoney(depositCardId, money); &#125; @GetMapping(\"/withdrawMoney\") public ThriftWithdrawStatus withdrawMoney(@RequestParam(\"depositCardId\") String depositCardId, @RequestParam(\"money\") double money) throws Exception &#123; return thriftClient.client().withdrawMoney(depositCardId, money); &#125; @GetMapping(\"/queryDepositHistory\") public List&lt;DepositHistory&gt; queryDepositHistory(@RequestParam(\"depositCardId\") String depositCardId) throws Exception &#123; return thriftClient.client().queryDepositHistorys(depositCardId) .stream().map(DepositHistory::fromThrift) .collect(Collectors.toList()); &#125; @GetMapping(\"/queryWithdrawHistory\") public List&lt;WithdrawHistory&gt; queryWithdrawHistory(@RequestParam(\"depositCardId\") String depositCardId) throws Exception &#123; return thriftClient.client().queryWithdrawHistorys(depositCardId) .stream().map(WithdrawHistory::fromThrift) .collect(Collectors.toList()); &#125;&#125; BankRpcController.java 123456789101112131415161718192021222324252627282930313233@RestController@RequestMapping(\"/rpc/bank\")public class BankRpcController &#123; @ThriftReferer private BankThriftClient thriftClient; @PostMapping(\"/addNewBank\") public void addNewBank(Bank bank) throws Exception &#123; thriftClient.client().registerNewBank(bank.toThrift()); &#125; @GetMapping(\"/getBankById\") public Bank getBankById(@RequestParam(\"bankId\") Long bankId) throws Exception &#123; return Bank.fromThrift(thriftClient.client().getBankById(bankId)); &#125; @GetMapping(\"/queryAllBranchesByRegion\") public Map&lt;Region, List&lt;Branch&gt;&gt; queryAllBranchesByRegion(@RequestParam(\"bankId\") Long bankId) throws Exception &#123; Map&lt;ThriftRegion, List&lt;ThriftBranch&gt;&gt; thriftRegionListMap = thriftClient.client() .queryAllBranchesByRegion(bankId); Map&lt;Region, List&lt;Branch&gt;&gt; regionListMap = new HashMap&lt;&gt;(); for (Map.Entry&lt;ThriftRegion, List&lt;ThriftBranch&gt;&gt; entry : thriftRegionListMap.entrySet()) &#123; ThriftRegion thriftRegion = entry.getKey(); Region region = Region.findByValue(thriftRegion.getValue()); List&lt;ThriftBranch&gt; thriftBranches = entry.getValue(); List&lt;Branch&gt; branchList = thriftBranches.stream().map(Branch::fromThrift).collect(Collectors.toList()); regionListMap.put(region, branchList); &#125; return regionListMap; &#125;&#125; 因为服务代理客户端接口使用@ThriftClient标识，通过(服务ID + 客户端桩 + 版本号)唯一标识, 即使同时注入多个服务代理客户端接口，@ThriftReferer也可忽略注解属性的配置。 总结有一点是肯定的，那就是在已有技术框架(比如说：Spring + Mybatis/JPA)内，为了提高服务的性能和吞吐量，而引入诸如Thrift的RPC框架，编程难度和复杂度是会大大提高的。好比一把双刃剑，技术选型时还需要多方面权衡利弊。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"Thrift","slug":"Thrift","permalink":"https://ostenant.coding.me/tags/Thrift/"},{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://ostenant.coding.me/tags/Spring-Cloud/"}]},{"title":"Spring Cloud整合Thrift RPC(一) - 使用指南","slug":"Spring Cloud整合Thrift RPC(一) - 使用指南","date":"2018-01-18T07:07:00.000Z","updated":"2018-05-08T02:49:46.092Z","comments":true,"path":"2018/01/18/Spring Cloud整合Thrift RPC(一) - 使用指南/","link":"","permalink":"https://ostenant.coding.me/2018/01/18/Spring Cloud整合Thrift RPC(一) - 使用指南/","excerpt":"前言前面几篇博客，着重对Apache Thrift的使用和原理做了介绍。在微服架构流行的今天，自然而然就会想到Spring Boot和Spring Cloud作为微服务的基础框架。然而，Spring Cloud从诞生以来，就基于HTTP协议的轻量级Restful API作为服务之间的通信方式。","text":"前言前面几篇博客，着重对Apache Thrift的使用和原理做了介绍。在微服架构流行的今天，自然而然就会想到Spring Boot和Spring Cloud作为微服务的基础框架。然而，Spring Cloud从诞生以来，就基于HTTP协议的轻量级Restful API作为服务之间的通信方式。 在微服务架构设计中，可以分为外部服务和内部服务。两者主要区别是： 外部服务：基于Restful风格的HTTP协议，通过外网向外部提供服务，相对来说简单并且通用。 内部服务：基于RPC消息通信的TCP/IP协议，提供内网服务与服务之间的调用，以达到减少带宽、降低延迟率、提高性能。 一些应用场景，尤其是内部服务需要高频地调用，就需要考虑是否需要改造为RPC实现，来提高吞吐量和系统性能，比如说鉴权服务一类。 正文简述下载 spring-cloud-starter-thrift并导入IDEA开发环境，项目地址：https://github.com/ostenant/spring-cloud-starter-thrift spring-cloud-starter-thrift 提供 Spring Cloud 对可伸缩的跨语言服务调用框架Apache Thrift的封装和集成。 spring-cloud-starter-thrift包括客户端spring-cloud-starter-thrift-client和服务端spring-cloud-starter-thrift-server两个模块。而spring-cloud-starter-thrift-examples 子模块提供了3个示例项目：calculator、deposit和test。 calculator：简单上手项目示例。 deposit：复杂业务场景项目示例。 test：性能测试项目示例。 服务端 支持 Apache Thrift的各种原生线程服务模型，包括单线程阻塞模型(simple)、单线程非阻塞模型(nonBlocking)、线程池阻塞模型(threadPool)、半同步半异步模型(hsHa)和线程选择器模型(threadedSelector)。 支持 Apache Thrift 0.10.0版本后提供的多路复用处理器，提供服务的统一注册管理功能。 支持由服务签名 (服务ID + 客户端Stub接口名称 + 服务版本号) 唯一标识服务Stub的具体实现类，支持服务版本的平滑升级。 支持Server Group形式的启动方式，每个服务实例可以开启多台Thrift Server，通过不同的端口号暴露给客户端。 客户端 支持由服务签名 (服务ID + 客户端Stub接口名称 + 服务版本号) 唯一标识和调用服务端的Stub具体实现类。 支持Apache Thrift的Transport层的连接池管理，减少了客户端与服务端之间连接的频繁创建和销毁。 支持与Spring Cloud Consul的无缝集成，客户端通过心跳检测与服务注册中心Consul保持连接，动态定时的刷新服务列表、监测服务的启用、关闭和健康状态。 支持客户端负载均衡，包括随机、轮询的负载均衡策略，客户端的Thrift程序通过本地的服务缓存列表实现调用的动态转发。 快速上手项目结构： calculator calculator-client calculator-iface calculator-server spring-cloud-starter-thrift 使用的是 0.10.0版本的 thrift。以calculator项目入手，首先，通过 Thrift IDL (接口描述语言) 编写客户端桩Stub和服务端骨架Skeleton，通过.thrift文件定义接口规范。 首先进入 spring-cloud-starter-thrift 根目录，pom.xml 定义如下： pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.8.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;modules&gt; &lt;module&gt;calculator-client&lt;/module&gt; &lt;module&gt;calculator-server&lt;/module&gt; &lt;module&gt;calculator-iface&lt;/module&gt;&lt;/modules&gt;&lt;artifactId&gt;calculator&lt;/artifactId&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Dalston.SR4&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 将项目打包并安装到本地Maven仓库： 1mvn clean install Thrift IDL编写1234567namespace java com.icekredit.rpc.thrift.exampleservice CalculatorService &#123; i32 add(1: i32 arg1, 2: i32 arg2) i32 subtract(1: i32 arg1, 2: i32 arg2) i32 multiply(1: i32 arg1, 2: i32 arg2) i32 division(1: i32 arg1, 2: i32 arg2)&#125; 下载并安装0.10.0的 Thrift IDL编译生成器，下载地址：http://thrift.apache.org/docs/install。通过编译器生成.java的Stub类文件。 1thrift -gen java ./CalculatorService.thrift 编译器生成的CalculatorService.java文件。CalculatorService.java有成千上万行代码。对于开发人员而言，只需要关注以下四个核心接口/类：Iface、AsyncIface、Client和AsyncClient。 Iface：服务端通过实现 HelloWorldService.Iface 接口，向客户端的提供具体的同步业务逻辑。 AsyncIface：服务端通过实现 HelloWorldService.Iface 接口，向客户端的提供具体的异步业务逻辑。 Client：客户端通过 HelloWorldService.Client 的实例对象，以同步的方式访问服务端提供的服务方法。 AsyncClient：客户端通过 HelloWorldService.AsyncClient 的实例对象，以异步的方式访问服务端提供的服务方法。 中间契约(calculator-iface)在中间契约模块引入thrift的maven依赖，拷贝上一步thrift编译生成器生成的 CalculatorService源文件到此模块。 pom.xml 123456789101112131415&lt;parent&gt; &lt;artifactId&gt;calculator&lt;/artifactId&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;calculator-iface&lt;/artifactId&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt; &lt;artifactId&gt;libthrift&lt;/artifactId&gt; &lt;version&gt;0.10.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 服务端(calculator-server)在服务端模块引入： spring-cloud-starter-thrift-server：thrift服务端的 starter程序。 calculator-iface：中间契约模块，这里作为服务端骨架(Skeleton)程序。 pom.xml 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;artifactId&gt;calculator&lt;/artifactId&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;calculator-server&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-thrift-server&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;calculator-iface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在application.yml中配置thrift服务端的运行参数： application.yml 1234567891011121314151617181920212223242526## 服务端Restful服务所在的HTTP端口号server: port: 8080## 用于Consul健康检查endpoints: actuator: sensitive: false enabled: truemanagement: security: enabled: false## Spring Thrift服务端配置spring: thrift: server: service-id: thrift-rpc-calculator ## service-model: hsHa ## 半同步/半异步服务模型 port: 25000 ## 服务端RPC服务所在的TCP端口号 worker-queue-capacity: 1000 ## 半同步/半异步服务模型参数配置 hs-ha: min-worker-threads: 5 ## 最少工作线程数 max-worker-threads: 20 ## 最大工作线程数 keep-alived-time: 3 ## 空闲线程存活时间 实现Thrift IDL生成的骨架(Skeleton)类CalculatorService的内部接口Iface，编写具体的业务逻辑： 这里需要注意几点： 实现 CalculatorService.Iface接口。 实现类标记 @ThriftService注解，包含以下属性： name：通过name标识服务名称，缺省时默认为类名称首字母小写。 version：通过version标识服务版本，缺省值为1.0，也就是说同一个服务名称可以拥有多个版本实现。 RpcCalculatorService.java 123456789101112131415161718192021222324252627282930@ThriftService(name = \"rpcCalculatorService\", version = 2.0)public class RpcCalculatorService implements CalculatorService.Iface &#123; @Override public int add(int arg1, int arg2) &#123; BigDecimal arg1Decimal = new BigDecimal(arg1); BigDecimal arg2Decimal = new BigDecimal(arg2); return arg1Decimal.add(arg2Decimal).intValue(); &#125; @Override public int subtract(int arg1, int arg2) &#123; BigDecimal arg1Decimal = new BigDecimal(arg1); BigDecimal arg2Decimal = new BigDecimal(arg2); return arg1Decimal.subtract(arg2Decimal).intValue(); &#125; @Override public int multiply(int arg1, int arg2) &#123; BigDecimal arg1Decimal = new BigDecimal(arg1); BigDecimal arg2Decimal = new BigDecimal(arg2); return arg1Decimal.multiply(arg2Decimal).intValue(); &#125; @Override public int division(int arg1, int arg2) &#123; BigDecimal arg1Decimal = new BigDecimal(arg1); BigDecimal arg2Decimal = new BigDecimal(arg2); return arg1Decimal.divide(arg2Decimal).intValue(); &#125;&#125; 对服务端程序进行打包： 1mvn clean package -Dmaven.test.skip=true 编写 Dockerfile 文件： 123FROM openjdk:8-jdk-alpineADD target/spring-boot-thrift-server-0.0.1-SNAPSHOT.jar calculator-server.jarENTRYPOINT [\"java\", \"-jar\", \"calculator-server.jar\"] 将Dockerfile 和 target/spring-boot-thrift-server-0.0.1-SNAPSHOT.jar拷贝到服务器上，构建 Thrift Server 的服务镜像： 1docker build . -t icekredit/calculator-server 客户端(calculator-client)在客户端模块引入： spring-cloud-starter-thrift-client：thrift客户端的 starter程序。 calculator-iface：中间契约模块，这里作为客户端桩(Stub)程序。 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;parent&gt; &lt;artifactId&gt;calculator&lt;/artifactId&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;calculator-client&lt;/artifactId&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-thrift-client&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;calculator-iface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在 application.yml中配置 thrift客户端的运行参数，需要与服务端配置保持一致： 1234567891011121314151617181920212223242526272829303132333435363738394041## 客户端Restful服务所在的HTTP端口号server: port: 8080## 用于Consul健康检查endpoints: actuator: sensitive: false enabled: truemanagement: security: enabled: false## Spring Thrift客户端配置(Thrift Client的自动配置取决于Spring Cloud Consul的正确配置)spring: application: name: thrift-calculator-client cloud: consul: host: 192.168.91.128 ## Consul的IP地址 port: 8500 ## Consul的HTTP端口号 discovery: register: false ## 不使用SpringCloud提供的基于服务的程序注册方式 register-health-check: false ## 不使用Spring Cloud进行健康检查 retry: max-attempts: 3 max-interval: 2000 ## Thrift Client配置 thrift: client: package-to-scan: com.icekredit.rpc.thrift.example.rpc ## 标记由有注解@ThriftClient接口的包路径 service-model: hsHa ##服务线程模型（这里必须与服务端保持一致, 默认都是hsHa） ## 客户端连接池配置 pool: retry-times: 3 ## 异常失败，连接超时后的重试次数 ## key由IP + Port组成，唯一标识一个服务实例 pool-max-total-per-key: 200 ## 客户端保持的最大连接数，包含不同的服务和服务实例 pool-min-idle-per-key: 10 ## 每个服务实例最小的空闲连接数 pool-max-idle-per-key: 40 ## 每个服务实例最大的空闲连接数 pool-max-wait: 30000 ## 空闲连接最大存活时间 connect-timeout: 2000 ## 连接超时时间 编写 Thrift Client的客户端代理接口，这里有两点注意事项： 接口需要继承于父接口 ThriftClientAware，且 ThriftClientAware 里的泛型参数填写为 Thrift IDL 生成的 Stub 类 CalculatorService 中的 Client 内部类。 接口需要标识 @ThriftClient 注解， @ThriftClient 包含如下属性： serviceId：此客户端代理接口绑定的 Thrift 服务端的服务注册ID (与服务端保持一致)。 refer：客户端桩 Stub的类型，例如这里是CalculatorService.class。 version：具体业务实现类的版本号(不填写默认为1.0)，需要与服务端保持一致。 CalculatorThriftClient.java 123@ThriftClient(serviceId = \"thrift-rpc-calculator\", refer = CalculatorService.class, version = 2.0)public interface CalculatorThriftClient extends ThriftClientAware&lt;CalculatorService.Client&gt; &#123;&#125; 使用注解 @ThriftReferer，在客户端的 Controller 中注入 CalculatorThriftClient。 使用时，通过 CalculatorThriftClient.thriftClient() 方法，即可调用Thrift Server的服务方法。 RpcCalculatorController.java 1234567891011121314151617181920212223242526@RestController@RequestMapping(\"/rpc\")public class RpcCalculatorController &#123; @ThriftReferer private CalculatorThriftClient calculators; @GetMapping(\"/add\") public int add(@RequestParam(\"arg1\") int arg1, @RequestParam(\"arg2\") int arg2) throws Exception &#123; return calculators.client().add(arg1, arg2); &#125; @GetMapping(\"/subtract\") public int subtract(@RequestParam(\"arg1\") int arg1, @RequestParam(\"arg2\") int arg2) throws Exception &#123; return calculators.client().subtract(arg1, arg2); &#125; @GetMapping(\"/multiply\") public int multiply(@RequestParam(\"arg1\") int arg1, @RequestParam(\"arg2\") int arg2) throws Exception &#123; return calculators.client().multiply(arg1, arg2); &#125; @GetMapping(\"/division\") public int division(@RequestParam(\"arg1\") int arg1, @RequestParam(\"arg2\") int arg2) throws Exception &#123; return calculators.client().division(arg1, arg2); &#125;&#125; 测试方便，在本地开发环境配置Consul的地址，运行客户端程序即可。对于容器环境测试，配置对客户端程序进行打包： 1mvn clean package -Dmaven.test.skip=true 编写 Dockerfile 文件： 123FROM openjdk:8-jdk-alpineADD target/spring-boot-thrift-client-0.0.1-SNAPSHOT.jar calculator-client.jarENTRYPOINT [\"java\", \"-jar\", \"calculator-client.jar\"] 将Dockerfile 和 target/spring-boot-thrift-client-0.0.1-SNAPSHOT.jar拷贝到服务器上，构建 Thrift Client 的服务镜像： 1docker build . -t icekredit/calculator-client 简单测试发布服务端程序为了方便测试，在一台主机上启动三个 Thrift Server 的 docker 容器，以不同的端口区分，分别指定对应的端口号和 Consul 注册信息： Thrift Server实例1(25001端口)： 1234567docker run -d -p 8081:8080 -p 25001:25000 --name calculator-server-01 \\ -e \"SERVICE_25000_NAME=thrift-rpc-calculator\" \\ -e \"SERVICE_25000_CHECK_TCP=/\" \\ -e \"SERVICE_25000_CHECK_INTERVAL=30s\" \\ -e \"SERVICE_25000_CHECK_TIMEOUT=3s\" \\ -e \"SERVICE_25000_TAGS=thrift-rpc-calculator-25001\" \\ icekredit/calculator-server Thrift Server实例2(25002端口)： 1234567docker run -d -p 8081:8080 -p 25002:25000 --name calculator-server-01 \\ -e \"SERVICE_25000_NAME=thrift-rpc-calculator\" \\ -e \"SERVICE_25000_CHECK_TCP=/\" \\ -e \"SERVICE_25000_CHECK_INTERVAL=30s\" \\ -e \"SERVICE_25000_CHECK_TIMEOUT=3s\" \\ -e \"SERVICE_25000_TAGS=thrift-rpc-calculator-25002\" \\ icekredit/calculator-server Thrift Server实例3(25003端口)： 1234567docker run -d -p 8081:8080 -p 25003:25000 --name calculator-server-01 \\ -e \"SERVICE_25000_NAME=thrift-rpc-calculator\" \\ -e \"SERVICE_25000_CHECK_TCP=/\" \\ -e \"SERVICE_25000_CHECK_INTERVAL=30s\" \\ -e \"SERVICE_25000_CHECK_TIMEOUT=3s\" \\ -e \"SERVICE_25000_TAGS=thrift-rpc-calculator-25003\" \\ icekredit/calculator-server 观察各个容器的启动日志，如果包含以下几行输出信息，则表明 Thrift Server 成功启动并正常提供 RPC 服务。 12342017-11-19 22:28:47.779 INFO 12960 --- [ main] c.i.r.t.s.context.ThriftServerContext : Build thrift server from HsHaServerContext2017-11-19 22:28:47.820 INFO 12960 --- [ main] c.i.r.t.s.p.TRegisterProcessorFactory : Processor bean org.ostenant.springboot.learning.examples.CalculatorService$Processor@445bce9a with signature [thrift-rpc-calculator$org.ostenant.springboot.learning.examples.CalculatorService$2.0] is instantiated2017-11-19 22:28:47.822 INFO 12960 --- [ main] c.i.r.t.s.p.TRegisterProcessorFactory : Single processor org.ostenant.springboot.learning.examples.CalculatorService$Processor@445bce9a register onto multiplexed processor with signature [thrift-rpc-calculator$org.ostenant.springboot.learning.examples.CalculatorService$2.0]2017-11-19 22:28:47.822 INFO 12960 --- [ main] c.i.r.t.s.p.TRegisterProcessorFactory : Multiplexed processor totally owns 1 service processors 启动 Consul 和Registrator 容器，Thrift Server 的三个服务实例成功注册到Consul服务列表： 有关 Consul和 Registrator的安装配置以及使用，请参考：Docker+Consul+Registrator(一) 搭建服务发现与注册集群！ 服务端程序成功运行，Thrift RPC服务正常发布！ 启动客户端程序在本地 8080 端口号启动 Thrift 客户端，正常启动后观察启动日志如下： 12345678910112017-11-20 11:00:20.025 INFO 4052 --- [ main] .r.t.c.ThriftClientBeanScannerConfigurer : Base package org.ostenant.springboot.learning.examples.rpc is to be scanned with com.icekredit.rpc.thrift.client.scanner.ThriftClientBeanScanner@374967202017-11-20 11:00:20.029 INFO 4052 --- [ main] c.i.r.t.c.s.ThriftClientBeanScanner : Packages scanned by thriftClientBeanDefinitionScanner is [org.ostenant.springboot.learning.examples.rpc]2017-11-20 11:00:20.029 INFO 4052 --- [ main] c.i.r.t.c.s.ThriftClientBeanScanner : Scanned and found thrift client, bean calculatorThriftClient assigned from org.ostenant.springboot.learning.examples.rpc.CalculatorThriftClient2017-11-20 11:00:20.050 INFO 4052 --- [ main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring2017-11-20 11:00:20.134 INFO 4052 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.ostenant.springboot.learning.examples.rest.CalculatorFeignClient' of type [org.springframework.cloud.netflix.feign.FeignClientFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-11-20 11:00:20.136 WARN 4052 --- [ main] c.i.r.t.c.s.ThriftClientFactoryBean : Bean class is not found2017-11-20 11:00:20.142 INFO 4052 --- [ main] c.i.r.t.c.s.ThriftClientFactoryBean : Succeed to instantiate an instance of ThriftClientFactoryBean: com.icekredit.rpc.thrift.client.scanner.ThriftClientFactoryBean@7bac686b2017-11-20 11:00:20.142 INFO 4052 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'calculatorThriftClient' of type [com.icekredit.rpc.thrift.client.scanner.ThriftClientFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-11-20 11:00:20.411 INFO 4052 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.netflix.metrics.MetricsInterceptorConfiguration$MetricsRestTemplateConfiguration' of type [org.springframework.cloud.netflix.metrics.MetricsInterceptorConfiguration$MetricsRestTemplateConfiguration$$EnhancerBySpringCGLIB$$a9ef18dc] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-11-20 11:00:20.423 INFO 4052 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$93dc7598] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-11-20 11:00:21.592 INFO 4052 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http) 启动过程中，所有的标记有注解 @ThriftClient的接口都生成了代理对象，并通过注解 @ThriftReferer注入到 Controller中。 同时，客户端启动时开启了一个ServerUpdater，定时动态的去Consul服务注册列表抓取健康的服务节点信息，缓存到本地服务列表中。 1232017-11-20 11:02:26.726 INFO 4052 --- [erListUpdater-0] t.c.l.ThriftConsulServerListLoadBalancer : Refreshed thrift serverList: [thrift-rpc-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25001], host='192.168.91.128', port=25001, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25002], host='192.168.91.128', port=25002, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25003], host='192.168.91.128', port=25003, address='192.168.91.128', isHealth=true&#125;], consul-8301: [ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=8301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=9301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=10301, address='192.168.91.128', isHealth=true&#125;], consul-8302: [ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=8302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=9302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=10302, address='192.168.91.128', isHealth=true&#125;], thrift-rest-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8081], host='192.168.91.128', port=8081, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8082], host='192.168.91.128', port=8082, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8083], host='192.168.91.128', port=8083, address='192.168.91.128', isHealth=true&#125;]]2017-11-20 11:02:56.752 INFO 4052 --- [erListUpdater-0] t.c.l.ThriftConsulServerListLoadBalancer : Refreshed thrift serverList: [thrift-rpc-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25001], host='192.168.91.128', port=25001, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25002], host='192.168.91.128', port=25002, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25003], host='192.168.91.128', port=25003, address='192.168.91.128', isHealth=true&#125;], consul-8301: [ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=8301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=9301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=10301, address='192.168.91.128', isHealth=true&#125;], consul-8302: [ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=8302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=9302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=10302, address='192.168.91.128', isHealth=true&#125;], thrift-rest-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8081], host='192.168.91.128', port=8081, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8082], host='192.168.91.128', port=8082, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8083], host='192.168.91.128', port=8083, address='192.168.91.128', isHealth=true&#125;]]2017-11-20 11:03:26.764 INFO 4052 --- [erListUpdater-0] t.c.l.ThriftConsulServerListLoadBalancer : Refreshed thrift serverList: [thrift-rpc-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25001], host='192.168.91.128', port=25001, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25002], host='192.168.91.128', port=25002, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25003], host='192.168.91.128', port=25003, address='192.168.91.128', isHealth=true&#125;], consul-8301: [ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=8301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=9301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=10301, address='192.168.91.128', isHealth=true&#125;], consul-8302: [ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=8302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=9302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=10302, address='192.168.91.128', isHealth=true&#125;], thrift-rest-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8081], host='192.168.91.128', port=8081, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8082], host='192.168.91.128', port=8082, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8083], host='192.168.91.128', port=8083, address='192.168.91.128', isHealth=true&#125;]] 访问本地Thrift客户端： 访问地址 参数arg1 参数arg2 页面输出结果 /rpc/add 200 100 300 /rpc/subtract 200 100 100 /rpc/multiply 200 100 20000 /rpc/division 200 100 2 总结本文简单地介绍了如何利用 starter 将 Apache Thrift 整合进入 Spring Cloud 中，关于更复杂的应用场景和starter内部的设计、实现原理，后续会一步步的给出具体的介绍！ 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"Thrift","slug":"Thrift","permalink":"https://ostenant.coding.me/tags/Thrift/"},{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://ostenant.coding.me/tags/Spring-Cloud/"}]},{"title":"阿里云CentOS 7上安装配置Docker","slug":"阿里云CentOS 7上安装配置Docker","date":"2018-01-18T01:44:00.000Z","updated":"2018-05-08T02:49:46.097Z","comments":true,"path":"2018/01/18/阿里云CentOS 7上安装配置Docker/","link":"","permalink":"https://ostenant.coding.me/2018/01/18/阿里云CentOS 7上安装配置Docker/","excerpt":"前言Docker是一个开源工具，它可以让创建和管理Linux容器变得简单。容器就像是轻量级的虚拟机，并且可以以毫秒级的速度来启动或停止。Docker帮助系统管理员和程序员在容器中开发应用程序，并且可以扩展到成千上万的节点。","text":"前言Docker是一个开源工具，它可以让创建和管理Linux容器变得简单。容器就像是轻量级的虚拟机，并且可以以毫秒级的速度来启动或停止。Docker帮助系统管理员和程序员在容器中开发应用程序，并且可以扩展到成千上万的节点。 这是一只鲸鱼，它托着许多集装箱。我们可以把宿主机可当做这只鲸鱼，把相互隔离的容器可看成集装箱，每个集装箱中都包含自己的应用程序。 传送门Docker与传统虚拟区别 传统虚拟化技术的体系架构： Docker技术的体系架构： 容器和虚拟机(VM)的主要区别是： 容器提供了基于进程的隔离，而虚拟机提供了资源(CPU、内存和硬盘)的完全隔离。 虚拟机可能需要一分钟来启动，而容器只需要一秒钟或更短。 虚拟机占用的内存空间可达到几个G，而容器可能只需要几百兆。 容器使用宿主操作系统的内核，而虚拟机使用独立的内核。 Docker平台的基本构成 Docker平台基本上由三部分组成： 客户端：用户使用Docker提供的工具(CLI以及API等)来构建，上传镜像并发布命令来创建和启动容器。 Docker主机：从Docker registry上下载镜像并启动和托管容器。 Docker registry：Docker镜像仓库，用于保存镜像，并提供镜像上传和下载。 Docker容器的状态机 一个容器在某个时刻可能处于以下几种状态之一： created：已经被创建 (使用docker ps -a命令可以列出) 但是还没有被启动，使用docker ps命令还无法列出。running：容器在这正常运行中。paused：容器的进程被暂停了。restarting：容器的进程正在重启过程中。exited：上图中的stopped状态，表示容器之前运行过但是现在处于停止状态 (要区别于created状态，它是指一个新创建的尚未运行过的容器)。可以通过start命令使其重新进入running状态。destroyed：容器从宿主机删除了，再也不存在了。 Docker的安装RedHat/CentOS必须要6.6版本以上，或者7.x才能安装docker，建议在RedHat/CentOS 7上使用docker，因为RedHat/CentOS 7的内核升级到了kernel 3.10，对lxc容器支持更好。 查看Linux内核版本(内核版本必须是3.10或者以上)： 12345678cat /proc/versionuname -alsb_release -a##无法执行命令安装yum install -y redhat-lsb 更新yum安装源： 1yum install docker -y 检查docker版本： 1docker -v 安装完成后，使用下面的命令来启动docker服务，并将其设置为开机启动： 12service docker startchkconfig docker on 下载官方的CentOS的docker镜像： 1docker pull centos 检查CentOS镜像是否被成功拉取到本地宿主机： 12345678# 查看本地镜像列表docker images# 删除镜像docker rmi &lt;image id&gt;# 删除镜像(针对多个相同image id的镜像)docker rmi repository:tag 镜像下载完成后，你应该会看到： 123[root@iZ2ze74fkxrls31tr2ia2fZ ~]# docker images centosREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/centos latest 3fa822599e10 3weeks ago 203.5 MB 如果看到以上输出，说明你可以使用docker.io/centos这个镜像了，或将其称为仓库(Repository)，该镜像有一个名为latest的标签(Tag)，此外还有一个名为3fa822599e10的镜像ID (可能您所看到的镜像 ID 与此处的不一致，那是正常现象，因为这个数字是随机生成的)。此外，我们可以看到该镜像只有203.5MB，非常小巧，而不像虚拟机的镜像文件那样庞大。 重命名TAG为centos： 12# docker tag IMAGE_ID(镜像id) REPOSITORY:TAG(仓库：标签)docker tag 3fa822599e10 docker.io/centos:centos 启动CentOS的容器： 1docker run -i -t -v /root/software/:/mnt/software/ 3fa822599e10 /bin/bash 命令参数说明：docker run &lt;相关参数&gt; &lt;镜像ID&gt; &lt;初始命令&gt; -i：表示以交互模式运行容器 -t：表示容器启动后会进入其命令行 -v：表示需要将本地哪个目录挂载到容器中，格式：-v &lt;宿主机目录&gt;:&lt;容器目录&gt; 更多参数详解： 12345678910111213141516171819202122232425262728293031323334353637383940Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] -d, --detach=false 指定容器运行于前台还是后台，默认为false -i, --interactive=false 打开STDIN，用于控制台交互 -t, --tty=false 分配tty设备，该可以支持终端登录，默认为false -u, --user=\"\" 指定容器的用户 -a, --attach=[] 登录容器（必须是以docker run -d启动的容器） -w, --workdir=\"\" 指定容器的工作目录 -c, --cpu-shares=0 设置容器CPU权重，在CPU共享场景使用 -e, --env=[] 指定环境变量，容器中可以使用该环境变量 -m, --memory=\"\" 指定容器的内存上限 -P, --publish-all=false 指定容器暴露的端口 -p, --publish=[] 指定容器暴露的端口 -h, --hostname=\"\" 指定容器的主机名 -v, --volume=[] 给容器挂载存储卷，挂载到容器的某个目录 --volumes-from=[] 给容器挂载其他容器上的卷，挂载到容器的某个目录 --cap-add=[] 添加权限，权限清单详见：http://linux.die.net/man/7/capabilities --cap-drop=[] 删除权限，权限清单详见：http://linux.die.net/man/7/capabilities --cidfile=\"\" 运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法 --cpuset=\"\" 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU --device=[] 添加主机设备给容器，相当于设备直通 --dns=[] 指定容器的dns服务器 --dns-search=[] 指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件 --entrypoint=\"\" 覆盖image的入口点 --env-file=[] 指定环境变量文件，文件格式为每行一个环境变量 --expose=[] 指定容器暴露的端口，即修改镜像的暴露端口 --link=[] 指定容器间的关联，使用其他容器的IP、env等信息 --lxc-conf=[] 指定容器的配置文件，只有在指定--exec-driver=lxc时使用 --name=\"\" 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字 --net=\"bridge\" 容器网络设置: bridge 使用docker daemon指定的网桥 host //容器使用主机的网络 container:NAME_or_ID &gt;//使用其他容器的网路，共享IP和PORT等网络资源 none 容器使用自己的网络（类似--net=bridge），但是不进行配置 --privileged=false 指定容器是否为特权容器，特权容器拥有所有的capabilities --restart=\"no\" 指定容器停止后的重启策略: no：容器退出时不重启 on-failure：容器故障退出（返回值非零）时重启 always：容器退出时总是重启 --rm=false 指定容器停止后自动删除容器(不支持以docker run -d启动的容器) --sig-proxy=true 设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理 Docker的常用命令我们可以把Docker的命令大概地分类如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960## 镜像操作： build Build an image from a Dockerfile commit Create a new image from a container's changes images List images load Load an image from a tar archive or STDIN pull Pull an image or a repository from a registry push Push an image or a repository to a registry rmi Remove one or more images search Search the Docker Hub for images tag Tag an image into a repository save Save one or more images to a tar archive history 显示某镜像的历史 inspect 获取镜像的详细信息## 容器及其中应用的生命周期操作： create 创建一个容器 kill Kill one or more running containers inspect Return low-level information on a container, image or task pause Pause all processes within one or more containers ps List containers rm 删除一个或者多个容器 rename Rename a container restart Restart a container run 创建并启动一个容器 start 启动一个处于停止状态的容器 stats 显示容器实时的资源消耗信息 stop 停止一个处于运行状态的容器 top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers wait Block until a container stops, then print its exit code attach Attach to a running container exec Run a command in a running container port List port mappings or a specific mapping for the container logs 获取容器的日志## 容器文件系统操作： cp Copy files/folders between a container and the local filesystem diff Inspect changes on a container's filesystem export Export a container's filesystem as a tar archive import Import the contents from a tarball to create a filesystem image Docker registry 操作： login Log in to a Docker registry. logout Log out from a Docker registry.## Volume操作： volume Manage Docker volumes## 网络操作： network Manage Docker networks## Swarm 相关操作： swarm Manage Docker Swarm service Manage Docker services node Manage Docker Swarm nodes## 系统操作： version Show the Docker version information events 持续返回docker 事件 info 显示Docker 主机系统范围内的信息 1234567891011121314151617181920212223242526# 查看运行中的容器docker ps# 查看所有容器docker ps -a# 退出容器按Ctrl+D 即可退出当前容器【但退出后会停止容器】# 退出不停止容器：组合键：Ctrl+P+Q# 启动容器docker start 容器名或ID# 进入容器docker attach 容器名或ID# 停止容器docker stop 容器名或ID# 暂停容器docker pause 容器名或ID#继续容器docker unpause 容器名或ID# 删除容器docker rm 容器名或ID# 删除全部容器--慎用docker stop $(docker ps -q) &amp; docker rm $(docker ps -aq)#保存容器，生成镜像docker commit 容器ID 镜像名称#从 host 拷贝文件到 container 里面docker cp /home/soft centos:/webapp docker run与start的区别docker run只在第一次运行时使用，将镜像放到容器中，以后再次启动这个容器时，只需要使用命令docker start 即可。 docker run相当于执行了两步操作：将镜像放入容器中(docker create)，然后将容器启动，使之变成运行时容器(docker start)。 而docker start的作用是，重新启动已存在的镜像。也就是说，如果使用这个命令，我们必须事先知道这个容器的ID，或者这个容器的名字，我们可以使用docker ps找到这个容器的信息。 因为容器的ID是随机码，而容器的名字又是看似无意义的命名，我们可以使用命令： 1docker rename jovial_cori centos 给这个容器命名。这样以后，我们再次启动或停止容器时，就可以直接使用这个名字： 1docker [stop] [start] new_name 而要显示出所有容器，包括没有启动的，可以使用命令： 1docker ps -a Docker的配置更改存储目录： 12345#复制docker存储目录rsync -aXS /var/lib/docker/. /home/docker#更改 docker 存储文件目录ln -s /home/docker /var/lib/docker 查看启动容器的具体信息： 1docker inspect &lt;container_id&gt; 要获取所有容器名称及其IP地址只需一个命令： 123docker inspect -f '&#123;&#123;.Name&#125;&#125; - &#123;&#123;.NetworkSettings.IPAddress &#125;&#125;' $(docker ps -aq)docker inspect --format='&#123;&#123;.Name&#125;&#125; - &#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;' $(docker ps -aq) Docker镜像加速器注册一个阿里云帐号： https://dev.aliyun.com/search.html 阿里云会自动为用户分配一个镜像加速器的地址，登录后进入”管理中心” —&gt; ”加速器”，里面有分配给你的镜像加速器的地址以及各个环境的使用说明。 镜像加速器地址示例：https://xxxxx.mirror.aliyuncs.com 如何配置镜像加速器针对Docker客户端版本大于1.10.0的用户，可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器**： 123&#123; \"registry-mirrors\": [\"&lt;your accelerate address&gt;\"]&#125; 重启Docker Daemon： 12sudo systemctl daemon-reloadsudo systemctl restart docker 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Docker学习系列","slug":"Docker学习系列","permalink":"https://ostenant.coding.me/categories/Docker学习系列/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://ostenant.coding.me/tags/Docker/"},{"name":"CentOS","slug":"CentOS","permalink":"https://ostenant.coding.me/tags/CentOS/"}]},{"title":"Apache Thrift系列详解(三) - 序列化机制","slug":"Apache Thrift系列详解(三) - 序列化机制","date":"2018-01-16T07:37:00.000Z","updated":"2018-05-08T02:49:46.087Z","comments":true,"path":"2018/01/16/Apache Thrift系列详解(三) - 序列化机制/","link":"","permalink":"https://ostenant.coding.me/2018/01/16/Apache Thrift系列详解(三) - 序列化机制/","excerpt":"前言Thrift支持二进制，压缩格式，以及json格式数据的序列化和反序列化。开发人员可以更加灵活的选择协议的具体形式。协议是可自由扩展的，新版本的协议，完全兼容老的版本！","text":"前言Thrift支持二进制，压缩格式，以及json格式数据的序列化和反序列化。开发人员可以更加灵活的选择协议的具体形式。协议是可自由扩展的，新版本的协议，完全兼容老的版本！ 正文数据交换格式简介当前流行的数据交换格式可以分为如下几类： (一) 自解析型序列化的数据包含完整的结构， 包含了field名称和value值。比如xml/json/java serizable，大百度的mcpack/compack，都属于此类。即调整不同属性的顺序对序列化/反序列化不造成影响。 (二) 半解析型序列化的数据，丢弃了部分信息， 比如field名称， 但引入了index(常常是id+type的方式)来对应具体属性和值。这方面的代表有google protobuf/thrift也属于此类。 (三) 无解析型传说中大百度的infpack实现，就是借助该种方式来实现，丢弃了很多有效信息，性能/压缩比最好，不过向后兼容需要开发做一定的工作， 详情不知。 交换格式 类型 优点 缺点 Xml 文本 易读 臃肿，不支持二进制数据类型 JSON 文本 易读 丢弃了类型信息，比如”score”:100，对score类型是int/double解析有二义性， 不支持二进制数据类型 Java serizable 二进制 使用简单 臃肿，只限制在JAVA领域 Thrift 二进制 高效 不易读，向后兼容有一定的约定限制 Google Protobuf 二进制 高效 不易读，向后兼容有一定的约定限制 Thrift的数据类型 基本类型： bool: 布尔值 byte: 8位有符号整数 i16: 16位有符号整数 i32: 32位有符号整数 i64: 64位有符号整数 double: 64位浮点数 string: UTF-8编码的字符串 binary: 二进制串 结构体类型： struct: 定义的结构体对象 容器类型： list: 有序元素列表 set: 无序无重复元素集合 map: 有序的key/value集合 异常类型： exception: 异常类型 服务类型： service: 具体对应服务的类 Thrift的序列化协议Thrift可以让用户选择客户端与服务端之间传输通信协议的类别，在传输协议上总体划分为文本(text)和二进制(binary)传输协议。为节约带宽，提高传输效率，一般情况下使用二进制类型的传输协议为多数，有时还会使用基于文本类型的协议，这需要根据项目/产品中的实际需求。常用协议有以下几种： TBinaryProtocol：二进制编码格式进行数据传输 TCompactProtocol：高效率的、密集的二进制编码格式进行数据传输 TJSONProtocol： 使用JSON文本的数据编码协议进行数据传输 TSimpleJSONProtocol：只提供JSON只写的协议，适用于通过脚本语言解析 Thrift的序列化测试(a). 首先编写一个简单的thrift文件pair.thrift： 1234struct Pair &#123; 1: required string key 2: required string value&#125; 这里标识了required的字段，要求在使用时必须正确赋值，否则运行时会抛出TProtocolException异常。缺省和指定为optional时，则运行时不做字段非空校验。 (b). 编译并生成java源代码： 1thrift -gen java pair.thrift (c). 编写序列化和反序列化的测试代码： 序列化测试，将Pair对象写入文件中 1234567private static void writeData() throws IOException， TException &#123; Pair pair = new Pair(); pair.setKey(\"key1\").setValue(\"value1\"); FileOutputStream fos = new FileOutputStream(new File(\"pair.txt\")); pair.write(new TBinaryProtocol(new TIOStreamTransport(fos))); fos.close();&#125; 反序列化测试，从文件中解析生成Pair对象 12345678private static void readData() throws TException， IOException &#123; Pair pair = new Pair(); FileInputStream fis = new FileInputStream(new File(\"pair.txt\")); pair.read(new TBinaryProtocol(new TIOStreamTransport(fis))); System.out.println(\"key =&gt; \" + pair.getKey()); System.out.println(\"value =&gt; \" + pair.getValue()); fis.close();&#125; (d) 观察运行结果，正常输出表明序列化和反序列化过程正常完成。 Thrift协议源码(一) writeData()分析首先查看thrift的序列化机制，即数据写入实现，这里采用二进制协议TBinaryProtocol，切入点为pair.write(TProtocol)： 查看scheme()方法，决定采用元组计划(TupleScheme)还是标准计划(StandardScheme)来实现序列化，默认采用的是标准计划StandardScheme。 标准计划(StandardScheme)下的write()方法： 这里完成了几步操作： (a). 根据Thrift IDL文件中定义了required的字段验证字段是否正确赋值。 123456789public void validate() throws org.apache.thrift.TException &#123; // check for required fields if (key == null) &#123; throw new org.apache.thrift.protocol.TProtocolException(\"Required field 'key' was not present! Struct: \" + toString()); &#125; if (value == null) &#123; throw new org.apache.thrift.protocol.TProtocolException(\"Required field 'value' was not present! Struct: \" + toString()); &#125;&#125; (b). 通过writeStructBegin()记录写入结构的开始标记。 1public void writeStructBegin(TStruct struct) &#123;&#125; (c). 逐一写入Pair对象的各个字段，包括字段字段开始标记、字段的值和字段结束标记。 123456if (struct.key != null) &#123; oprot.writeFieldBegin(KEY_FIELD_DESC); oprot.writeString(struct.key); oprot.writeFieldEnd();&#125;// 省略... (1). 首先是字段开始标记，包括type和field-id。type是字段的数据类型的标识号，field-id是Thrift IDL定义的字段次序，比如说key为1，value为2。 1234public void writeFieldBegin(TField field) throws TException &#123; writeByte(field.type); writeI16(field.id);&#125; Thrift提供了TType，对不同的数据类型(type)提供了唯一标识的typeID。 12345678910111213141516public final class TType &#123; public static final byte STOP = 0; // 数据读写完成 public static final byte VOID = 1; // 空值 public static final byte BOOL = 2; // 布尔值 public static final byte BYTE = 3; // 字节 public static final byte DOUBLE = 4; // 双精度浮点型 public static final byte I16 = 6; // 短整型 public static final byte I32 = 8; // 整型 public static final byte I64 = 10; // 长整型 public static final byte STRING = 11; // 字符串类型 public static final byte STRUCT = 12; // 引用类型 public static final byte MAP = 13; // Map public static final byte SET = 14; // 集合 public static final byte LIST = 15; // 列表 public static final byte ENUM = 16; // 枚举&#125; (2). 然后是写入字段的值，根据字段的数据类型又归纳为以下实现：writeByte()、writeBool()、writeI32()、writeI64()、writeDouble()、writeString()和writeBinary()方法。 TBinaryProtocol通过一个长度为8的byte字节数组缓存写入或读取的临时字节数据。 1private final byte[] inoutTemp = new byte[8]; 常识1：16进制的介绍。以0x开始的数据表示16进制，0xff换成十进制为255。在16进制中，A、B、C、D、E、F这五个字母来分别表示10、11、12、13、14、15。 16进制变十进制：f表示15。第n位的权值为16的n次方，由右到左从0位起：0xff = 1516^1 + 1516^0 = 25516进制变二进制再变十进制：0xff = 1111 1111 = 2^8 - 1 = 255 常识2：位运算符的使用。&gt;&gt;表示代表右移符号，如：int i=15; i&gt;&gt;2的结果是3，移出的部分将被抛弃。而&lt;&lt;表示左移符号，与&gt;&gt;刚好相反。 转为二进制的形式可能更好理解，0000 1111(15)右移2位的结果是0000 0011(3)，0001 1010(18)右移3位的结果是0000 0011(3)。 writeByte()：写入单个字节数据。 1234public void writeByte(byte b) throws TException &#123; inoutTemp[0] = b; trans_.write(inoutTemp， 0， 1);&#125; writeBool()：写入布尔值数据。 123public void writeBool(boolean b) throws TException &#123; writeByte(b ? (byte)1 : (byte)0);&#125; writeI16()：写入短整型short类型数据。 12345public void writeI16(short i16) throws TException &#123; inoutTemp[0] = (byte)(0xff &amp; (i16 &gt;&gt; 8)); inoutTemp[1] = (byte)(0xff &amp; (i16)); trans_.write(inoutTemp， 0， 2);&#125; writeI32()：写入整型int类型数据。 1234567public void writeI32(int i32) throws TException &#123; inoutTemp[0] = (byte)(0xff &amp; (i32 &gt;&gt; 24)); inoutTemp[1] = (byte)(0xff &amp; (i32 &gt;&gt; 16)); inoutTemp[2] = (byte)(0xff &amp; (i32 &gt;&gt; 8)); inoutTemp[3] = (byte)(0xff &amp; (i32)); trans_.write(inoutTemp， 0， 4);&#125; writeI64()：写入长整型long类型数据。 1234567891011public void writeI64(long i64) throws TException &#123; inoutTemp[0] = (byte)(0xff &amp; (i64 &gt;&gt; 56)); inoutTemp[1] = (byte)(0xff &amp; (i64 &gt;&gt; 48)); inoutTemp[2] = (byte)(0xff &amp; (i64 &gt;&gt; 40)); inoutTemp[3] = (byte)(0xff &amp; (i64 &gt;&gt; 32)); inoutTemp[4] = (byte)(0xff &amp; (i64 &gt;&gt; 24)); inoutTemp[5] = (byte)(0xff &amp; (i64 &gt;&gt; 16)); inoutTemp[6] = (byte)(0xff &amp; (i64 &gt;&gt; 8)); inoutTemp[7] = (byte)(0xff &amp; (i64)); trans_.write(inoutTemp， 0， 8);&#125; writeDouble()：写入双浮点型double类型数据。 123public void writeDouble(double dub) throws TException &#123; writeI64(Double.doubleToLongBits(dub));&#125; writeString()：写入字符串类型，这里先写入字符串长度，再写入字符串内容。 123456789public void writeString(String str) throws TException &#123; try &#123; byte[] dat = str.getBytes(\"UTF-8\"); writeI32(dat.length); trans_.write(dat， 0， dat.length); &#125; catch (UnsupportedEncodingException uex) &#123; throw new TException(\"JVM DOES NOT SUPPORT UTF-8\"); &#125;&#125; writeBinary：写入二进制数组类型数据，这里数据输入是NIO中的ByteBuffer类型。 12345public void writeBinary(ByteBuffer bin) throws TException &#123; int length = bin.limit() - bin.position(); writeI32(length); trans_.write(bin.array()， bin.position() + bin.arrayOffset()， length);&#125; (3). 每个字段写入完成后，都需要记录字段结束标记。 1public void writeFieldEnd() &#123;&#125; (d). 当所有的字段都写入以后，需要记录字段停止标记。 123public void writeFieldStop() throws TException &#123; writeByte(TType.STOP);&#125; (e). 当所有数据写入完成后，通过writeStructEnd()记录写入结构的完成标记。 1public void writeStructEnd() &#123;&#125; (二) readData()分析查看thrift的反序列化机制，即数据读取实现，同样采用二进制协议TBinaryProtocol，切入点为pair.read(TProtocol)： 数据读取和数据写入一样，也是采用的标准计划StandardScheme。标准计划(StandardScheme)下的read()方法： 这里完成的几步操作： (a). 通过readStructBegin读取结构的开始标记。 1iprot.readStructBegin(); (b). 循环读取结构中的所有字段数据到Pair对象中，直到读取到org.apache.thrift.protocol.TType.STOP为止。iprot.readFieldBegin()指明开始读取下一个字段的前需要读取字段开始标记。 1234567while (true) &#123; schemeField = iprot.readFieldBegin(); if (schemeField.type == org.apache.thrift.protocol.TType.STOP) &#123; break; &#125; // 字段的读取，省略...&#125; (c). 根据Thrift IDL定义的field-id读取对应的字段，并赋值到Pair对象中，并设置Pair对象相应的字段为已读状态(前提：字段在IDL中被定义为required)。 1234567891011121314151617181920switch (schemeField.id) &#123; case 1: // KEY if (schemeField.type == org.apache.thrift.protocol.TType.STRING) &#123; struct.key = iprot.readString(); struct.setKeyIsSet(true); &#125; else &#123; org.apache.thrift.protocol.TProtocolUtil.skip(iprot， schemeField.type); &#125; break; case 2: // VALUE if (schemeField.type == org.apache.thrift.protocol.TType.STRING) &#123; struct.value = iprot.readString(); struct.setValueIsSet(true); &#125; else &#123; org.apache.thrift.protocol.TProtocolUtil.skip(iprot， schemeField.type); &#125; break; default: org.apache.thrift.protocol.TProtocolUtil.skip(iprot， schemeField.type);&#125; 关于读取字段的值，根据字段的数据类型也分为以下实现：readByte()、readBool()、readI32()、readI64()、readDouble()、readString()和readBinary()方法。 readByte()：读取单个字节数据。 123456789public byte readByte() throws TException &#123; if (trans_.getBytesRemainingInBuffer() &gt;= 1) &#123; byte b = trans_.getBuffer()[trans_.getBufferPosition()]; trans_.consumeBuffer(1); return b; &#125; readAll(inoutTemp， 0， 1); return inoutTemp[0];&#125; readBool()：读取布尔值数据。 123public boolean readBool() throws TException &#123; return (readByte() == 1);&#125; readI16()：读取短整型short类型数据。 123456789101112131415public short readI16() throws TException &#123; byte[] buf = inoutTemp; int off = 0; if (trans_.getBytesRemainingInBuffer() &gt;= 2) &#123; buf = trans_.getBuffer(); off = trans_.getBufferPosition(); trans_.consumeBuffer(2); &#125; else &#123; readAll(inoutTemp， 0， 2); &#125; return (short) (((buf[off] &amp; 0xff) &lt;&lt; 8) | ((buf[off+1] &amp; 0xff)));&#125; readI32()：读取整型int类型数据。 12345678910111213141516public int readI32() throws TException &#123; byte[] buf = inoutTemp; int off = 0; if (trans_.getBytesRemainingInBuffer() &gt;= 4) &#123; buf = trans_.getBuffer(); off = trans_.getBufferPosition(); trans_.consumeBuffer(4); &#125; else &#123; readAll(inoutTemp， 0， 4); &#125; return ((buf[off] &amp; 0xff) &lt;&lt; 24) | ((buf[off+1] &amp; 0xff) &lt;&lt; 16) | ((buf[off+2] &amp; 0xff) &lt;&lt; 8) | ((buf[off+3] &amp; 0xff));&#125; readI64()：读取长整型long类型数据。 123456789101112131415161718192021public long readI64() throws TException &#123; byte[] buf = inoutTemp; int off = 0; if (trans_.getBytesRemainingInBuffer() &gt;= 8) &#123; buf = trans_.getBuffer(); off = trans_.getBufferPosition(); trans_.consumeBuffer(8); &#125; else &#123; readAll(inoutTemp， 0， 8); &#125; return ((long)(buf[off] &amp; 0xff) &lt;&lt; 56) | ((long)(buf[off+1] &amp; 0xff) &lt;&lt; 48) | ((long)(buf[off+2] &amp; 0xff) &lt;&lt; 40) | ((long)(buf[off+3] &amp; 0xff) &lt;&lt; 32) | ((long)(buf[off+4] &amp; 0xff) &lt;&lt; 24) | ((long)(buf[off+5] &amp; 0xff) &lt;&lt; 16) | ((long)(buf[off+6] &amp; 0xff) &lt;&lt; 8) | ((long)(buf[off+7] &amp; 0xff));&#125; readDouble()：读取双精度浮点double类型数据。 123public double readDouble() throws TException &#123; return Double.longBitsToDouble(readI64());&#125; readString()：读取字符串类型的数据，首先读取并校验4字节的字符串长度，然后检查NIO缓冲区中是否有对应长度的字节未消费。如果有，直接从缓冲区中读取；否则，从传输通道中读取数据。 12345678910111213141516public String readString() throws TException &#123; int size = readI32(); checkStringReadLength(size); if (trans_.getBytesRemainingInBuffer() &gt;= size) &#123; try &#123; String s = new String(trans_.getBuffer()， trans_.getBufferPosition()， size， \"UTF-8\"); trans_.consumeBuffer(size); return s; &#125; catch (UnsupportedEncodingException e) &#123; throw new TException(\"JVM DOES NOT SUPPORT UTF-8\"); &#125; &#125; return readStringBody(size);&#125; 如果是从传输通道中读取数据，查看readStringBody()方法： 123456789public String readStringBody(int size) throws TException &#123; try &#123; byte[] buf = new byte[size]; trans_.readAll(buf， 0， size); return new String(buf， \"UTF-8\"); &#125; catch (UnsupportedEncodingException uex) &#123; throw new TException(\"JVM DOES NOT SUPPORT UTF-8\"); &#125;&#125; readBinary()：读取二进制数组类型数据，和字符串读取类似，返回一个ByteBuffer字节缓存对象。 1234567891011121314public ByteBuffer readBinary() throws TException &#123; int size = readI32(); checkStringReadLength(size); if (trans_.getBytesRemainingInBuffer() &gt;= size) &#123; ByteBuffer bb = ByteBuffer.wrap(trans_.getBuffer()， trans_.getBufferPosition()， size); trans_.consumeBuffer(size); return bb; &#125; byte[] buf = new byte[size]; trans_.readAll(buf， 0， size); return ByteBuffer.wrap(buf);&#125; (d). 每个字段数据读取完成后，都需要再读取一个字段结束标记。 1public void readFieldEnd() &#123;&#125; (e). 当所有字段读取完成后，需要通过readStructEnd()再读入一个结构完成标记。 1public void readStructEnd() &#123;&#125; (f). 读取结束后，同样需要校验在Thrift IDL中定义为required的字段是否为空，是否合法。 123456789public void validate() throws org.apache.thrift.TException &#123; // check for required fields if (key == null) &#123; throw new org.apache.thrift.protocol.TProtocolException(\"Required field 'key' was not present! Struct: \" + toString()); &#125; if (value == null) &#123; throw new org.apache.thrift.protocol.TProtocolException(\"Required field 'value' was not present! Struct: \" + toString()); &#125;&#125; 总结其实到这里，对于Thrift的序列化机制和反序列化机制的具体实现和高效性，相信各位已经有了比较深入的认识！ 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"Thrift","slug":"Thrift","permalink":"https://ostenant.coding.me/tags/Thrift/"},{"name":"Apache","slug":"Apache","permalink":"https://ostenant.coding.me/tags/Apache/"},{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"}]},{"title":"Apache Thrift系列详解(二) - 网络服务模型","slug":"Apache Thrift系列详解(二) - 网络服务模型","date":"2018-01-11T09:36:00.000Z","updated":"2018-05-08T02:49:46.088Z","comments":true,"path":"2018/01/11/Apache Thrift系列详解(二) - 网络服务模型/","link":"","permalink":"https://ostenant.coding.me/2018/01/11/Apache Thrift系列详解(二) - 网络服务模型/","excerpt":"前言Thrift提供的网络服务模型：单线程、多线程、事件驱动，从另一个角度划分为：阻塞服务模型、非阻塞服务模型。","text":"前言Thrift提供的网络服务模型：单线程、多线程、事件驱动，从另一个角度划分为：阻塞服务模型、非阻塞服务模型。 阻塞服务模型：TSimpleServer、TThreadPoolServer。 非阻塞服务模型：TNonblockingServer、THsHaServer和TThreadedSelectorServer。 TServer类的层次关系： 正文TServerTServer定义了静态内部类Args，Args继承自抽象类AbstractServerArgs。AbstractServerArgs采用了建造者模式，向TServer提供各种工厂： 工厂属性 工厂类型 作用 ProcessorFactory TProcessorFactory 处理层工厂类，用于具体的TProcessor对象的创建 InputTransportFactory TTransportFactory 传输层输入工厂类，用于具体的TTransport对象的创建 OutputTransportFactory TTransportFactory 传输层输出工厂类，用于具体的TTransport对象的创建 InputProtocolFactory TProtocolFactory 协议层输入工厂类，用于具体的TProtocol对象的创建 OutputProtocolFactory TProtocolFactory 协议层输出工厂类，用于具体的TProtocol对象的创建 下面是TServer的部分核心代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public abstract class TServer &#123; public static class Args extends org.apache.thrift.server.TServer.AbstractServerArgs&lt;org.apache.thrift.server.TServer.Args&gt; &#123; public Args(TServerTransport transport) &#123; super(transport); &#125; &#125; public static abstract class AbstractServerArgs&lt;T extends org.apache.thrift.server.TServer.AbstractServerArgs&lt;T&gt;&gt; &#123; final TServerTransport serverTransport; TProcessorFactory processorFactory; TTransportFactory inputTransportFactory = new TTransportFactory(); TTransportFactory outputTransportFactory = new TTransportFactory(); TProtocolFactory inputProtocolFactory = new TBinaryProtocol.Factory(); TProtocolFactory outputProtocolFactory = new TBinaryProtocol.Factory(); public AbstractServerArgs(TServerTransport transport) &#123; serverTransport = transport; &#125; &#125; protected TProcessorFactory processorFactory_; protected TServerTransport serverTransport_; protected TTransportFactory inputTransportFactory_; protected TTransportFactory outputTransportFactory_; protected TProtocolFactory inputProtocolFactory_; protected TProtocolFactory outputProtocolFactory_; private boolean isServing; protected TServer(org.apache.thrift.server.TServer.AbstractServerArgs args) &#123; processorFactory_ = args.processorFactory; serverTransport_ = args.serverTransport; inputTransportFactory_ = args.inputTransportFactory; outputTransportFactory_ = args.outputTransportFactory; inputProtocolFactory_ = args.inputProtocolFactory; outputProtocolFactory_ = args.outputProtocolFactory; &#125; public abstract void serve(); public void stop() &#123;&#125; public boolean isServing() &#123; return isServing; &#125; protected void setServing(boolean serving) &#123; isServing = serving; &#125;&#125; TServer的三个方法：serve()、stop()和isServing()。serve()用于启动服务，stop()用于关闭服务，isServing()用于检测服务的起停状态。 TServer的不同实现类的启动方式不一样，因此serve()定义为抽象方法。不是所有的服务都需要优雅的退出, 因此stop()方法没有被定义为抽象。 TSimpleServerTSimpleServer的工作模式采用最简单的阻塞IO，实现方法简洁明了，便于理解，但是一次只能接收和处理一个socket连接，效率比较低。它主要用于演示Thrift的工作过程，在实际开发过程中很少用到它。 (一) 工作流程 (二) 使用入门服务端： 12345678910111213ServerSocket serverSocket = new ServerSocket(ServerConfig.SERVER_PORT);TServerSocket serverTransport = new TServerSocket(serverSocket);HelloWorldService.Processor processor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldServiceImpl());TBinaryProtocol.Factory protocolFactory = new TBinaryProtocol.Factory();TSimpleServer.Args tArgs = new TSimpleServer.Args(serverTransport);tArgs.processor(processor);tArgs.protocolFactory(protocolFactory);// 简单的单线程服务模型 一般用于测试TServer tServer = new TSimpleServer(tArgs);System.out.println(\"Running Simple Server\");tServer.serve(); 客户端： 12345678TTransport transport = new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT);TProtocol protocol = new TBinaryProtocol(transport);HelloWorldService.Client client = new HelloWorldService.Client(protocol);transport.open();String result = client.say(\"Leo\");System.out.println(\"Result =: \" + result);transport.close(); (三) 源码分析查看上述流程的源代码，即TSimpleServer.java中的serve()方法如下： serve()方法的操作： 设置TServerSocket的listen()方法启动连接监听。 以阻塞的方式接受客户端地连接请求，每进入一个连接即为其创建一个通道TTransport对象。 为客户端创建处理器对象、输入传输通道对象、输出传输通道对象、输入协议对象和输出协议对象。 通过TServerEventHandler对象处理具体的业务请求。 ThreadPoolServerTThreadPoolServer模式采用阻塞socket方式工作，主线程负责阻塞式监听是否有新socket到来，具体的业务处理交由一个线程池来处理。 (一) 工作流程 (二) 使用入门服务端： 1234567891011121314ServerSocket serverSocket = new ServerSocket(ServerConfig.SERVER_PORT);TServerSocket serverTransport = new TServerSocket(serverSocket);HelloWorldService.Processor&lt;HelloWorldService.Iface&gt; processor = new HelloWorldService.Processor&lt;&gt;(new HelloWorldServiceImpl());TBinaryProtocol.Factory protocolFactory = new TBinaryProtocol.Factory();TThreadPoolServer.Args ttpsArgs = new TThreadPoolServer.Args(serverTransport);ttpsArgs.processor(processor);ttpsArgs.protocolFactory(protocolFactory);// 线程池服务模型 使用标准的阻塞式IO 预先创建一组线程处理请求TServer ttpsServer = new TThreadPoolServer(ttpsArgs);System.out.println(\"Running ThreadPool Server\");ttpsServer.serve(); 客户端： 12345678TTransport transport = new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT);TProtocol protocol = new TBinaryProtocol(transport);HelloWorldService.Client client = new HelloWorldService.Client(protocol);transport.open();String result = client.say(\"ThreadPoolClient\");System.out.println(\"Result =: \" + result);transport.close(); (三) 源码分析ThreadPoolServer解决了TSimpleServer不支持并发和多连接的问题，引入了线程池。实现的模型是One Thread Per Connection。查看上述流程的源代码，先查看线程池的代码片段： TThreadPoolServer.java中的serve()方法如下： serve()方法的操作： 设置TServerSocket的listen()方法启动连接监听。 以阻塞的方式接受客户端的连接请求，每进入一个连接，将通道对象封装成一个WorkerProcess对象(WorkerProcess实现了Runnabel接口)，并提交到线程池。 WorkerProcess的run()方法负责业务处理，为客户端创建了处理器对象、输入传输通道对象、输出传输通道对象、输入协议对象和输出协议对象。 通过TServerEventHandler对象处理具体的业务请求。 WorkerProcess的run()方法： (四) 优缺点TThreadPoolServer模式的优点拆分了监听线程(Accept Thread)和处理客户端连接的工作线程(Worker Thread)，数据读取和业务处理都交给线程池处理。因此在并发量较大时新连接也能够被及时接受。 线程池模式比较适合服务器端能预知最多有多少个客户端并发的情况，这时每个请求都能被业务线程池及时处理，性能也非常高。 TThreadPoolServer模式的缺点线程池模式的处理能力受限于线程池的工作能力，当并发请求数大于线程池中的线程数时，新请求也只能排队等待。 TNonblockingServerTNonblockingServer模式也是单线程工作，但是采用NIO的模式，借助Channel/Selector机制, 采用IO事件模型来处理。 所有的socket都被注册到selector中，在一个线程中通过seletor循环监控所有的socket。 每次selector循环结束时，处理所有的处于就绪状态的socket，对于有数据到来的socket进行数据读取操作，对于有数据发送的socket则进行数据发送操作，对于监听socket则产生一个新业务socket并将其注册到selector上。 注意：TNonblockingServer要求底层的传输通道必须使用TFramedTransport。 (一) 工作流程 (二) 使用入门服务端： 123456789101112TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldServiceImpl());TNonblockingServerSocket tnbSocketTransport = new TNonblockingServerSocket(ServerConfig.SERVER_PORT);TNonblockingServer.Args tnbArgs = new TNonblockingServer.Args(tnbSocketTransport);tnbArgs.processor(tprocessor);tnbArgs.transportFactory(new TFramedTransport.Factory());tnbArgs.protocolFactory(new TCompactProtocol.Factory());// 使用非阻塞式IO服务端和客户端需要指定TFramedTransport数据传输的方式TServer server = new TNonblockingServer(tnbArgs);System.out.println(\"Running Non-blocking Server\");server.serve(); 客户端： 123456789TTransport transport = new TFramedTransport(new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT));// 协议要和服务端一致TProtocol protocol = new TCompactProtocol(transport);HelloWorldService.Client client = new HelloWorldService.Client(protocol);transport.open();String result = client.say(\"NonBlockingClient\");System.out.println(\"Result =: \" + result);transport.close(); (三) 源码分析TNonblockingServer继承于AbstractNonblockingServer，这里我们更关心基于NIO的selector部分的关键代码。 (四) 优缺点TNonblockingServer模式优点相比于TSimpleServer效率提升主要体现在IO多路复用上，TNonblockingServer采用非阻塞IO，对accept/read/write等IO事件进行监控和处理，同时监控多个socket的状态变化。 TNonblockingServer模式缺点TNonblockingServer模式在业务处理上还是采用单线程顺序来完成。在业务处理比较复杂、耗时的时候，例如某些接口函数需要读取数据库执行时间较长，会导致整个服务被阻塞住，此时该模式效率也不高，因为多个调用请求任务依然是顺序一个接一个执行。 THsHaServer鉴于TNonblockingServer的缺点，THsHaServer继承于TNonblockingServer，引入了线程池提高了任务处理的并发能力。THsHaServer是半同步半异步(Half-Sync/Half-Async)的处理模式，Half-Aysnc用于IO事件处理(Accept/Read/Write)，Half-Sync用于业务handler对rpc的同步处理上。 注意：THsHaServer和TNonblockingServer一样，要求底层的传输通道必须使用TFramedTransport。 (一) 工作流程 (二) 使用入门服务端： 1234567891011TNonblockingServerSocket tnbSocketTransport = new TNonblockingServerSocket(ServerConfig.SERVER_PORT);TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldServiceImpl());// 半同步半异步THsHaServer.Args thhsArgs = new THsHaServer.Args(tnbSocketTransport);thhsArgs.processor(tprocessor);thhsArgs.transportFactory(new TFramedTransport.Factory());thhsArgs.protocolFactory(new TBinaryProtocol.Factory());TServer server = new THsHaServer(thhsArgs);System.out.println(\"Running HsHa Server\");server.serve(); 客户端： 123456789TTransport transport = new TFramedTransport(new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT));// 协议要和服务端一致TProtocol protocol = new TBinaryProtocol(transport);HelloWorldService.Client client = new HelloWorldService.Client(protocol);transport.open();String result = client.say(\"HsHaClient\");System.out.println(\"Result =: \" + result);transport.close(); (三) 源码分析THsHaServer继承于TNonblockingServer，新增了线程池并发处理工作任务的功能，查看线程池的相关代码： 任务线程池的创建过程： 下文的TThreadedSelectorServer囊括了THsHaServer的大部分特性，源码分析可参考TThreadedSelectorServer。 (四) 优缺点THsHaServer的优点THsHaServer与TNonblockingServer模式相比，THsHaServer在完成数据读取之后，将业务处理过程交由一个线程池来完成，主线程直接返回进行下一次循环操作，效率大大提升。 THsHaServer的缺点主线程仍然需要完成所有socket的监听接收、数据读取和数据写入操作。当并发请求数较大时，且发送数据量较多时，监听socket上新连接请求不能被及时接受。 TThreadedSelectorServerTThreadedSelectorServer是对THsHaServer的一种扩充，它将selector中的读写IO事件(read/write)从主线程中分离出来。同时引入worker工作线程池，它也是种Half-Sync/Half-Async的服务模型。 TThreadedSelectorServer模式是目前Thrift提供的最高级的线程服务模型，它内部有如果几个部分构成： 一个AcceptThread线程对象，专门用于处理监听socket上的新连接。 若干个SelectorThread对象专门用于处理业务socket的网络I/O读写操作，所有网络数据的读写均是有这些线程来完成。 一个负载均衡器SelectorThreadLoadBalancer对象，主要用于AcceptThread线程接收到一个新socket连接请求时，决定将这个新连接请求分配给哪个SelectorThread线程。 一个ExecutorService类型的工作线程池，在SelectorThread线程中，监听到有业务socket中有调用请求过来，则将请求数据读取之后，交给ExecutorService线程池中的线程完成此次调用的具体执行。主要用于处理每个rpc请求的handler回调处理(这部分是同步的)。 (一) 工作流程 (二) 使用入门服务端： 12345678910111213TNonblockingServerSocket serverSocket = new TNonblockingServerSocket(ServerConfig.SERVER_PORT);TProcessor processor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldServiceImpl());// 多线程半同步半异步TThreadedSelectorServer.Args ttssArgs = new TThreadedSelectorServer.Args(serverSocket);ttssArgs.processor(processor);ttssArgs.protocolFactory(new TBinaryProtocol.Factory());// 使用非阻塞式IO时 服务端和客户端都需要指定数据传输方式为TFramedTransportttssArgs.transportFactory(new TFramedTransport.Factory());// 多线程半同步半异步的服务模型TThreadedSelectorServer server = new TThreadedSelectorServer(ttssArgs);System.out.println(\"Running ThreadedSelector Server\");server.serve(); 客户端： 12345678910111213141516171819202122232425for (int i = 0; i &lt; 10; i++) &#123; new Thread(\"Thread \" + i) &#123; @Override public void run() &#123; // 设置传输通道 对于非阻塞服务 需要使用TFramedTransport(用于将数据分块发送) for (int j = 0; j &lt; 10; j++) &#123; TTransport transport = null; try &#123; transport = new TFramedTransport(new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT)); TProtocol protocol = new TBinaryProtocol(transport); HelloWorldService.Client client = new HelloWorldService.Client(protocol); transport.open(); String result = client.say(\"ThreadedSelector Client\"); System.out.println(\"Result =: \" + result); transport.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 关闭传输通道 transport.close(); &#125; &#125; &#125; &#125;.start();&#125; (三) 核心代码以上工作流程的三个组件AcceptThread、SelectorThread和ExecutorService在源码中的定义如下： TThreadedSelectorServer模式中有一个专门的线程AcceptThread用于处理新连接请求，因此能够及时响应大量并发连接请求；另外它将网络I/O操作分散到多个SelectorThread线程中来完成，因此能够快速对网络I/O进行读写操作，能够很好地应对网络I/O较多的情况。 TThreadedSelectorServer默认参数定义如下： 负责网络IO读写的selector默认线程数(selectorThreads)：2 负责业务处理的默认工作线程数(workerThreads)：5 工作线程池单个线程的任务队列大小(acceptQueueSizePerThread)：4 创建、初始化并启动AcceptThread和SelectorThreads，同时启动selector线程的负载均衡器(selectorThreads)。 AcceptThread源码AcceptThread继承于Thread，可以看出包含三个重要的属性：非阻塞式传输通道(TNonblockingServerTransport)、NIO选择器(acceptSelector)和选择器线程负载均衡器(threadChooser)。 查看AcceptThread的run()方法，可以看出accept线程一旦启动，就会不停地调用select()方法： 查看select()方法，acceptSelector选择器等待IO事件的到来，拿到SelectionKey即检查是不是accept事件。如果是，通过handleAccept()方法接收一个新来的连接；否则，如果是IO读写事件，AcceptThread不作任何处理，交由SelectorThread完成。 在handleAccept()方法中，先通过doAccept()去拿连接通道，然后Selector线程负载均衡器选择一个Selector线程，完成接下来的IO读写事件。 接下来继续查看doAddAccept()方法的实现，毫无悬念，它进一步调用了SelectorThread的addAcceptedConnection()方法，把非阻塞传输通道对象传递给选择器线程做进一步的IO读写操作。 SelectorThreadLoadBalancer源码SelectorThreadLoadBalancer如何创建？ SelectorThreadLoadBalancer是一个基于轮询算法的Selector线程选择器，通过线程迭代器为新进来的连接顺序分配SelectorThread。 SelectorThread源码SelectorThread和AcceptThread一样，是TThreadedSelectorServer的一个成员内部类，每个SelectorThread线程对象内部都有一个阻塞式的队列，用于存放该线程被接收的连接通道。 阻塞队列的大小可由构造函数指定： 上面看到，在AcceptThread的doAddAccept()方法中调用了SelectorThread的addAcceptedConnection()方法。 这个方法做了两件事： 将被此SelectorThread线程接收的连接通道放入阻塞队列中。 通过wakeup()方法唤醒SelectorThread中的NIO选择器selector。 既然SelectorThread也是继承于Thread，查看其run()方法的实现： SelectorThread方法的select()监听IO事件，仅仅用于处理数据读取和数据写入。如果连接有数据可读，读取并以frame的方式缓存；如果需要向连接中写入数据，缓存并发送客户端的数据。且在数据读写处理完成后，需要向NIO的selector清空和注销自身的SelectionKey。 数据写操作完成以后，整个rpc调用过程也就结束了，handleWrite()方法如下： 数据读操作完成以后，Thrift会利用已读数据执行目标方法，handleRead()方法如下： handleRead方法在执行read()方法，将数据读取完成后，会调用requestInvoke()方法调用目标方法完成具体业务处理。requestInvoke()方法将请求数据封装为一个Runnable对象，提交到工作任务线程池(ExecutorService)进行处理。 select()方法完成后，线程继续运行processAcceptedConnections()方法处理下一个连接的IO事件。 这里比较核心的几个操作： 尝试从SelectorThread的阻塞队列acceptedQueue中获取一个连接的传输通道。如果获取成功，调用registerAccepted()方法；否则，进入下一次循环。 registerAccepted()方法将传输通道底层的连接注册到NIO的选择器selector上面，获取到一个SelectionKey。 创建一个FrameBuffer对象，并绑定到获取的SelectionKey上面，用于数据传输时的中间读写缓存。 总结本文对Thrift的各种线程服务模型进行了介绍，包括2种阻塞式服务模型：TSimpleServer、TThreadPoolServer，3种非阻塞式服务模型：TNonblockingServer、THsHaServer和TThreadedSelectorServer。对各种服务模型的具体用法、工作流程、原理和源码实现进行了一定程度的分析。 鉴于篇幅较长，请各位看官请慢慢批阅！ 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"Thrift","slug":"Thrift","permalink":"https://ostenant.coding.me/tags/Thrift/"},{"name":"Apache","slug":"Apache","permalink":"https://ostenant.coding.me/tags/Apache/"},{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"}]},{"title":"Apache Thrift系列详解(一) - 概述与入门","slug":"Apache Thrift系列详解(一) - 概述与入门","date":"2018-01-08T02:14:00.000Z","updated":"2018-05-08T02:49:46.087Z","comments":true,"path":"2018/01/08/Apache Thrift系列详解(一) - 概述与入门/","link":"","permalink":"https://ostenant.coding.me/2018/01/08/Apache Thrift系列详解(一) - 概述与入门/","excerpt":"前言Thrift是一个轻量级、跨语言的远程服务调用框架，最初由Facebook开发，后面进入Apache开源项目。它通过自身的IDL中间语言, 并借助代码生成引擎生成各种主流语言的RPC服务端/客户端模板代码。","text":"前言Thrift是一个轻量级、跨语言的远程服务调用框架，最初由Facebook开发，后面进入Apache开源项目。它通过自身的IDL中间语言, 并借助代码生成引擎生成各种主流语言的RPC服务端/客户端模板代码。 Thrift支持多种不同的编程语言，包括C++、Java、Python、PHP、Ruby等，本系列主要讲述基于Java语言的Thrift的配置方式和具体使用。 正文Thrift的技术栈Thrift对软件栈的定义非常的清晰, 使得各个组件能够松散的耦合, 针对不同的应用场景, 选择不同是方式去搭建服务。 Thrift软件栈分层从下向上分别为：传输层(Transport Layer)、协议层(Protocol Layer)、处理层(Processor Layer)和服务层(Server Layer)。 传输层(Transport Layer)：传输层负责直接从网络中读取和写入数据，它定义了具体的网络传输协议；比如说TCP/IP传输等。 协议层(Protocol Layer)：协议层定义了数据传输格式，负责网络传输数据的序列化和反序列化；比如说JSON、XML、二进制数据等。 处理层(Processor Layer)：处理层是由具体的IDL（接口描述语言）生成的，封装了具体的底层网络传输和序列化方式，并委托给用户实现的Handler进行处理。 服务层(Server Layer)：整合上述组件，提供具体的网络线程/IO服务模型，形成最终的服务。 Thrift的特性(一) 开发速度快通过编写RPC接口Thrift IDL文件，利用编译生成器自动生成服务端骨架(Skeletons)和客户端桩(Stubs)。从而省去开发者自定义和维护接口编解码、消息传输、服务器多线程模型等基础工作。 服务端：只需要按照服务骨架即接口，编写好具体的业务处理程序(Handler)即实现类即可。 客户端：只需要拷贝IDL定义好的客户端桩和服务对象，然后就像调用本地对象的方法一样调用远端服务。 (二) 接口维护简单通过维护Thrift格式的IDL（接口描述语言）文件（注意写好注释），即可作为给Client使用的接口文档使用，也自动生成接口代码，始终保持代码和文档的一致性。且Thrift协议可灵活支持接口的可扩展性。 (三) 学习成本低因为其来自Google Protobuf开发团队，所以其IDL文件风格类似Google Protobuf，且更加易读易懂；特别是RPC服务接口的风格就像写一个面向对象的Class一样简单。 初学者只需参照：http://thrift.apache.org/，一个多小时就可以理解Thrift IDL文件的语法使用。 (四) 多语言/跨语言支持Thrift支持C++、 Java、Python、PHP、Ruby、Erlang、Perl、Haskell、C#、Cocoa、JavaScript、Node.js、Smalltalk等多种语言，即可生成上述语言的服务器端和客户端程序。 对于我们经常使用的Java、PHP、Python、C++支持良好，虽然对iOS环境的Objective-C(Cocoa)支持稍逊，但也完全满足我们的使用要求。 (五) 稳定/广泛使用Thrift在很多开源项目中已经被验证是稳定和高效的，例如Cassandra、Hadoop、HBase等；国外在Facebook中有广泛使用，国内包括百度、美团小米、和饿了么等公司。 Thrift的数据类型Thrift 脚本可定义的数据类型包括以下几种类型： 基本类型： bool: 布尔值 byte: 8位有符号整数 i16: 16位有符号整数 i32: 32位有符号整数 i64: 64位有符号整数 double: 64位浮点数 string: UTF-8编码的字符串 binary: 二进制串 结构体类型： struct: 定义的结构体对象 容器类型： list: 有序元素列表 set: 无序无重复元素集合 map: 有序的key/value集合 异常类型： exception: 异常类型 服务类型： service: 具体对应服务的类 Thrift的协议Thrift可以让用户选择客户端与服务端之间传输通信协议的类别，在传输协议上总体划分为文本(text)和二进制(binary)传输协议。为节约带宽，提高传输效率，一般情况下使用二进制类型的传输协议为多数，有时还会使用基于文本类型的协议，这需要根据项目/产品中的实际需求。常用协议有以下几种： TBinaryProtocol：二进制编码格式进行数据传输 TCompactProtocol：高效率的、密集的二进制编码格式进行数据传输 TJSONProtocol： 使用JSON文本的数据编码协议进行数据传输 TSimpleJSONProtocol：只提供JSON只写的协议，适用于通过脚本语言解析 Thrift的传输层常用的传输层有以下几种： TSocket：使用阻塞式I/O进行传输，是最常见的模式 TNonblockingTransport：使用非阻塞方式，用于构建异步客户端 TFramedTransport：使用非阻塞方式，按块的大小进行传输，类似于Java中的NIO Thrift的服务端类型 TSimpleServer：单线程服务器端，使用标准的阻塞式I/O TThreadPoolServer：多线程服务器端，使用标准的阻塞式I/O TNonblockingServer：单线程服务器端，使用非阻塞式I/O THsHaServer：半同步半异步服务器端，基于非阻塞式IO读写和多线程工作任务处理 TThreadedSelectorServer：多线程选择器服务器端，对THsHaServer在异步IO模型上进行增强 Thrift入门示例(一) 编写Thrift IDL文件a). 下载0.10.0的Thrift IDL编译器，下载地址：http://thrift.apache.org/docs/install。 通过编译生成器生成.java接口的类文件。 b). 下载Windows安装环境的.exe文件，将thrift.exe的路径加入环境变量中。在Idea上安装Thrift编辑插件。 c). 编写hello.thrift的IDL文件： 123service HelloWorldService &#123; string say(1: string username)&#125; d). 使用代码生成工具生成代码，执行以下命令： 1thrift -gen java hello.thrift e). 由于未指定代码生成的目标目录，生成的类文件默认存放在gen-java目录下。这里生成一个HelloWorldService.java类文件，文件大小超过数千行，下面截取一部分核心代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class HelloWorldService &#123; public interface Iface &#123; public String say(String username) throws org.apache.thrift.TException; &#125; public interface AsyncIface &#123; public void say(String username, org.apache.thrift.async.AsyncMethodCallback&lt;String&gt; resultHandler) throws org.apache.thrift.TException; &#125; public static class Client extends org.apache.thrift.TServiceClient implements Iface &#123; public static class Factory implements org.apache.thrift.TServiceClientFactory&lt;Client&gt; &#123; public Factory() &#123; &#125; public Client getClient(org.apache.thrift.protocol.TProtocol prot) &#123; return new Client(prot); &#125; public Client getClient(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot) &#123; return new Client(iprot, oprot); &#125; &#125; public Client(org.apache.thrift.protocol.TProtocol prot) &#123; super(prot, prot); &#125; public Client(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot) &#123; super(iprot, oprot); &#125; public String say(String username) throws org.apache.thrift.TException &#123; send_say(username); return recv_say(); &#125; // 省略..... &#125; public static class AsyncClient extends org.apache.thrift.async.TAsyncClient implements AsyncIface &#123; public static class Factory implements org.apache.thrift.async.TAsyncClientFactory&lt;AsyncClient&gt; &#123; private org.apache.thrift.async.TAsyncClientManager clientManager; private org.apache.thrift.protocol.TProtocolFactory protocolFactory; public Factory(org.apache.thrift.async.TAsyncClientManager clientManager, org.apache.thrift.protocol.TProtocolFactory protocolFactory) &#123; this.clientManager = clientManager; this.protocolFactory = protocolFactory; &#125; public AsyncClient getAsyncClient(org.apache.thrift.transport.TNonblockingTransport transport) &#123; return new AsyncClient(protocolFactory, clientManager, transport); &#125; &#125; public AsyncClient(org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.async.TAsyncClientManager clientManager, org.apache.thrift.transport.TNonblockingTransport transport) &#123; super(protocolFactory, clientManager, transport); &#125; public void say(String username, org.apache.thrift.async.AsyncMethodCallback&lt;String&gt; resultHandler) throws org.apache.thrift.TException &#123; checkReady(); say_call method_call = new say_call(username, resultHandler, this, ___protocolFactory, ___transport); this.___currentMethod = method_call; ___manager.call(method_call); &#125; // 省略..... &#125; // 省略.....&#125; 对于开发人员而言，使用原生的Thrift框架，仅需要关注以下四个核心内部接口/类：Iface, AsyncIface, Client和AsyncClient。 Iface：服务端通过实现HelloWorldService.Iface接口，向客户端的提供具体的同步业务逻辑。 AsyncIface：服务端通过实现HelloWorldService.Iface接口，向客户端的提供具体的异步业务逻辑。 Client：客户端通过HelloWorldService.Client的实例对象，以同步的方式访问服务端提供的服务方法。 AsyncClient：客户端通过HelloWorldService.AsyncClient的实例对象，以异步的方式访问服务端提供的服务方法。 (二) 新建Maven工程a). 新建maven工程，引入thrift的依赖，这里使用的是版本0.10.0。 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt; &lt;artifactId&gt;libthrift&lt;/artifactId&gt; &lt;version&gt;0.10.0&lt;/version&gt;&lt;/dependency&gt; b). 将生成类的HelloWorldService.java源文件拷贝进项目源文件目录中，并实现HelloWorldService.Iface的定义的say()方法。 HelloWorldServiceImpl.java 123456public class HelloWorldServiceImpl implements HelloWorldService.Iface &#123; @Override public String say(String username) throws TException &#123; return \"Hello \" + username; &#125;&#125; c). 服务器端程序编写： SimpleServer.java 123456789101112131415161718public class SimpleServer &#123; public static void main(String[] args) throws Exception &#123; ServerSocket serverSocket = new ServerSocket(ServerConfig.SERVER_PORT); TServerSocket serverTransport = new TServerSocket(serverSocket); HelloWorldService.Processor processor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldServiceImpl()); TBinaryProtocol.Factory protocolFactory = new TBinaryProtocol.Factory(); TSimpleServer.Args tArgs = new TSimpleServer.Args(serverTransport); tArgs.processor(processor); tArgs.protocolFactory(protocolFactory); // 简单的单线程服务模型 一般用于测试 TServer tServer = new TSimpleServer(tArgs); System.out.println(\"Running Simple Server\"); tServer.serve(); &#125;&#125; d). 客户端程序编写： SimpleClient.java 1234567891011121314151617181920public class SimpleClient &#123; public static void main(String[] args) &#123; TTransport transport = null; try &#123; transport = new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT); TProtocol protocol = new TBinaryProtocol(transport); HelloWorldService.Client client = new HelloWorldService.Client(protocol); transport.open(); String result = client.say(\"Leo\"); System.out.println(\"Result =: \" + result); &#125; catch (TException e) &#123; e.printStackTrace(); &#125; finally &#123; if (null != transport) &#123; transport.close(); &#125; &#125; &#125;&#125; e). 运行服务端程序，服务端在指定端口监听客户端的连接请求，控制台输出启动日志： f). 运行客户端程序，客户端通过网络请求HelloWorldService的say()方法的具体实现，控制台输出返回结果： 这里使用的一个基于单线程同步的简单服务模型，一般仅用于入门学习和测试！ 总结本文对Thrift的概念做了相关介绍，体验了一番thrift程序如何编写！ 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"Thrift","slug":"Thrift","permalink":"https://ostenant.coding.me/tags/Thrift/"},{"name":"Apache","slug":"Apache","permalink":"https://ostenant.coding.me/tags/Apache/"},{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"}]},{"title":"深入浅出OAuth 2.0授权机制","slug":"深入浅出OAuth 2.0授权机制","date":"2018-01-04T13:10:00.000Z","updated":"2018-05-08T02:49:46.097Z","comments":true,"path":"2018/01/04/深入浅出OAuth 2.0授权机制/","link":"","permalink":"https://ostenant.coding.me/2018/01/04/深入浅出OAuth 2.0授权机制/","excerpt":"前言举个简单的例子。新浪微博是你的家，有时候你会想让一些人(第三方应用)去你的家里帮你办点事情，或者取点东西。你可以直接复制一把钥匙(用户名和密码)给他们，但这里存在几个问题：","text":"前言举个简单的例子。新浪微博是你的家，有时候你会想让一些人(第三方应用)去你的家里帮你办点事情，或者取点东西。你可以直接复制一把钥匙(用户名和密码)给他们，但这里存在几个问题： 别人拿了钥匙后可以去你家里的所有房间。 别人拿到你的钥匙后也许会不小心丢到，甚至故意送到它人手里。这样你都不知到谁有你家钥匙。 过一段时间你也许会想要回自己的钥匙，但别人不还怎么办？ 总结起来就是两个问题：其一，拿到钥匙的人权限太大，可以进入任一房间；其二，拿到钥匙的人可能对钥匙进行复制和更改。 OAuth是高级钥匙，可以理解为指纹识别，它主要解决了以上的缺陷： 你可以配置不同权限的钥匙。有些只能进大厅(读取你的微博流)。有些钥匙可以进储藏柜(读取你的相片)。 钥匙上带着指纹验证程序(指纹 = appkey)，只有收到钥匙的人自己能使用钥匙。 钥匙有一定的时效性，同时你也可以远程废除钥匙。 正文OAuth是一个关于授权(authorization)的开放网络标准，在全世界得到广泛应用，目前的版本是2.0版。本文对OAuth 2.0的设计思路和运行流程，做一个简明通俗的解释。 应用场景为了理解OAuth的适用场景，举一个通俗易懂的例子。有一个”云冲印”的网站，可以将用户储存在Google的照片，冲印出来。用户为了使用该服务，必须让”云冲印”读取自己储存在Google上的照片。 问题是只有得到用户的授权，Google才会同意”云冲印”读取这些照片。那么，”云冲印”怎样获得用户的授权呢？传统方法是，用户将自己的Google用户名和密码，告诉”云冲印”，后者就可以读取用户的照片了。这样的做法有以下几个严重的缺点。 1. &quot;云冲印&quot;为了后续的服务，会保存用户的密码，这样很不安全。 2. Google不得不部署密码登录，而我们知道，单纯的密码登录并不安全。 3. &quot;云冲印&quot;拥有了获取用户储存在Google所有资料的权利，用户没法限制&quot;云冲印&quot;获得授权的范围和有效期。 4. 用户只有修改密码，才能收回赋予&quot;云冲印&quot;的权力。但是这样做，会使得其他所有获得用户授权的第三方应用程序全部失效。 5. 只要有一个第三方应用程序被破解，就会导致用户密码泄漏，以及所有被密码保护的数据泄漏。 OAuth就是为了解决上面这些问题而诞生的。 专业术语在详细讲解OAuth 2.0之前，需要了解几个专用名词。它们对读懂后面的讲解，尤其是几张图，至关重要。 专业术语 中文含义 具体解释说明 Third-party application 第三方应用程序 本文中又称”客户端”(client)，即上一节例子中的”云冲印” Resource Owner 资源所有者 本文中又称”用户”(user)。 HTTP service HTTP服务提供商 本文中简称”服务提供商”，即上一节例子中的Google。 User Agent 用户代理 本文中就是指浏览器。 Authorization server 认证服务器 即服务提供商专门用来处理认证的服务器。 Resource server 资源服务器 即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。 OAuth的思路OAuth在”客户端“与”服务提供商“之间，设置了一个授权层(authorization layer)。”客户端“不能直接登录”服务提供商“，只能登录授权层，以此将用户与客户端区分开来。”客户端“登录授权层所用的令牌(token)，与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。“客户端”登录授权层以后，”服务提供商”根据令牌的权限范围和有效期，向”客户端“开放用户储存的资料。 具体流程 (A). 用户打开客户端以后，客户端要求用户给予授权。 (B). 用户同意给予客户端授权。 (C). 客户端拿到上一步获取到的授权，向认证服务器申请令牌。 (D). 认证服务器对客户端进行认证以后，确认无误，统一发放令牌。 (E). 客户端使用令牌，向资源服务器申请获取用户的资源。 (F). 资源服务器确认令牌无误，同意向客户端开放资源。 不难看出来，上面六个步骤之中，步骤(B)是关键，即用户怎样才能给于客户端授权。有了这个授权以后，客户端就可以获取令牌，进而凭令牌获取资源。 几种授权模式客户端必须得到了用户的授权。(authorization grant)，才能获取令牌(access token)。OAuth 2.0定义了四种授权方式。 授权码模式(authorization code) 简化模式(implicit) 密码模式(resource owner password credentials) 客户端模式(client credentials) 下面一一讲解客户端获取授权的四种模式。 (一). 授权码模式授权码模式(authorization code)是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与”服务提供商“的认证服务器进行互动。 它的步骤如下： (A). 用户访问客户端，后者将前者导向认证服务器。 (B). 用户选择是否给予客户端授权。 (C). 假设用户给予授权，认证服务器将用户导向客户端事先指定的&quot;重定向URI&quot;(redirection URI)，同时附上一个授权码。 (D). 客户端收到授权码，附上早先的&quot;重定向URI&quot;，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。 (E). 认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌(access token)和更新令牌(refresh token)。 对于每个步骤具体所需要参数如下： A步骤中，客户端申请认证的URI，包含以下参数： 参数 具体含义 是否必填 response_type 授权类型 必选项，此处的值固定为”code” client_id 客户端的ID 必选项 redirect_uri 重定向URI 可选项 scope 申请的权限范围 可选项 state 客户端的当前状态，认证服务器会原封不动地返回这个值 可选项，可以指定任意值 下面是一个例子：123GET /authorize?response_type=code&amp;client_id=s6BhdRkqt3&amp;state=xyz &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1Host: server.example.com C步骤中，服务器回应客户端的URI，包含以下参数： 参数 具体含义 是否必填 code 授权码。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系 必选项 state 如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。 可选项 下面是一个例子： 12HTTP/1.1 302 FoundLocation: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA&amp;state=xyz D步骤中，客户端向认证服务器申请令牌的HTTP请求，包含以下参数： 参数 具体含义 是否必填 grant_type 授权模式 必选项，此处的值固定为”authorization_code” code 上一步获得的授权码 必选项 redirect_uri 重定向URI 必选项，且必须与A步骤中的该参数值保持一致 client_id 客户端ID 必选项 下面是一个例子： 1234567POST /token HTTP/1.1Host: server.example.comAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JWContent-Type: application/x-www-form-urlencodedgrant_type=authorization_code&amp;code=SplxlOBeZQQYbYS6WxSbIA&amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb E步骤中，认证服务器发送的HTTP回复，包含以下参数： 参数 具体含义 是否必填 access_token 访问令牌 必选项 token_type 牌类型，该值大小写不敏感 必选项，可以是bearer类型或mac类型 expires_in 过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间 可选项 refresh_token 更新令牌，用来获取下一次的访问令牌 可选项 scope 申请的权限范围 可选项 下面是一个例子： 123456789101112HTTP/1.1 200 OKContent-Type: application/json;charset=UTF-8Cache-Control: no-storePragma: no-cache&#123; \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\", \"token_type\":\"bearer\", \"expires_in\":3600, \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\", \"example_parameter\":\"example_value\"&#125; 从上面代码可以看到，相关参数使用JSON格式发送(Content-Type: application/json)。此外，HTTP头信息中明确指定不得缓存。 (二). 简化模式简化模式(implicit grant type)不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了”授权码“这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。 它的步骤如下： (A). 客户端将用户导向认证服务器。 (B). 用户决定是否给于客户端授权。 (C). 假设用户给予授权，认证服务器将用户导向客户端指定的&quot;重定向URI&quot;，并在URI的Hash部分包含了访问令牌。 (D). 浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。 (E). 资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。 (F). 浏览器执行上一步获得的脚本，提取出令牌。 (G). 浏览器将令牌发给客户端。 下面是上面这些步骤所需要的参数： A步骤中，客户端发出的HTTP请求，包含以下参数： 参数 具体含义 是否必填 response_type 授权类型 必选项，此处的值固定为”token” client_id 客户端的ID 必选项 redirect_uri 重定向URI 可选项 scope 申请的权限范围 可选项 state 客户端的当前状态，认证服务器会原封不动地返回这个值 可选项，可以指定任意值 下面是一个例子： 123GET /authorize?response_type=token&amp;client_id=s6BhdRkqt3&amp;state=xyz &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1Host: server.example.com C步骤中，认证服务器回应客户端的URI，包含以下参数： 参数 具体含义 是否必填 access_token 访问令牌 必选项 token_type 牌类型，该值大小写不敏感 必选项 expires_in 过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间 可选项 scope 权限范围 如果与客户端申请的范围一致，此项可省略 state 如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数 可选项 下面是一个例子： 123HTTP/1.1 302 FoundLocation: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA &amp;state=xyz&amp;token_type=example&amp;expires_in=3600 下面是一个例子： 123HTTP/1.1 302 FoundLocation: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA &amp;state=xyz&amp;token_type=bearer&amp;expires_in=3600 在上面的例子中，认证服务器用HTTP头信息的Location栏，指定浏览器重定向的网址。注意，在这个网址的Hash部分包含了令牌。根据上面的D步骤，下一步浏览器会访问Location指定的网址，但是Hash部分不会发送。接下来的E步骤，服务提供商的资源服务器发送过来的脚本代码，会提取出Hash中的令牌。 (三). 密码模式密码模式(Resource Owner Password Credentials Grant)中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向”服务商提供商“索要授权。 在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分，或者由一个著名公司出品。而认证服务器只有在其他授权模式无法执行的情况下，才能考虑使用这种模式。 它的步骤如下： (A). 用户向客户端提供用户名和密码。 (B). 客户端将用户名和密码发给认证服务器，向后者请求令牌。 (C). 认证服务器确认无误后，向客户端提供访问令牌。 B步骤中，客户端发出的HTTP请求，包含以下参数： 参数 具体含义 是否必填 grant_type 授权类型 必选项，此处的值固定为”password” username 用户名 必选项 password 用户的密码 必选项 scope 申请的权限范围 可选项 下面是一个例子： 123456POST /token HTTP/1.1Host: server.example.comAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JWContent-Type: application/x-www-form-urlencodedgrant_type=password&amp;username=johndoe&amp;password=A3ddj3w C步骤中，认证服务器向客户端发送访问令牌： 参数 具体含义 是否必填 access_token 访问令牌 必选项 token_type 牌类型，该值大小写不敏感 必选项 expires_in 过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间 可选项 scope 权限范围 如果与客户端申请的范围一致，此项可省略 example_parameter 如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数 可选项 下面是一个例子： 123456789101112HTTP/1.1 200 OKContent-Type: application/json;charset=UTF-8Cache-Control: no-storePragma: no-cache&#123; \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\", \"token_type\":\"example\", \"expires_in\":3600, \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\", \"example_parameter\":\"example_value\"&#125; (四). 客户端模式客户端模式(Client Credentials Grant)指客户端以自己的名义，而不是以用户的名义，向”服务提供商“进行认证。严格地说，客户端模式并不属于OAuth框架所要解决的问题。 在这种模式中，用户直接向客户端注册，客户端以自己的名义要求”服务提供商“提供服务，其实不存在授权问题。 它的步骤如下： (A). 客户端向认证服务器进行身份认证，并要求一个访问令牌。 (B). 认证服务器确认无误后，向客户端提供访问令牌。 A步骤中，客户端发出的HTTP请求，包含以下参数： 参数 具体含义 是否必填 grant_type 授权类型 必选项，此处的值固定为”clientcredentials” scope 权限范围 可选项。 123456POST /token HTTP/1.1Host: server.example.comAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JWContent-Type: application/x-www-form-urlencodedgrant_type=client_credentials 认证服务器必须以某种方式，验证客户端身份。 B步骤中，认证服务器向客户端发送访问令牌，下面是一个例子： 1234567891011HTTP/1.1 200 OKContent-Type: application/json;charset=UTF-8Cache-Control: no-storePragma: no-cache&#123; \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\", \"token_type\":\"example\", \"expires_in\":3600, \"example_parameter\":\"example_value\"&#125; 总结本文介绍了OAuth 2.0的一些基本概念，以及四种授权模式：授权码模式、简单模式、密码模式和客户端模式。o 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"认证与授权系列","slug":"认证与授权系列","permalink":"https://ostenant.coding.me/categories/认证与授权系列/"}],"tags":[{"name":"OAuth 2.0","slug":"OAuth-2-0","permalink":"https://ostenant.coding.me/tags/OAuth-2-0/"}]},{"title":"Java NIO系列(四) - Selector","slug":"Java NIO系列(四) - Selector","date":"2017-12-31T04:16:00.000Z","updated":"2018-05-08T02:49:46.092Z","comments":true,"path":"2017/12/31/Java NIO系列(四) - Selector/","link":"","permalink":"https://ostenant.coding.me/2017/12/31/Java NIO系列(四) - Selector/","excerpt":"前言Selector 是 Java NIO 中的一个组件，用于检查一个或多个通道 Channel 的状态是否处于可读、可写状态。如此可以实现单线程管理多个通道，也就是可以管理多个网络连接。","text":"前言Selector 是 Java NIO 中的一个组件，用于检查一个或多个通道 Channel 的状态是否处于可读、可写状态。如此可以实现单线程管理多个通道，也就是可以管理多个网络连接。 为什么使用Selector?用单线程处理多个 Channel 的好处是我需要更少的线程来处理 Channel 。实际上，你甚至可以用一个线程来处理所有的Channel。从操作系统的角度来看，切换线程的开销是比较昂贵的，并且每个线程都需要占用系统资源，因此暂用线程越少越好。 简而言之，通过 Selector 我们可以实现单线程操作多个 Channel。下面是单线程使用一个 Selector 处理 3 个 Channel 的示例图： 正文Selector的组件Java NIO Selector中有三个重要的组成：Selector、SelectableChannel 和 SelectionKey。 (一) 选择器(Selector)Selector选择器类管理着一个被注册的通道集合的信息和它们的就绪状态。选择器所在线程不停地更新通道的就绪状态，对通道注册的连接、数据读写事件等事件进行响应。 (二) 可选择通道(SelectableChannel)SelectableChannel 是一个抽象类，提供了通道的可选择性所需要的公共方法的实现，它是所有支持就绪检查的通道类的父类。 因为 FileChannel 类没有继承 SelectableChannel，因此不是可选通道。而所有 Socket 通道都是可选择的，包括从管道 (Pipe) 对象的中获得的通道。SelectableChannel 可以被注册到 Selector 对象上，并且注册时可以指定感兴趣的事件操作，比如：数据读取、数据写入操作。一个通道可以被注册到多个选择器上，但对每个选择器而言只能被注册一次。 (三) 选择键(SelectionKey)选择键封装了特定的通道与特定的选择器的注册关系。选择键对象由被 SelectableChannel.register() 返回并提供一个表示这种注册关系的标记。选择键包含了两个比特集(以整数的形式进行编码)，指示了该注册关系所关心的通道操作，以及通道已经准备好的操作。 Selector的使用(一) 创建Selector对象Selector 对象是通过调用静态工厂方法 open() 来实例化的，如下： 1Selector Selector = Selector.open(); (二) 将SelectableChannel注册到Selector为了将 Channel 和 Selector 配合使用，必须将 Channel 注册到 Selector 上。通过 SelectableChannel.register() 方法来实现，如下： 123channel.configureBlocking(false);// 对读操作感兴趣，向Selector注册读事件SelectionKey key = channel.register(selector, Selectionkey.OP_READ); 与 Selector 一起使用时，Channel 必须处于非阻塞模式下。这意味着不能将 FileChannel 与 Selector 一起使用，因为 FileChannel 不能切换到非阻塞模式，而套接字通道都可以。 注意 register() 方法的第二个参数。这是一个兴趣 (interest) 集合，意思是在通过 Selector 监听 Channel 时对什么事件感兴趣。可以监听四种不同类型的事件： 连接操作(Connect)：监听 SocketChannel 到来的连接事件。 接受操作(Accept)：对应常量 SelectionKey.OP_ACCEPT，专注于监听 ServerSocketChannel 接受 SocketChannel 的事件。 读操作(Read)：对应常量 SelectionKey.OP_READ，监听数据完全到达，通道可读的事件。 写操作(Write)：对应常量 SelectionKey.OP_READ，监听数据准备完成，通道可写的事件。 注意：并非所有的操作在所有的可选择通道上都能被支持。比如 ServerSocketChannel 支持 Accept操作，而 SocketChannel 中不支持。我们可以通过通道上的 validOps() 方法来获取特定通道下所有支持的操作集合。 以上四种事件用 SelectionKey 的四个常量来表示： 1234public static final int OP_READ = 1 &lt;&lt; 0; // 1public static final int OP_WRITE = 1 &lt;&lt; 2; // 4public static final int OP_CONNECT = 1 &lt;&lt; 3; // 8public static final int OP_ACCEPT = 1 &lt;&lt; 4; // 16 如果一个通道同时对多种操作感兴趣，可以用 “位或” 操作符将常量连接起来，如下： 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; (三) 为SelectionKey绑定附加对象可以将一个对象或者更多信息附着到 SelectionKey 上，这样就能方便的识别某个给定的通道。例如，可以附加与通道一起使用的 Buffer，或是包含聚集数据的某个对象。使用方法如下： 12selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 还可以在用 register() 方法向 Selector 注册 Channel 的时候附加对象，例如： 1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 如果要取消该对象，则可以通过该种方式: 1selectionKey.attach(null); (四) 通过Selector选择通道一旦向 Selector 注册了一或多个通道，就可以调用几个重载的 select() 方法。这些方法返回你所感兴趣的事件 (如连接、接受、读或写) 已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣，select() 方法会返回读事件已经就绪的那些通道的 SelectionKey。 下面是 select() 方法的几个重载： int select()：阻塞到至少有一个通道在此选择器注册的事件上就绪了。 int select(long timeout)：select(long timeout) 和 select() 一样，除了最长会阻塞timeout毫秒(参数)。 int selectNow()：不会阻塞，不管什么通道就绪都立刻返回。如果没有通道变成可选择的，则此方法直接返回 0。 也可以通过遍历 SelectionKey 上的已选择键集合来访问就绪的通道，如下： 123456789101112131415Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator();while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // 一个连接被ServerSocketChannel接受 &#125; else if (key.isConnectable()) &#123; // 与远程服务器建立了连接 &#125; else if (key.isReadable()) &#123; // 一个channel做好了读准备 &#125; else if (key.isWritable()) &#123; // 一个channel做好了写准备 &#125; keyIterator.remove();&#125; 注意：每次迭代完成时 Selector 自己不会将已经处理完成的 SelectionKey实例移除，在迭代的末尾需要调用 keyIterator.remove() 方法手动移除。 SelectionKey.channel() 方法返回的通道需要强转为你要处理的类型，如：ServerSocketChannel 或 SocketChannel 等。 Selector完整实例服务端代码1234567891011121314151617181920212223242526272829303132333435ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.configureBlocking(false);serverSocketChannel.socket().bind(new InetSocketAddress(port));Selector selector = Selector.open();serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);while (true) &#123; int number = selector.select(); if (number == 0) continue; Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey selectionKey = iterator.next(); if (selectionKey.isAcceptable()) &#123; // 获取客户端通道 SocketChannel socketChannel = (SocketChannel) selectionKey.channel(); socketChannel.configureBlocking(false); // 将客户端通道注册到选择器上 socketChannel.register(selector, SelectionKey.OP_READ, ByteBuffer.allocate(bufferSize)); &#125; if (selectionKey.isReadable()) &#123; handleRead(selectionKey); &#125; if (selectionKey.isWritable()) &#123; handleWrite(selectionKey); &#125; if (selectionKey.isConnectable()) &#123; System.out.println(\"Isonnectable := true\"); &#125; iterator.remove(); &#125;&#125; 服务端操作过程 创建 ServerSocketChannel 实例，设置为非阻塞模式，并绑定指定的服务端口； 创建 Selector 实例； 将 serverSocketChannel 注册到 selector 上面，并指定事件 OP_ACCEPT，最底层的 socket 通过 channel 和 selector 建立关联； 如果没有准备好 (Accept) 的socket，select方法会被阻塞一段时间并返回 0； 如果底层有 socket 已经准备好，selector 的 select() 方法会返回 socket 的个数，而且 selectedKeys 方法会返回 socket 对应的事件(connect、accept、read 和 write)； 根据事件类型，进行不同的处理逻辑。 总结这里简单的介绍了 Java NIO 中选择器的用法，有关 Selector 底层的实现原理需要进一步查看源码。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java编程进阶系列","slug":"Java编程进阶系列","permalink":"https://ostenant.coding.me/categories/Java编程进阶系列/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://ostenant.coding.me/tags/NIO/"}]},{"title":"Java NIO系列(三) - Channel","slug":"Java NIO系列(三) - Channel","date":"2017-12-27T07:22:00.000Z","updated":"2018-05-08T02:49:46.091Z","comments":true,"path":"2017/12/27/Java NIO系列(三) - Channel/","link":"","permalink":"https://ostenant.coding.me/2017/12/27/Java NIO系列(三) - Channel/","excerpt":"前言上文讲到Java NIO一些基本概念。在标准的IO中，都是基于字节流/字符流进行数据操作的，而在NIO中则是是基于Channel和Buffer进行操作，其中的Channel的虽然模拟了流的概念，实则大不相同。 本文将详细阐述NIO中的通道Channel的概念和具体的用法。","text":"前言上文讲到Java NIO一些基本概念。在标准的IO中，都是基于字节流/字符流进行数据操作的，而在NIO中则是是基于Channel和Buffer进行操作，其中的Channel的虽然模拟了流的概念，实则大不相同。 本文将详细阐述NIO中的通道Channel的概念和具体的用法。 Channel和Stream的区别 区别 Stream Channel 是否支持异步 不支持 支持 是否支持双向数据传输 不支持，只能单向 支持，既可以从通道读取数据，也可以向通道写入数据 是否结合Buffer使用 不 必须结合Buffer使用 性能 较低 较高 Channel用于在字节缓冲区和位于通道另一侧的服务（通常是文件或者套接字）之间以便有效的进行数据传输。借助通道，可以用最小的总开销来访问操作系统本身的I/O服务。 需要注意的是Channel必须结合Buffer使用，应用程序不能直接向通道中读/写数据，也就是缓冲区充当着应用程序和通道数据流动的转换的角色。 正文Channel的源码查看Channel的源码。所有的接口都实现于Channel接口，从接口上来看，所有的通道都有这两种操作：检查通道的开启状态和关闭通道。 12345public interface Channel extends Closeable &#123; public boolean isOpen(); public void close() throws IOException;&#125; Channel的分类广义上来说通道可以被分为两类：文件I/O和网络I/O，也就是文件通道和套接字通道。如果分的更细致一点则是： FileChannel：从文件读写数据； SocketChannel：通过TCP读写网络数据； ServerSocketChannel：可以监听新进来的TCP连接，并对每个链接创建对应的SocketChannel； DatagramChannel：通过UDP读写网络中的数据。 Channel的特性单向or双向通道既可以是单向的也可以是双向的。只实现ReadableByteChannel接口中的read()方法或者只实现WriteableByteChannel接口中的write()方法的通道皆为单向通道，同时实现ReadableByteChannel和WriteableByteChannel为双向通道，比如ByteChannel。 12public interface ByteChannel extends ReadableByteChannel, WritableByteChannel &#123;&#125; 对于Socket通道来说，它们一直是双向的，而对于FileChannel来说，它同样实现了ByteChannel，但是通过FileInputStream的getChannel()获取的FileChannel只具有文件的只读权限。 注意：调用FileChannel的write()方法会抛出了NonWriteChannelException异常。 阻塞or非阻塞通道的工作模式有两种：阻塞或非阻塞。在非阻塞模式下，调用的线程不会休眠，请求的操作会立刻返回结果；在阻塞模式下，调用的线程会产生休眠。 除FileChannel不能运行在非阻塞模式下，其余的通道都可阻塞运行也可以以非阻塞的方式运行。 另外从SelectableChannel引申出的类可以和支持有条件选择的Selector结合使用，进而充分利用多路复用的I/O(Multiplexed I/O)来提高性能。 SelectableChannel的源码中有以下几个抽象方法，可以看出支持配置两种工作模式：1234567891011121314public abstract class SelectableChannel extends AbstractInterruptibleChannel implements Channel &#123; /** * 配置是否为Channel阻塞模式 */ public abstract SelectableChannel configureBlocking(boolean block) throws IOException; /** * 判断是否为Channel阻塞模式 */ public abstract boolean isBlocking(); /** * 获取阻塞的锁对象 */ public abstract Object blockingLock();&#125; 对于Socket通道类来说，通常与Selector共同使用以提高性能。需要注意的是通道不能被同时使用，一个打开的通道代表着与一个特定I/O服务进行连接并封装了该连接的状态，通道一旦关闭，该连接便会断开。 通道的close()比较特殊，无论在通道时在阻塞模式下还是非阻塞模式下，由于close()方法的调用而导致底层I/O的关闭都可能会造成线程的暂时阻塞。在一个已关闭的通道上调用close()并没有任何意义，只会立即返回。 Channel的实战 对于Socket通道来说存在直接创建新Socket通道的方法，而对于文件通道来说，升级之后的FileInputStream、FileOutputStream和RandomAccessFile提供了getChannel()方法来获取通道。 FileChannelJava NIO中的FileChannel是一个连接到文件的通道，可以通过文件通道读写文件。文件通道总是阻塞式的，因此FileChannel无法设置为非阻塞模式。 文件读写(一). 文件写操作： 123456789101112131415161718192021public static void testWriteOnFileChannel() &#123; try &#123; RandomAccessFile randomAccess = new RandomAccessFile(\"D://test.txt\", \"rw\"); FileChannel fileChannel = randomAccess.getChannel(); byte[] bytes = new String(\"Java Non-blocking IO\").getBytes(); ByteBuffer byteBuffer = ByteBuffer.wrap(bytes); // 将缓冲区中的字节写入文件通道中 fileChannel.write(byteBuffer); // 强制将通道中未写入磁盘的数据立刻写入到磁盘 fileChannel.force(true); // 清空缓冲区，释放内存 byteBuffer.clear(); fileChannel.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; (二). 文件读操作： 12345678910111213141516171819202122232425public static void testReadOnFileChannel() &#123; try &#123; FileInputStream inputStream = new FileInputStream(new File(\"D://test.txt\")); FileChannel fileChannel = inputStream.getChannel(); ByteBuffer byteBuffer = ByteBuffer.allocate(10); // 不断地写入缓冲区，写一次读一次 while (fileChannel.read(byteBuffer) != -1) &#123; // 缓冲区从写模式切换为读模式 byteBuffer.flip(); // 开始读取 while (byteBuffer.hasRemaining()) &#123; // 一个字节一个字节地读取，并向后移动position地位置 System.out.print((char) byteBuffer.get()); &#125; // 缓冲区不会被自动覆盖，需要主动调用该方法(实际上还是覆盖) byteBuffer.clear(); &#125; fileChannel.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 文件读写测试：123456789public static void main(String[] args) &#123; System.out.println(\"Start to write\"); // 通过FileChannel写入数据 testWriteOnFileChannel(); System.out.println(\"Start to read\"); // 通过FileChannel读取数据 testReadOnFileChannel();&#125; 测试结果： transferFrom和transferTo(一). transferFrom()的使用 FileChannel的transferFrom()方法可以将数据从源通道传输到FileChannel中。下面是一个简单的例子： 12345678910111213141516public static void testTransferFrom()&#123; try &#123; RandomAccessFile fromFile = new RandomAccessFile(\"D://file1.txt\", \"rw\"); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile(\"D://file2.txt\", \"rw\"); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); toChannel.transferFrom(fromChannel, position, count); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; (二). transferTo()的使用 transferTo()方法将数据从FileChannel传输到目标channel中。下面是一个简单的例子： 123456789101112131415public static void testTransferTo() &#123; try &#123; RandomAccessFile fromFile = new RandomAccessFile(\"D://file1.txt\", \"rw\"); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile(\"D://file3.txt\", \"rw\"); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); fromChannel.transferTo(position, count, toChannel); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; ServerSocketChannelJava NIO中的ServerSocketChannel是一个可以监听新进来的TCP连接的通道。它类似ServerSocket，要注意的是和DatagramChannel和SocketChannel不同，ServerSocketChannel本身不具备传输数据的能力，而只是负责监听传入的连接和创建新的SocketChannel。 ServerSocketChannel的用法(一). 创建ServerSocketChannel 通过ServerSocketChannel.open()方法来创建一个新的ServerSocketChannel对象，该对象关联了一个未绑定ServerSocket的通道。通过调用该对象上的socket()方法可以获取与之关联的ServerSocket。 1ServerSocketChannel socketChannel = ServerSocketChannel.open(); (二). 为ServerSocketChannel绑定监听端口号 在JDK 1.7之前，ServerSocketChannel没有bind()方法，因此需要通过他关联的的socket对象的socket()来绑定。 12// JDK1.7之前serverSocketChannel.socket().bind(new InetSocketAddress(25000)); 从JDK1.7及以后，可以直接通过ServerSocketChannel的bind()方法来绑定端口号。 12// JDK1.7之后serverSocketChannel.bind(new InetSocketAddress(25000)); (三). 设置ServerSocketChannel的工作模式 ServerSocketChannel底层默认采用阻塞的工作模式，它提供了一个configureBlocking()方法，允许配置ServerSocketChannel以非阻塞方式运行。 12// 设置为非阻塞模式serverSocketChannel.configureBlocking(false); 进一步查看configureBlocking源码如下： 12345678910111213public final SelectableChannel configureBlocking(boolean block) throws IOException &#123; synchronized (regLock) &#123; if (!isOpen()) throw new ClosedChannelException(); if (blocking == block) return this; if (block &amp;&amp; haveValidKeys()) throw new IllegalBlockingModeException(); implConfigureBlocking(block); blocking = block; &#125; return this;&#125; Javadoc解释configureBlocking()方法用于调整底层通道的工作模式，即阻塞和非阻塞，默认是阻塞工作模式。 如果block设置为true，直接返回当前的阻塞式的通道；如果block设置为false，configureBlocking()方法会调用implConfigureBlocking()方法。这里implConfigureBlocking()是由ServerSocketChannelImpl实现，最终调用了IOUtil中的native方法configureBlocking()。 (四). 监听新进来的连接 通过ServerSocketChannel.accept()方法监听新进来的连接，这里需要根据configureBlocking()的配置区分两种工作模式的使用： 在阻塞模式下，当accept()方法返回的时候，它返回一个包含新连接的SocketChannel，否则accept()方法会一直阻塞到有新连接到达。 在非阻塞模式下，在没有新连接的情况下，accept()会立即返回null，该模式下通常不会仅仅监听一个连接，因此需在while循环中调用accept()方法. 阻塞模式： 123456while(true) &#123; SocketChannel socketChannel = serverSocketChannel.accept(); // 新连接没到达之前，后面的程序无法继续执行 InetSocketAddress remoteAddress = (InetSocketAddress) socketChannel.getRemoteAddress(); // 其他操作&#125; 非阻塞模式： 12345678while(true) &#123; SocketChannel socketChannel = serverSocketChannel.accept(); // 新连接没到达之前，后面程序一直循环，直到检测到socketChannel不为null时进入真正的执行逻辑 if(socketChannel != null) &#123; InetSocketAddress remoteAddress = (InetSocketAddress) socketChannel.getRemoteAddress(); // 其他操作 &#125;&#125; (五). 关闭ServerSocketChannel 通过调用ServerSocketChannel.close()方法来关闭ServerSocketChannel。 1serverSocketChannel.close(); ServerSocketChannel的完整示例(一). 阻塞模式 代码示例： 12345678910111213141516171819202122public static void blockingTest() throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.bind(new InetSocketAddress(25000)); System.out.println(\"ServerSocketChannel listening on 25000...\"); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); while(true) &#123; SocketChannel socketChannel = serverSocketChannel.accept(); InetSocketAddress remoteAddress = (InetSocketAddress) socketChannel.getRemoteAddress(); System.out.println(\"Remote address: \" + remoteAddress.getHostString()); while (socketChannel.read(byteBuffer) != -1) &#123; byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; System.out.print((char) byteBuffer.get()); &#125; byteBuffer.clear(); &#125; &#125;&#125; 运行结果： (二). 非阻塞模式 代码示例： 123456789101112131415161718192021222324public static void nonBlockingTest() throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.bind(new InetSocketAddress(25001)); System.out.println(\"ServerSocketChannel listening on 25001...\"); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); while (true) &#123; SocketChannel socketChannel = serverSocketChannel.accept(); System.out.println(\"SocketChannel： \" + socketChannel); if (socketChannel != null) &#123; InetSocketAddress remoteAddress = (InetSocketAddress) socketChannel.getRemoteAddress(); System.out.println(\"Remote address: \" + remoteAddress.getHostString()); while (socketChannel.read(byteBuffer) != -1) &#123; byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; System.out.print((char) byteBuffer.get()); &#125; byteBuffer.clear(); &#125; &#125; &#125;&#125; 运行结果： SocketChannelJava NIO中的SocketChannel是一个连接到TCP网络套接字的通道，它是Socket类的对等类。 通常SocketChannel在客户端向服务器发起连接请求，每个SocketChannel对象创建时都关联一个对等的Socket对象。同样SocketChannel也可以运行在非阻塞模式下。 SocketChannel的用法SocketChannel创建的方式有两种： 客户端主动创建：客户端打开一个SocketChannel并连接到某台服务器上； 服务端被动创建：一个新连接到达ServerSocketChannel时，服务端会创建一个SocketChannel。 (一). 创建SocketChannel 通过SocketChannel的静态方法open()创建SocketChannel对象。此时通道虽然打开，但并未建立连接。此时如果进行I/O操作会抛出NotYetConnectedException异常。 1SocketChannel socketChannel = SocketChannel.open(); (二). 连接指定服务器 通过SocketChannel对象的connect()连接指定地址。该通道一旦连接，将保持连接状态直到被关闭。可通过isConnected()来确定某个SocketChannel当前是否已连接。 阻塞模式： 如果在客户端的SocketChannel阻塞模式下，即服务器端的ServerSocketChannel也为阻塞模式： 123socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 25000));// connect()方法调用以后，socketChannel底层的连接创建完成后，才会执行后面的打印语句System.out.println(\"连接创建完成...\"); 非阻塞模式： 两点需要注意：其一，SocketChannel需要通过configureBlocking()设置为非阻塞模式；其二，非阻塞模式下，connect()方法调用后会异步返回，为了确定连接是否建立，需要调用finishConnect()的方法。 123456789socketChannel.configureBlocking(false);socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 25001));// connect()方法调用以后，异步返回，需要手动调用finishConnect确保连接创建while(!socketChannel.finishConnect())&#123; // 检测到还未创建成功则睡眠10ms TimeUnit.MILLISECONDS.sleep(10);&#125;System.out.println(\"连接创建完成...\"); (三). 从SocketChannel读数据 利用SocketChannel对象的read()方法将数据从SocketChannel读取到Buffer。 12345678910ByteBuffer byteBuffer = ByteBuffer.allocate(1024);// 非阻塞模式下，read()方法在尚未读取到任何数据时可能就返回了，所以需要关注它的int返回值。while (socketChannel.read(byteBuffer) != -1) &#123; byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; System.out.println((char) byteBuffer.get()); &#125; byteBuffer.clear();&#125; (四). 向SocketChannel写数据 利用SocketChannel对象的write()将Buffer的数据写入SocketChannel。 12345678910111213ByteBuffer byteBuffer = ByteBuffer.allocate(1024);byteBuffer.put(\"Client Blocking SocketChannel\".getBytes());// byteBuffer.put(\"Client Non-Blocking SocketChannel\".getBytes());byteBuffer.flip();// 非阻塞模式下，write()方法在尚未写出任何内容时可能就返回了。所以需要在循环中调用write()while (byteBuffer.hasRemaining()) &#123; socketChannel.write(byteBuffer);&#125;// 保持睡眠，观察控制台输出TimeUnit.SECONDS.sleep(20000);socketChannel.close(); (五). 关闭SocketChannel 利用SocketChannel对象的close()方法关闭SocketChannel。 1socketChannel.close(); SocketChannel的完整示例(一). 阻塞模式 代码示例： 123456789101112131415public static void blockingWrite() throws Exception &#123; SocketChannel socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 25000)); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); byteBuffer.put(\"Client Blocking SocketChannel\".getBytes()); byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; socketChannel.write(byteBuffer); &#125; TimeUnit.SECONDS.sleep(20000); socketChannel.close();&#125; 服务端打印结果： (一). 非阻塞模式 代码示例： 12345678910111213141516171819public static void nonBlockingWrite() throws Exception &#123; SocketChannel socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 25001)); while(!socketChannel.finishConnect())&#123; TimeUnit.MILLISECONDS.sleep(10); &#125; ByteBuffer byteBuffer = ByteBuffer.allocate(1024); byteBuffer.put(\"Client Non-Blocking SocketChannel\".getBytes()); byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; socketChannel.write(byteBuffer); &#125; TimeUnit.SECONDS.sleep(20000); socketChannel.close();&#125; 服务端打印结果： DatagramChannelJava NIO中的DatagramChannel是一个能收发UDP包的通道，其底层实现为DatagramSocket + Selector。DatagramChannel可以调用socket()方法获取对等DatagramSocket对象。DatagramChannel对象既可以充当服务端（监听者），也可以充当客户端（发送者）。如果需要新创建的通道负责监听，那么该通道必须绑定一个端口（或端口组）： DatagramChannel的完整示例数据报发送方： 123456public static void main(String[] args) throws Exception &#123; DatagramChannel datagramChannel = DatagramChannel.open(); ByteBuffer byteBuffer = ByteBuffer.wrap(\"DatagramChannel Sender\".getBytes()); int byteSent = datagramChannel.send(byteBuffer, new InetSocketAddress(\"127.0.0.1\", 50020)); System.out.println(\"Byte sent is: \" + byteSent);&#125; 数据报接收方： 123456789101112public static void main(String[] args) throws Exception &#123; DatagramChannel datagramChannel = DatagramChannel.open(); datagramChannel.socket().bind(new InetSocketAddress(50020)); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); datagramChannel.receive(byteBuffer); byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; System.out.print((char) byteBuffer.get()); &#125;&#125; 先运行DatagramChannelReceiveTest，再运行DatagramChannelSendTest，观察控制台输出： 数据报发送方： 数据报接收方： 工具类ChannelsNIO通道提供了一个便捷的通道类Channels，其中定义了几种静态的工厂方法以简化通道和流转换。其中常用的方法如下： 方法 返回 描述 newChannel(InputStream in) ReadableByteChannel 返回一个将从给定的输入流读取数据的通道。 newChannel(OutputStream out) WritableByteChannel 返回一个将向给定的输出流写入数据的通道。 newInputStream(ReadableByteChannel ch) InputStream 返回一个将从给定的通道读取字节的流。 newOutputStream(WritableByteChannel ch) OutputStream 返回一个将向给定的通道写入字节的流。 newReader(ReadableByteChannel ch, CharsetDecoder dec, int minBufferCap) Reader 返回一个reader，它将从给定的通道读取字节并依据提供的字符集名称对读取到的字节进行解码。 newReader(ReadableByteChannel ch, String csName) Reader 返回一个reader，它将从给定的通道读取字节并依据提供的字符集名称将读取到的字节解码成字符。 newWriter(WritableByteChannel ch, CharsetEncoder dec, int minBufferCap) Writer 返回一个writer，它将使用提供的字符集名称对字符编码并写到给定的通道中。 newWriter(WritableByteChannel ch, String csName) Writer 返回一个writer，它将依据提供的字符集名称对字符编码并写到给定的通道中。 总结本文针对NIO中的通道的做了详细的介绍，对于文件通道FileChannel，网络通道SocketChannel、ServerSocketChannel和DatagramChannel进行了实战演示。 篇幅较长，可见NIO提供的原生的通道API在使用上并不是太容易。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java编程进阶系列","slug":"Java编程进阶系列","permalink":"https://ostenant.coding.me/categories/Java编程进阶系列/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://ostenant.coding.me/tags/NIO/"}]},{"title":"Java NIO系列(二) - Buffer","slug":"Java NIO系列(二) - Buffer","date":"2017-12-26T13:41:00.000Z","updated":"2018-05-08T02:49:46.091Z","comments":true,"path":"2017/12/26/Java NIO系列(二) - Buffer/","link":"","permalink":"https://ostenant.coding.me/2017/12/26/Java NIO系列(二) - Buffer/","excerpt":"前言在Java NIO中，缓冲区用来临时存储数据，可以理解为是I/O操作中数据暂存的中转站。缓冲区直接为通道(Channel)服务，数据是从通道读入缓冲区，从缓冲区写入到通道中的。 缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问这块内存。","text":"前言在Java NIO中，缓冲区用来临时存储数据，可以理解为是I/O操作中数据暂存的中转站。缓冲区直接为通道(Channel)服务，数据是从通道读入缓冲区，从缓冲区写入到通道中的。 缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问这块内存。 正文Buffer的类型Java NIO提供以下几种Buffer类型： ByteBuffer MappedByteBuffer ShortBuffer LongBuffer FloatBuffer CharBuffer IntBuffer DoubleBuffer 这些Buffer类型代表了Java中7种基本数据类型。换句话说，就是可以通过byte、char、short、int、long、float或double类型来操作缓冲区中的数据。 Buffer的基本用法使用Buffer读写数据一般遵循以下四个步骤： 写入数据到Buffer中； 调用Buffer的flip()方法； 从Buffer中读取数据； 调用clear()方法或者compact()方法。 当向Buffer写入数据时，Buffer会记录下写了多少数据。一旦要读取数据，需要通过flip()方法将Buffer从写模式切换到读模式。在读模式下，可以读取之前写入到Buffer的所有数据。 一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。两种方式能清空缓冲区：调用clear()或compact()方法。 clear()方法：清空整个缓冲区，包括已读和未读的数据。 compact()方法：只会清空已读的数据，未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。 下面给出一个ByteBuffer的简单使用示例，其他缓冲区API的使用类似： 123456789101112131415161718192021222324public static void testReadFromBuffer() &#123; try &#123; RandomAccessFile file = new RandomAccessFile(\"D://test.txt\", \"rw\"); FileChannel fileChannel = file.getChannel(); //创建容量为10byte的buffer ByteBuffer byteBuffer = ByteBuffer.allocate(10); // 不断地写入缓冲区，写一次读一次 while (fileChannel.read(byteBuffer) != -1) &#123; // 设置buffer切换模式为读模式 byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; // 每次读取1byte，也就是一个字节 System.out.print((char) byteBuffer.get()); &#125; // 清空整个缓存区，准备下次写入 byteBuffer.clear(); &#125; fileChannel.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; Buffer的重要属性为了理解Buffer的工作原理，需要熟悉它的4个核心属性： 属性 含义 具体描述 capacity 容量 缓冲区可以容纳的最大数据量，在缓冲区创建时被设定并且不能改变 limit 上界 缓冲区中当前已使用的数据量 position 位置 缓冲区下一个要被读或写的元素的索引 mark 标记 调用mark()来设置mark=position，再调用reset()可以让position恢复到标记的位置即position=mark 其中，position和limit的含义取决于Buffer处在读模式还是写模式。不管Buffer处在什么模式，capacity的含义总是一样的。 capacity作为一个内存块，Buffer有一个固定的大小值，也叫capacity。你最多只能写入capacity个的byte、char、int、long等类型数据。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续往里写数据。 position 写入数据时： 当你写数据到Buffer中时，position表示下一个可写入的数据的位置。position的初始位置为0，当一个byte、char、int、long等数据写到Buffer后，position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。 读取数据时： 当从Buffer读取数据时，position表示下一个可读取的数据的位置。当将Buffer从写模式切换到读模式，position会被重置为0。当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。 limit 写入数据时： 在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。写模式下，limit等于Buffer的capacity，也就是内存块的最大容量。 写入数据时： 当切换Buffer到读模式时，limit会被设置成写模式下的position值，limit表示你最多能读到多少数据。limit被设置成已写数据的数量，这个值在写模式下就是position。 Buffer的方法Buffer的分配要想获得一个Buffer对象首先要进行分配，每一个Buffer类都有一个allocate()方法。下面是一个分配10字节capacity的ByteBuffer的例子： 1ByteBuffer buf = ByteBuffer.allocate(10); 这是分配一个可存储1024个字符的CharBuffer： 1CharBuffer buf = CharBuffer.allocate(1024); 向Buffer中写入数据写数据到Buffer有两种方式： 从Channel将数据写入Buffer。 1int bytesRead = channel.read(buffer); 通过Buffer的put()方法写到Buffer中。 1buffer.put(1); put()在ByteBuffer中为抽象方法，在ByteBuffer有很多的重载，由其子类HeapByteBuffer和DirectByteBuffer实现。 写模式切换为读模式flip()方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。 1buffer.flip(); 查看flip()方法的源码确认： 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; 从Buffer从读取数据从Buffer中读取数据也有两种方式： 从Buffer读取数据到Channel中。 1int bytesWritten = channel.write(buf); 通过Buffer的get()方法从Buffer中读取数据。 1byte b = buffer.get(); get()方法和put()一样有很多的重载，允许以不同的方式从Buffer中读取数据。例如：从指定position读取，或者从Buffer中读取数据到字节数组。 clear()和compact()方法一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。前面也说了，可以通过clear()或compact()方法来完成。 clear()方法如果调用的是clear()方法，position将被设回0，limit被设置成capacity的值。 1buffer.clear(); 查看clear()方法的源码确认： 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; 换句话说，Buffer被清空了。Buffer中的数据并未清除，只是这些标记告诉我们可以从哪里开始往Buffer里写数据。 compact()方法如果调用的是compact()方法，所有的未读数据都将被拷贝到Buffer的起始位置，position会设置为最后一个未读元素的后面。limit()方法和clear()方法一样，会被设置为capacity的大小。 查看compact()方法的实现，此方法在ByteBuffer中为抽象方法，查看其子类HeapByteBuffer的实现： 1234567891011public ByteBuffer compact() &#123; // 将未读的数据往前移动 System.arraycopy(hb, ix(position()), hb, ix(0), remaining()); // 设置postion为最后一个未读数据后面的位置 position(remaining()); // 设置limit为最大的容量 limit(capacity()); // 清除标记位 discardMark(); return this;&#125; 现在Buffer准备好写数据了，但是不会覆盖未读的数据。 mark()与reset()方法通过调用mark()方法，可以标记Buffer中的一个特定position。之后可以通过调用reset()方法恢复到这个position。例如： mark()方法1buffer.mark(); 查看mark()方法的源码，mark变量被设置为position的值： 1234public final Buffer mark() &#123; mark = position; return this;&#125; reset()方法1buffer.reset(); 查看mark()方法的源码，position变量被设置为之前的mark的值： 1234567public final Buffer reset() &#123; int m = mark; if (m &lt; 0) throw new InvalidMarkException(); position = m; return this;&#125; equals()与compareTo()方法可以使用equals()和compareTo()方法比较两个Buffer。 equals()方法当同时满足下列条件时，表示两个Buffer相等： 有相同的类型(byte、char、int和long类型等)。 Buffer中剩余的byte、char等元素的个数相等。 Buffer中所有剩余的byte、char等都相同。 equals()方法比较的实际是Buffer中的剩余元素是否相等。它只是比较Buffer的一部分，不是每一个在它里面的元素都比较。 compareTo()方法compareTo()方法比较两个Buffer的剩余元素(byte、char等)。当满足下列条件时，则认为一个Buffer小于另一个Buffer。 第一个不相等的元素小于另一个Buffer中对应的元素。 所有元素都相等，但第一个Buffer比另一个先耗尽(第一个Buffer的元素个数比另一个少)。 总结这里只是对Buffer进行了入门的介绍，具体深入学习还需要查看各种缓冲区以及相关的具体实现。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java编程进阶系列","slug":"Java编程进阶系列","permalink":"https://ostenant.coding.me/categories/Java编程进阶系列/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://ostenant.coding.me/tags/NIO/"}]},{"title":"一天一个设计模式(五) - 适配器模式(Adapter)","slug":"一天一个设计模式(五) - 适配器模式(Adapter)","date":"2017-12-25T12:46:00.000Z","updated":"2018-05-08T02:49:46.094Z","comments":true,"path":"2017/12/25/一天一个设计模式(五) - 适配器模式(Adapter)/","link":"","permalink":"https://ostenant.coding.me/2017/12/25/一天一个设计模式(五) - 适配器模式(Adapter)/","excerpt":"前言适配器模式把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。","text":"前言适配器模式把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。 适配器模式的用途最经典的就是电器的例子，笔记本电脑的插头一般都是三相的，即除了阳极、阴极之外，还有一个地极。而有些地方的电源插座却只有两极，没有地极。电源插座与笔记本电脑的电源插头不匹配使得笔记本电脑无法使用。这时候一个三相到两相的转换器（适配器）就能解决此问题，而这正像是本模式所做的事情。 适配器模式的形式适配器模式有类的适配器模式和对象的适配器模式两种不同的形式。 正文类的适配器模式类的适配器模式，简单来说，就是适配的类的API转换成为目标接口的API。 从上图可以看出，Adaptee类并没有sampleOperation2()方法，而客户端则期待这个方法。 为了使客户端能够使用Adaptee类，提供一个中间环节，即类Adapter，把Adaptee类的API同Target接口的API衔接起来。Adapter与Adaptee是继承关系，这决定了这个适配器模式是类的适配器模式。 相关角色 目标(Target)角色：这就是所期待得到的接口。注意：由于这里讨论的是类适配器模式，因此目标不可以是类。 源(Adaptee)角色：现在需要适配的到目标角色的类。 适配器(Adapter)角色：适配器是目标角色和源角色之间的桥梁。适配器把源角色的类转换成目标接口的实现。 示例代码Target.java 1234567891011public interface Target &#123; /** * 这是源类Adaptee中也有的方法 */ public void sampleOperation1(); /** * 这是源类Adaptee中没有的方法 */ public void sampleOperation2();&#125; 上面给出的是目标角色的接口代码，这个角色是以一个接口的形式实现的。可以看出，这个接口声明了两个方法：sampleOperation1()和sampleOperation2()，而源角色Adaptee是一个具体类，它有一个sampleOperation1()方法，但是没有sampleOperation2()方法。 Adaptee.java 12345public class Adaptee &#123; public void sampleOperation1() &#123; System.out.println(\"Operation 1st\"); &#125;&#125; 适配器角色Adapter拓展了Adaptee，同时又实现了目标角色Target接口。由于Adaptee没有提供sampleOperation2()方法，而目标接口有要求这个方法，因此适配器角色Adapter实现了这个方法。 Adapter.java 123456public class Adapter extends Adaptee implements Target &#123; @Override public void sampleOperation2() &#123; System.out.println(\"Operation 2nd\"); &#125;&#125; 对象的适配器模式与类的适配器模式一样，对象的适配器模式把被适配类的API转换成为目标类的API。 与类的适配器模式不同的是，对象的适配器模式不是使用继承关系链接到Adaptee类，而是使用委派关系连接到Adaptee类。 从上图可以看出，Adaptee类并没有sampleOperation2()方法，而客户端则期待这个方法。 为使客户端能够使用Adaptee类，需要提供一个包装Wrapper类Adapter。这个包装类包括了一个Adaptee的实例，从而此包装类能够把Adaptee的API与Target类的API衔接起来。Adapter类与Adaptee类是委派关系，这决定了适配器模式是对象的。 相关角色 目标(Target)角色：这就是所期待得到的接口。注意：由于这里讨论的是类适配器模式，因此目标不可以是类。 源(Adaptee)角色：现在需要适配的到目标角色的类。 适配器(Adapter)角色：适配器是目标角色和源角色之间的桥梁。适配器把源角色的类包装到目标接口的实现中。 示例代码Target.java 1234567891011public interface Target &#123; /** * 这是源类Adaptee中也有的方法 */ public void sampleOperation1(); /** * 这是源类Adaptee中没有的方法 */ public void sampleOperation2();&#125; 上面给出的是目标角色的接口代码，这个角色是以一个接口的形式实现的。可以看出，这个接口声明了两个方法：sampleOperation1()和sampleOperation2()，而源角色Adaptee是一个具体类，它有一个sampleOperation1()方法，但是没有sampleOperation2()方法。 Adaptee.java 12345public class Adaptee &#123; public void sampleOperation1() &#123; System.out.println(\"Operation 1st\"); &#125;&#125; 在对象的适配器模式中，适配器角色中持有一个对源角色的引用，并在需要适配的方法中使用源角色的方法实现。 Adapter.java 1234567891011121314151617181920212223public class Adapter &#123; private Adaptee adaptee; public Adapter (Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; /** * 源类Adaptee有方法sampleOperation1 * 因此适配器可以直接进行委派 */ public void sampleOperation1() &#123; this.adaptee.sampleOperation1(); &#125; /** * 源类Adaptee没有方法sampleOperation2 * 因此适配器需要自己实现此方法 */ public void sampleOperation2() &#123; System.out.println(\"Operation 2nd\"); &#125;&#125; 两种适配器模式的对比类的适配器模式 使用对象继承的方式，是静态的定义方式。 由于适配器直接继承了Adaptee，使得适配器不能和Adaptee的子类一起工作。因为继承是静态的关系，而适配器继承了Adaptee后，就不可能再去处理Adaptee的子类了。 适配器可以重定义Adaptee的部分行为，相当于子类覆盖父类的部分实现方法。 不需要额外的引用过来间接得到Adaptee。 对象的适配器模式 使用对象组合的方式，是动态的组合方式。 一个适配器可以把多种不同的适配源适配到同一个目标类上。换言之，同一个适配器可以把源类和它的子类都适配到目标接口。因为对象适配器采用的是对象组合的关系，只要对象类型正确，是不是子类都无所谓。 要重定义Adaptee的行为比较困难，这种情况下，需要定义Adaptee的子类来实现重定义，然后让适配器组合子类。这样，虽然增加了一定的复杂性，也提供了一定的灵活性。 需要额外的引用来间接得到Adaptee。 建议尽量使用对象适配器的实现方式，多用合成/聚合，少用继承。当然，具体问题还是需要具体分析，根据需要来选用实现方式，最适合的才是最好的。 总结适配器模式的优点 更好的复用性 系统需要使用现有的类，因此类的接口不符合系统的需要。那么通过适配器模式就可以让这些功能得到更好的复用。 更好的拓展性 在实现适配器功能的时候，可以调用自己开发的功能，从而自然的拓展系统的功能。 适配器模式的缺点过多的使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是A接口，其实内部都被适配成了B接口的实现。一个系统如果太多的出现这种情况，无异于异常灾难。 因此如果不是很有必要，可以不是用适配器，而是直接对系统进行重构。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA设计模式系列","slug":"JAVA设计模式系列","permalink":"https://ostenant.coding.me/categories/JAVA设计模式系列/"}],"tags":[{"name":"Adapter","slug":"Adapter","permalink":"https://ostenant.coding.me/tags/Adapter/"}]},{"title":"一天一个设计模式(四) - 原型模式(Prototype)","slug":"一天一个设计模式(四) - 原型模式(Prototype)","date":"2017-12-21T08:22:00.000Z","updated":"2018-05-08T02:49:46.094Z","comments":true,"path":"2017/12/21/一天一个设计模式(四) - 原型模式(Prototype)/","link":"","permalink":"https://ostenant.coding.me/2017/12/21/一天一个设计模式(四) - 原型模式(Prototype)/","excerpt":"前言原型模式属于对象的创建模式。通过给出一个原型对象来指明所有创建的对象的类型，然后用这个原型对象提供的复制办法创建出更多同类型的对象。","text":"前言原型模式属于对象的创建模式。通过给出一个原型对象来指明所有创建的对象的类型，然后用这个原型对象提供的复制办法创建出更多同类型的对象。 原型模式的结构原型模式要求对象实现一个可以克隆自身的接口(类型)。这样一来，通过原型实例创建新的对象，就不需要关心这个实例本身的类型，只需要实现克隆自身的方法，也而无需再去通过new来创建。 原型类型的表现形式 简单形式 登记形式 正文简单形式 相关角色 客户(Client)角色：客户类提出创建对象的请求； 抽象原型(Prototype)角色：这是一个抽象角色，通常由一个Java接口或者Java抽象类实现。此角色定义了的具体原型类所需的实现的方法。 具体原型(Concrete Prototype)角色：此角色需要实现抽象原型角色要求的克隆相关的接口。 示例代码Prototype.java 123456789101112131415161718192021222324/** * 抽象原型角色 */public abstract class Prototype &#123; private String id; public Prototype(String id) &#123; this.id = id; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; /** * 克隆自身的方法 * @return 一个从自身克隆出来的对象。 */ public abstract Prototype clone();&#125; ConcretePrototype1.java 12345678910public class ConcretePrototype1 extends Prototype &#123; public ConcretePrototype1(String id) &#123; super(id); &#125; public Prototype clone() &#123; Prototype prototype = new ConcretePrototype1(this.getId()); return prototype; &#125;&#125; ConcretePrototype2.java 12345678910public class ConcretePrototype2 extends Prototype &#123; public ConcretePrototype2(String id) &#123; super(id); &#125; public Prototype clone() &#123; Prototype prototype = new ConcretePrototype2(this.getId()); return prototype; &#125;&#125; 运行结果 登记形式 相关角色 客户(Client)角色：客户类提出创建对象的请求； 抽象原型(Prototype)角色：这是一个抽象角色，通常由一个Java接口或者Java抽象类实现。此角色定义了的具体原型类所需的实现的方法。 具体原型(Concrete Prototype)角色：此角色需要实现抽象原型角色要求的克隆相关的接口。 原型管理器(Prototype Manager)角色：提供各种原型对象的创建和管理。 示例代码除了原型管理器Prototype Manager以外，登记模式和简单模式并无其他差异。 Prototype.javaW12345public interface Prototype &#123; public Prototype clone(); public String getName(); public void setName(String name);&#125; ConcretePrototype1.java1234567891011121314151617181920212223242526public class ConcretePrototype1 implements Prototype &#123; private String name; @Override public String getName() &#123; return this.name; &#125; @Override public void setName(String name) &#123; this.name = name; &#125; @Override public Prototype clone() &#123; Prototype prototype = new ConcretePrototype1(); prototype.setName(this.name); return prototype; &#125; @Override public String toString() &#123; return \"ConcretePrototype1 [name=\" + name + \"]\"; &#125;&#125; ConcretePrototype2.java12345678910111213141516171819202122232425public class ConcretePrototype2 implements Prototype &#123; private String name; @Override public String getName() &#123; return this.name; &#125; @Override public void setName(String name) &#123; this.name = name; &#125; @Override public Prototype clone() &#123; Prototype prototype = new ConcretePrototype2(); prototype.setName(this.name); return prototype; &#125; @Override public String toString() &#123; return \"ConcretePrototype2 [name=\" + name + \"]\"; &#125;&#125; PrototypeManager.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class PrototypeManager &#123; /** * 用来记录原型的编号同原型实例的对象关系 */ private static Map&lt;String, Prototype&gt; map = new HashMap&lt;&gt;(); /** * 私有化构造方法，避免从外部创建实例 */ private PrototypeManager() &#123; &#125; /** * 向原型管理器里面添加或者修改原型实例 * * @param prototypeId 原型编号 * @param prototype 原型实例 */ public static void setProtoType(String prototypeId, Prototype prototype) &#123; map.put(prototypeId, prototype); &#125; /** * 根据原型编号从原型管理器里面移除原型实例 * * @param prototypeId 原型编号 */ public static void removePrototype(String prototypeId) &#123; map.remove(prototypeId); &#125; /** * 根据原型编号获取原型实例 * * @param prototypeId 原型编号 * @return 原型实例对象 * @throws Exception 如果根据原型编号无法获取对应实例，则提示异常“您希望获取的原型还没有注册或已被销毁” */ public static Prototype getPrototype(String prototypeId) throws Exception &#123; Prototype prototype = map.get(prototypeId); if (prototype == null) &#123; throw new Exception(\"您希望获取的原型还没有注册或已被销毁\"); &#125; return prototype; &#125;&#125; Client.java12345678910111213141516171819202122232425262728293031323334public class Client &#123; public static void main(String[] args) &#123; try &#123; // 创建第一个实例 Prototype p1 = new ConcretePrototype1(); // 注册第一个实例 PrototypeManager.setProtoType(\"p1\", p1); // 克隆第一个实例的原型 Prototype p3 = PrototypeManager.getPrototype(\"p1\").clone(); p3.setName(\"张三\"); System.out.println(\"第一个实例的副本：\" + p3); // 创建第二个实例 Prototype p2 = new ConcretePrototype2(); // 注册第二个实例 PrototypeManager.setProtoType(\"p2\", p2); // 克隆第二个实例的原型 Prototype p4 = PrototypeManager.getPrototype(\"p2\").clone(); p4.setName(\"李四\"); System.out.println(\"第二个实例的副本：\" + p4); // 注销第一个实例 PrototypeManager.removePrototype(\"p1\"); // 再次克隆第一个实例的原型 Prototype p5 = PrototypeManager.getPrototype(\"p1\").clone(); p5.setName(\"王五\"); System.out.println(\"第一个实例的副本：\" + p5); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果 两者之间的比较简单形式和登记形式的原型模式各有其长处和短处。 如果要创建的原型对象数据较少而且比较固定的话，可以采用第一种形式。在这种情况下，原型对象的引用可以由客户端自己保存。 如果要创建的原型对象数据不固定的话，可以采用第二种形式。在这种情况下，客户端不保存对原型对象的引用，这个任务被交给原型管理器角色。在克隆一个对象之前，客户端可以查看管理员对象是否已经有一个满足要求的原型对象。如果有，可以从原型管理器角色中取得这个对象引用；如果没有，客户端就需要自行复制此原型对象。 总结原型模式的优点原型模式允许在运行时动态改变具体的实现类型。原型模式可以在运行期间，有客户来注册符合原型接口的实现类型，也可以动态的改变具体的实现类型，看起来接口没有任何变化，但是其实运行的已经是另外一个类实体了。因为克隆一个原型对象就类似于实例化一个类。 原型模式的缺点原型模式最主要的缺点是每一个类都必须要配备一个克隆方法。配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类来说并不是很难，但是对于已有的类来说并不容易。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA设计模式系列","slug":"JAVA设计模式系列","permalink":"https://ostenant.coding.me/categories/JAVA设计模式系列/"}],"tags":[{"name":"Prototype","slug":"Prototype","permalink":"https://ostenant.coding.me/tags/Prototype/"}]},{"title":"一天一个设计模式(三) - 建造者模式(Builder)","slug":"一天一个设计模式(三) - Builder建造者模式","date":"2017-12-19T09:20:00.000Z","updated":"2018-05-08T02:49:46.093Z","comments":true,"path":"2017/12/19/一天一个设计模式(三) - Builder建造者模式/","link":"","permalink":"https://ostenant.coding.me/2017/12/19/一天一个设计模式(三) - Builder建造者模式/","excerpt":"前言建造模式是对象的创建模式。建造模式可以将一个产品的内部表象(internal representation)与产品的生产过程分割开来，从而可以使一个建造过程生成具有不同的内部表象的产品对象。","text":"前言建造模式是对象的创建模式。建造模式可以将一个产品的内部表象(internal representation)与产品的生产过程分割开来，从而可以使一个建造过程生成具有不同的内部表象的产品对象。 (一). 产品的内部表象一个产品常有不同的组成成分作为产品的零件，这些零件有可能是对象，也有可能不是对象，他们通常又称为产品的内部表象(internal representation)。 (二). 对象性质的建造有些情况下，一个对象会有些重要的性质，在它们没有正确赋值之前，对象不能作为一个完整的产品使用。比如：一个电子邮件有发件人地址、收件人地址、主题、内容、附件等部分，而在最基本的发件人地址得到赋值之前，这个电子邮件是不可以发送的。 有些情况下，一个对象的有些性质必须按照某个顺序赋值才有意义。在某个性质没有赋值之前，另一个性质则无法赋值。 这些情况使得性质本身的建造设计到复杂的业务逻辑。设置后，此对象相当于一个有待建造的产品，而对象的这些性质相当于产品的零件，建造产品的过程是建造零件的过程。 由于建造零件的过程很复杂，因此，这些零件的建造过程往往被外部化到另一个成为建造者的对象中，建造者对象返还给客户端的是一个全部零件都建造完毕的产品对象。 建造模式利用一个导演者对象和具体建造者对象一个个的建造出所有的零件，从而建造出完整的产品对象。建造者模式将产品的结构和产品的零件的建造过程对客户端隐藏起来，把对建造过程进行指挥的责任和具体建造者零件的责任分割开来，达到责任划分和封装的目的。 正文建造模式的结构 在这个示意的系统里，最终产品Product只有两个零件，即part1和part2。相应的构造方法也有两个，即buildPart1()和buildPart2()。 同时可以看出本模式涉及到四个角色，它们分别为： 抽象建造者(Builder)：给出一个抽象接口，以规范产品对象的各个组成成分的建造。模式中真正创建产品对象的是具体建造者ConcreteBuilder角色。 具体建造者类必须实现这个接口要求的两种方法： 一种是产品具体零件建造方法：buildPart1()和buildPart2()； 另一种是返回构造完成的产品的方法retrieveResult()。 一般来说，产品所包含的零件数目与建造方法的数目相符。换言之，有多少零件需要建造，就会有多少相应的建造方法。 具体建造者(ContreteBuilder)：担任这个角色的是抽象建造者在具体业务场景的下的建造实现。这个角色要完成的任务包括： 实现抽象建造者Builder所声明的接口，给出一步步完成创建产品实例的操作。 在建造过程完成后，提供产品的实例。 导演者(Director)：担任这个角色的类调用具体建造者角色以创建产品对象。应当指出的是，导演者角色并没有产品类的具体知识，真正拥有产品类的具体知识的是具体建造者角色。 产品(Product)：产品便是建造中的复杂对象，一般来说，一个系统中会有多于一个的产品类，而且这些产品类并不一定有共同的接口，而完全可以是不相关联的。 建造模式的示例代码Product.java12345678910111213141516171819202122232425public class Product &#123; /** * 产品零件 */ private String part1; private String part2; public String getPart1() &#123; return part1; &#125; public void setPart1(String part1) &#123; this.part1 = part1; &#125; public String getPart2() &#123; return part2; &#125; public void setPart2(String part2) &#123; this.part2 = part2; &#125; @Override public String toString() &#123; return \"Product [part1=\" + part1 + \", part2=\" + part2 + \"]\"; &#125;&#125; Builder.java 1234567891011/** * 抽象建造者角色 * * 提供零件建造方法及返回结果方法 */public interface Builder &#123; void buildPart1(); void buildPart2(); Product retrieveResult();&#125; ConcreteBuilder.java 123456789101112131415161718192021222324252627282930313233/** * 具体建造者角色 */public class ConcreteBuilder implements Builder &#123; private Product product = new Product(); /** * 建造零件1 */ @Override public void buildPart1() &#123; product.setPart1(\"零件分类1，编号：10000\"); &#125; /** * 建造零件2 */ @Override public void buildPart2() &#123; product.setPart2(\"零件分类2，编号：20000\"); &#125; /** * 返回建造后成功的产品 * @return */ @Override public Product retrieveResult() &#123; return product; &#125;&#125; Director.java 123456789101112131415161718192021222324252627/** * 导演者角色 */public class Director &#123; /** * 创建建造者对象 */ private Builder builder; /** * 构造函数，给定建造者对象 * @param builder 建造者对象 */ public Director(Builder builder) &#123; this.builder = builder; &#125; /** * 产品构造方法，在该方法内，调用产品零件建造方法。 */ public Product construct()&#123; builder.buildPart1(); builder.buildPart2(); // 返回builder建造完成的产品对象 return builder.construct(); &#125;&#125; Client.java 1234567891011public class Client &#123; public static void main(String[] args) &#123; //创建具体建造者对象 Builder builder = new ConcreteBuilder(); //创造导演者角色，给定建造者对象 Director director = new Director(builder); //调用导演者角色，创建产品零件。并返回产品建造结果。 Product product = director.construct(); System.out.println(product); &#125;&#125; 上述代码完成的具体步骤： 客户端创建具体建造者对象； 将具体建造者对象交给导演者； 导演者操作建造者对象建造产品零件； 当产品创建完成后，导演者将产品返回给客户端。 建造者模式构建复杂对象考虑这样一个实际业务应用，要创建一个保险合同的对象，里面很多属性的值都有约束，要求创建出来的对象是满足这些约束规则的。 约束规则如下： 保险合同通常情况下可以和个人签订，也可以和某个公司签订个，但是一份保险合同不能同时和个人和公司签订。这个对象里有很多类似于这样的约束，采用建造者模式来构建复杂的对象，通常会对建造者模式进行一定的简化，因为目标明确，就是创建某个复杂对象，因此做适当的简化会使得程序更简介。 具体实现思路如下： 由于是用Builder建造者模式来创建某个对象，因此就没有必要再定义一个Builder接口，直接提供一个具体的建造类就可以了。 对于创建一个复杂的对象，可能会有很多种不同的选择和步骤，干脆去掉导演者Director，把导演者的功能和Client客户端的功能合并起来，也就是说Client客户端的功能就相当于导演者，它来指导建造者去构建需要的复杂对象。 于是，建造者(Builder)可以抽象到目标产品(Product)的内部，这样最大的好处对外屏蔽掉具体的建造实现，是示例代码如下： InstranceContract.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125/** * 保险合同编号 */public class InstranceContract &#123; /** * 保险合同编号 */ private String contractId; /** * 受保人名称，此处因为有限制条件：要么同个人签订，要么同公司签订 * 也就是说，受保人名称属性同受保公司名称属性不能同时有值。 */ private String personName; /** * 受保公司名称 */ private String companyName; /** * 开始时间 */ private long beginDate; /** * 结束时间，需要大于开始时间 */ private long endDate; /** * 其他数据 */ private String otherData; private InstranceContract(ConcreteBuilder builder)&#123; this.contractId = builder.contractId; this.personName = builder.personName; this.companyName = builder.companyName; this.beginDate = builder.beginDate; this.endDate = builder.endDate; this.otherData = builder.otherData; &#125; /** * 保险合同的一些操作 */ public void someOperation()&#123; System.out.println(\"当前正在操作的保险合同编号为【\"+this.contractId+\"】\"); System.out.println(this); &#125; @Override public String toString() &#123; return \"InstranceContract [contractId=\" + contractId + \", personName=\" + personName + \", companyName=\"+ companyName + \", beginDate=\" + beginDate + \", endDate=\" + endDate + \", otherData=\" + otherData + \"]\"; &#125; public static class ConcreteBuilder &#123; private String contractId; private String personName; private String companyName; private long beginDate; private long endDate; private String otherData; /** * 构造方法 * @param contractId 保险合同编号 * @param beginDate 生效时间 * @param endDate 失效时间 */ public ConcreteBuilder(String contractId, long beginDate, long endDate) &#123; this.contractId = contractId; this.beginDate = beginDate; this.endDate = endDate; &#125; public ConcreteBuilder setPersonName(String personName) &#123; this.personName = personName; return this; &#125; public ConcreteBuilder setCompanyName(String companyName) &#123; this.companyName = companyName; return this; &#125; public ConcreteBuilder setOtherData(String otherData) &#123; this.otherData = otherData; return this; &#125; public InstranceContract build() &#123; if (contractId == null || contractId.trim().length() == 0) &#123; throw new IllegalArgumentException(\"合同编号不能为空\"); &#125; boolean signPerson = (personName != null &amp;&amp; personName.trim().length() &gt; 0); boolean signCompany = (companyName != null &amp;&amp; companyName.trim().length() &gt; 0); if (signPerson &amp;&amp; signCompany) &#123; throw new IllegalArgumentException(\"一份保险合同不能同时与个人和公司签订\"); &#125; if (!signPerson &amp;&amp; !signCompany) &#123; throw new IllegalArgumentException(\"一份保险合同不能没有签订对象\"); &#125; if (beginDate &lt;= 0) &#123; throw new IllegalArgumentException(\"一份保险合同必须有生效的日期\"); &#125; if (endDate &lt;= 0) &#123; throw new IllegalArgumentException(\"一份保险合同必须有失效的日期\"); &#125; if (endDate &lt;= beginDate) &#123; throw new IllegalArgumentException(\"一份保险合同的失效日期必须要大于生效的日期\"); &#125; return new InstranceContract(this); &#125; &#125;&#125; 客户端(Client)、导演者(Director)合并到一个类上面，如下： 123456789101112public class Client &#123; public static void main(String[] args) &#123; InstranceContract.ConcreteBuilder builder = new InstranceContract.ConcreteBuilder(\"8888\", 1233L, 2253L); // 导演者进行组装 InstranceContract contract = builder.setPersonName(\"赵四\").setOtherData(\"测试数据\").build(); contract.someOperation(); &#125;&#125; 总结建造者模式主要适用于如下的业务场景： 内部结构复杂： 需要生成的产品对象有复杂的内部结构，每一个内部组件本身也可以是复杂对象，也可以仅仅是一个简单的组成部分。 属性顺序和依赖： 需要生成的产品对象的属性相互依赖。建造模式可以强制实行一种分步骤顺序进行的建造过程。因此，如果产品对象的一个属性必须在另外一个属性赋值之后才可以被赋值，那么，使用建造者模式是一个很好的设计思想。 属性获取过程复杂： 在对象创建过程中会使用到系统中的一些其他对象，这些对象在产品对象的创建过程中不易得到。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA设计模式系列","slug":"JAVA设计模式系列","permalink":"https://ostenant.coding.me/categories/JAVA设计模式系列/"}],"tags":[{"name":"Builder","slug":"Builder","permalink":"https://ostenant.coding.me/tags/Builder/"}]},{"title":"Java NIO系列(一) - 概述","slug":"Java NIO系列(一) - 概述","date":"2017-12-19T03:23:00.000Z","updated":"2018-05-08T02:49:46.091Z","comments":true,"path":"2017/12/19/Java NIO系列(一) - 概述/","link":"","permalink":"https://ostenant.coding.me/2017/12/19/Java NIO系列(一) - 概述/","excerpt":"前言Java NIO全称java non-blocking IO，是指jdk1.4及以上版本里提供的新api(New IO)，为所有的原始类型(boolean类型除外)提供缓存支持的数据容器，使用它可以提供非阻塞式的高伸缩性网络。","text":"前言Java NIO全称java non-blocking IO，是指jdk1.4及以上版本里提供的新api(New IO)，为所有的原始类型(boolean类型除外)提供缓存支持的数据容器，使用它可以提供非阻塞式的高伸缩性网络。 Java NIO提供了与标准IO不同的IO工作方式，Channel、Buffer和Selector构成了核心的API。其它组件，如Pipe和FileLock，只不过是与三个核心组件共同使用的工具类。 通道和缓冲区 (Channel and Buffer)： 标准的IO基于字节流和字符流进行单向的数据读写操作。而NIO是基于通道(Channel)和缓冲区(Buffer)进行操作，数据总是从通道中读取到缓冲区中，或者从缓冲区中写入到通道中。 异步IO (Asynchronous IO)： Java NIO可以让你异步的使用IO，例如：当线程从通道读取数据到缓冲区时，线程还是可以进行其他事情；当数据被线程写入到缓冲区时，线程可以继续处理它。从缓冲区写入通道也类似。 选择器 (Selector)： Java NIO引入了选择器的概念，选择器用于监听多个通道的事件（比如：连接打开，数据读取和数据写入）。因此，单个的线程可以监听多个数据通道。 下面就来详细介绍Java NIO的相关知识。 正文1. Java NIO概述Java NIO由以下几个核心部分组成： Channel Buffer Selector 1.1. Channel和Buffer基本上，所有的IO 在NIO中都从一个Channel`开始： 通道Channel有点像流(Stream)，两者可以做个简单对比： 流是单向的，一个流对象要么是输出流、要么是输入流。 通道是全双工的，一个通道通常搭配缓存一起使用。数据可以从Channel读到Buffer中，也可以从Buffer写到Channel中。 这里有个图示： Channel和Buffer`有好几种类型。 JAVA NIO中的一些主要Channel的实现，主要涵盖了文件IO和UDP、TCP的网络IO： FileChannel：从文件中读写数据 ServerSocketChannel：能通过UDP读写网络中的数据 SocketChannel：能通过TCP读写网络中的数据 DatagramChannel：可以监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。 JAVA NIO中关键的Buffer实现，涵盖了除boolean的其余7种基本数据类型(byte、short、int、long、float、double 和 char)： ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 1.2. SelectorSelector允许单线程处理多个Channel的连接事件和数据读写。如果你的应用打开了多个连接（通道），但每个连接的流量都很低，使用Selector就会很方便，例如：一个聊天服务器。 这是在一个单线程中使用一个Selector处理3个Channel的图示： 要使用Selector，得向Selector注册Channel，然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件。 事件类型主要包括：新连接进来、数据接收、数据发送等。 2. Java NIO对比IO上面提到了NIO主要的组件和特性，在实际的IO操作中，应该如何在标准IO和NIO进行选择，这里就需要具体对比两者的差异，并引入一些概念。 IO NIO 底层读写实现 面向流读写 面向缓冲区读写 是否有选择器 无 基于选择器的事件分离 IO是否阻塞 阻塞式IO 非阻塞式IO 2.1. 底层读写实现Java NIO和IO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 面向流 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 面向缓冲区 Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。 2.2. 是否有选择器Java NIO的选择器允许一个单独的线程来监视多个输入通道。 IO的读写速度和CPU的处理速度相差了一个数量级，导致IO事件延长了CPU的空闲等待时间，导致性能上的瓶颈。为了尽量的缩短CPU的等待时间，在单个IO操作进行时CPU可以抽出身来去做别的事情(其他IO)，NIO引入单线程处理多IO事件的概念，从而充分利用CPU分配的资源。 Java NIO允许已注册的多个通道使用一个选择器，然后使用一个单独的线程来选择通道。这种选择机制，使得一个单线程很容易地管理多个通道。 2.3. IO是否阻塞所谓阻塞，就是线程在进行IO操作时，不能抽出身来去干其他事情，必须等待数据读写完成。 Java IO的各种流是阻塞的。 当一个线程调用read()或write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情。 Java NIO的非阻塞的。 当监听某个通道的读操作事件时，线程向该通道发送请求读取数据，之后这个线程就可以去干别的事情。 当监听某个通道的写操作事件时，线程向请求向该通道写入数据，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道(channel)。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA编程进阶系列","slug":"JAVA编程进阶系列","permalink":"https://ostenant.coding.me/categories/JAVA编程进阶系列/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"},{"name":"NIO","slug":"NIO","permalink":"https://ostenant.coding.me/tags/NIO/"}]},{"title":"Java基础篇 - 强引用、弱引用、软引用和虚引用","slug":"Java基础篇 - 强引用、弱引用、软引用和虚引用","date":"2017-12-18T07:38:00.000Z","updated":"2018-05-08T02:49:46.092Z","comments":true,"path":"2017/12/18/Java基础篇 - 强引用、弱引用、软引用和虚引用/","link":"","permalink":"https://ostenant.coding.me/2017/12/18/Java基础篇 - 强引用、弱引用、软引用和虚引用/","excerpt":"前言Java执行GC判断对象是否存活有两种方式其中一种是引用计数。","text":"前言Java执行GC判断对象是否存活有两种方式其中一种是引用计数。 引用计数：Java堆中每一个对象都有一个引用计数属性，引用每新增1次计数加1，引用每释放1次计数减1。 在JDK 1.2以前的版本中，若一个对象不被任何变量引用，那么程序就无法再使用这个对象。也就是说，只有对象处于(reachable)可达状态，程序才能使用它。 从JDK 1.2版本开始，对象的引用被划分为4种级别，从而使程序能更加灵活地控制对象的生命周期。这4种级别由高到低依次为：强引用、软引用、弱引用和虚引用。 正文(一) 强引用(StrongReference)强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。如下： 1Object strongReference = new Object(); 当内存空间不足时，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。如果强引用对象不使用时，需要弱化从而使GC能够回收，如下： 1strongReference = null; 显式地设置strongReference对象为null，或让其超出对象的生命周期范围，则gc认为该对象不存在引用，这时就可以回收这个对象。具体什么时候收集这要取决于GC算法。 1234public void test() &#123; Object strongReference = new Object(); // 省略其他操作&#125; 在一个方法的内部有一个强引用，这个引用保存在Java栈中，而真正的引用内容(Object)保存在Java堆中。当这个方法运行完成后，就会退出方法栈，则引用对象的引用数为0，这个对象会被回收。 但是如果这个strongReference是全局变量时，就需要在不用这个对象时赋值为null，因为强引用不会被垃圾回收。 ArrayList的Clear方法： 在ArrayList类中定义了一个elementData数组，在调用clear方法清空数组时，每个数组元素被赋值为null。不同于elementData=null，强引用仍然存在，避免在后续调用add()等方法添加元素时进行内存的重新分配。使用如clear()方法内存数组中存放的引用类型进行内存释放特别适用，这样就可以及时释放内存。 (二) 软引用(SoftReference)如果一个对象只具有软引用，则内存空间充足时，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。 软引用可用来实现内存敏感的高速缓存。 12345// 强引用String strongReference = new String(\"abc\");// 软引用String str = new String(\"abc\");SoftReference&lt;String&gt; softReference = new SoftReference&lt;String&gt;(str); 软引用可以和一个引用队列(ReferenceQueue)联合使用。如果软引用所引用对象被垃圾回收，JAVA虚拟机就会把这个软引用加入到与之关联的引用队列中。 123456789101112ReferenceQueue&lt;String&gt; referenceQueue = new ReferenceQueue&lt;&gt;();String str = new String(\"abc\");SoftReference&lt;String&gt; softReference = new SoftReference&lt;&gt;(str, referenceQueue);str = null;// Notify GCSystem.gc();System.out.println(softReference.get()); // abcReference&lt;? extends String&gt; reference = referenceQueue.poll();System.out.println(reference); //null 注意：软引用对象是在jvm内存不够的时候才会被回收，我们调用System.gc()方法只是起通知作用，JVM什么时候扫描回收对象是JVM自己的状态决定的。就算扫描到软引用对象也不一定会回收它，只有内存不够的时候才会回收。 当内存不足时，JVM首先将软引用中的对象引用置为null，然后通知垃圾回收器进行回收： 123456if(JVM内存不足) &#123; // 将软引用中的对象引用置为null str = null; // 通知垃圾回收器进行回收 System.gc();&#125; 也就是说，垃圾收集线程会在虚拟机抛出OutOfMemoryError之前回收软引用对象，而且虚拟机会尽可能优先回收长时间闲置不用的软引用对象。对那些刚构建的或刚使用过的“较新的”软对象会被虚拟机尽可能保留，这就是引入引用队列ReferenceQueue的原因。 应用场景： 浏览器的后退按钮。按后退时，这个后退时显示的网页内容是重新进行请求还是从缓存中取出呢？这就要看具体的实现策略了。 如果一个网页在浏览结束时就进行内容的回收，则按后退查看前面浏览过的页面时，需要重新构建； 如果将浏览过的网页存储到内存中会造成内存的大量浪费，甚至会造成内存溢出。 这时候就可以使用软引用，很好的解决了实际的问题： 1234567891011121314151617// 获取浏览器对象进行浏览Browser browser = new Browser();// 从后台程序加载浏览页面BrowserPage page = browser.getPage();// 将浏览完毕的页面置为软引用SoftReference softReference = new SoftReference(page);// 回退或者再次浏览此页面时if(softReference.get() != null) &#123; // 内存充足，还没有被回收器回收，直接获取缓存 page = softReference.get();&#125; else &#123; // 内存不足，软引用的对象已经回收 page = browser.getPage(); // 重新构建软引用 softReference = new SoftReference(page);&#125; (三) 弱引用(WeakReference)弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。 123String str = new String(\"abc\");WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str);str = null; JVM首先将软引用中的对象引用置为null，然后通知垃圾回收器进行回收： 12str = null;System.gc(); 注意：如果一个对象是偶尔(很少)的使用，并且希望在使用时随时就能获取到，但又不想影响此对象的垃圾收集，那么你应该用Weak Reference来记住此对象。 下面的代码会让一个弱引用再次变为一个强引用： 1234String str = new String(\"abc\");WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str);// 弱引用转强引用String strongReference = weakReference.get(); 同样，弱引用可以和一个引用队列(ReferenceQueue)联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 简单测试： GCTarget.java 12345678910111213141516public class GCTarget &#123; // 对象的ID public String id; // 占用内存空间 byte[] buffer = new byte[1024]; public GCTarget(String id) &#123; this.id = id; &#125; protected void finalize() throws Throwable &#123; // 执行垃圾回收时打印显示对象ID System.out.println(\"Finalizing GCTarget, id is : \" + id); &#125;&#125; GCTargetWeakReference.java 1234567891011121314public class GCTargetWeakReference extends WeakReference&lt;GCTarget&gt; &#123; // 弱引用的ID public String id; public GCTargetWeakReference(GCTarget gcTarget, ReferenceQueue&lt;? super GCTarget&gt; queue) &#123; super(gcTarget, queue); this.id = gcTarget.id; &#125; protected void finalize() &#123; System.out.println(\"Finalizing GCTargetWeakReference \" + id); &#125;&#125; WeakReferenceTest.java 1234567891011121314151617181920212223242526272829303132333435363738public class WeakReferenceTest &#123; // 弱引用队列 private final static ReferenceQueue&lt;GCTarget&gt; REFERENCE_QUEUE = new ReferenceQueue&lt;&gt;(); public static void main(String[] args) &#123; LinkedList&lt;GCTargetWeakReference&gt; gcTargetList = new LinkedList&lt;&gt;(); // 创建弱引用的对象，依次加入链表中 for (int i = 0; i &lt; 5; i++) &#123; GCTarget gcTarget = new GCTarget(String.valueOf(i)); GCTargetWeakReference weakReference = new GCTargetWeakReference(gcTarget, REFERENCE_QUEUE); gcTargetList.add(weakReference); System.out.println(\"Just created GCTargetWeakReference obj: \" + gcTargetList.getLast()); &#125; // 通知GC进行垃圾回收 System.gc(); try &#123; // 休息几分钟，等待上面的垃圾回收线程运行完成 Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 检查关联的引用队列是否为空 Reference&lt;? extends GCTarget&gt; reference; while((reference = REFERENCE_QUEUE.poll()) != null) &#123; if(reference instanceof GCTargetWeakReference) &#123; System.out.println(\"In queue, id is: \" + ((GCTargetWeakReference) (reference)).id); &#125; &#125; &#125;&#125; 运行WeakReferenceTest.java，运行结果如下： 可见WeakReference对象的生命周期基本由垃圾回收器决定，一旦垃圾回收线程发现了弱引用对象，在下一次GC过程中就会对其进行回收。 (四) 虚引用(PhantomReference)虚引用顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 应用场景： 虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列(ReferenceQueue)联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 1234String str = new String(\"abc\");ReferenceQueue queue = new ReferenceQueue();// 创建虚引用，要求必须与一个引用队列关联PhantomReference pr = new PhantomReference(str, queue); 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要进行垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 总结 Java中4种引用的级别和强度由高到低依次为：强引用 -&gt; 软引用 -&gt; 弱引用 -&gt; 虚引用 当垃圾回收器回收时，某些对象会被回收，某些不会被回收。垃圾回收器会从根对象Object来标记存活的对象，然后将某些不可达的对象和一些引用的对象进行回收。 通过表格来说明一下，如下： 引用类型 被垃圾回收时间 用途 生存时间 强引用 从来不会 对象的一般状态 JVM停止运行时终止 软引用 当内存不足时 对象缓存 内存不足时终止 弱引用 正常垃圾回收时 对象缓存 垃圾回收后终止 虚引用 正常垃圾回收时 跟踪对象的垃圾回收 垃圾回收后终止 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java编程基础系列","slug":"Java编程基础系列","permalink":"https://ostenant.coding.me/categories/Java编程基础系列/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"},{"name":"Reference","slug":"Reference","permalink":"https://ostenant.coding.me/tags/Reference/"}]},{"title":"Java 8系列(二) - JDK1.8函数式接口详解","slug":"Java 8系列(二) - JDK1.8函数式接口详解","date":"2017-07-05T02:24:00.000Z","updated":"2018-05-08T02:49:46.091Z","comments":true,"path":"2017/07/05/Java 8系列(二) - JDK1.8函数式接口详解/","link":"","permalink":"https://ostenant.coding.me/2017/07/05/Java 8系列(二) - JDK1.8函数式接口详解/","excerpt":"简述函数式接口的概念函数式接口本质上还是一个接口，但是它是一种特殊的SAM类型的接口（Single Abstract Method）。","text":"简述函数式接口的概念函数式接口本质上还是一个接口，但是它是一种特殊的SAM类型的接口（Single Abstract Method）。 函数式接口的使用 一个函数式接口只能声明一个抽象方法； JDK1.8中的默认方法(default)和静态方法(static)都不算抽象方法 函数式接口默认继承了Java.lang.Object，覆盖了Object类中的所有方法，equals(Object)、hashCode()、clone()、toString()等方法都不算为抽象方法； 如果接口被标注了@FunctionalInterface，这个类就必须符合函数式接口的规范。即使一个接口没有标注@FunctionalInterface，如果这个接口满足函数式接口规则，依旧被当作函数式接口。 JDK中以前所有的函数式接口都已经使用@FunctionalInterface定义，可以通过查看JDK1.8源码来确认，以下附JDK 8之前已有的函数式接口： java.lang.Runnable java.util.concurrent.Callable java.security.PrivilegedAction java.util.Comparator java.io.FileFilter java.nio.file.PathMatcher java.lang.reflect.InvocationHandler java.beans.PropertyChangeListener java.awt.event.ActionListener javax.swing.event.ChangeListener 函数式接口的意义函数式接口使得Lambda表达式能够作为方法调用的参数。一旦我们调用某方法，可以传入lambda表达式作为参数，那么这个方法的参数类型，必定是一个函数式的接口，这个类型必定会使用@FunctionalInterface进行修饰。 正文Java8里关于函数式接口的包是java.util.function，里面全部是函数式接口。主要包含几大类：Function、Predicate、Supplier和Consumer，如图所示： JDK1.8内置的几个函数式接口 接口名称 抽象方法 方法含义 Function R apply(T) 就是函数映射的意思，一个输入，一个相应的输出。 Predicate boolean test(T) 表示判断。输入一个对象，返回布尔值。 Consumer void accept(T) 消费一个操作。输入一个对象，处理（消费）完后不返回值。 Supplier T get() 直接返回一个对象。 其他的接口无非是基于以上几个接口给出的扩展，下面依次对这几个接口展开讨论： Function接口Function接口接收一个参数，并返回单一的结果。默认方法可以将多个函数串在一起（compose, andThen）。首先查看Function接口的源码： 123456789101112131415161718@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; R apply(T t); default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) &#123; Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v)); &#125; default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t)); &#125; static &lt;T&gt; Function&lt;T, T&gt; identity() &#123; return t -&gt; t; &#125;&#125; Function接口使用@FunctionalInterface标识，表明此接口为函数式接口，有且只能有一个抽象方法； Function泛型规定了T、R分别对应Lambda表达式的输入参数类型和输出参数类型； Function定义了compose、andThen两个默认方法和静态方法identity。 apply()1R apply(T t); 把Function&lt;T, R&gt;对象运用于输入的参数t中，即执行传入的满足Function定义（一个输入、一个输出）的Lambda表达式的方法体，返回R类型输出结果r。 compose()1234default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) &#123; Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v));&#125; 构建一个Lambda表达式，输入类型为V，输出类型为R； 先传入before对象的apply方法 – before.apply(v) – 其中before对象的类型为Function&lt;V, T&gt;，其输入为类型V，输出为类型T； 再传入当前对象的apply方法 – apply(before.apply(v)) – 其中当前对象的类型为Function&lt;T, R&gt;，其输入类型为T，输出类型为R。 最终构造出输入类型为V，输出类型为R的函数接口(中间转换结果类型为T)：Function&lt;V, R&gt; – 对应的Lambda表达式为：(V v) -&gt; apply(before.apply(v))。 andThen()1234default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t));&#125; 构建一个Lambda表达式，输入类型为T，输出类型为V； 先传入当前对象对象的apply方法 – apply(t) – 其中当前对象的类型为Function&lt;T, R&gt;，其输入为类型T，输出为类型R； 再传入after对象的apply方法 – after.apply(apply(t)) – 其中after对象的类型为Function&lt;R, V&gt;，其输入类型为R，输出类型为V。 最终构造出输入类型为T，输出类型为V的函数接口(中间转换结果类型为R)：Function&lt;T, V&gt; – 对应的Lambda表达式为：(T t) -&gt; after.apply(apply(t))。 identity()123static &lt;T&gt; Function&lt;T, T&gt; identity() &#123; return t -&gt; t;&#125; 返回一个输入类型和输出类型都为T的Function对象。 案例12345678910111213@Testpublic void test() throws Exception &#123; // 创建一个Function对象 Function&lt;String, Integer&gt; function = x -&gt; Integer.parseInt(x) * 10; // 1. apply()方法 System.out.println(function.apply(\"10\")); // 2. compose()方法 System.out.println(function.compose((String y) -&gt; y.substring(1)).apply(\"a10\")); // 3. andThen()方法 System.out.println(function.andThen((Integer x) -&gt; \"[\" + x + \"]\").apply(\"10\")); // 4. identity()静态方法。identity()本来就是一个函数式接口 System.out.println(Function.identity().apply(10));&#125; 输出结果： 100100[100]10 Predicate接口Predicate接口接收一个参数，并返回boolean类型的返回值。默认方法可以将多个函数串在一起（and, or, negate）。首先查看Predicate接口接口的源码： 123456789101112131415161718192021222324@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; boolean test(T t); default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); &#125; default Predicate&lt;T&gt; negate() &#123; return (t) -&gt; !test(t); &#125; default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t); &#125; static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) &#123; return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object); &#125;&#125; Predicate接口使用@FunctionalInterface标识，表明此接口为函数式接口，有且只能有一个抽象方法； Predicate泛型规定了T对应Lambda表达式的输入参数类型； Predicate定义了and、or、negate三个默认方法和静态方法isEqual。 test()1boolean test(T t); and()1234default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t);&#125; or()1234default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t);&#125; negate()123default Predicate&lt;T&gt; negate() &#123; return (t) -&gt; !test(t);&#125; isEqual()12345static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) &#123; return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object);&#125; 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JDK1.8编程系列","slug":"JDK1-8编程系列","permalink":"https://ostenant.coding.me/categories/JDK1-8编程系列/"}],"tags":[{"name":"JDK1.8","slug":"JDK1-8","permalink":"https://ostenant.coding.me/tags/JDK1-8/"}]},{"title":"Java 8系列(一) - JDK1.8对字符串的连接处理","slug":"Java 8系列(一) - JDK1.8对字符串连接处理","date":"2017-07-04T08:35:00.000Z","updated":"2018-05-08T02:49:46.090Z","comments":true,"path":"2017/07/04/Java 8系列(一) - JDK1.8对字符串连接处理/","link":"","permalink":"https://ostenant.coding.me/2017/07/04/Java 8系列(一) - JDK1.8对字符串连接处理/","excerpt":"简述在JDK1.8之前，我们通常使用StringBuffer、StringBuilder等可变字符串进行字符串的截取、拼接、替换、组装等功能。","text":"简述在JDK1.8之前，我们通常使用StringBuffer、StringBuilder等可变字符串进行字符串的截取、拼接、替换、组装等功能。 例如，我们需要将List&lt;String&gt;中的所有字符串组装为str1,str2,str3,…strn的形式。在JDK1.8之前我们通常会作如下处理： 1234567891011121314151617181920private final static List&lt;String&gt; LIST = Arrays.asList(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\");private final static String DELIMITER = \", \";public static void main(String[] args) &#123; String result = concatList(LIST, DELIMITER); System.out.println(result);&#125;public static String concatList(List&lt;String&gt; list, String delimiter) &#123; StringBuilder result = new StringBuilder(); for (String i : list) &#123; result.append(i).append(DELIMITER); &#125; if (result.length() &gt; 0) &#123; // 删除最后一个分隔符 result.delete(result.length() - delimiter.length(), result.length()); &#125; return result.toString();&#125; 使用StringBuilder的运行结果如下： a, b, c, d, e, f, g 下面我们看看如何用JDK1.8提供的字符串处理API完成以上操作。 正文StringJoiner(delimiter)JDK1.8新增了一个用于字符串连接的新类，专门用于这种需要分隔符的场合 – StringJoiner。StringJoiner在构造时可以指定一个分隔符（delimiter），然后每连接一个元素它便会加上一个delimiter。 concatList方法如下：1234567public static String concatList(List&lt;String&gt; list, String delimiter) &#123; StringJoiner result = new StringJoiner(DELIMITER); for (String i : list) &#123; result.add(i); &#125; return result.toString();&#125; 同样，使用StringJoiner的运行结果如下： a, b, c, d, e, f, g String.join(delimiter, elements)StringJoiner使得代码更加的简洁了。当然,还可以更简洁。JDK1.8为String类添加了一个新的静态方法 – String.join。 concatList方法如下：123public static String concatList(List&lt;String&gt; list, String delimiter) &#123; return String.join(delimiter, list);&#125; 同样，使用String.join()的运行结果如下： a, b, c, d, e, f, g 查看String.join()的源码，可以发现join()静态方法也是通过StringJoiner来实现的：12345678910public static String join(CharSequence delimiter, CharSequence... elements) &#123; Objects.requireNonNull(delimiter); Objects.requireNonNull(elements); // Number of elements not likely worth Arrays.stream overhead. StringJoiner joiner = new StringJoiner(delimiter); for (CharSequence cs: elements) &#123; joiner.add(cs); &#125; return joiner.toString();&#125; StringJoiner(delimiter, prefix, suffix)String.join方法的不足是它不能指定前缀和后缀 – 比如我们想要直接将List&lt;String&gt;格式化为 { str1,str2,str3,…strn } 就不行。而StringJoiner提供了StringJoiner(delimiter, prefix, suffix)的构造方法完美地解决了这个问题。 1234567public static String concatList(List&lt;String&gt; list, String delimiter, String prefix, String suffix) &#123; StringJoiner result = new StringJoiner(DELIMITER, PREFIX, SUFFIX); for (String i : list) &#123; result.add(i); &#125; return result.toString();&#125; 运行结果如下： { a, b, c, d, e, f, g } Collectors.joining(delimiter, prefix, suffix)使用StringJoiner已经完全可以实现带前后缀的字符串组装。更优雅同时也更加推荐的方式是使用Collectors.joining()方法。123public static String concatList(List&lt;String&gt; list, String delimiter, String prefix, String suffix) &#123; return list.stream().collect(Collectors.joining(delimiter, prefix, suffix));&#125; 同样，运行结果如下： { a, b, c, d, e, f, g } 总结查看StringJoiner的源码，我们可以知道StringJoiner的底层实现就是StringBuilder– Java8将使用分隔符连接多个字符串这一功能进行封装，提供很多易用且简介的API，确实在很大程度上方便了我们编码。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JDK1.8编程系列","slug":"JDK1-8编程系列","permalink":"https://ostenant.coding.me/categories/JDK1-8编程系列/"}],"tags":[{"name":"JDK1.8","slug":"JDK1-8","permalink":"https://ostenant.coding.me/tags/JDK1-8/"}]},{"title":"一天一个设计模式(二) -单例模式(Singleton)","slug":"一天一个设计模式(二) - 单例模式(Singleton)","date":"2017-06-03T07:37:00.000Z","updated":"2018-05-08T02:49:46.093Z","comments":true,"path":"2017/06/03/一天一个设计模式(二) - 单例模式(Singleton)/","link":"","permalink":"https://ostenant.coding.me/2017/06/03/一天一个设计模式(二) - 单例模式(Singleton)/","excerpt":"前言单例模式 (Singleton) 是一种创建型模式，指某个类采用Singleton模式，则在这个类被创建后，只可能产生一个实例供外部访问，并且提供一个全局的访问点。","text":"前言单例模式 (Singleton) 是一种创建型模式，指某个类采用Singleton模式，则在这个类被创建后，只可能产生一个实例供外部访问，并且提供一个全局的访问点。 正文(一). 优缺点Java中单例模式 (Singleton) 是一种广泛使用的设计模式。单例模式的主要作用是保证在Java程序中，某个类只有一个实例存在。一些管理器和控制器常被设计成单例模式。 1. 优点 提供了对唯一实例的受控访问。 由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象单例模式无疑可以提高系统的性能。 可以根据实际情况需要，在单例模式的基础上扩展做出双例模式，多例模式。 2. 缺点 单例类的职责过重，里面的代码可能会过于复杂，在一定程度上违背了“单一职责原则”。 如果实例化的对象长时间不被利用，会被系统认为是垃圾而被回收，这将导致对象状态的丢失。 (二). 具体实现简单点说，就是一个应用程序中，某个类的实例对象只有一个，你没有办法去new，因为构造器是被private修饰的，一般通过getInstance()的方法来获取它们的实例。getInstance()的返回值是一个同一个对象的引用，并不是一个新的实例。单例模式 实现起来也很容易，以下给出六种实现方式： 1. 饿汉式特点：线程安全，无法实现实例懒加载策略。123456789public class Singleton1 &#123; private final static Singleton1 singleton1 = new Singleton1(); private Singleton1() &#123; &#125; public static Singleton1 getInstance() &#123; return singleton1; &#125;&#125; 2. 懒汉式特点：线程不安全，实现了实例懒加载策略。1234567891011public class Singleton2 &#123; private final static Singleton2 singleton2; private Singleton2() &#123; &#125; public static Singleton2 getInstance() &#123; if (singleton2 == null) singleton2 = new Singleton2(); return singleton2; &#125;&#125; 3. 全局锁式特点：线程安全，且实现了懒加载策略，但是线程同步时效率不高。1234567891011public class Singleton3 &#123; private final static Singleton3 singleton3; private Singleton3() &#123; &#125; public synchronized static Singleton3 getInstance() &#123; if (singleton3 == null) singleton3 = new Singleton3(); return singleton3; &#125;&#125; 4. 静态代码块式特点：线程安全，类主动加载时才初始化实例，实现了懒加载策略，且线程安全。123456789101112public class Singleton4 &#123; private final static Singleton4 singleton4; private Singleton4() &#123; &#125; static &#123; singleton4 = new Singleton4(); &#125; public static Singleton4 getInstance() &#123; return singleton4; &#125;&#125; 5. 双重校验锁式特点：线程安全，且实现了懒加载策略，同时保证了线程同步时的效率。但是volatile强制当前线程每次读操作进行时，保证所有其他的线程的写操作已完成。volatile使得JVM内部的编译器舍弃了编译时优化，对于性能有一定的影响。 12345678910111213141516public class Singleton5 &#123; private static volatile Singleton5 singleton5; private Singleton5() &#123; &#125; public static Singleton5 getInstance() &#123; if (singleton5 == null) &#123; synchronized (Singleton5.class) &#123; if (singleton5 == null) &#123; singleton5 = new Singleton5(); &#125; &#125; &#125; return singleton5; &#125;&#125; 6. 静态内部类式【推荐】特点：线程安全，不存在线程同步问题，且单例对象在程序第一次 getInstance() 时主动加载 SingletonHolder 和其 静态成员 INSTANCE，因而实现了懒加载策略。123456789101112public class Singleton6 &#123; private Singleton6() &#123; &#125; private static class SingletonHolder &#123; private static final Singleton6 INSTANCE = new Singleton6(); &#125; public static Singleton6 getInstance() &#123; return Singleton6.SingletonHolder.INSTANCE; &#125;&#125; 7. 枚举方式【作者推荐】特点：线程安全，不存在线程同步问题，且单例对象在枚举类型 INSTANCE 第一次引用时通过枚举的 构造函数 初始化，因而实现了懒加载策略。1234567891011121314151617181920212223242526public class Singleton7 &#123; private Singleton7() &#123; &#125; enum SingletonEnum &#123; INSTANCE; private final Singleton7 singleton7; private SingletonEnum() &#123; singleton7 = new Singleton7(); &#125; &#125; public static Singleton7 getInstance() &#123; return SingletonEnum.INSTANCE.singleton7; &#125; public static void main(String[] args) &#123; IntStream.rangeClosed(0, 100).forEach(i -&gt; new Thread() &#123; public void run() &#123; out.println(Singleton7.getInstance()); &#125;; &#125;.start()); &#125;&#125; 这种方式是Effective Java作者 Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象，可谓是很坚强的壁垒啊。不过，由于JDK 1.5中才加入enum特性，用这种方式写不免让人感觉生疏。 测试代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@FixMethodOrderpublic class SingletonTester &#123; protected final static int FROM = 0; protected final static int TO = 1000; protected static HashSet&lt;Object&gt; GLOBAL_SET = new HashSet&lt;&gt;(); static &#123; Runtime.getRuntime().addShutdownHook(new Thread() &#123; @Override public void run() &#123; out.println(); // count GLOBAL_SET.forEach((value) -&gt; &#123; out.println(\"Global [\" + value + \"]\"); &#125;); &#125; &#125;); &#125; // testSingleton1 @Test public void testSingleton1() throws Exception &#123; final HashSet&lt;Object&gt; localSet = new HashSet&lt;&gt;(); final CountDownLatch latch = new CountDownLatch(TO); IntStream.range(FROM, TO).forEach(i -&gt; new Thread() &#123; public void run() &#123; Singleton1 singleton = Singleton1.getInstance(); count(singleton); &#125; protected void count(Singleton1 singleton) &#123; localSet.add(singleton); out.println(\"Size of HashSet1 is: [\" + localSet.size() + \"]\"); // 计数减1，释放线程 latch.countDown(); &#125;; &#125;.start()); // 等待子线程执行结束 latch.await(); synchronized (localSet) &#123; // count localSet.forEach((value) -&gt; &#123; out.println(\"[\" + value + \"]\"); out.println(); &#125;); GLOBAL_SET.addAll(localSet); &#125; &#125; // testSingleton2 // testSingleton3 // testSingleton4 // testSingleton5 // testSingleton6 // testSingleton7&#125; 测试结果截图如下，测试用例反映7种单例模式的方案都可以正常执行： 这里只演示其中一种单例方式，运行截图如下： 上图显示，通过 getInstance() 得到的实例全局唯一。对于其余六中方式，根据测试用例测试得到的结果一致，大家可以自行测试。 总结本文总结了七种Java中实现单例模式的方法，其中使用双重校验锁、静态内部类 和 枚举类 的方式可以解决大部分问题。其中，极为推荐 静态内部类 和 枚举类 这两种实现方式。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA设计模式系列","slug":"JAVA设计模式系列","permalink":"https://ostenant.coding.me/categories/JAVA设计模式系列/"}],"tags":[{"name":"Singleton","slug":"Singleton","permalink":"https://ostenant.coding.me/tags/Singleton/"}]},{"title":"一天一个设计模式(一) - 总体概述","slug":"一天一个设计模式(一) - 总体概述","date":"2017-06-02T05:22:00.000Z","updated":"2018-05-08T02:49:46.093Z","comments":true,"path":"2017/06/02/一天一个设计模式(一) - 总体概述/","link":"","permalink":"https://ostenant.coding.me/2017/06/02/一天一个设计模式(一) - 总体概述/","excerpt":"前言最近在对设计模式进行了一系列总结，本文将给大家关于设计模式的一个整体的介绍。","text":"前言最近在对设计模式进行了一系列总结，本文将给大家关于设计模式的一个整体的介绍。 正文1. 定义设计模式是某类特定问题的代码设计解决方案，是一套代码设计的经验总结。 2. 作用 提高代码复用率，降低开发成本和周期 提高代码可维护性、可拓展性 使代码更加优雅，可读性更强 让代码更容易被他人理解 3. 设计原则在设计模式进行设计时需要遵循以下的面向对象设计原则： 单一职责原则 (SRP)：就一个类而言，应该仅有一个引起它变化的原因。 开闭原则 (ASD)：类、模块、函数等等应该是可以拓展的，但是不可修改。 里氏替换原则 (LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。 依赖倒置原则 (DIP)：高层模块不应该依赖低层模块，两个都应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 迪米特原则 (LOD)：一个软件实体应当尽可能少地与其他实体发生相互作用。 接口隔离原则 (ISP)：一个类对另一个类的依赖应该建立在最小的接口上。 4. 设计模式分类常用的23种设计模式总体来说分为三大类：创建型模式、结构型模式 和 行为型模式。 创建型模式 (共五种)：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式 (共七种)：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式 (共十一种)：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 三大类设计模式及其分类，如下图所示： 总结本文对设计模式的定义进行了大致总体的介绍，接下来我会对几种常用的设计模式进行详细的分析。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA设计模式系列","slug":"JAVA设计模式系列","permalink":"https://ostenant.coding.me/categories/JAVA设计模式系列/"}],"tags":[]},{"title":"JVM系列(五) - JVM类加载机制详解","slug":"JVM系列(五) - JVM类加载机制详解","date":"2017-05-10T03:17:00.000Z","updated":"2018-05-08T02:49:46.090Z","comments":true,"path":"2017/05/10/JVM系列(五) - JVM类加载机制详解/","link":"","permalink":"https://ostenant.coding.me/2017/05/10/JVM系列(五) - JVM类加载机制详解/","excerpt":"前言本文将由浅及深，介绍Java类加载的过程和原理，进一步对类加载器的进行源码分析，完成一个自定义的类加载器。","text":"前言本文将由浅及深，介绍Java类加载的过程和原理，进一步对类加载器的进行源码分析，完成一个自定义的类加载器。 正文(一). 类加载器是什么类加载器简言之，就是用于把.class文件中的字节码信息转化为具体的java.lang.Class对象的过程的工具。 具体过程： 在实际类加载过程中，JVM会将所有的.class字节码文件中的二进制数据读入内存中，导入运行时数据区的方法区中。 当一个类首次被主动加载或被动加载时，类加载器会对此类执行类加载的流程 – 加载、连接（验证、准备、解析）、初始化。 如果类加载成功，堆内存中会产生一个新的Class对象，Class对象封装了类在方法区内的数据结构。 Class对象的创建过程描述： (二). 类加载的过程类加载的过程分为三个步骤(五个阶段) ：加载 -&gt; 连接（验证、准备、解析）-&gt; 初始化。 加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段可以在初始化阶段之后发生，也称为动态绑定或晚期绑定。 类加载的过程描述： 1. 加载加载：查找并加载类的二进制数据的过程。 加载的过程描述： 通过类的全限定名定位.class文件，并获取其二进制字节流。 把字节流所代表的静态存储结构转换为方法区的运行时数据结构。 在Java堆中生成一个此类的java.lang.Class对象，作为方法区中这些数据的访问入口。 2. 连接连接：包括验证、准备、解析三步。 a). 验证验证：确保被加载的类的正确性。验证是连接阶段的第一步，用于确保Class字节流中的信息是否符合虚拟机的要求。 具体验证形式： 文件格式验证：验证字节流是否符合Class文件格式的规范；例如：是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了java.lang.Object之外。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。 b). 准备准备：为类的静态变量分配内存，并将其初始化为默认值。准备过程通常分配一个结构用来存储类信息，这个结构中包含了类中定义的成员变量，方法和接口信息等。 具体行为： 这时候进行内存分配的仅包括类变量(static)，而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。 这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式赋值。 c). 解析解析：把类中对常量池内的符号引用转换为直接引用。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符等7类符号引用进行。 3. 初始化初始化：对类静态变量赋予正确的初始值 (注意和连接时的解析过程区分开)。 初始化的目标 实现对声明类静态变量时指定的初始值的初始化； 实现对使用静态代码块设置的初始值的初始化。 初始化的步骤 如果此类没被加载、连接，则先加载、连接此类； 如果此类的直接父类还未被初始化，则先初始化其直接父类； 如果类中有初始化语句，则按照顺序依次执行初始化语句。 初始化的时机 创建类的实例(new关键字)； java.lang.reflect包中的方法(如：Class.forName(“xxx”))； 对类的静态变量进行访问或赋值； 访问调用类的静态方法； 初始化一个类的子类，父类本身也会被初始化； 作为程序的启动入口，包含main方法(如：SpringBoot入口类)。 (三). 类的主动引用和被动引用主动引用主动引用：在类加载阶段，只执行加载、连接操作，不执行初始化操作。 主动引用的几种形式 创建类的实例(new关键字)； java.lang.reflect包中的方法(如：Class.forName(“xxx”))； 对类的静态变量进行访问或赋值； 访问调用类的静态方法； 初始化一个类的子类，父类本身也会被初始化； 作为程序的启动入口，包含main方法(如：SpringBoot入口类)。 主动引用1 - main方法在初始类中代码示例：123456789public class OptimisticReference0 &#123; static &#123; System.out.println(OptimisticReference0.class.getSimpleName() + \" is referred!\"); &#125; public static void main(String[] args) &#123; System.out.println(); &#125;&#125; 运行结果： OptimisticReference0 is referred! 主动引用2 – 创建子类会触发父类的初始化代码示例：1234567891011121314151617public class OptimisticReference1 &#123; public static class Parent &#123; static &#123; System.out.println(Parent.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static class Child extends Parent &#123; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static void main(String[] args) &#123; new Child(); &#125;&#125; 运行结果： Parent is referred!Child is referred! 主动引用3 – 访问一个类静态变量代码示例：12345678910111213public class OptimisticReference2 &#123; public static class Child &#123; protected static String name; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); name = \"Child\"; &#125; &#125; public static void main(String[] args) &#123; System.out.println(Child.name); &#125;&#125; 运行结果： Child is referred!Child 主动引用4 – 对类的静态变量进行赋值代码示例：123456789101112public class OptimisticReference3 &#123; public static class Child &#123; protected static String name; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static void main(String[] args) &#123; Child.name = \"Child\"; &#125;&#125; 运行结果： Child is referred! 主动引用5 – 使用java.lang.reflect包提供的反射机制代码示例： 12345public class OptimisticReference4 &#123; public static void main(String[] args) throws ClassNotFoundException &#123; Class.forName(\"org.ostenant.jdk8.learning.examples.reference.optimistic.Child\"); &#125;&#125; 运行结果： Child is referred! 被动引用被动引用： 在类加载阶段，会执行加载、连接和初始化操作。 被动引用的几种形式： 通过子类引用父类的的静态字段，不会导致子类初始化； 定义类的数组引用而不赋值，不会触发此类的初始化； 访问类定义的常量，不会触发此类的初始化。 被动引用1 – 子类引用父类的的静态字段，不会导致子类初始化代码示例：123456789101112131415161718public class NegativeReference0 &#123; public static class Parent &#123; public static String name = \"Parent\"; static &#123; System.out.println(Parent.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static class Child extends Parent &#123; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static void main(String[] args) &#123; System.out.println(Child.name); &#125;&#125; 运行结果： Parent is referred!Parent 被动引用2 – 定义类的数组引用而不赋值，不会触发此类的初始化代码示例：1234567891011public class NegativeReference1 &#123; public static class Child &#123; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static void main(String[] args) &#123; Child[] childs = new Child[10]; &#125;&#125; 运行结果： 无输出 被动引用3 – 访问类定义的常量，不会触发此类的初始化示例代码：123456789101112public class NegativeReference2 &#123; public static class Child &#123; public static final String name = \"Child\"; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static void main(String[] args) &#123; System.out.println(Child.name); &#125;&#125; 运行结果： Child (四). 三种类加载器类加载器：类加载器负责加载程序中的类型（类和接口），并赋予唯一的名字予以标识。 类加载器的组织结构 类加载器的关系 Bootstrap Classloader 是在Java虚拟机启动后初始化的。 Bootstrap Classloader 负责加载 ExtClassLoader，并且将 ExtClassLoader的父加载器设置为 Bootstrap Classloader Bootstrap Classloader 加载完 ExtClassLoader 后，就会加载 AppClassLoader，并且将 AppClassLoader 的父加载器指定为 ExtClassLoader。 类加载器的作用 Class Loader 实现方式 具体实现类 负责加载的目标 Bootstrap Loader C++ 由C++实现 %JAVA_HOME%/jre/lib/rt.jar以及-Xbootclasspath参数指定的路径以及中的类库 Extension ClassLoader Java sun.misc.Launcher$ExtClassLoader %JAVA_HOME%/jre/lib/ext路径下以及java.ext.dirs系统变量指定的路径中类库 Application ClassLoader Java sun.misc.Launcher$AppClassLoader Classpath以及-classpath、-cp指定目录所指定的位置的类或者是jar文档，它也是Java程序默认的类加载器 类加载器的特点 层级结构：Java里的类装载器被组织成了有父子关系的层级结构。Bootstrap类装载器是所有装载器的父亲。 代理模式： 基于层级结构，类的代理可以在装载器之间进行代理。当装载器装载一个类时，首先会检查它在父装载器中是否进行了装载。如果上层装载器已经装载了这个类，这个类会被直接使用。反之，类装载器会请求装载这个类 可见性限制：一个子装载器可以查找父装载器中的类，但是一个父装载器不能查找子装载器里的类。 不允许卸载：类装载器可以装载一个类但是不可以卸载它，不过可以删除当前的类装载器，然后创建一个新的类装载器装载。 类加载器的隔离问题每个类装载器都有一个自己的命名空间用来保存已装载的类。当一个类装载器装载一个类时，它会通过保存在命名空间里的类全局限定名(Fully Qualified Class Name) 进行搜索来检测这个类是否已经被加载了。 JVM 及 Dalvik 对类唯一的识别是 ClassLoader id + PackageName + ClassName，所以一个运行程序中是有可能存在两个包名和类名完全一致的类的。并且如果这两个类不是由一个 ClassLoader 加载，是无法将一个类的实例强转为另外一个类的，这就是 ClassLoader 隔离性。 为了解决类加载器的隔离问题，JVM引入了双亲委托机制。 (五). 双亲委托机制核心思想：其一，自底向上检查类是否已加载；其二，自顶向下尝试加载类。 具体加载过程 当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败（例如在%JAVA_HOME%/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载； 如果ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 源码分析ClassLoader.class loadClass()：通过指定类的全限定名称，由类加载器检测、装载、创建并返回该类的java.lang.Class对象。 ClassLoader通过loadClass()方法实现了双亲委托机制，用于类的动态加载。 loadClass()本身是一个递归向上调用的过程。 自底向上检查类是否已加载 先通过findLoadedClass()方法从最底端类加载器开始检查类是否已经加载。 如果已经加载，则根据resolve参数决定是否要执行连接过程，并返回Class对象。 如果没有加载，则通过parent.loadClass()委托其父类加载器执行相同的检查操作(默认不做连接处理)。 直到顶级类加载器，即parent为空时，由findBootstrapClassOrNull()方法尝试到Bootstrap ClassLoader中检查目标类。 自顶向下尝试加载类 如果仍然没有找到目标类，则从Bootstrap ClassLoader开始，通过findClass()方法尝试到对应的类目录下去加载目标类。 如果加载成功，则根据resolve参数决定是否要执行连接过程，并返回Class对象。 如果加载失败，则由其子类加载器尝试加载，直到最底端类加载器也加载失败，最终抛出ClassNotFoundException。 findLoadedClass() 查找当前类加载器的缓存中是否已经加载目标类。findLoadedClass()实际调用了底层的native方法findLoadedClass0()。 findBootstrapClassOrNull() 查找最顶端Bootstrap类加载器的是否已经加载目标类。同样，findBootstrapClassOrNull()实际调用了底层的native方法findBootstrapClass()。 findClass() ClassLoader是java.lang包下的抽象类，也是所有类加载器(除了Bootstrap)的基类，findClass()是ClassLoader对子类提供的加载目标类的抽象方法。 注意：Bootstrap ClassLoader并不属于JVM的层次，它不遵守ClassLoader的加载规则，Bootstrap classLoader并没有子类。 defineClass() defineClass()是ClassLoader向子类提供的方法，它可以将.class文件的二进制数据转换为合法的java.lang.Class对象。 (六). 类的动态加载类的几种加载方式 通过命令行启动时由JVM初始化加载； 通过Class.forName()方法动态加载； 通过ClassLoader.loadClass()方法动态加载。 Class.forName()和ClassLoader.loadClass() Class.forName()：把类的.class文件加载到JVM中，对类进行解释的同时执行类中的static静态代码块； ClassLoader.loadClass()：只是把.class文件加载到JVM中，不会执行static代码块中的内容，只有在newInstance才会去执行。 (七). 对象的初始化对象的初始化顺序静态变量/静态代码块 -&gt; 普通代码块 -&gt; 构造函数 父类静态变量和静态代码块（先声明的先执行）； 子类静态变量和静态代码块（先声明的先执行）； 父类普通成员变量和普通代码块（先声明的先执行）； 父类的构造函数； 子类普通成员变量和普通代码块（先声明的先执行）； 子类的构造函数。 对象的初始化示例Parent.java Children.java Tester.java 测试结果： 测试结果表明：JVM在创建对象时，遵守以上对象的初始化顺序。 (八). 自定义类加载器编写自己的类加载器在源码分析阶段，我们已经解读了如何实现自定义类加载器，现在我们开始怼自己的类加载器。 Step 1：定义待加载的目标类Parent.java和Children.java。 Parent.java1234567891011121314151617181920212223242526272829package org.ostenant.jdk8.learning.examples.classloader.custom;public class Parent &#123; protected static String CLASS_NAME; protected static String CLASS_LOADER_NAME; protected String instanceID; // 1.先执行静态变量和静态代码块（只在类加载期间执行一次） static &#123; CLASS_NAME = Parent.class.getName(); CLASS_LOADER_NAME = Parent.class.getClassLoader().toString(); System.out.println(\"Step a: \" + CLASS_NAME + \" is loaded by \" + CLASS_LOADER_NAME); &#125; // 2.然后执行变量和普通代码块（每次创建实例都会执行） &#123; instanceID = this.toString(); System.out.println(\"Step c: Parent instance is created: \" + CLASS_LOADER_NAME + \" -&gt; \" + instanceID); &#125; // 3.然后执行构造方法 public Parent() &#123; System.out.println(\"Step d: Parent instance：\" + instanceID + \", constructor is invoked\"); &#125; public void say() &#123; System.out.println(\"My first class loader...\"); &#125;&#125; Children.java12345678910111213141516171819202122package org.ostenant.jdk8.learning.examples.classloader.custom;public class Children extends Parent &#123; static &#123; CLASS_NAME = Children.class.getName(); CLASS_LOADER_NAME = Children.class.getClassLoader().toString(); System.out.println(\"Step b: \" + CLASS_NAME + \" is loaded by \" + CLASS_LOADER_NAME); &#125; &#123; instanceID = this.toString(); System.out.println(\"Step e: Children instance is created: \" + CLASS_LOADER_NAME + \" -&gt; \" + instanceID); &#125; public Children() &#123; System.out.println(\"Step f: Children instance：\" + instanceID + \", constructor is invoked\"); &#125; public void say() &#123; System.out.println(\"My first class loader...\"); &#125;&#125; Step 2：实现自定义类加载器CustomClassLoader CustomClassLoader.java123456789101112131415161718192021222324252627282930313233343536373839public class CustomClassLoader extends ClassLoader &#123; private String classPath; public CustomClassLoader(String classPath) &#123; this.classPath = classPath; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; Class&lt;?&gt; c = findLoadedClass(name); // 可省略 if (c == null) &#123; byte[] data = loadClassData(name); if (data == null) &#123; throw new ClassNotFoundException(); &#125; return defineClass(name, data, 0, data.length); &#125; return null; &#125; protected byte[] loadClassData(String name) &#123; try &#123; // package -&gt; file folder name = name.replace(\".\", \"//\"); FileInputStream fis = new FileInputStream(new File(classPath + \"//\" + name + \".class\")); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int len = -1; byte[] b = new byte[2048]; while ((len = fis.read(b)) != -1) &#123; baos.write(b, 0, len); &#125; fis.close(); return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; Step 3：测试类加载器的加载过程 CustomerClassLoaderTester.java 测试程序启动时，逐一拷贝并加载待加载的目标类源文件。 12345678910111213141516private static final String CHILDREN_SOURCE_CODE_NAME = SOURCE_CODE_LOCATION + \"Children.java\";private static final String PARENT_SOURCE_CODE_NAME = SOURCE_CODE_LOCATION + \"Parent.java\";private static final List&lt;String&gt; SOURCE_CODE = Arrays.asList(CHILDREN_SOURCE_CODE_NAME, PARENT_SOURCE_CODE_NAME);static &#123; SOURCE_CODE.stream().map(path -&gt; new File(path)) // 路径转文件对象 .filter(f -&gt; !f.isDirectory()) // 文件遍历 .forEach(f -&gt; &#123; // 拷贝后源代码 File targetFile = copySourceFile(f); // 编译源代码 compileSourceFile(targetFile); &#125;);&#125; 拷贝单一源文件到自定义类加载器的类加载目录。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected static File copySourceFile(File f) &#123; BufferedReader reader = null; BufferedWriter writer = null; try &#123; reader = new BufferedReader(new FileReader(f)); // package ...; String firstLine = reader.readLine(); StringTokenizer tokenizer = new StringTokenizer(firstLine, \" \"); String packageName = \"\"; while (tokenizer.hasMoreElements()) &#123; String e = tokenizer.nextToken(); if (e.contains(\"package\")) &#123; continue; &#125; else &#123; packageName = e.trim().substring(0, e.trim().length() - 1); &#125; &#125; // package -&gt; path String packagePath = packageName.replace(\".\", \"//\"); // java file path String targetFileLocation = TARGET_CODE_LOCALTION + \"//\" + packagePath + \"//\"; String sourceFilePath = f.getPath(); String fileName = sourceFilePath.substring(sourceFilePath.lastIndexOf(\"\\\\\") + 1); File targetFile = new File(targetFileLocation, fileName); File targetFileLocationDir = new File(targetFileLocation); if (!targetFileLocationDir.exists()) &#123; targetFileLocationDir.mkdirs(); &#125; // writer writer = new BufferedWriter(new FileWriter(targetFile)); // 写入第一行 writer.write(firstLine); writer.newLine(); writer.newLine(); String input = \"\"; while ((input = reader.readLine()) != null) &#123; writer.write(input); writer.newLine(); &#125; return targetFile; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; reader.close(); writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return null;&#125; 对拷贝后的.java源文件执行手动编译，在同级目录下生成.class文件。 123456789101112131415protected static void compileSourceFile(File f) &#123; try &#123; JavaCompiler javaCompiler = ToolProvider.getSystemJavaCompiler(); StandardJavaFileManager standardFileManager = javaCompiler.getStandardFileManager(null, null, null); Iterable&lt;? extends JavaFileObject&gt; javaFileObjects = standardFileManager.getJavaFileObjects(f); // 执行编译任务 CompilationTask task = javaCompiler.getTask(null, standardFileManager, null, null, null, javaFileObjects); task.call(); standardFileManager.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 通过自定义类加载器加载Children的java.lang.Class&lt;?&gt;对象，然后用反射机制创建Children的实例对象。 123456789101112131415161718@Testpublic void test() throws Exception &#123; // 创建自定义类加载器 CustomClassLoader classLoader = new CustomClassLoader(TARGET_CODE_LOCALTION); // E://myclassloader//classpath // 动态加载class文件到内存中（无连接） Class&lt;?&gt; c = classLoader.loadClass(\"org.ostenant.jdk8.learning.examples.classloader.custom.Children\"); // 通过反射拿到所有的方法 Method[] declaredMethods = c.getDeclaredMethods(); for (Method method : declaredMethods) &#123; if (\"say\".equals(method.getName())) &#123; // 通过反射拿到children对象 Object children = c.newInstance(); // 调用children的say()方法 method.invoke(children); break; &#125; &#125;&#125; 测试编写的类加载器(一). 测试场景一 保留static代码块，把目标类Children.java和Parent.java拷贝到类加载的目录，然后进行手动编译。 保留测试项目目录中的目标类Children.java和Parent.java。 测试结果输出： 测试结果分析： 我们成功创建了Children对象，并通过反射调用了它的say()方法。然而查看控制台日志，可以发现类加载使用的仍然是AppClassLoader，CustomClassLoader并没有生效。 查看CustomClassLoader的类加载目录： 类目录下有我们拷贝并编译的Parent和Chidren文件。 分析原因： 由于项目空间中的Parent.java和Children.java，在拷贝后并没有移除。导致AppClassLoader优先在其Classpath下面找到并成功加载了目标类。 (二). 测试场景二 注释掉static代码块（类目录下有已编译的目标类.class文件）。 移除测试项目目录中的目标类Children.java和Parent.java。 测试结果输出：测试结果分析： 我们成功通过自定义类加载器加载了目标类。创建了Children对象，并通过反射调用了它的say()方法。 至此，我们自己的一个简单的类加载器就完成了！ 参考书籍周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java虚拟机系列","slug":"Java虚拟机系列","permalink":"https://ostenant.coding.me/categories/Java虚拟机系列/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"},{"name":"JDK","slug":"JDK","permalink":"https://ostenant.coding.me/tags/JDK/"}]},{"title":"JVM系列(四) - JVM GC回收算法","slug":"JVM系列(四) - JVM GC回收算法","date":"2017-05-02T10:09:00.000Z","updated":"2018-05-08T02:49:46.090Z","comments":true,"path":"2017/05/02/JVM系列(四) - JVM GC回收算法/","link":"","permalink":"https://ostenant.coding.me/2017/05/02/JVM系列(四) - JVM GC回收算法/","excerpt":"前言第二篇介绍了Java内存运行时区域，其中程序计数器、虚拟机栈、本地方法栈 三个区域随线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，因此这几个区域的内存分配和回收都具备确定性。在这几个区域内不需要过多考虑回收的问题，因为方法结束或线程结束时，内存自然就跟随着回收了。","text":"前言第二篇介绍了Java内存运行时区域，其中程序计数器、虚拟机栈、本地方法栈 三个区域随线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，因此这几个区域的内存分配和回收都具备确定性。在这几个区域内不需要过多考虑回收的问题，因为方法结束或线程结束时，内存自然就跟随着回收了。 而Java堆 和 方法区 则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样。我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器 所关注的是这部分内存。 正文 (一). 对象生死判定如何判断Java中一个对象应该 “存活” 还是 “死去”，这是 垃圾回收器要做的第一件事。 1. 引用计数算法Java 堆 中每个具体对象（不是引用）都有一个引用计数器。当一个对象被创建并初始化赋值后，该变量计数设置为1。每当有一个地方引用它时，计数器值就加1。当引用失效时，即一个对象的某个引用超过了生命周期（出作用域后）或者被设置为一个新值时，计数器值就减1。任何引用计数为0的对象可以被当作垃圾收集。当一个对象被垃圾收集时，它引用的任何对象计数减1。 优点： 引用计数收集器执行简单，判定效率高，交织在程序运行中。对程序不被长时间打断的实时环境比较有利。 缺点： 难以检测出对象之间的循环引用。同时，引用计数器增加了程序执行的开销。所以Java语言并没有选择这种算法进行垃圾回收。 2. 可达性分析算法可达性分析算法也叫根搜索算法，通过一系列的称为 GC Roots 的对象作为起点，然后向下搜索。搜索所走过的路径称为引用链 （Reference Chain）， 当一个对象到 GC Roots 没有任何引用链相连时, 即该对象不可达，也就说明此对象是 不可用的。 如下图所示: Object5、Object6、Object7 虽然互有关联, 但它们到GC Roots是不可达的, 因此也会被判定为可回收的对象。 GC根对象 在Java中, 可作为GC Roots的对象包括以下四种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 本地方法栈 中 JNI （Native方法）引用的变量 方法区 中类静态属性引用的变量 方法区 中常量引用的变量 JVM中用到的所有现代GC算法在回收前都会先找出所有仍存活的对象。可达性分析算法是从离散数学中的图论引入的，程序把所有的引用关系看作一张图。下图展示的JVM中的内存布局可以用来很好地阐释这一概念： (二). 对象引用分类1. 强引用(Strong Reference)在代码中普遍存在的，类似Object obj = new Object()这类引用，只要强引用还在，垃圾收集器永远不会回收掉被引用的对象。 2. 软引用(Sofe Reference)有用但并非必需 的对象，可用SoftReference类来实现软引用。在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。 3. 弱引用(Weak Reference)非必需 的对象，但它的强度比软引用更弱，被弱引用关联的对象只能生存到下一次垃圾收集发生之前，JDK提供了WeakReference类来实现弱引用。无论当前内存是否足够，用软引用相关联的对象都会被回收掉。 4. 虚引用(Phantom Reference)虚引用也称为幽灵引用或幻影引用，是最弱的一种引用关系，JDK提供了PhantomReference类来实现虚引用。为一个对象设置虚引用的唯一目的是：能在这个对象在垃圾回收器回收时收到一个系统通知。 (三). finalize()二次标记一个对象是否应该在垃圾回收器在GC时回收，至少要经历两次标记过程。 第一次标记过程，通过可达性分析算法分析对象是否与GC Roots可达。经过第一次标记，并且被筛选为不可达的对象会进行第二次标记。 第二次标记过程，判断不可达对象是否有必要执行finalize方法。执行条件是当前对象的finalize方法被重写，并且还未被系统调用过。如果允许执行那么这个对象将会被放到一个叫F-Query的队列中，等待被执行。 注意：由于finalize由一个优先级比较低的Finalizer线程运行，所以该对象的的finalize方法不一定被执行，即使被执行了，也不保证finalize方法一定会执行完。如果对象第二次小规模标记，即finalize方法中拯救自己，只需要重新和引用链上的任一对象建立关联即可。 (四). 垃圾回收算法本节具体介绍一下各种垃圾回收算法的思想： 1. 标记-清除算法标记-清除算法对根集合进行扫描，对存活的对象进行标记。标记完成后，再对整个空间内未被标记的对象扫描，进行回收。 优点： 实现简单，不需要进行对象进行移动。 缺点： 标记、清除过程效率低，产生大量不连续的内存碎片，提高了垃圾回收的频率。 2. 复制算法这种收集算法解决了标记清除算法存在的效率问题。它将内存区域划分成相同的两个内存块。每次仅使用一半的空间，JVM生成的新对象放在一半空间中。当一半空间用完时进行GC，把可到达对象复制到另一半空间，然后把使用过的内存空间一次清理掉。 优点： 按顺序分配内存即可，实现简单、运行高效，不用考虑内存碎片。 缺点： 可用的内存大小缩小为原来的一半，对象存活率高时会频繁进行复制。 3. 标记-整理算法标记-整理算法 采用和 标记-清除算法 一样的方式进行对象的标记，但后续不直接对可回收对象进行清理，而是将所有的存活对象往一端空闲空间移动，然后清理掉端边界以外的内存空间。 优点： 解决了标记-清理算法存在的内存碎片问题。 缺点： 仍需要进行局部对象移动，一定程度上降低了效率。 4. 分代收集算法当前商业虚拟机都采用分代收集的垃圾收集算法。分代收集算法，顾名思义是根据对象的存活周期将内存划分为几块。一般包括年轻代、老年代 和 永久代，如图所示： 新生代（Young generation）绝大多数最新被创建的对象会被分配到这里，由于大部分对象在创建后会很快变得不可达，所以很多对象被创建在新生代，然后消失。对象从这个区域消失的过程我们称之为 minor GC。 新生代 中存在一个Eden区和两个Survivor区。新对象会首先分配在Eden中（如果新对象过大，会直接分配在老年代中）。在GC中，Eden中的对象会被移动到Survivor中，直至对象满足一定的年纪（定义为熬过GC的次数），会被移动到老年代。 可以设置新生代和老年代的相对大小。这种方式的优点是新生代大小会随着整个堆大小动态扩展。参数 -XX:NewRatio 设置老年代与新生代的比例。例如 -XX:NewRatio=8 指定 老年代/新生代 为8/1. 老年代 占堆大小的 7/8 ，新生代 占堆大小的 1/8（默认即是 1/8）。 例如： -XX:NewSize=64m -XX:MaxNewSize=1024m -XX:NewRatio=8 老年代（Old generation）对象没有变得不可达，并且从新生代中存活下来，会被拷贝到这里。其所占用的空间要比新生代多。也正由于其相对较大的空间，发生在老年代上的GC要比新生代要少得多。对象从老年代中消失的过程，可以称之为major GC（或者full GC）。 永久代（permanent generation）像一些类的层级信息，方法数据 和方法信息（如字节码，栈 和 变量大小），运行时常量池（JDK7之后移出永久代），已确定的符号引用和虚方法表等等。它们几乎都是静态的并且很少被卸载和回收，在JDK8之前的HotSpot虚拟机中，类的这些“永久的” 数据存放在一个叫做永久代的区域。 永久代一段连续的内存空间，我们在JVM启动之前可以通过设置-XX:MaxPermSize的值来控制永久代的大小。但是JDK8之后取消了永久代，这些元数据被移到了一个与堆不相连的称为元空间 (Metaspace) 的本地内存区域。 小结JDK8堆内存一般是划分为年轻代和老年代，不同年代 根据自身特性采用不同的垃圾收集算法。 对于新生代，每次GC时都有大量的对象死亡，只有少量对象存活。考虑到复制成本低，适合采用复制算法。因此有了From Survivor和To Survivor区域。 对于老年代，因为对象存活率高，没有额外的内存空间对它进行担保。因而适合采用标记-清理算法和标记-整理算法进行回收。 参考周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java虚拟机系列","slug":"Java虚拟机系列","permalink":"https://ostenant.coding.me/categories/Java虚拟机系列/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://ostenant.coding.me/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"}]},{"title":"JVM系列(三) - JVM对象探秘","slug":"JVM系列(三) - JVM对象探秘","date":"2017-04-28T03:22:00.000Z","updated":"2018-05-08T02:49:46.089Z","comments":true,"path":"2017/04/28/JVM系列(三) - JVM对象探秘/","link":"","permalink":"https://ostenant.coding.me/2017/04/28/JVM系列(三) - JVM对象探秘/","excerpt":"前言对于 JVM 运行时区域有了一定了解以后，本文将更进一步介绍虚拟机内存中的数据的细节信息。以JVM虚拟机(Hotspot)的内存区域Java堆为例，探讨Java堆是如何创建对象、如何布局对象以及如何访问对象的。","text":"前言对于 JVM 运行时区域有了一定了解以后，本文将更进一步介绍虚拟机内存中的数据的细节信息。以JVM虚拟机(Hotspot)的内存区域Java堆为例，探讨Java堆是如何创建对象、如何布局对象以及如何访问对象的。 正文 (一). 对象的创建说到对象的创建，首先让我们看看 Java 中提供的几种对象创建方式： Header 解释 使用new关键字 调用了构造函数 使用Class的newInstance方法 调用了构造函数 使用Constructor类的newInstance方法 调用了构造函数 使用clone方法 没有调用构造函数 使用反序列化 没有调用构造函数 下面举例说明五种方式的具体操作方式： Employee.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class Employee implements Cloneable, Serializable &#123; private static final long serialVersionUID = 1L; private String name; public Employee() &#123;&#125; public Employee(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public int hashCode() &#123; final int prime = 31; int result = 1; result = prime * result + ((name == null) ? 0 : name.hashCode()); return result; &#125; @Override public boolean equals(Object obj) &#123; if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; Employee other = (Employee) obj; if (name == null) &#123; if (other.name != null) return false; &#125; else if (!name.equals(other.name)) return false; return true; &#125; @Override public String toString() &#123; return \"Employee [name=\" + name + \"]\"; &#125; @Override public Object clone() &#123; Object obj = null; try &#123; obj = super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return obj; &#125;&#125; 1. new关键字这是最常见也是最简单的创建对象的方式了。通过这种方式，我们可以调用任意的构造函数(无参的和带参数的)。 1Employee emp1 = new Employee(); 1Employee emp1 = new Employee(name); 2. Class类的newInstance方法我们也可以使用Class类的newInstance方法创建对象。这个newInstance方法调用无参的构造函数创建对象。 方式一： 1Employee emp2 = (Employee) Class.forName(\"org.ostenant.jvm.instance.Employee\").newInstance(); 方式二： 1Employee emp2 = Employee.class.newInstance(); 3. Constructor类的newInstance方法和Class类的newInstance方法很像， java.lang.reflect.Constructor类里也有一个newInstance方法可以创建对象。我们可以通过这个newInstance方法调用有参数的和私有的构造函数。其中，Constructor可以从对应的Class类中获得。 12Constructor&lt;Employee&gt; constructor = Employee.class.getConstructor();Employee emp3 = constructor.newInstance(); 这两种newInstance方法就是大家所说的反射。事实上Class的newInstance方法内部调用Constructor的newInstance方法。 4. Clone方法无论何时我们调用一个对象的clone方法，JVM都会创建一个新的对象，将前面对象的内容全部拷贝进去。用clone方法创建对象并不会调用任何构造函数。 为了使用clone方法，我们需要先实现Cloneable接口并实现其定义的clone方法。 1Employee emp4 = (Employee) emp3.clone(); 5. 反序列化当我们序列化和反序列化一个对象，JVM会给我们创建一个单独的对象。在反序列化时，JVM创建对象并不会调用任何构造函数。 为了反序列化一个对象，我们需要让我们的类实现Serializable接口。 12345678ByteArrayOutputStream out = new ByteArrayOutputStream();ObjectOutputStream oos = new ObjectOutputStream(out);oos.writeObject(emp4);ByteArrayInputStream in = new ByteArrayInputStream(oos.toByteArray());ObjectInputStream ois =new ObjectInputStream(in);Employee emp5 = (Employee) in.readObject(); 本文以new关键字为例，讲述JVM堆中对象实例的创建过程如下： 当虚拟机遇到一条new指令时，首先会检查这个指令的参数能否在常量池中定位一个符号引用。然后检查这个符号引用的类字节码对象是否加载、解析和初始化。如果没有，将执行对应的类加载过程。 类加载 完成以后，虚拟机将会为新生对象分配内存区域，对象所需内存空间大小在类加载完成后就已确定。 内存分配 完成以后，虚拟机将分配到的内存空间都初始化为零值。 虚拟机对对象进行一系列的设置，如所属类的元信息、对象的哈希码、对象GC分带年龄 、线程持有的锁 、偏向线程ID 等信息。这些信息存储在对象头 (Object Header)。 上述工作完成以后，从虚拟机的角度来说，一个新的对象已经产生了。然而，从Java程序的角度来说，对象创建才刚开始。 (二). 对象的布局HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头在HotSpot虚拟机中，对象头有两部分信息组成：运行时数据 和 类型指针。 1. 运行时数据用于存储对象自身运行时的数据，如哈希码（hashCode）、GC分带年龄、线程持有的锁、偏向线程ID 等信息。 这部分数据的长度在32位和64位的虚拟机（暂不考虑开启压缩指针的场景）中分别为32个和64个Bit，官方称它为 “Mark Word”。 在32位的HotSpot虚拟机中对象未被锁定的状态下，Mark Word的32个Bit空间中的25Bit用于存储对象哈希码（HashCode），4Bit用于存储对象分代年龄，2Bits用于存储锁标志位，1Bit固定为0。 在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容如下表所示： 存储内容 标志位 状态 对象哈希码、对象分代年龄 01 未锁定 指向锁记录的指针 00 轻量级锁定 指向重量级锁的指针 10 膨胀（重量级锁定） 空，不需要记录信息 11 GC标记 偏向线程ID、偏向时间戳、对象分代年龄 01 可偏向 2. 类型指针指向实例对象的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据。 实例数据实例数据 部分是对象真正存储的有效信息，无论是从父类继承下来的还是该类自身的，都需要记录下来，而这部分的存储顺序受虚拟机的分配策略和定义的顺序的影响。 默认分配策略： long/double -&gt; int/float -&gt; short/char -&gt; byte/boolean -&gt; reference 如果设置了-XX:FieldsAllocationStyle=0（默认是1），那么引用类型数据就会优先分配存储空间： reference -&gt; long/double -&gt; int/float -&gt; short/char -&gt; byte/boolean 结论： 分配策略总是按照字节大小由大到小的顺序排列，相同字节大小的放在一起。 对齐填充HotSpot虚拟机要求每个对象的起始地址必须是8字节的整数倍，也就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（32位为1倍，64位为2倍），因此，当对象实例数据部分没有对齐的时候，就需要通过对齐填充来补全。 (三). 对象的访问定位Java程序需要通过 JVM 栈上的引用访问堆中的具体对象。对象的访问方式取决于 JVM 虚拟机的实现。目前主流的访问方式有 句柄 和 直接指针 两种方式。 指针： 指向对象，代表一个对象在内存中的起始地址。句柄： 可以理解为指向指针的指针，维护着对象的指针。句柄不直接指向对象，而是指向对象的指针（句柄不发生变化，指向固定内存地址），再由对象的指针指向对象的真实内存地址。 1. 句柄Java堆中划分出一块内存来作为句柄池，引用中存储对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息，具体构造如下图所示： 优势：引用中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而引用本身不需要修改。 2. 直接指针如果使用直接指针访问，引用 中存储的直接就是对象地址，那么Java堆对象内部的布局中就必须考虑如何放置访问类型数据的相关信息。 优势：速度更快，节省了一次指针定位的时间开销。由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是非常可观的执行成本。 参考周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA虚拟机系列","slug":"JAVA虚拟机系列","permalink":"https://ostenant.coding.me/categories/JAVA虚拟机系列/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://ostenant.coding.me/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"}]},{"title":"JVM系列(二) - JVM内存区域和内存溢出异常详解","slug":"JVM系列(二) - JVM内存区域和内存溢出异常详解","date":"2017-04-25T09:57:00.000Z","updated":"2018-05-08T02:49:46.090Z","comments":true,"path":"2017/04/25/JVM系列(二) - JVM内存区域和内存溢出异常详解/","link":"","permalink":"https://ostenant.coding.me/2017/04/25/JVM系列(二) - JVM内存区域和内存溢出异常详解/","excerpt":"前言JVM内存区域包括PC计数器、Java虚拟机栈、本地方法栈、堆、方法区、运行时常量池和直接内存。 本文主要介绍各个内存区域的作用和特性，同时分别阐述各个区域发生内存溢出的可能性和异常类型。","text":"前言JVM内存区域包括PC计数器、Java虚拟机栈、本地方法栈、堆、方法区、运行时常量池和直接内存。 本文主要介绍各个内存区域的作用和特性，同时分别阐述各个区域发生内存溢出的可能性和异常类型。 正文 (一). JVM内存区域Java虚拟机执行Java程序的过程中，会把所管理的内存划分为若干不同的数据区域。这些内存区域各有各的用途，以及创建和销毁时间。有的区域随着虚拟机进程的启动而存在，有的区域伴随着用户线程的启动和结束而创建和销毁。 JVM内存区域也称为Java运行时数据区域。其中包括：程序计数器、虚拟机栈、本地方法栈、堆、静态方法区、静态常量池等。 注意：程序计数器、虚拟机栈、本地方法栈属于每个线程私有的；堆和方法区属于线程共享访问的。 1.1. PC计数器程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码行号指示器。 当前线程所执行的字节码行号指示器。 每个线程都有一个自己的PC计数器。 线程私有的，生命周期与线程相同，随JVM启动而生，JVM关闭而死。 线程执行Java方法时，记录其正在执行的虚拟机字节码指令地址。 线程执行Native方法时，计数器记录为空(Undefined)。 唯一在Java虚拟机规范中没有规定任何OutOfMemoryError情况区域。 1.2. Java虚拟机栈线程私有内存空间，它的生命周期和线程相同。线程执行期间，每个方法执行时都会创建一个栈帧(Stack Frame) ，用于存储 局部变量表、操作数栈 、动态链接 、方法出口 等信息。 局部变量表 操作数栈 动态链接 方法出口 每一个方法从调用直到执行完成的过程，就对应着一个栈帧在虚拟机栈中的入栈和出栈的全过程。 下面依次解释栈帧里的四种组成元素的具体结构和功能： 1). 局部变量表局部变量表是一组变量值的存储空间，用于存储方法参数和局部变量。 在 Class 文件的方法表的 Code 属性的 max_locals 指定了该方法所需局部变量表的最大容量。 局部变量表在编译期间分配内存空间，可以存放编译期的各种变量类型： 基本数据类型 ：boolean, byte, char, short, int, float, long, double等8种； 对象引用类型 ：reference，指向对象起始地址的引用指针； 返回地址类型 ：returnAddress，返回地址的类型。 变量槽(Variable Slot)： 变量槽是局部变量表的最小单位，规定大小为32位。对于64位的long和double变量而言，虚拟机会为其分配两个连续的Slot空间。 2). 操作数栈操作数栈（Operand Stack）也常称为操作栈，是一个后入先出栈。在 Class 文件的 Code 属性的 max_stacks 指定了执行过程中最大的栈深度。Java虚拟机的解释执行引擎被称为基于栈的执行引擎 ，其中所指的栈就是指－操作数栈。 和局部变量表一样，操作数栈也是一个以32字长为单位的数组。 虚拟机在操作数栈中可存储的数据类型：int、long、float、double、reference和returnType等类型 (对于byte、short以及char类型的值在压入到操作数栈之前，也会被转换为int)。 和局部变量表不同的是，它不是通过索引来访问，而是通过标准的栈操作 — 压栈和出栈来访问。比如，如果某个指令把一个值压入到操作数栈中，稍后另一个指令就可以弹出这个值来使用。 虚拟机把操作数栈作为它的工作区——大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。 123456beginiload_0 // push the int in local variable 0 onto the stackiload_1 // push the int in local variable 1 onto the stackiadd // pop two ints, add them, push resultistore_2 // pop int, store into local variable 2end 在这个字节码序列里，前两个指令 iload_0 和 iload_1 将存储在局部变量表中索引为0和1的整数压入操作数栈中，其后iadd指令从操作数栈中弹出那两个整数相加，再将结果压入操作数栈。第四条指令istore_2则从操作数栈中弹出结果，并把它存储到局部变量表索引为2的位置。 下图详细表述了这个过程中局部变量表和操作数栈的状态变化(图中没有使用的局部变量表和操作数栈区域以空白表示)。 3). 动态链接每个栈帧都包含一个指向运行时常量池中所属的方法引用，持有这个引用是为了支持方法调用过程中的动态链接。 Class文件的常量池中存在有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用为参数。这些符号引用： 静态解析：一部分会在类加载阶段或第一次使用的时候转化为直接引用（如final、static域等），称为静态解析， 动态解析：另一部分将在每一次的运行期间转化为直接引用，称为动态链接。 4). 方法返回地址当一个方法开始执行以后，只有两种方法可以退出当前方法： 正常返回：当执行遇到返回指令，会将返回值传递给上层的方法调用者，这种退出的方式称为正常完成出口(Normal Method Invocation Completion)，一般来说，调用者的PC计数器可以作为返回地址。 异常返回：当执行遇到异常，并且当前方法体内没有得到处理，就会导致方法退出，此时是没有返回值的，称为异常完成出口(Abrupt Method Invocation Completion)，返回地址要通过异常处理器表来确定。 当一个方法返回时，可能依次进行以下3个操作： 恢复上层方法的局部变量表和操作数栈。 把返回值压入调用者栈帧的操作数栈。 将PC计数器的值指向下一条方法指令位置。 小结： 注意：在Java虚拟机规范中，对这个区域规定了两种异常。其一：如果当前线程请求的栈深度大于虚拟机栈所允许的深度，将会抛出 StackOverflowError 异常（在虚拟机栈不允许动态扩展的情况下）；其二：如果扩展时无法申请到足够的内存空间，就会抛出 OutOfMemoryError 异常。 1.3. 本地方法栈本地方法栈和Java虚拟机栈发挥的作用非常相似，主要区别是Java虚拟机栈执行的是Java方法服务，而本地方法栈执行Native方法服务(通常用C编写)。 有些虚拟机发行版本(譬如Sun HotSpot虚拟机)直接将本地方法栈和Java虚拟机栈合二为一。与虚拟机栈一样，本地方法栈也会抛出StackOverflowError和OutOfMemoryError异常。 1.4. 堆Java堆是被所有线程共享的最大的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 在Java中，堆被划分成两个不同的区域：新生代 (Young Generation) 、老年代 (Old Generation) 。新生代 (Young) 又被划分为三个区域：一个Eden区和两个Survivor区 - From Survivor区和To Survivor区。 简要归纳：新的对象分配是首先放在年轻代 (Young Generation) 的Eden区，Survivor区作为Eden区和Old区的缓冲，在Survivor区的对象经历若干次收集仍然存活的，就会被转移到老年代Old中。 这样划分的目的是为了使JVM能够更好的管理堆内存中的对象，包括内存的分配以及回收。 1.5. 方法区方法区和Java堆一样，为多个线程共享，它用于存储类信息、常量、静态常量和即时编译后的代码等数据。 1.6. 运行时常量池运行时常量池是方法区的一部分，Class文件中除了有类的版本、字段、方法和接口等描述信息外，还有一类信息是常量池，用于存储编译期间生成的各种字面量和符号引用。 1.7. 直接内存直接内存不属于虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。Java NIO允许Java程序直接访问直接内存，通常直接内存的速度会优于Java堆内存。因此，对于读写频繁、性能要求高的场景，可以考虑使用直接内存。 (二). 常见内存溢出异常除了程序计数器外，Java虚拟机的其他运行时区域都有可能发生OutOfMemoryError的异常，下面分别给出验证： 2.1. Java堆溢出Java堆能够存储对象实例。通过不断地创建对象，并保证GC Roots到对象有可达路径来避免垃圾回收机制清除这些对象。当对象数量到达最大堆的容量限制时就会产生OutOfMemoryError异常。 设置JVM启动参数：-Xms20M设置堆的最小内存为20M，-Xmx20M设置堆的最大内存和最小内存一样，这样可以防止Java堆在内存不足时自动扩容。-XX:+HeapDumpOnOutOfMemoryError参数可以让虚拟机在出现内存溢出异常时Dump出内存堆运行时快照。 HeapOOM.java 1234567891011121314/** * VM Args: -Xms20M -Xmx20M -XX:+HeapDumpOnOutOfMemoryError */public class HeapOOM &#123; public static class OOMObject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMObject&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new OOMObject()); &#125; &#125;&#125; 测试运行结果： 打开Java VisualVM导出Heap内存运行时的dump文件。 HeapOOM对象不停地被创建，堆内存使用达到99%。垃圾回收器不断地尝试回收但都以失败告终。 分析：遇到这种情况，通常要考虑内存泄露和内存溢出两种可能性。 如果是内存泄露： 进一步使用Java VisualVM工具进行分析，查看泄露对象是通过怎样的路径与GC Roots关联而导致垃圾回收器无法回收的。 如果是内存溢出： 通过Java VisualVM工具分析，不存在泄露对象，也就是说堆内存中的对象必须得存活着。就要考虑如下措施： 从代码上检查是否存在某些对象生命周期过长、持续状态时间过长的情况，尝试减少程序运行期的内存。 检查虚拟机的堆参数(-Xmx与-Xms)，对比机器的物理内存看是否还可以调大。 2.2. 虚拟机和本地方法栈溢出关于虚拟机栈和本地方法栈，分析内存异常类型可能存在以下两种： 如果现场请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。 如果虚拟机在扩展栈时无法申请到足够的内存空间，可能会抛出OutOfMemoryError异常。 可以划分为两类问题，当栈空间无法分配时，到底时栈内存太小，还是已使用的栈内存过大。 StackOverflowError异常测试方案一： 使用-Xss参数减少栈内存的容量，异常发生时打印栈的深度。 定义大量的本地局部变量，以达到增大栈帧中的本地变量表的长度。 设置JVM启动参数：-Xss128k设置栈内存的大小为128k。 JavaVMStackSOF.java 123456789101112131415161718192021/** * VM Args: -Xss128k */public class JavaVMStackSOF &#123; private int stackLength = 1; private void stackLeak() &#123; stackLength++; stackLeak(); &#125; public static void main(String[] args) &#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try &#123; oom.stackLeak(); &#125; catch (Throwable e) &#123; System.out.println(\"Stack length: \" + oom.stackLength); throw e; &#125; &#125;&#125; 测试结果： 分析：在单个线程下，无论是栈帧太大还是虚拟机栈容量太小，当无法分配内存的时候，虚拟机抛出的都是StackOverflowError异常。 测试方案二： 不停地创建线程并保持线程运行状态。 JavaVMStackOOM.java 12345678910111213141516171819202122232425/** * VM Args: -Xss2M */public class JavaVMStackOOM &#123; private void running() &#123; while (true) &#123; &#125; &#125; public void stackLeakByThread() &#123; while (true) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; running(); &#125; &#125;).start(); &#125; &#125; public static void main(String[] args) &#123; JavaVMStackOOM oom = new JavaVMStackOOM(); oom.stackLeakByThread(); &#125;&#125; 测试结果：1Exception in thread \"main\" java.lang.OutOfMemoryError: unable to create new native thread 上述测试代码运行时存在较大的风险，可能会导致操作系统假死，这里就不亲自测试了，引用作者的测试结果。 2.3. 方法区和运行时常量池溢出(一). 运行时常量池内存溢出测试运行时常量和字面量都存放于运行时常量池中，常量池又是方法区的一部分，因此两个区域的测试是一样的。这里采用String.intern()进行测试： String.intern()是一个native方法，它的作用是：如果字符串常量池中存在一个String对象的字符串，那么直接返回常量池中的这个String对象；否则，将此String对象包含的字符串放入常量池中，并且返回这个String对象的引用。 设置JVM启动参数：通过-XX:PermSize=10M和-XX:MaxPermSize=10M限制方法区的大小为10M，从而间接的限制其中常量池的容量。 RuntimeConstantPoolOOM.java 123456789101112131415/** * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M */public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; // 使用List保持着常量池的引用，避免Full GC回收常量池 List&lt;String&gt; list = new ArrayList&lt;&gt;(); // 10MB的PermSize在Integer范围内足够产生OOM了 int i = 0; while (true) &#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125; 测试结果分析： JDK1.6版本运行结果：12Exception in thread \"main\" java.lang.OutOfMemoryError: PermGen space at java.lang.String.intern(Native Method) JDK1.6版本运行结果显示常量池会溢出并抛出永久带的OutOfMemoryError异常。而JDK1.7及以上的版本则不会得到相同的结果，它会一直循环下去。 (二). 方法区内存溢出测试方法区存放Class相关的信息，比如类名、访问修饰符、常量池、字段描述、方法描述等。对于方法区的内存溢出的测试，基本思路是在运行时产生大量类字节码区填充方法区。 这里引入Spring框架的CGLib动态代理的字节码技术，通过循环不断生成新的代理类，达到方法区内存溢出的效果。 JavaMethodAreaOOM.java 1234567891011121314151617181920212223242526/** * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M */public class JavaMethodAreaOOM &#123; public static void main(String[] args) &#123; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; return proxy.invokeSuper(obj, args); &#125; &#125;); enhancer.create(); &#125; &#125; private static class OOMObject &#123; public OOMObject() &#123; &#125; &#125;&#125; JDK1.6版本运行结果：1234Exception in thread \"main\" java.lang.OutOfMemoryError: PermGen space at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClassCond(ClassLoader.java:632) at java.lang.ClassLoader.defineClass(ClassLoader.java:616) 测试结果分析： JDK1.6版本运行结果显示常量池会溢出并抛出永久带的OutOfMemoryError异常。而JDK1.7及以上的版本则不会得到相同的结果，它会一直循环下去。 2.4. 直接内存溢出本机直接内存的容量可通过-XX:MaxDirectMemorySize指定，如果不指定，则默认与Java堆最大值(-Xmx指定)一样。 测试场景： 直接通过反射获取Unsafe实例，通过反射向操作系统申请分配内存： 设置JVM启动参数：-Xmx20M指定Java堆的最大内存，-XX:MaxDirectMemorySize=10M指定直接内存的大小。 DirectMemoryOOM.java 12345678910111213141516/** * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M */public class DirectMemoryOOM &#123; private static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception &#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while (true) &#123; unsafe.allocateMemory(_1MB); &#125; &#125;&#125; 测试结果： 测试结果分析： 由DirectMemory导致的内存溢出，一个明显的特征是Heap Dump文件中不会看到明显的异常信息。如果OOM发生后Dump文件很小，并且程序中直接或者间接地使用了NIO，那么就可以考虑一下这方面的问题。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java虚拟机系列","slug":"Java虚拟机系列","permalink":"https://ostenant.coding.me/categories/Java虚拟机系列/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://ostenant.coding.me/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"}]},{"title":"JVM系列(一) - JVM总体概述","slug":"JVM系列(一) - JVM总体概述","date":"2017-04-22T06:55:00.000Z","updated":"2018-05-08T02:49:46.089Z","comments":true,"path":"2017/04/22/JVM系列(一) - JVM总体概述/","link":"","permalink":"https://ostenant.coding.me/2017/04/22/JVM系列(一) - JVM总体概述/","excerpt":"前言JVM是Java Virtual Machine(Java虚拟机)的缩写，JVM是一种用于计算设备的规范，它是一个虚构的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。","text":"前言JVM是Java Virtual Machine(Java虚拟机)的缩写，JVM是一种用于计算设备的规范，它是一个虚构的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。 JVM屏蔽了与具体操作系统平台相关的信息，使Java程序只需生成在Java虚拟机上一次编译，多次运行，具有跨平台性。JVM在执行字节码时，实际上最终还是把字节码解释成具体平台上的机器指令执行。 Java虚拟机包括一套字节码指令集、一组寄存器、一个栈、一个垃圾回收堆和一个存储方法区。 本文将简述以下内容: JVM是什么？ JVM能干什么？ JVM生命周期？ JVM组成架构？ 正文 JVM是什么JDK、JRE和JVM对比 JVM，JRE，JDK 都是 java 语言的支柱，他们分工协作。但不同的是 Jdk 和 JRE 是真实存在的，而 JVM 是一个抽象的概念，并不真实存在。 JDKJDK(Java Development Kit) 是 Java 语言的软件开发工具包（SDK）。JDK 物理存在，是 programming tools、JRE 和 JVM 的一个集合。 JREJRE（Java Runtime Environment）Java 运行时环境，JRE 是物理存在的，主要由Java API 和 JVM 组成，提供了用于执行 java 应用程序最低要求的环境。 JVMJVM是一种用于计算设备的规范，它是一个虚构的计算机的软件实现，简单的说，JVM是运行byte code字节码程序的一个容器。 JVM的特点 基于堆栈`的虚拟机 ：最流行的计算机体系结构，如英特尔X86架构和ARM架构上运行基于寄存器 。比如，安卓的Davilk虚拟机就是基于寄存器结构 但是，JVM是基于栈结构的。 符号引用 ：除了基本类型以外的数据 （类和接口） 都是通过符号来引用，而不是通过显式地使用内存地址来引用。 垃圾收集 ：一个类的实例是由用户程序创建和垃圾回收自动销毁。 网络字节顺序 ：Java class文件用网络字节码顺序来进行存储，保证了小端的Intel x86架构和大端的RISC系列的架构之间的无关性。 JVM字节码JVM使用Java字节码的方式，作为Java 用户语言 和 机器语言 之间的中间语言。实现一个通用的、 机器无关 的执行平台。 JVM能干什么基于安全方面考虑，JVM 要求在 class 文件中使用强制性的语法和约束，但任意一门语言都可以转换为被 JVM 接受的有效的 class 文件。作为一个通用的、机器无关的执行平台，任何其他语言的实现者都可将 JVM 当作他的语言产品交付媒介。 JVM 中执行过程如下： 加载代码 验证代码 执行代码 提供运行环境 JVM生命周期 启动：任何一个拥有main方法的class都可以作为JVM实例运行的起点。 运行：main函数为起点，程序中的其他线程均有它启动，包括daemon守护线程和non-daemon普通线程。daemon是JVM自己使用的线程比如GC线程，main方法的初始线程是non-daemon。 消亡：所有线程终止时，JVM实例结束生命。 JVM组成架构JAVA 代码执行过程如下： 1. 类加载器（Class Loader）类加载器 负责加载程序中的类型（类和接口），并赋予唯一的名字予以标识。 JDK 默认提供的三种 ClassLoader如下： 类加载器的关系 Bootstrap Classloader 是在Java虚拟机启动后初始化的。 Bootstrap Classloader 负责加载 ExtClassLoader，并且将 ExtClassLoader的父加载器设置为 Bootstrap Classloader Bootstrap Classloader 加载完 ExtClassLoader 后，就会加载 AppClassLoader，并且将 AppClassLoader 的父加载器指定为 ExtClassLoader。 类加载器的作用 Class Loader 实现 负责加载 Bootstrap Loader C++ %JAVA_HOME%/jre/lib, %JAVA_HOME%/jre/classes以及-Xbootclasspath参数指定的路径以及中的类 Extension ClassLoader Java %JAVA_HOME%/jre/lib/ext，路径下的所有classes目录以及java.ext.dirs系统变量指定的路径中类库 Application ClassLoader Java Classpath所指定的位置的类或者是jar文档，它也是Java程序默认的类加载器 双亲委托机制Java中ClassLoader的加载采用了双亲委托机制，采用双亲委托机制加载类的时候采用如下的几个步骤： 当前ClassLoader首先从自己已经加载的类中查询是否此类已经加载，如果已经加载则直接返回原来已经加载的类。 当前ClassLoader的缓存中没有找到被加载的类的时候，委托父类加载器去加载，父类加载器采用同样的策略，首先查看自己的缓存，然后委托父类的父类去加载，一直到Bootstrap ClassLoader。 当所有的父类加载器都没有加载的时候，再由当前的类加载器加载，并将其放入它自己的缓存中，以便下次有加载请求的时候直接返回。 小结 ：双亲委托机制的核心思想分为两个步骤。其一，自底向上检查类是否已经加载；其二，自顶向下尝试加载类。 ClassLoader隔离问题每个类装载器都有一个自己的命名空间用来保存已装载的类。当一个类装载器装载一个类时，它会通过保存在命名空间里的类全局限定名(Fully Qualified Class Name)进行搜索来检测这个类是否已经被加载了。 JVM 及 Dalvik 对类唯一的识别是 ClassLoader id + PackageName + ClassName，所以一个运行程序中是有可能存在两个包名和类名完全一致的类的。并且如果这两个”类”不是由一个 ClassLoader 加载，是无法将一个类的示例强转为另外一个类的，这就是 ClassLoader 隔离。 双亲委托 是 ClassLoader类一致问题的一种解决方案，也是 Android 差价化开发和热修复的基础。 类装载器特点Java提供了动态加载特性。在运行时的第一次引用到一个class的时候会对它进行装载(Loading) 、 链接(Linking) 和 初始化(Initialization) ，而不是在编译时进行。不同的JVM的实现不同，本文所描述的内容均只限于Hotspot JVM。 JVM的类装载器负责动态装载，Java的类装载器有如下几个特点： 层级结构：Java里的类装载器被组织成了有父子关系的层级结构。Bootstrap类装载器是所有装载器的父亲。 代理模式： 基于层级结构，类的代理可以在装载器之间进行代理。当装载器装载一个类时，首先会检查它在父装载器中是否进行了装载。如果上层装载器已经装载了这个类，这个类会被直接使用。反之，类装载器会请求装载这个类 可见性限制：一个子装载器可以查找父装载器中的类，但是一个父装载器不能查找子装载器里的类。 不允许卸载：类装载器可以装载一个类但是不可以卸载它，不过可以删除当前的类装载器，然后创建一个新的类装载器装载。 类装载器过程 加载（Loading） 首先，根据类的全限定名找到代表这个类的Class文件，然后读取到一个字节数组中。接着，这些字节会被解析检验它们是否代表一个Class对象 并包含正确的major、minor版本信息。直接父类 的类和接口也会被加载进来。这些操作一旦完成，类或者接口对象 就从二进制表示中创建出来了。 链接（Linking） 链接是检验类或接口并准备类型和父类接口的过程。链接过程包含三步：校验（Verifying）、准备（Preparing）、部分解析（Optionally resolving）。 验证 这是类装载中最复杂的过程，并且花费的时间也是最长的。任务是确保导入类型的准确性，验证阶段做的检查，运行时不需要再做。虽然减慢加了载速度，但是避免了多次检查。 准备 准备过程通常分配一个结构用来存储类信息，这个结构中包含了类中定义的成员变量，方法 和接口信息等。 解析 解析是可选阶段，把这个类的常量池中的所有的符号引用改变成直接引用。如果不执行，符号解析要等到字节码指令使用这个引用时才会进行。 初始化（Initialization） 把类中的变量初始化成合适的值。执行静态初始化程序，把静态变量初始化成指定的值。 JVM规范定义了上面的几个任务，不过它允许具体执行的时候能够有些灵活的变动。 2. 执行引擎（Execution Engine）通过类装载器装载的，被分配到JVM的运行时数据区的字节码会被执行引擎执行。 执行引擎 以指令为单位读取 Java 字节码。它就像一个 CPU 一样，一条一条地执行机器指令。每个字节码指令都由一个1字节的操作码和附加的操作数组成。执行引擎 取得一个操作码，然后根据操作数来执行任务，完成后就继续执行下一条操作码。 不过 Java 字节码是用一种人类可以读懂的语言编写的，而不是用机器可以直接执行的语言。因此，执行引擎 必须把字节码转换成可以直接被 JVM 执行的语言。 字节码 可以通过以下两种方式转换成机器语言： 解释器 解释器 一条一条地读取字节码，解释 并且 执行 字节码指令。因为它一条一条地解释和执行指令，所以它可以很快地解释字节码，但是执行起来会比较慢。这是解释执行的语言的一个缺点。字节码这种“语言”基本来说是解释执行的。 即时（Just-In-Time)编译器 即时编译器 被引入用来弥补解释器的缺点。执行引擎 首先按照 解释执行 的方式来执行，然后在合适的时候，即时编译器 把 整段字节码 编译成 本地代码。然后，执行引擎就没有必要再去解释执行方法了，它可以直接通过本地代码去执行它。执行本地代码比一条一条进行解释执行的速度快很多。编译后的代码可以执行的很快，因为本地代码是保存在缓存里的。 Java 字节码是解释执行的，但是没有直接在 JVM 宿主执行原生代码快。为了提高性能，Oracle Hotspot 虚拟机会找到执行最频繁的字节码片段并把它们编译成原生机器码。编译出的原生机器码被存储在非堆内存的代码缓存中。 通过这种方法（JIT），Hotspot 虚拟机将权衡下面两种时间消耗：将字节码编译成本地代码需要的额外时间和解释执行字节码消耗更多的时间。 这里插入一下 Android 5.0 以后用的 ART 虚拟机使用的是 AOT 机制。 Dalvik 是依靠一个 Just-In-Time (JIT)编译器去解释字节码。开发者编译后的应用代码需要通过一个解释器在用户的设备上运行，这一机制并不高效，但让应用能更容易在不同硬件和架构上运行。ART 则完全改变了这套做法，在应用安装时就预编译字节码到机器语言，这一机制叫Ahead-Of-Time (AOT）编译。在移除解释代码这一过程后，应用程序执行将更有效率，启动更快。 参考周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java虚拟机系列","slug":"Java虚拟机系列","permalink":"https://ostenant.coding.me/categories/Java虚拟机系列/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://ostenant.coding.me/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"}]},{"title":"ECMAScript 6入门篇(二) - 变量的解构赋值","slug":"ECMAScript 6入门篇(二) - 变量的解构赋值","date":"2017-04-21T14:27:00.000Z","updated":"2018-05-08T02:49:46.088Z","comments":true,"path":"2017/04/21/ECMAScript 6入门篇(二) - 变量的解构赋值/","link":"","permalink":"https://ostenant.coding.me/2017/04/21/ECMAScript 6入门篇(二) - 变量的解构赋值/","excerpt":"简介ES6允许按照一定的模式，对数组和对象进行值提取，然后将值赋给变量，这叫做变量的解构（Destructuring）。值得一提的是，解构只能用于数组或对象，原始数据类型的值可以转换为相应的对象。","text":"简介ES6允许按照一定的模式，对数组和对象进行值提取，然后将值赋给变量，这叫做变量的解构（Destructuring）。值得一提的是，解构只能用于数组或对象，原始数据类型的值可以转换为相应的对象。 ES5变量赋值的方式123var a = 1;var b = 2;var c = 3; ES6变量赋值的方式1var [a, b, c] = [1, 2, 3]; 上面代码表示，可以从数组中提取值，按照对应位置，对变量赋值。 基础数组的解构赋值1. 数组嵌套赋值1234567891011121314// 嵌套方式var [foo, [[bar], baz]] = [1, [[2], 3]];foo // 1bar // 2baz // 3// 省略方式var [,,third] = [\"foo\", \"bar\", \"baz\"];third // \"baz\"// 可变数组var [head, ...tail] = [1, 2, 3, 4];head // 1tail // [2, 3, 4] 如果解构不成功，变量的值就等于undefined。 2. 数组解构失败123456var [foo] = []; // Empty Arrayvar [foo] = 1; // Numbervar [foo] = 'Hello'; // Stringvar [foo] = false; // Booleanvar [foo] = NaN; // 非数字值var [bar, foo] = [1]; // 2 -&gt; 1 以上几种情况都属于解构不成功，foo的值都会等于undefined。另一种情况是不完全解构。 3. 数组局部解构123var [x, y] = [1, 2, 3];x // 1y // 2 以上情况，x和y都能成功解析赋值。4. 空值未定义值解构123// 报错var [foo] = undefined;var [foo] = null; 以上情况，数组变量赋值为null或undefined会报错。因为null和undefined不能转换为相应的对象。 5. 数组解构默认值12345678910var [foo = true] = [];foo // true[x, y = 'b'] = ['a'];x // 'a'y // 'b'[x, y = 'b'] = ['a', 'undefined'];x // 'a'y // 'b' 6. Set结构的数组解构12[a, b, c] = new Set(['a', 'b', 'c']);a // \"a\" 事实上，只要某种数据结构具有Iterator接口，都可以采用数组形式的结构赋值。 对象的解构赋值解构不仅可以用于数组，还可以用于对象。1. 对象解构基本用法123var &#123; foo, bar &#125; = &#123; foo: \"aaa\", bar: \"bbb\" &#125;;foo // \"aaa\"bar // \"bbb\" 2. 位置置换赋值方式对象的解构与数组有一个重要的不同。数组的元素是按次序排列的，变量的取值由它的位置决定；而对象的属性没有次序，变量必须与属性同名，才能取到正确的值。123456var &#123; bar, foo &#125; = &#123; foo: \"aaa\", bar: \"bbb\" &#125;;foo // \"aaa\"bar // \"bbb\"var &#123; baz &#125; = &#123; foo: \"aaa\", bar: \"bbb\" &#125;;baz // undefined 上面代码的第一个例子，等号左边的两个变量的次序，与等号右边两个同名属性的次序不一致，但是对取值完全没有影响。第二个例子的变量没有对应的同名属性，导致取不到值，最后等于undefined。 3. 变量别名赋值方式如果变量名与属性名不一致，必须写成下面这样。12var &#123; baz: foo &#125; = &#123; foo: \"aaa\", bar: \"bbb\" &#125;;baz // \"aaa\" 4. 对象嵌套结构解构赋值12345678910var o = &#123; p: [ \"Hello\", &#123; y: \"World\" &#125; ]&#125;;var &#123; p: [x, &#123; y &#125;] &#125; = o;x // \"Hello\"y // \"World\" 对象的解构也可以指定默认值。12345var &#123; x = 3 &#125; = &#123;&#125;;x // 3var &#123;x, y = 5&#125; = &#123;x: 1&#125;;console.log(x, y) // 1, 5 用途1. 交换变量的值1234let x = 1;let y = 2;[x, y] = [y, x]; 上面代码交换变量x和y的值，这样的写法不仅简洁，而且易读，语义非常清晰。 2. 从函数返回多个值函数只能返回一个值，如果要返回多个值，只能将它们放在数组或对象里返回。有了解构赋值，取出这些值就非常方便。 1234567891011121314// 返回一个数组function example() &#123; return [1, 2, 3];&#125;let [a, b, c] = example();// 返回一个对象function example() &#123; return &#123; foo: 1, bar: 2 &#125;;&#125;let &#123; foo, bar &#125; = example(); 3. 函数入参的定义1234567// 参数是一组有次序的值function f([x, y, z]) &#123; ... &#125;f([1, 2, 3]);// 参数是一组无次序的值function f(&#123;x, y, z&#125;) &#123; ... &#125;f(&#123;z: 3, y: 2, x: 1&#125;); 4. 提取JSON数据解构赋值对提取JSON对象中的数据，尤其有用12345678910let jsonData = &#123; id: 42, status: \"OK\", data: [867, 5309]&#125;;let &#123; id, status, data: number &#125; = jsonData;console.log(id, status, number);// 42, \"OK\", [867, 5309] 5. 函数参数的默认值1234567891011jQuery.ajax = function (url, &#123; async = true, beforeSend = function () &#123;&#125;, cache = true, complete = function () &#123;&#125;, crossDomain = false, global = true, // ... more config&#125;) &#123; // ... do stuff&#125;; 指定参数的默认值，就避免了在函数体内部再写var foo = config.foo || &#39;default foo&#39;;这样的语句。 6. 遍历Map结构任何部署了Iterator接口的对象，都可以用for...of循环遍历。Map结构原生支持Iterator接口，配合变量的解构赋值，获取键名和键值就非常方便。 123456789var map = new Map();map.set('first', 'hello');map.set('second', 'world');for (let [key, value] of map) &#123; console.log(key + \" is \" + value);&#125;// first is hello// second is world 如果只想获取键名，或者只想获取键值，可以写成下面这样。123456789// 获取键名for (let [key] of map) &#123; // ...&#125;// 获取键值for (let [,value] of map) &#123; // ...&#125; 7. 输入模块的指定方法加载模块时，往往需要指定输入哪些方法。解构赋值使得输入语句非常清晰。1const &#123; SourceMapConsumer, SourceNode &#125; = require(\"source-map\"); 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"ECMAScript基础系列","slug":"ECMAScript基础系列","permalink":"https://ostenant.coding.me/categories/ECMAScript基础系列/"}],"tags":[{"name":"ECMAScript","slug":"ECMAScript","permalink":"https://ostenant.coding.me/tags/ECMAScript/"}]},{"title":"ECMAScript 6入门篇(一) - var, let, const命令","slug":"ECMAScript 6入门篇(一) - var, let, const命令","date":"2017-04-14T07:45:00.000Z","updated":"2018-05-08T02:49:46.088Z","comments":true,"path":"2017/04/14/ECMAScript 6入门篇(一) - var, let, const命令/","link":"","permalink":"https://ostenant.coding.me/2017/04/14/ECMAScript 6入门篇(一) - var, let, const命令/","excerpt":"简介let和const都是es5，es6新版本的js语言规范出来的定义，在这以前定义一个变量只能用var。简言之，let和const都是为了弥补var的一些缺陷而新设计出来的。 let修复了var的作用域上的bug，let是更好的var。var的作用域是函数级别，而let是块级别（大括号括起来的内容）。","text":"简介let和const都是es5，es6新版本的js语言规范出来的定义，在这以前定义一个变量只能用var。简言之，let和const都是为了弥补var的一些缺陷而新设计出来的。 let修复了var的作用域上的bug，let是更好的var。var的作用域是函数级别，而let是块级别（大括号括起来的内容）。 var声明的变量，其作用域为该语句所在的函数体内部，且存在变量提升现象； let声明的变量，其作用域为该语句所在的代码块内部，不存在变量提升现象； const声明的是常量，声明时必须给定初始值，在后面出现的代码中不能再修改该常量的值。 正文let, var命令基本用法示例一：作用域比较1234567&#123; let a = 10; var b = 10;&#125;a // ReferenceError: a is not defined.b // 10 上述代码中，let命令仅在所在的代码块内有效，var命令在代码块外依然有效。 示例二：循环计数器1234for (var i = 0; i &lt; 10; i++) &#123;&#125;console.log(i);//10 上述代码中，var声明的计数器i在全局范围内都有效，全局只有唯一的变量i。 1234for (let i = 0; i &lt; 10; i++) &#123;&#125;console.log(i);//ReferenceError: i is not defined 上述代码中，let声明的计数器i只在循环体内部有效。 1234567var a = [];for (var i = 0; i &lt; 10; i++) &#123; a[i] = function () &#123; console.log(i); &#125;;&#125;a[6](); // 10 上述代码中，每一次循环，变量i的值都会发生改变，而循环内被赋给数组a的function在运行时，会通过闭包读到这同一个变量i，导致最后输出的是最后一轮的i的值，也就是10。1234567var a = [];for (let i = 0; i &lt; 10; i++) &#123; a[i] = function () &#123; console.log(i); &#125;;&#125;a[6](); // 6 上述代码中，计数器i是由let命令声明的，当前的i只在本轮循环中有效，每一次循环的i实际上都是一个新的变量。let声明的变量为当前一轮循环。最后a[6]()输出结果为6。 示例三：循环内部作用域 for循环一个特别之处为：循环语句 部分为一个父作用域，循环体内部 则作为每一个单独的子作用域。1234567for (let i = 0; i &lt; 3; i++) &#123; let i = 'abc'; console.log(i);&#125;// abc// abc// abc 上述代码输出了三次abc，表明循环语句内的变量i和每一轮循环体内的变量i是隔离的。 变量提升var命令会发生变量提升现象，即变量可以在声明之前使用，值为undefined。let命令改变了语法行为，它所声明的变量一定要在声明后使用，否则报错。1234567// var 的情况console.log(foo1); // 输出undefinedvar foo1 = 2;// let 的情况console.log(foo2); // 报错ReferenceErrorlet foo2 = 2; 变量foo1用var命令声明，会发生变量提升，即脚本开始运行时，变量foo1已经存在了，但是没有值，所以会输出undefined。 变量foo2用let命令声明，不会发生变量提升。这表示在声明它之前，变量foo2是不存在的，这时如果用到它，就会抛出一个错误。 暂时性死区只要块作用域内存区域存在let命令，let命令声明的变量绑定到此区域。12345var tmp = 123;if (true) &#123; tmp = 'abc'; // ReferenceError let tmp;&#125; 上面代码中，存在一个全局变量tmp，在if块级作用域中又用let声明了一个局部变量tmp。导致后者与块级作用域绑定，而在声明tmp变量之前就使用导致tmp赋值失败报错。 总之，在代码块内，使用let命令声明变量之前，该变量都是不可用的。 不允许重复声明let不允许在相同作用域内，重复声明同一个变量。12345678910// 报错function () &#123; let a = 10; var a = 10;&#125;// 报错function () &#123; let a = 10; let a = 10&#125; 因此，不能在函数内部重新声明参数。 12345678function func(arg) &#123; let arg; // 报错&#125;function func(arg) &#123; &#123; let arg; // 不报错 &#125;&#125; const命令基本用法示例一：常量不可修改const声明一个只读的常量。一旦声明，常量的值就不能改变。12345const PI = 3.1415;PI // 3.1415PI = 3;// TypeError: Assignment to constant variable. 上面代码表明改变常量的值会报错。 示例二：常量初始化const一旦声明变量，就必须立即初始化，不能留到以后赋值。12const foo;// SyntaxError: Missing initializer in const declaration 上面代码表示，对于const来说，只声明不赋值，就会报错。 示例三：常量作用域const的作用域与let命令相同：只在声明所在的块级作用域内有效。12345if (true) &#123; const MAX = 5;&#125;MAX // Uncaught ReferenceError: MAX is not defined 示例四：常量不可提升const命令声明的常量也是不提升，同样存在暂时性死区，只能在声明的位置后面使用。 1234if (true) &#123; console.log(MAX); // ReferenceError const MAX = 5;&#125; 上面代码在常量MAX声明之前就调用，结果报错。 示例五：常量不可重复const声明的常量，也与let一样不可重复声明。123456var message = \"Hello!\";let age = 25;// 以下两行都会报错const message = \"Goodbye!\";const age = 30; 本质const实际上保证的，并不是变量的值不得改动，而是变量指向的那个内存地址不得改动。 对于简单类型的数据（数值、字符串、布尔值），值就保存在变量指向的那个内存地址，因此等同于常量。 对于复合类型的数据（主要是对象和数组），变量指向的内存地址，保存的只是一个指针，const只能保证这个指针是固定的，至于它指向的数据结构是不是可变的，就完全不能控制了。因此，将一个对象声明为常量必须非常小心。 示例一：const引用对象12345678const foo = &#123;&#125;;// 为 foo 添加一个属性，可以成功foo.prop = 123;foo.prop // 123// 将 foo 指向另一个对象，就会报错foo = &#123;&#125;; // TypeError: \"foo\" is read-only 上面代码中，常量foo储存的是一个地址，这个地址指向一个对象。不可变的只是这个地址，即不能把foo指向另一个地址，但对象本身是可变的，所以依然可以为其添加新属性。 1234const a = [];a.push('Hello'); // 可执行a.length = 0; // 可执行a = ['Dave']; // 报错 上面代码中，常量a是一个数组，这个数组本身是可写的，但是如果将另一个数组赋值给a，就会报错。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"ECMAScript基础系列","slug":"ECMAScript基础系列","permalink":"https://ostenant.coding.me/categories/ECMAScript基础系列/"}],"tags":[{"name":"ECMAScript","slug":"ECMAScript","permalink":"https://ostenant.coding.me/tags/ECMAScript/"}]},{"title":"大型Web网站架构演变","slug":"大型Web网站架构演变","date":"2017-03-24T07:55:00.000Z","updated":"2018-05-08T02:49:46.096Z","comments":true,"path":"2017/03/24/大型Web网站架构演变/","link":"","permalink":"https://ostenant.coding.me/2017/03/24/大型Web网站架构演变/","excerpt":"前言我们以Java Web为例，来搭建一个简单的电商系统，看看这个系统可以如何一步步演变。该系统具备的功能： 用户模块：用户注册和管理 商品模块：商品展示和管理 交易模块：创建交易和管理","text":"前言我们以Java Web为例，来搭建一个简单的电商系统，看看这个系统可以如何一步步演变。该系统具备的功能： 用户模块：用户注册和管理 商品模块：商品展示和管理 交易模块：创建交易和管理 正文 阶段一、单机构建网站网站的初期，我们经常会在单机上跑我们所有的程序和软件。此时我们使用一个容器，如Tomcat、Jetty、Jboss，然后直接使用JSP/Servlet技术，或者使用一些开源的框架如Maven + Spring + Struts + Hibernate、Maven + Spring + Spring MVC + Mybatis。最后再选择一个数据库管理系统来存储数据，如MySQL、SqlServer、Oracle，然后通过JDBC进行数据库的连接和操作。 把以上的所有软件包括数据库、应用程序都装载同一台机器上，应用跑起来了，也算是一个小系统了。此时系统结果如下： 阶段二、应用服务器与数据库分离随着网站的上线，访问量逐步上升，服务器的负载慢慢提高，在服务器还没有超载的时候，我们应该就要做好准备，提升网站的负载能力。假如我们代码层面已难以优化，在不提高单台机器的性能的情况下，采用增加机器是一个不错的方式，不仅可以有效地提高系统的负载能力，而且性价比高。 增加的机器用来做什么呢？此时我们可以把数据库服务器和Web服务器拆分开来，这样不仅提高了单台机器的负载能力，也提高了容灾能力。 应用服务器与数据库分开后的架构如下图所示： 阶段三、应用服务器集群随着访问量继续增加，单台应用服务器已经无法满足需求了。在假设数据库服务器没有压力的情况下，我们可以把应用服务器从一台变成了两台甚至多台，把用户的请求分散到不同的服务器中，从而提高负载能力。而多台应用服务器之间没有直接的交互，他们都是依赖数据库各自对外提供服务。著名的做故障切换的软件有KeepAlived，KeepAlived是一个类似于Layer3、4、7交换机制的软件，他不是某个具体软件故障切换的专属品，而是可以适用于各种软件的一款产品。KeepAlived配合上ipvsadm又可以做负载均衡，可谓是神器。 我们以增加了一台应用服务器为例，增加后的系统结构图如下： 系统演变到这里，将会出现下面四个问题： 用户的请求由谁来转发到到具体的应用服务器？ 有那些转发的算法和策略可以使用？ 应用服务器如何返回用户的请求？ 用户如果每次访问到的服务器不一样，那么如何维护session的一致性？ 针对以上问题，常用的解决方案如下： 1、负载均衡的问题一般以下有5种解决方案： 1、HTTP重定向 HTTP重定向就是应用层的请求转发。用户的请求其实已经到了HTTP重定向负载均衡服务器，服务器根据算法要求用户重定向，用户收到重定向请求后，再次请求真正的集群 优点：简单易用； 缺点：性能较差。 2、DNS域名解析负载均衡 DNS域名解析负载均衡就是在用户请求DNS服务器，获取域名对应的IP地址时，DNS服务器直接给出负载均衡后的服务器IP。 优点：交给DNS，不用我们去维护负载均衡服务器； 缺点：当一个应用服务器挂了，不能及时通知DNS，而且DNS负载均衡的控制权在域名服务商那里，网站无法做更多的改善和更强大的管理。 3、反向代理服务器 在用户的请求到达反向代理服务器时（已经到达网站机房），由反向代理服务器根据算法转发到具体的服务器。常用的Apache，Nginx都可以充当反向代理服务器。 优点：部署简单； 缺点：代理服务器可能成为性能的瓶颈，特别是一次上传大文件。 4、IP层负载均衡 在请求到达负载均衡器后，负载均衡器通过修改请求的目的IP地址，从而实现请求的转发，做到负载均衡。 优点：性能更好； 缺点：负载均衡器的宽带成为瓶颈。 5、数据链路层负载均衡 在请求到达负载均衡器后，负载均衡器通过修改请求的MAC地址，从而做到负载均衡，与IP负载均衡不一样的是，当请求访问完服务器之后，直接返回客户。而无需再经过负载均衡器。 2、集群调度转发算法1、rr轮询调度算法 顾名思义，轮询分发请求。 优点：实现简单 缺点：不考虑每台服务器的处理能力 2、wrr加权调度算法 我们给每个服务器设置权值Weight，负载均衡调度器根据权值调度服务器，服务器被调用的次数跟权值成正比。 优点：考虑了服务器处理能力的不同 3、sh原地址散列算法 提取用户IP，根据散列函数得出一个key，再根据静态映射表，查处对应的value，即目标服务器IP。过目标机器超负荷，则返回空。 优点：实现同一个用户访问同一个服务器。 4、dh目标地址散列算法 原理同上，只是现在提取的是目标地址的IP来做哈希。 优点：实现同一个用户访问同一个服务器。 5、lc最少连接算法 优先把请求转发给连接数少的服务器。 优点：使得集群中各个服务器的负载更加均匀。 6、wlc加权最少连接算法 在lc的基础上，为每台服务器加上权值。算法为：（活动连接数 * 256 + 非活动连接数） ÷ 权重，计算出来的值小的服务器优先被选择。 优点：可以根据服务器的能力分配请求。 7、sed最短期望延迟算法 其实sed跟wlc类似，区别是不考虑非活动连接数。算法为：（活动连接数 +1 ) * 256 ÷ 权重，同样计算出来的值小的服务器优先被选择。 8、nq永不排队算法 改进的sed算法。我们想一下什么情况下才能“永不排队”，那就是服务器的连接数为0的时候，那么假如有服务器连接数为0，均衡器直接把请求转发给它，无需经过sed的计算。 9、LBLC基于局部性最少连接算法 负载均衡器根据请求的目的IP地址，找出该IP地址最近被使用的服务器，把请求转发之。若该服务器超载，最采用最少连接数算法。 10、LBLCR带复制的基于局部性最少连接算法 负载均衡器根据请求的目的IP地址，找出该IP地址最近使用的“服务器组”，注意，并不是具体某个服务器，然后采用最少连接数从该组中挑出具体的某台服务器出来，把请求转发之。若该服务器超载，那么根据最少连接数算法，在集群的非本服务器组的服务器中，找出一台服务器出来，加入本服务器组，然后把请求转发。 3、集群请求返回模式问题1、NAT 负载均衡器接收用户的请求，转发给具体服务器，服务器处理完请求返回给均衡器，均衡器再重新返回给用户。 2、DR 负载均衡器接收用户的请求，转发给具体服务器，服务器出来玩请求后直接返回给用户。需要系统支持IP Tunneling协议，难以跨平台。 3、TUN 同上，但无需IP Tunneling协议，跨平台性好，大部分系统都可以支持。 4、集群Session一致性问题1、Session Sticky Session sticky就是把同一个用户在某一个会话中的请求，都分配到固定的某一台服务器中，这样我们就不需要解决跨服务器的session问题了，常见的算法有ip_hash算法，即上面提到的两种散列算法。 优点：实现简单； 缺点：应用服务器重启则session消失。 2、Session Replication Session replication就是在集群中复制session，使得每个服务器都保存有全部用户的session数据。 优点：减轻负载均衡服务器的压力，不需要要实现ip_hasp算法来转发请求； 缺点：复制时网络带宽开销大，访问量大的话Session占用内存大且浪费。 3、Session数据集中存储 Session数据集中存储就是利用数据库来存储session数据，实现了session和应用服务器的解耦。 优点：相比Session replication的方案，集群间对于宽带和内存的压力大幅减少； 缺点：需要维护存储Session的数据库。 4、Cookie Base Cookie base就是把Session存在Cookie中，由浏览器来告诉应用服务器我的session是什么，同样实现了session和应用服务器的解耦。 优点：实现简单，基本免维护。 缺点：cookie长度限制，安全性低，带宽消耗。 值得一提的是： Nginx目前支持的负载均衡算法有wrr、sh（支持一致性哈希）、fair（lc）。但Nginx作为均衡器的话，还可以一同作为静态资源服务器。 Keepalived + ipvsadm比较强大，目前支持的算法有：rr、wrr、lc、wlc、lblc、sh、dh Keepalived支持集群模式有：NAT、DR、TUN Nginx本身并没有提供session同步的解决方案，而Apache则提供了session共享的支持。 解决了以上的问题之后，系统的结构如下： 阶段四、数据库读写分离化上面我们总是假设数据库负载正常，但随着访问量的的提高，数据库的负载也在慢慢增大。那么可能有人马上就想到跟应用服务器一样，把数据库一份为二再负载均衡即可。 但对于数据库来说，并没有那么简单。假如我们简单的把数据库一分为二，然后对于数据库的请求，分别负载到A机器和B机器，那么显而易见会造成两台数据库数据不统一的问题。那么对于这种情况，我们可以先考虑使用读写分离和主从复制的方式。 读写分离后的系统结构如下： 这个结构变化后也会带来两个问题： 主从数据库之间数据同步问题。 应用对于数据源的选择问题。 解决方案： 使用MySQL自带的Master + Slave的方式实现主从复制。 采用第三方数据库中间件，例如MyCat。MyCat是从Cobar发展而来的，而Cobar是阿里开源的数据库中间件，后来停止开发。MyCat是国内比较好的MySql开源数据库分库分表中间件。 阶段五、用搜索引擎缓解读库的压力数据库做读库的话，常常对模糊查找力不从心，即使做了读写分离，这个问题还未能解决。以我们所举的交易网站为例，发布的商品存储在数据库中，用户最常使用的功能就是查找商品，尤其是根据商品的标题来查找对应的商品。对于这种需求，一般我们都是通过like功能来实现的，但是这种方式的代价非常大，而且结果非常不准确。此时我们可以使用搜索引擎的倒排索引来完成。 搜索引擎具有的优点：它能够大大提高查询速度和搜索准确性。 引入搜索引擎的开销 带来大量的维护工作，我们需要自己实现索引的构建过程，设计全量/增加的构建方式来应对非实时与实时的查询需求。 需要维护搜索引擎集群 搜索引擎并不能替代数据库，它解决了某些场景下的精准、快速、高效的“读”操作，是否引入搜索引擎，需要综合考虑整个系统的需求。 引入搜索引擎后的系统结构如下： 阶段六、用缓存缓解读库的压力常用的缓存机制包括页面级缓存、应用数据缓存和数据库缓存。 应用层和数据库层的缓存随着访问量的增加，逐渐出现了许多用户访问同一部分热门内容的情况，对于这些比较热门的内容，没必要每次都从数据库读取。我们可以使用缓存技术，例如可以使用Google的开源缓存技术Guava或者使用Memecahed作为应用层的缓存，也可以使用Redis作为数据库层的缓存。 另外，在某些场景下，关系型数据库并不是很适合，例如我想做一个“每日输入密码错误次数限制”的功能，思路大概是在用户登录时，如果登录错误，则记录下该用户的IP和错误次数，那么这个数据要放在哪里呢？假如放在内存中，那么显然会占用太大的内容；假如放在关系型数据库中，那么既要建立数据库表，还要简历对应的Java bean，还要写SQL等等。而分析一下我们要存储的数据，无非就是类似{ip:errorNumber}这样的key:value数据。对于这种数据，我们可以用NOSQL数据库来代替传统的关系型数据库。 页面缓存除了数据缓存，还有页面缓存。比如使用HTML5的localstroage或者Cookie。除了页面缓存带来的性能提升外，对于并发访问且页面置换频率小的页面，应尽量使用页面静态化技术。 优点：减轻数据库的压力， 大幅度提高访问速度； 缺点：需要维护缓存服务器，提高了编码的复杂性。 值得一提的是： 缓存集群的调度算法不同与上面提到的应用服务器和数据库。最好采用一致性哈希算，这样才能提高命中率。 加入缓存后的系统结构如下： 阶段七、数据库水平拆分与垂直拆分我们的网站演进到现在，交易、商品、用户的数据都还在同一个数据库中。尽管采取了增加缓存和读写分离的方式，但随着数据库的压力继续增加，数据库数据量的瓶颈越来越突出，此时，我们可以有数据垂直拆分和水平拆分两种选择。 数据垂直拆分垂直拆分的意思是把数据库中不同的业务数据拆分到不同的数据库中，结合现在的例子，就是把交易、商品、用户的数据分开。 优点： 解决了原来把所有业务放在一个数据库中的压力问题； 可以根据业务的特点进行更多的优化。 缺点： 需要维护多个数据库的状态一致性和数据同步。 问题： 需要考虑原来跨业务的事务； 跨数据库的Join。 解决问题方案： 应该在应用层尽量避免跨数据库的分布式事务，如果非要跨数据库，尽量在代码中控制。 通过第三方中间件来解决，如上面提到的MyCat，MyCat提供了丰富的跨库Join方案，详情可参考MyCat官方文档。 数据垂直拆分后的结构如下： 数据水平拆分数据水平拆分就是把同一个表中的数据拆分到两个甚至多个数据库中。产生数据水平拆分的原因是某个业务的数据量或者更新量到达了单个数据库的瓶颈，这时就可以把这个表拆分到两个或更多个数据库中。 优点： 如果能克服以上问题，那么我们将能够很好地对数据量及写入量增长的情况。 问题： 访问用户信息的应用系统需要解决SQL路由的问题，因为现在用户信息分在了两个数据库中，需要在进行数据操作时了解需要操作的数据在哪里。 主键 的处理也变得不同，例如原来自增字段，现在不能简单地继续使用。 如果需要分页查询，那就更加麻烦。 解决问题方案： 我们还是可以通过可以解决第三方中间件，如MyCat。MyCat可以通过SQL解析模块对我们的SQL进行解析，再根据我们的配置，把请求转发到具体的某个数据库。我们可以通过UUID保证唯一或自定义ID方案来解决。 MyCat也提供了丰富的分页查询方案，比如先从每个数据库做分页查询，再合并数据做一次分页查询等等。 数据水平拆分后的结构如下： 阶段八、应用的拆分按微服务拆分应用随着业务的发展，业务越来越多，应用越来越大。我们需要考虑如何避免让应用越来越臃肿。这就需要把应用拆开，从一个应用变为俩个甚至更多。还是以我们上面的例子，我们可以把用户、商品、交易拆分开。变成“用户、商品”和“用户，交易”两个子系统。 拆分后的结构： 问题： 这样拆分后，可能会有一些相同的代码，如用户相关的代码，商品和交易都需要用户信息，所以在两个系统中都保留差不多的操作用户信息的代码。如何保证这些代码可以复用是一个需要解决的问题。 解决问题： 通过走服务化SOA的路线来解决频繁公共的服务。 走SOA服务化治理道路为了解决上面拆分应用后所出现的问题，我们把公共的服务拆分出来，形成一种服务化的模式，简称SOA。 采用服务化之后的系统结构： 优点： 相同的代码不会散落在不同的应用中了，这些实现放在了各个服务中心，使代码得到更好的维护。 我们把对数据库的交互业务放在了各个服务中心，让前端的Web应用更注重与浏览器交互的工作。 问题： 如何进行远程的服务调用？ 解决方法： 可以通过下面的引入消息中间件来解决。 阶段九、引入消息中间件随着网站的继续发展，的系统中可能出现不同语言开发的子模块和部署在不同平台的子系统。此时我们需要一个平台来传递可靠的，与平台和语言无关的数据，并且能够把负载均衡透明化，能在调用过程中收集并分析调用数据，推测出网站的访问增长率等等一系列需求，对于网站应该如何成长做出预测。开源消息中间件有阿里的Dubbo，可以搭配Google开源的分布式程序协调服务Zookeeper实现服务器的注册与发现。 引入消息中间件后的结构： 总结以上的演变过程只是一个例子，并不适合所有的网站，实际中网站演进过程与自身业务和不同遇到的问题有密切的关系，没有固定的模式。只有认真的分析和不断地探究，才能发现适合自己网站的架构。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"架构学习系列","slug":"架构学习系列","permalink":"https://ostenant.coding.me/categories/架构学习系列/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://ostenant.coding.me/tags/Web/"}]},{"title":"HTTP协议详解","slug":"HTTP协议详解","date":"2017-02-25T14:14:00.000Z","updated":"2018-05-08T02:49:46.089Z","comments":true,"path":"2017/02/25/HTTP协议详解/","link":"","permalink":"https://ostenant.coding.me/2017/02/25/HTTP协议详解/","excerpt":"简介HTTP协议(超文本传输协议HyperText Transfer Protocol)，它是基于TCP协议的应用层传输协议，简单来说就是客户端和服务端进行数据传输的一种规则。","text":"简介HTTP协议(超文本传输协议HyperText Transfer Protocol)，它是基于TCP协议的应用层传输协议，简单来说就是客户端和服务端进行数据传输的一种规则。 注意：客户端与服务器的角色不是固定的，一端充当客户端，也可能在某次请求中充当服务器。这取决与请求的发起端。HTTP协议属于应用层，建立在传输层协议TCP之上。客户端通过与服务器建立TCP连接，之后发送HTTP请求与接收HTTP响应都是通过访问Socket接口来调用TCP协议实现。 HTTP 是一种无状态 (stateless) 协议, HTTP协议本身不会对发送过的请求和相应的通信状态进行持久化处理。这样做的目的是为了保持HTTP协议的简单性，从而能够快速处理大量的事务, 提高效率。 然而，在许多应用场景中，我们需要保持用户登录的状态或记录用户购物车中的商品。由于HTTP是无状态协议，所以必须引入一些技术来记录管理状态，例如Cookie。 正文HTTP URLHTTP URL 包含了用于查找某个资源的详细信息, 格式如下: 1http://host[&quot;:&quot;port][abs_path] HTTP请求下图是在网上找的一张图，觉得能很好的表达HTTP请求的所发送的数据格式。 由上图可以看到，http请求由请求行，消息报头，请求正文三部分构成。 HTTP请求状态行请求行由请求Method, URL 字段和HTTP Version三部分构成, 总的来说请求行就是定义了本次请求的请求方式, 请求的地址, 以及所遵循的HTTP协议版本例如： 1GET /example.html HTTP/1.1 (CRLF) HTTP协议的方法有： GET： 请求获取Request-URI所标识的资源 POST： 在Request-URI所标识的资源后增加新的数据 HEAD： 请求获取由Request-URI所标识的资源的响应消息报头 PUT： 请求服务器存储或修改一个资源，并用Request-URI作为其标识 DELETE： 请求服务器删除Request-URI所标识的资源 TRACE： 请求服务器回送收到的请求信息，主要用于测试或诊断 CONNECT： 保留将来使用 OPTIONS： 请求查询服务器的性能，或者查询与资源相关的选项和需求 HTTP请求头消息报头由一系列的键值对组成，允许客户端向服务器端发送一些附加信息或者客户端自身的信息，主要包括： Header 解释 示例 Accept 指定客户端能够接收的内容类型 Accept: text/plain, text/html Accept-Charset 浏览器可以接受的字符编码集 Accept-Charset: iso-8859-5,utf-8 Accept-Encoding 指定浏览器可以支持的web服务器返回内容压缩编码类型 Accept-Encoding: compress, gzip Accept-Language 浏览器可接受的语言 Accept-Language: en,zh Accept-Ranges 可以请求网页实体的一个或者多个子范围字段 Accept-Ranges: bytes Authorization HTTP授权的授权证书类型 Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Cache-Control 指定请求和响应遵循的缓存机制 Cache-Control: no-cache Connection 表示是否需要持久连接（HTTP 1.1默认进行持久连接） Connection: close Cookie HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器 Cookie: $Version=1; Skin=new; Content-Length 请求的内容长度 Content-Length: 348 Content-Type 请求的与实体对应的MIME信息 Content-Type: application/x-www-form-urlencoded Date 请求发送的日期和时间 Date: Tue, 15 Nov 2010 08:12:31 GMT Expect 请求的特定的服务器行为 Expect: 100-continue From 发出请求的用户的Email From: user@email.com Host 指定请求的服务器的域名和端口号 Host: www.zcmhi.com If-Match 只有请求内容与实体相匹配才有效 If-Match: “737060cd8c284d8af7ad3082f209582d” If-Modified-Since 如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304代码 If-Modified-Since: Sat, 29 Oct 2010 19:43:31 GMT If-None-Match 如果内容未改变返回304代码，参数为服务器先前发送的Etag，与服务器回应的Etag比较判断是否改变 If-None-Match: “737060cd8c284d8af7ad3082f209582d” If-Range 如果实体未改变，服务器发送客户端丢失的部分，否则发送整个实体。参数也为Etag If-Range: “737060cd8c284d8af7ad3082f209582d” If-Unmodified-Since 只在实体在指定时间之后未被修改才请求成功 If-Unmodified-Since: Sat, 29 Oct 2010 19:43:31 GMT Max-Forwards 限制信息通过代理和网关传送的时间 Max-Forwards: 10 Pragma 用来包含实现特定的指令 Pragma: no-cache Proxy-Authorization 连接到代理的授权证书 Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Range 只请求实体的一部分，指定范围 Range: bytes=500-999 Referer 先前网页的地址，当前请求网页紧随其后, 即来路 Referer: http://www.zcmhi.com/archives/71.html TE 客户端愿意接受的传输编码，并通知服务器接受接受尾加头信息 TE: trailers,deflate;q=0.5 Upgrade 向服务器指定某种传输协议以便服务器进行转换（如果支持） Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 User-Agent User-Agent的内容包含发出请求的用户信息 User-Agent: Mozilla/5.0 (Linux; X11) Via 通知中间网关或代理服务器地址，通信协议 Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1) Warning 关于消息实体的警告信息 Warn: 199 Miscellaneous warning HTTP请求正文只有在发送POST请求时才会有请求正文，GET方法并没有请求正文。 HTTP请求报文 HTTP响应与HTTP请求类似，先上一张图： HTTP响应也由三部分组成，包括状态行，消息报头，响应正文。 HTTP响应状态行状态行也由三部分组成，包括HTTP协议的版本，状态码，以及对状态码的文本描述。例如： 1HTTP/1.1 200 OK （CRLF） HTTP响应状态码状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值： 1xx：指示信息 - 表示请求已接收，继续处理 2xx：成功 - 表示请求已被成功接收、理解、接受 3xx：重定向 - 要完成请求必须进行更进一步的操作 4xx：客户端错误 - 请求有语法错误或请求无法实现 5xx：服务器端错误 - 服务器未能实现合法的请求 常见状态代码、状态描述、说明： 200： OK - 客户端请求成功 400： Bad Request - 客户端请求有语法错误，不能被服务器所理解 401： Unauthorized - 请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403： Forbidden - 服务器收到请求，但是拒绝提供服务 404： Not Found - 请求资源不存在，eg：输入了错误的URL 500： Internal Server Error - 服务器发生不可预期的错误 503： Server Unavailable - 服务器当前不能处理客户端的请求，一段时间后,可能恢复正常 HTTP响应状态码说明 StatusCode StatusCode语义 中文描述 100 Continue 继续。客户端应继续其请求 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 200 OK 请求成功。一般用于GET与POST请求 201 Created 已创建。成功请求并创建了新的资源 202 Accepted 已接受。已经接受请求，但未处理完成 203 Non-Authoritative Information 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 204 No Content 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 205 Reset Content 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 206 Partial Content 部分内容。服务器成功处理了部分GET请求 300 Multiple Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 301 Moved Permanently 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 302 Found 临时移动。 与301类似。但资源只是临时被移动。客户端应继续使用原有URI 303 See Other 查看其它地址。与301类似。使用GET和POST请求查看 304 Not Modified 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 305 Use Proxy 使用代理。所请求的资源必须通过代理访问 306 Unused 已经被废弃的HTTP状态码 307 Temporary Redirect 临时重定向。与302类似。使用GET请求重定向 400 Bad Request 客户端请求的语法错误，服务器无法理解 401 Unauthorized 请求要求用户的身份认证 402 Payment Required 保留，将来使用 403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求 404 Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面 405 Method Not Allowed 客户端请求中的方法被禁止 406 Not Acceptable 服务器无法根据客户端请求的内容特性完成请求 407 Proxy Authentication Required 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 408 Request Time-out 服务器等待客户端发送的请求时间过长，超时 409 Conflict 服务器完成客户端的PUT请求是可能返回此代码，服务器处理请求时发生了冲突 410 Gone 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 411 Length Required 服务器无法处理客户端发送的不带Content-Length的请求信息 412 Precondition Failed 客户端请求信息的先决条件错误 413 Request Entity Too Large 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 414 Request-URI Too Larg 请求的URI过长（URI通常为网址），服务器无法处理 415 Unsupported Media Type 服务器无法处理请求附带的媒体格式 416 Requested range not satisfiable 客户端请求的范围无效 417 Expectation Failed 服务器无法满足Expect的请求头信息 500 Internal Server Error 服务器内部错误，无法完成请求 501 Not Implemented 服务器不支持请求的功能，无法完成请求 502 Bad Gateway 充当网关或代理的服务器，从远端服务器接收到了一个无效的请求 503 Service Unavailable 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求 505 HTTP Version not supported 服务器不支持请求的HTTP协议的版本，无法完成处理 HTTP响应报文 HTTP协议详解HTTP的五大特点 支持客户/服务器模式。 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。早期这么做的原因是请求资源少，追求快。后来通过Connection: Keep-Alive实现长连接 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 非持久连接和持久连接在实际的应用中，客户端往往会发出一系列请求，接着服务器端对每个请求进行响应。对于这些请求|响应，如果每次都经过一个单独的TCP连接发送，称为非持久连接。反之，如果每次都经过相同的TCP连接进行发送，称为持久连接。 非持久连接在每次请求|响应之后都要断开连接，下次再建立新的TCP连接，这样就造成了大量的通信开销。例如前面提到的往返时间(RTT) 就是在建立TCP连接的过程中的代价。 非持久连接给服务器带来了沉重的负担，每台服务器可能同时面对数以百计甚至更多的请求。持久连接就是为了解决这些问题，其特点是一直保持TCP连接状态，直到遇到明确的中断要求之后再中断连接。持久连接减少了通信开销，节省了通信量。 HTTP和HTTPSHTTP的不足 通信使用明文(不加密),内容可能会被窃听 不验证通信方的身份,因此有可能遭遇伪装 无法证明报文的完整性,所以有可能已遭篡改 HTTPS介绍HTTP 协议中没有加密机制,但可以通 过和 SSL(Secure Socket Layer, 安全套接层 )或 TLS(Transport Layer Security, 安全层传输协议)的组合使用,加密 HTTP 的通信内容。属于通信加密，即在整个通信线路中加密。 1HTTP + 加密 + 认证 + 完整性保护 = HTTPS（HTTP Secure ） HTTPS 采用共享密钥加密（对称）和公开密钥加密（非对称）两者并用的混合加密机制。若密钥能够实现安全交换,那么有可能会考虑仅使用公开密钥加密来通信。但是公开密钥加密与共享密钥加密相比,其处理速度要慢。 所以应充分利用两者各自的优势, 将多种方法组合起来用于通信。 在交换密钥阶段使用公开密钥加密方式,之后的建立通信交换报文阶段 则使用共享密钥加密方式。 HTTPS握手过程的简单描述如下： 浏览器将自己支持的一套加密规则发送给网站。 1服务器获得浏览器公钥 网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。 1浏览器获得服务器公钥 获得网站证书之后浏览器要做以下工作： (a). 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。 (b). 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码（接下来通信的密钥），并用证书中提供的公钥加密（共享密钥加密）。 (c) 使用约定好的HASH计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。 123浏览器验证 -&gt; 随机密码服务器的公钥加密 -&gt; 通信的密钥通信的密钥 -&gt; 服务器 网站接收浏览器发来的数据之后要做以下的操作： (a). 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。 (b). 使用密码加密一段握手消息，发送给浏览器。 1服务器用自己的私钥解出随机密码 -&gt; 用密码解密握手消息（共享密钥通信）-&gt; 验证HASH与浏览器是否一致（验证浏览器） HTTPS的不足 加密解密过程复杂，导致访问速度慢 加密需要认向证机构付费 整个页面的请求都要使用HTTPS 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"网络协议系列","slug":"网络协议系列","permalink":"https://ostenant.coding.me/categories/网络协议系列/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://ostenant.coding.me/tags/HTTP/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://ostenant.coding.me/tags/HTTPS/"}]},{"title":"TCP协议简介","slug":"TCP协议简介","date":"2017-02-25T03:59:00.000Z","updated":"2018-05-08T02:49:46.092Z","comments":true,"path":"2017/02/25/TCP协议简介/","link":"","permalink":"https://ostenant.coding.me/2017/02/25/TCP协议简介/","excerpt":"前言TCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。","text":"前言TCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。 TCP的特性 TCP提供一种面向连接的, 可靠的字节流服务; 在一个TCP连接中，仅有两方进行彼此通信。广播和多播不能用于TCP; TCP使用校验和, 确认和重传机制来保证可靠传输; TCP使用累积确认 TCP使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制 TCP三次握手与四次挥手三次握手 所谓三次握手(Three-way Handshake)，是指建立一个 TCP 连接时，需要客户端和服务器总共发送3个包。 三次握手的目的是连接服务器指定端口，建立 TCP 连接，并同步连接双方的序列号和确认号，交换 TCP 窗口大小信息。在Socket 编程中，客户端执行 connect() 时。将触发三次握手。 12345678910111213141516171. 第一次握手(SYN=1, seq=x); - 客户端发送一个 TCP 的 SYN 标志位置1的包, 指明客户端打算连接的服务器的端口，以及初始序号 X, 保存在包头的序列号(Sequence Number)字段里。 - 发送完毕后，客户端进入 `SYN_SEND` 状态。2. 第二次握手(SYN=1, ACK=1, seq=y, ACKnum=x+1); - 服务器发回确认包(ACK)应答。即 SYN 标志位和 ACK 标志位均为1。服务器端选择自己 ISN 序列号, 放到 Seq 域里, 同时将确认序号(Acknowledgement Number)设置为客户端的 ISN 加1, 即x+1。 - 发送完毕后，服务器端进入 `SYN_RCVD` 状态。3. 第三次握手(ACK=1，ACKnum=y+1) - 客户端再次发送确认包(ACK), SYN 标志位为0, ACK 标志位为1, 并且把服务器发来 ACK 的序号字段+1, 放在确定字段中发送给对方, 并且在数据段放写ISN的+1 - 发送完毕后，客户端进入 `ESTABLISHED` 状态，当服务器端接收到这个包时，也进入 `ESTABLISHED` 状态，TCP 握手结束。 三次握手的过程的示意图如下： 四次挥手TCP的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，也叫做改进的三次握手。客户端或服务器均可主动发起挥手动作，在 socket 编程中，任何一方执行 close() 操作即可产生挥手操作。 123456789101112131415161718192021222324251. 第一次挥手(FIN=1, seq=x); - 假设客户端想要关闭连接，客户端发送一个 FIN 标志位置为1的包, 表示自己已经没有数据可以发送了, 但是仍然可以接受数据。 - 发送完毕后，客户端进入 `FIN_WAIT_1` 状态。2. 第二次挥手(ACK=1, ACKnum=x+1); - 服务器端确认客户端的 FIN 包，发送一个确认包, 表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接。 - 发送完毕后，服务器端进入 `CLOSE_WAIT` 状态, 客户端接收到这个确认包之后，进入 `FIN_WAIT_2` 状态, 等待服务器端关闭连接。3. 第三次挥手(FIN=1, seq=y); - 服务器端准备好关闭连接时, 向客户端发送结束连接请求, `FIN` 置为1。 - 发送完毕后, 服务器端进入 `LAST_ACK` 状态, 等待来自客户端的最后一个ACK。4. 第四次挥手(ACK=1，ACKnum=y+1) - 客户端接收到来自服务器端的关闭请求, 发送一个确认包, 并进入 `TIME_WAIT` 状态, 等待可能出现的要求重传的 ACK 包。 - 服务器端接收到这个确认包之后, 关闭连接, 进入 `CLOSED` 状态。 - 客户端等待了某个固定时间（两个最大段生命周期, 2MSL, 2 Maximum Segment Lifetime）之后, 没有收到服务器端的 ACK, 认为服务器端已经正常关闭连接, 于是自己也关闭连接, 进入 `CLOSED` 状态。 四次挥手的示意图如下： SYN攻击 什么是 SYN 攻击（SYN Flood）？ 12345在三次握手过程中，服务器发送 SYN-ACK 之后，收到客户端的 ACK 之前的 TCP 连接称为半连接(half-open connect)。此时服务器处于 SYN_RCVD 状态。当收到 ACK 后，服务器才能转入 ESTABLISHED 状态.SYN 攻击指的是，攻击客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送SYN包，服务器回复确认包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN请求被丢弃，导致目标系统运行缓慢，严重者会引起网络堵塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。 如何检测 SYN 攻击？ 1检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。在 Linux/Unix 上可以使用系统自带的 netstats 命令来检测 SYN 攻击。 如何防御 SYN 攻击？ 123456SYN攻击不能完全被阻止，除非将TCP协议重新设计。我们所做的是尽可能的减轻SYN攻击的危害，常见的防御 SYN 攻击的方法有如下几种： - 缩短超时（SYN Timeout）时间 - 增加最大半连接数 - 过滤网关防护 - SYN cookies技术 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"网络协议系列","slug":"网络协议系列","permalink":"https://ostenant.coding.me/categories/网络协议系列/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://ostenant.coding.me/tags/TCP/"}]},{"title":"WebSocket协议入门简介","slug":"WebSocket协议入门简介","date":"2017-02-23T07:47:00.000Z","updated":"2018-05-08T02:49:46.093Z","comments":true,"path":"2017/02/23/WebSocket协议入门简介/","link":"","permalink":"https://ostenant.coding.me/2017/02/23/WebSocket协议入门简介/","excerpt":"前言以前的网站为了实现推送功能，使用的方法都是轮询。所谓的轮询就是在特定的时间间隔（例如1秒），由浏览器向服务器发出一个 Http request ，然后服务器返回最新的数据给客户端浏览器，从而给出一种服务端实时推送的假象。由于 Http Request 的 Header（请求头）很长,而传输的数据可能很短就只占一点点，每次请求消耗的带宽大部分都消耗在 Header 上。从网上资料得知后来还有改进的轮询方法叫做 Comet ，使用 Ajax 。但这种技术虽然可达到双向通信，但依然需要发出请求，而且在 Comet 中，普遍采用了长轮询，这也会大量消耗服务器带宽和资源。","text":"前言以前的网站为了实现推送功能，使用的方法都是轮询。所谓的轮询就是在特定的时间间隔（例如1秒），由浏览器向服务器发出一个 Http request ，然后服务器返回最新的数据给客户端浏览器，从而给出一种服务端实时推送的假象。由于 Http Request 的 Header（请求头）很长,而传输的数据可能很短就只占一点点，每次请求消耗的带宽大部分都消耗在 Header 上。从网上资料得知后来还有改进的轮询方法叫做 Comet ，使用 Ajax 。但这种技术虽然可达到双向通信，但依然需要发出请求，而且在 Comet 中，普遍采用了长轮询，这也会大量消耗服务器带宽和资源。 正文所以 HTML5 定义了WebSocket 协议，以及相关的编程 API ，能更好的实现双向通信且节省服务器资源和带宽。 WebSocket原理 注意： WebSocket 实际上指的是一种协议，与我们熟知的 Http 协议是同等协议栈的一个网络协议。用网络模型结构来解释的话， WebSocket 和 Http 协议都属于 应用层协议，两者都基于传输层协议 TCP协议。 WebSocket与HTTP的联系简述：WebSocket 和 Http 一样，都是基于都 TCP，属于应用层的协议。 WebSocket并不是 HTTP 协议，WebSocket协议只是基于 HTTP 协议在客户端和服务器通过握手建立连接，连接建立以后就通过 TCP 协议发送和接收报文，与 HTTP 协议无关了。 WebSocket 协议和 HTTP 协议是两种不同的东西，它们的联系如下： 客户端开始建立 WebSocket 连接时要发送一个 header 标记了 Upgrade 的 HTTP 请求，表示请求协议升级。 服务器端做出响应的是，直接在现有的 HTTP 服务器和现有的 HTTP 端口上实现 WebSocket 协议，重用 HTTP 握手建立连接这一功能（比如解析和认证这个 HTTP 请求。如果在 TCP 协议上实现，这两个功能就要重新实现），然后再回一个状态码为 101 的 HTTP 响应完成握手，再往后发送数据时就没 HTTP 的事了。 WebSocket组件WebSocket通信架构HTML5 WebSockets规范定义了一个API,它允许web页面使用websocket协议与远程主机双向沟通。介绍了WebSocket接口,并定义了一个全双工的通信通道,通过一个套接字在网络上运行。相比不断客户端轮询的请求方式，HTML5 WebSockets长连接方式极大的减少了不必要的网络流量和延迟。 HTML5 WebSocketHTML5 WebSocket 规范定义了 WebSocket API , 允许用户在 Browser 使用 。WebSocket 协议为全双工通信,远程主机。基本原理是通过引入 WebSocket Endpoint, 定义一个 全双工 的通信通道, 通过一个 套接字 在网络上运行。HTML5 WebSocket 通过单个套接字长连接有效地降低网络上的开销。相比原有的的轮询和长轮询(Comet)方式来说，极大的减少了不必要的 网络流量 和延迟, 通常用于 推送实时数据 到客户端, 甚至可以通过维护两个HTTP连接来模拟 全双工连接 。 Proxy Server通常,代理服务器建立于内网和公网之间。代理服务器可以监控流量, 通过超时机制断开连接。HTTP 代理服务器——原本为文档转移——可以选择关闭或闲置 WebSocket 连接, 它会试图不断去call一个反应迟钝的 HTTP 服务器。对于长连接, 比如网络套接字, 这种行为是不合理的。另外, 代理服务器可能会缓存未加密的 HTTP 响应报文, 从而会给 HTTP 响应流带来巨大的延迟。 HTML5 WebSocket and Proxy Servers让我们看看 HTML5 WebSockes 是如何与代理服务器通信的。WebSocket 连接使用标准的HTTP端口 (80和443)。因此, HTML5 WebSocket 不需要新的硬件设备, 或新开放其他的网络端口。没有任何代理服务器 (代理或反向代理服务器、防火墙、负载平衡路由器等等), 浏览器和 WebSocket 服务器之间通信非常简单, 只要服务器和客户端都支持 WebSocket 协议。然而, 在生产环境中, 大量的网络通信都会穿透防火墙、代理服务器等。 HTML5 WebSocket and Proxy Servers之间的网络拓扑图 与常规的HTTP请求/响应，不断建立断开连接的方式相比, WebSocket 连接可以保持很长一段时间。代理服务器可能会对这种长连接的方式进行合理的处理, 但也可能带来不可预料的问题。 WebSocket示例Copy下面的代码,保存为 websocket.html。然后在浏览器中打开它。页面将自动连接到 ws://echo.websocket.org/ 服务器,发送一个消息，显示反应，关闭连接。参考链接：http://www.websocket.org/echo.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;!DOCTYPE html&gt;&lt;meta charset=\"utf-8\" /&gt;&lt;title&gt;WebSocket Test&lt;/title&gt;&lt;script language=\"javascript\" type=\"text/javascript\"&gt;var wsUri = \"ws://echo.websocket.org/\";var output;function init()&#123; output = document.getElementById(\"output\"); testWebSocket();&#125;function testWebSocket()&#123; websocket = new WebSocket(wsUri); websocket.onopen = function(evt) &#123; onOpen(evt) &#125;; websocket.onclose = function(evt) &#123; onClose(evt) &#125;; websocket.onmessage = function(evt) &#123; onMessage(evt) &#125;; websocket.onerror = function(evt) &#123; onError(evt) &#125;;&#125;function onOpen(evt)&#123; writeToScreen(\"CONNECTED\"); doSend(\"WebSocket rocks\");&#125;function onClose(evt)&#123; writeToScreen(\"DISCONNECTED\");&#125;function onMessage(evt)&#123; writeToScreen('&lt;span style=\"color: blue;\"&gt;RESPONSE: ' + evt.data+'&lt;/span&gt;'); websocket.close();&#125;function onError(evt)&#123; writeToScreen('&lt;span style=\"color: red;\"&gt;ERROR:&lt;/span&gt; ' + evt.data);&#125;function doSend(message)&#123; writeToScreen(\"SENT: \" + message); websocket.send(message);&#125;function writeToScreen(message)&#123; var pre = document.createElement(\"p\"); pre.style.wordWrap = \"break-word\"; pre.innerHTML = message; output.appendChild(pre);&#125;window.addEventListener(\"load\", init, false);&lt;/script&gt;&lt;h2&gt;WebSocket Test&lt;/h2&gt;&lt;div id=\"output\"&gt;&lt;/div&gt; 解读 创建一个 WebSocket 对象，参数是需要连接的服务器端的地址，同 http 协议使用http://开头 一样，WebSocket 协议的URL使用ws://开头，另外安全的WebSocket 协议使用wss://开头。。12var wsUri =\"ws://echo.websocket.org/\";websocket = new WebSocket(wsUri); WebSocket 对象一共支持 onopen , onmessage , onclose 和 onerror四个消息事件。 当Browser和 WebSocketServer 连接成功后，会触发 onopen 消息;12websocket.onopen = function(evt) &#123;&#125;; 如果连接失败，发送、接收数据失败或者处理数据出现错误，browser会触发 onerror 消息;12websocket.onerror = function(evt) &#123;&#125;; 当Browser接收到 WebSocketServer 发送过来的数据时，就会触发 onmessage 消息，参数evt中包含server传输过来的数据;12websocket.onmessage = function(evt) &#123;&#125;; 当Browser接收到 WebSocketServer 端发送的关闭连接请求时，就会触发 onclose 消息。12websocket.onclose = function(evt) &#123;&#125;; WebSocket报文下面给出 WebSocket 通过 HTTP 握手建立连接时发送的 request 和接收的 repsonse报文。 注意：下面的请求报文与响应报文中的内容不是完整的报文，而是 WebSocket 基于 Http 请求（响应）报文添加的内容。 客户端向 WebSocket 服务器发送 HTTP 请求，在请求头中加入Upgrade请求头，要求把连接从 HTTP 升级到 WebSocket，示例请求报文：12345678GET ws://echo.websocket.org/?encoding=text HTTP/1.1Origin: http://websocket.orgCookie: __utma=99asConnection: UpgradeHost: echo.websocket.orgSec-WebSocket-Key: uRovscZjNol/umbTt5uKmw==Upgrade: websocketSec-WebSocket-Version: 13 服务器发现客户端的请求是 WebSocket 协议，通过在在响应报文中添加Upgrade协议将连接从 HTTP 升级为 WebSocket，示例响应报文：123456HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: fFBooB7FAkLlXgRSz0BT3v4hq5s=Sec-WebSocket-Origin: nullSec-WebSocket-Location: ws://example.com/ 接下来，HTTP 连接断开连接，被底层同样依赖于 TCP/IP的 WebSocket连接所替换。对于WebSocket协议，默认情况下，同样是使用的 HTTP (80) 端口和 HTTPS (443) 端口。 WebSocket报文格式 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"网络协议系列","slug":"网络协议系列","permalink":"https://ostenant.coding.me/categories/网络协议系列/"}],"tags":[{"name":"WebSocket","slug":"WebSocket","permalink":"https://ostenant.coding.me/tags/WebSocket/"}]}]}