{"meta":{"title":"Icarus's Blog","subtitle":"上善若水任方猿","description":"上善若水任方猿","author":"Chen Icarus","url":"https://ostenant.coding.me"},"pages":[{"title":"","date":"2018-05-08T02:49:46.087Z","updated":"2018-05-08T02:49:46.087Z","comments":true,"path":"404.html","permalink":"https://ostenant.coding.me/404.html","excerpt":"","text":"404 | HelloDog"},{"title":"","date":"2018-06-06T14:04:42.377Z","updated":"2018-06-06T14:04:42.377Z","comments":true,"path":"baidu_verify_PzNbZXZJGn.html","permalink":"https://ostenant.coding.me/baidu_verify_PzNbZXZJGn.html","excerpt":"","text":"PzNbZXZJGn"},{"title":"","date":"2018-06-06T14:12:39.865Z","updated":"2018-06-06T14:12:39.864Z","comments":true,"path":"google02ecf273f044a1cf.html","permalink":"https://ostenant.coding.me/google02ecf273f044a1cf.html","excerpt":"","text":"google-site-verification: google02ecf273f044a1cf.html"},{"title":"关于我","date":"2018-06-07T02:23:23.000Z","updated":"2018-06-26T07:45:22.515Z","comments":true,"path":"about/index.html","permalink":"https://ostenant.coding.me/about/index.html","excerpt":"","text":"陈林 - 电子科技大学 - 软件工程 技术领域：涉猎 Java、Go、Python、Groovy 等语言，高性能、高并发、高可用、异步与消息中间件、缓存与数据库、分布式与微服务、容器和自动化等领域； 兴趣爱好：篮球，骑行，读书，发呆； 职业规划：励志成为一名出色的服务器端 - 系统架构师。 开源项目 集成Spring Cloud、Thrift、Docker和Consul的分布式RPC框架：Spring-Cloud-Starter-Thrift MyBatis逆向工程自定义插件扩展：MyBatis-Generator-Plus 工作经历 SAP成都研发中心 - 后端研发工程师 - 2015.12-2017.05 上海冰鉴信息科技有限公司 - 后端研发工程师 &amp; 架构师助理 - 2017.06-2018.04 ThougthWorks成都分公司 - 后端研发工程师 - 2018.05-至今 我的博客 CSDN：https://blog.csdn.net/baidu_22254181/ 简书：https://www.jianshu.com/u/864bef6dca50 掘金：https://juejin.im/user/5b265fc86fb9a00e562c41d4 处世之道 昔日寒山问拾得曰：世间有人谤我、欺我、辱我、笑我、轻我、贱我、恶我、骗我、如何处治乎？拾得曰：只要忍他、让他、由他、避他、耐他、敬他、不要理他，再待几年你且看他。 骚扰我 邮箱: chenlin6509@gmail.comQQ: 1546622705"},{"title":"分类","date":"2018-06-07T07:55:47.550Z","updated":"2018-06-07T07:55:47.550Z","comments":true,"path":"categories/index.html","permalink":"https://ostenant.coding.me/categories/index.html","excerpt":"","text":""},{"title":"微信公众号 - 零壹技术栈","date":"2018-06-18T00:23:23.000Z","updated":"2018-06-18T02:03:51.276Z","comments":true,"path":"wechat/index.html","permalink":"https://ostenant.coding.me/wechat/index.html","excerpt":"","text":"本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。"},{"title":"标签","date":"2018-06-07T07:55:42.364Z","updated":"2018-06-07T07:55:42.364Z","comments":true,"path":"tags/index.html","permalink":"https://ostenant.coding.me/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"JVM系列(六) - JVM垃圾回收器","slug":"JVM系列(六) - JVM垃圾回收器","date":"2018-08-02T22:58:00.000Z","updated":"2018-08-04T02:28:26.831Z","comments":true,"path":"2018/08/03/JVM系列(六) - JVM垃圾回收器/","link":"","permalink":"https://ostenant.coding.me/2018/08/03/JVM系列(六) - JVM垃圾回收器/","excerpt":"前言在之前的几篇博客中，我们大致介绍了，常见的 垃圾回收算法 及 JVM 中常见的分类回收算法。这些都是从算法和规范上分析 Java 中的垃圾回收，属于方法论。在 JVM 中，垃圾回收的具体实现是由 垃圾回收器（Garbage Collector）负责的。","text":"前言在之前的几篇博客中，我们大致介绍了，常见的 垃圾回收算法 及 JVM 中常见的分类回收算法。这些都是从算法和规范上分析 Java 中的垃圾回收，属于方法论。在 JVM 中，垃圾回收的具体实现是由 垃圾回收器（Garbage Collector）负责的。 正文概述在了解垃圾回收器\b之前，首先得了解一下垃圾回收器的几个名词。 1. 吞吐量CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值。比如说虚拟机总运行了 100 分钟，用户代码 时间 99 分钟，垃圾回收 时间 1 分钟，那么吞吐量就是 99%。 吞吐量 = 运行用户代码时间/（运行用户代码时间 + 垃圾回收时间） 2. 停顿时间\b停顿时间 指垃圾回收器正在运行时，应用程序 的 暂停时间。对于 独占回收器 而言，停顿时间可能会比较长。使用 并发回收器 时，由于垃圾回收器和应用程序 交替运行，程序的 停顿时间 会变短，但是，由于其 效率 很可能不如独占垃圾回收器，故系统的 吞吐量 可能会较低。 3. GC的名词3.1. 新生代GC（Minor GC）指发生在 新生代 的垃圾回收动作，因为 Java 对象大多都具备 朝生夕死 的特性，所以 Minor GC 通常 非常频繁，一般回收速度也比较快。 3.2. 老年代GC（Major GC）指发生在 老年代 的垃圾回收动作，出现了 Major GC，经常会伴随至少一次的 Minor GC（发生这种情况，那么 整个堆 都 GC 一遍，通常称为 Full GC）。Major GC 的速度一般会比 Minor GC 慢 10 倍以上。 4. 并发与并行4.1. 串行（Parallel）单线程 进行垃圾回收工作，但此时 用户线程 仍然处于 等待状态。 4.2. 并发（Concurrent）这里的并发指 用户线程 与 垃圾回收线程 交替执行。 4.3. 并行（Parallel）这里的并行指 用户线程 和多条 垃圾回收线程 分别在不同 CPU 上同时工作。 垃圾回收算法\b1. 根搜索算法根搜索算法 是从 离散数学 中的图论引入的，程序把所有引用关系看作一张图，从一个节点 GC ROOT 开始，寻找对应的 引用节点，找到这个节点后，继续寻找 这个节点 的 引用节点。当所有的引用节点寻找完毕后，剩余的节点 则被认为是 没有被引用到 的节点，即 无用 的节点。 上图 红色 为无用的节点，可以被 回收。目前 Java 中可以作为 GC ROOT 的对象有： 虚拟机栈 中引用的对象（本地变量表）； 方法区 中 静态\b变量 引用的对象； 方法区 中 常量 引用的对象； 本地方法栈 中引用的对象（Native 对象）。 基本所有 GC 算法都引用 根搜索算法 这种概念。 2. 标记 - 清除算法标记-清除算法 从 根集合 进行扫描，对 存活的对象 进行 标记。标记完毕后，再扫描整个空间中 未被标记 的对象进行 直接回收，如下图所示： 标记-清除算法 不需要进行 对象的移动，并且仅对 不存活 的对象进行处理，在 存活 的对象 比较多 的情况下 极为高效。但由于 标记-清除算法 直接回收不存活的对象，并没有对还存活的对象进行 整理，因此会导致 内存碎片。 3. 复制算法复制算法 将内存划分为 两个区间，使用此算法时，所有 动态分配 的对象都只能分配在 其中一个 区间（活动区间），而 另外一个 区间（空间区间）则是 空闲 的。 复制算法 同样从 根集合 扫描，将 存活 的对象 复制 到 空闲区间。当扫描完毕活动区间后，会的将 活动区间 一次性全部 回收。此时原本的 空闲区间 变成了 活动区间。下次 GC 时候又会重复刚才的操作，以此循环。 复制算法 在存活对象 比较少 的时候，极为高效，但是带来的成本是 牺牲一半的内存空间 用于进行 对象的移动。所以 复制算法 的使用场景，必须是对象的 存活率非常低 才行。最重要的是，我们需要克服 50% 的 内存浪费。 4. 标记 - 整理算法标记-整理算法 采用 标记-清除算法 一样的方式进行对象的 标记，但在回收 不存活的对象 占用的空间后，会将所有 存活的对象 往 左端空闲空间 移动，并更新对应的指针。 标记-整理 是在 标记-清除 之上，又进行了 对象的移动排序整理，因此 成本更高，但却解决了 内存碎片 的问题。 JVM 为了 优化内存 的回收，使用了 分代回收 的方式。对于 新生代内存 的回收（Minor GC）主要采用 复制算法。而对于 老年代内存 的回收（Major GC），大多采用 标记-整理算法。 垃圾\b\b回收器1. 垃圾回收器分类标准 2. 七种垃圾回收器概述在 JVM 中，具体实现有 Serial、ParNew、Parallel Scavenge、CMS、Serial Old（MSC）、Parallel Old、G1 等。在下图中，你可以看到 不同垃圾回收器 适合于 不同的内存区域，如果两个垃圾回收器之间 存在连线，那么表示两者可以 配合使用。 如果当 垃圾回收器 进行垃圾清理时，必须 暂停 其他所有的 工作线程，直到它完全收集结束。我们称这种需要暂停工作线程才能进行清理的策略为 Stop-the-World。以上回收器中， Serial、ParNew、Parallel Scavenge、Serial Old、Parallel Old 均采用的是 Stop-the-World 的策略。 图中有 7 种不同的 垃圾回收器，它们\b分别用于不同\b分代的垃圾回收。 新生代回收器：Serial、ParNew、Parallel Scavenge 老年代回收器：Serial Old、Parallel Old、CMS 整堆回收器：G1 两个 垃圾回收器 之间有连线表示它们可以 搭配使用，可选的\b搭配方案如下： 新生代 老年代 Serial Serial Old Serial CMS ParNew Serial Old ParNew CMS Parallel Scavenge Serial Old Parallel Scavenge Parallel Old G1 G1 3. 单线程垃圾回收器3.1. Serial（-XX:+UseSerialGC）Serial 回收器是最基本的 新生代 垃圾回收器，是 单线程 的垃圾回收器。由于垃圾清理时，Serial 回收器 不存在 线程间的切换，因此，特别是在单 CPU 的环境下，它的 垃圾清除效率 比较高。对于 Client 运行模式的程序，选择 Serial 回收器是一个不错的选择。 Serial 新生代回收器 采用的是 复制算法。 3.2. Serial Old（-XX:+UseSerialGC）Serial Old 回收器是 Serial 回收器的 老生代版本，属于 单线程回收器，它使用 标记-整理 算法。对于 Server 模式下的虚拟机，在 JDK1.5 及其以前，它常与 Parallel Scavenge 回收器配合使用，达到较好的 吞吐量，另外它也是 CMS 回收器在 Concurrent Mode Failure 时的 后备方案。 Serial 回收器和 Serial Old 回收器的执行效果如下： Serial Old 老年代回收器 采用的是 标记 - 整理算法。 4. 多线程垃圾回收器（\b吞吐量优先）4.1. ParNew（-XX:+UseParNewGC）ParNew 回收器是在 Serial 回收器的基础上演化而来的，属于 Serial 回收器的 多线程版本，同样运行在 新生代区域。在实现上，两者共用很多代码。在不同运行环境下，根据 CPU 核数，开启 不同的线程数，从而达到 最优 的垃圾回收效果。对于那些 Server 模式的应用程序，如果考虑采用 CMS 作为 老生代回收器 时，ParNew 回收器是一个不错的选择。 ParNew 新生代回收器 采用的是 复制算法。 4.2. Parallel Scavenge（-XX:+UseParallelGC）和 ParNew 回收一样，Parallel Scavenge 回收器也是运行在 新生代区域，属于 多线程 的回收器。但不同的是，ParNew 回收器是通过控制 垃圾回收 的 线程数 来进行参数调整，而 Parallel Scavenge 回收器更关心的是 程序运行的吞吐量。即一段时间内，用户代码 运行时间占 总运行时间 的百分比。 Parallel Scavenge 新生代回收器 采用的是 复制算法。 4.3. Parallel Old\b（-XX:+UseParallelOldGC）Parallel Old 回收器是 Parallel Scavenge 回收器的 老生代版本，属于 多线程回收器，采用 标记-整理算法。Parallel Old 回收器和 Parallel Scavenge 回收器同样考虑了 吞吐量优先 这一指标，非常适合那些 注重吞吐量 和 CPU 资源敏感 的场合。 Parallel Old 老年代回收器 采用的是 标记 - 整理算法。 5. 其他的回收器（\b停顿时间优先）5.1. CMS（-XX:+UseConcMarkSweepGC）CMS（Concurrent Mark Sweep） 回收器是在 最短回收停顿时间 为前提的回收器，属于 多线程回收器，采用 标记-清除算法。 相比之前的回收器，CMS 回收器的运作过程比较复杂，分为四步： 初始标记（CMS initial mark） 初始标记 仅仅是标记 GC Roots 内 直接关联 的对象。这个阶段 速度很快，需要 Stop the World。 并发标记（CMS concurrent mark） 并发标记 进行的是 GC Tracing，从 GC Roots 开始对堆进行 可达性分析，找出 存活对象。 重新标记（CMS remark） 重新标记 阶段为了 修正 并发期间由于 用户进行运作 导致的 标记变动 的那一部分对象的 标记记录。这个阶段的 停顿时间 一般会比 初始标记阶段 稍长一些，但远比 并发标记 的时间短，也需要 Stop The World。 并发清除（CMS concurrent sweep） 并发清除 阶段会清除垃圾对象。 初始标记（CMS initial mark）和 重新标记（CMS remark）会导致 用户线程 卡顿，Stop the World 现象发生。 在整个过程中，CMS 回收器的 内存回收 基本上和 用户线程 并发执行，如下所示： 由于 CMS 回收器 并发收集、停顿低，因此有些地方成为 并发低停顿回收器（Concurrent Low Pause Sweep Collector）。 CMS 回收器的缺点： CMS回收器对CPU资源非常依赖 CMS 回收器过分依赖于 多线程环境，默认情况下，开启的 线程数 为（CPU 的数量 + 3）/ 4，当 CPU 数量少于 4 个时，CMS 对 用户查询 的影响将会很大，因为他们要分出一半的运算能力去 执行回收器线程； CMS回收器无法清除浮动垃圾 由于 CMS 回收器 清除已标记的垃圾 （处于最后一个阶段）时，用户线程 还在运行，因此会有新的垃圾产生。但是这部分垃圾 未被标记，在下一次 GC 才能清除，因此被成为 浮动垃圾。 由于 内存回收 和 用户线程 是同时进行的，内存在被 回收 的同时，也在被 分配。当 老生代 中的内存使用超过一定的比例时，系统将会进行 垃圾回收；当 剩余内存 不能满足程序运行要求时，系统将会出现 Concurrent Mode Failure，临时采用 Serial Old 算法进行 清除，此时的 性能 将会降低。 垃圾收集结束后残余大量空间碎片 CMS 回收器采用的 标记清除算法，本身存在垃圾收集结束后残余 大量空间碎片 的缺点。CMS 配合适当的 内存整理策略，在一定程度上可以解决这个问题。 5.2. G1回收器（垃圾区域Region优先）G1 是 JDK 1.7 中正式投入使用的用于取代 CMS 的 压缩回收器。它虽然没有在物理上隔断 新生代 与 老生代，但是仍然属于 分代垃圾回收器。G1 仍然会区分 年轻代 与 老年代，年轻代依然分有 Eden 区与 Survivor 区。 G1 首先将 堆 分为 大小相等 的 Region，避免 全区域 的垃圾回收。然后追踪每个 Region 垃圾 堆积的价值大小，在后台维护一个 优先列表，根据允许的回收时间优先回收价值最大的 Region。同时 G1采用 Remembered Set 来存放 Region 之间的 对象引用 ，其他回收器中的 新生代 与 老年代 之间的对象引用，从而避免 全堆扫描。G1 的分区示例如下图所示： 这种使用 Region 划分 内存空间 以及有 优先级 的区域回收方式，保证 G1 回收器在有限的时间内可以获得尽可能 高的回收效率。 G1 和 CMS 运作过程有很多相似之处，整个过程也分为 4 个步骤： 初始标记（CMS initial mark） 初始标记 仅仅是标记 GC Roots 内 直接关联 的对象。这个阶段 速度很快，需要 Stop the World。 并发标记（CMS concurrent mark） 并发标记 进行的是 GC Tracing，从 GC Roots 开始对堆进行 可达性分析，找出 存活对象。 重新标记（CMS remark） 重新标记 阶段为了 修正 并发期间由于 用户进行运作 导致的 标记变动 的那一部分对象的 标记记录。这个阶段的 停顿时间 一般会比 初始标记阶段 稍长一些，但远比 并发标记 的时间短，也需要 Stop The World。 筛选回收 首先对各个 Region 的 回收价值 和 成本 进行排序，根据用户所期望的 GC 停顿时间 来制定回收计划。这个阶段可以与用户程序一起 并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿 用户线程 将大幅提高回收效率。 与其它 GC 回收相比，G1 具备如下 4 个特点： 并行与并发 使用多个 CPU 来缩短 Stop-the-World 的 停顿时间，部分其他回收器需要停顿 Java 线程执行的 GC 动作，G1 回收器仍然可以通过 并发的方式 让 Java 程序继续执行。 分代回收 与其他回收器一样，分代概念 在 G1 中依然得以保留。虽然 G1 可以不需要 其他回收器配合 就能独立管理 整个GC堆，但它能够采用 不同的策略 去处理 新创建的对象 和 已经存活 一段时间、熬过多次 GC 的旧对象，以获取更好的回收效果。新生代 和 老年代 不再是 物理隔离，是多个 大小相等 的独立 Region。 空间整合 与 CMS 的 标记—清理 算法不同，G1 从 整体 来看是基于 标记—整理 算法实现的回收器。从 局部（两个 Region 之间）上来看是基于 复制算法 实现的。 但无论如何，这 两种算法 都意味着 G1 运作期间 不会产生内存空间碎片，回收后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象 时不会因为无法找到 连续内存空间 而提前触发 下一次 GC。 可预测的停顿 这是 G1 相对于 CMS 的另一大优势，降低停顿时间 是 G1 和 CMS 共同的关注点。G1 除了追求 低停顿 外，还能建立 可预测 的 停顿时间模型，能让使用者明确指定在一个 长度 为 M 毫秒的 时间片段 内，消耗在 垃圾回收 上的时间不得超过 N 毫秒。（后台维护的 优先列表，优先回收 价值大 的 Region）。 参考周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 欢迎关注技术公众号：零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA虚拟机系列","slug":"JAVA虚拟机系列","permalink":"https://ostenant.coding.me/categories/JAVA虚拟机系列/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://ostenant.coding.me/tags/JVM/"}]},{"title":"浅谈Nginx服务器的内部核心架构设计","slug":"浅谈Nginx服务器的内部核心架构设计","date":"2018-07-15T10:50:00.000Z","updated":"2018-07-15T23:47:46.842Z","comments":true,"path":"2018/07/15/浅谈Nginx服务器的内部核心架构设计/","link":"","permalink":"https://ostenant.coding.me/2018/07/15/浅谈Nginx服务器的内部核心架构设计/","excerpt":"前言Nginx 是一个 免费的，开源的，高性能 的 HTTP 服务器和 反向代理，以及 IMAP/POP3 代理服务器。 Nginx 以其高性能，稳定性，丰富的功能，简单的配置和低资源消耗而闻名。Nginx是一个 Web 服务器，也可以用作 反向代理，负载均衡器 和 HTTP 缓存。","text":"前言Nginx 是一个 免费的，开源的，高性能 的 HTTP 服务器和 反向代理，以及 IMAP/POP3 代理服务器。 Nginx 以其高性能，稳定性，丰富的功能，简单的配置和低资源消耗而闻名。Nginx是一个 Web 服务器，也可以用作 反向代理，负载均衡器 和 HTTP 缓存。 很多高知名度的网站都使用 Nginx，如：Netflix，GitHub，SoundCloud，MaxCDN 等。 正文1. Nginx的整体架构 1.1. 主进程Nginx 启动时，会生成两种类型的 进程*，一个是 主进程（master），一个（windows 版本的目前只有一个）或 多个工作进程（worker）。主进程 并不处理网络请求，主要负责 调度工作进程，也就是图示的 3 项：加载配置、启动工作进程 及 非停升级。所以，Nginx 启动以后，查看操作系统的进程列表，我们就能看到 至少有两个 Nginx 进程。 1.2. 工作进程服务器实际 处理网络请求 及 响应 的是 工作进程（worker），在类 unix 系统上，Nginx 可以配置 多个 worker，而每个 worker 进程 都可以同时处理 数以千计 的 网络请求。 1.3. 模块化设计Nginx 的 worker 进程，包括 核心 和 功能性模块，核心模块 负责维持一个 运行循环（run-loop），执行网络请求处理的 不同阶段 的模块功能，比如：网络读写、存储读写、内容传输、外出过滤，以及 将请求发往上游服务器 等。而其代码的 模块化设计，也使得我们可以根据需要对 功能模块 进行适当的 选择 和 修改，编译成具有 特定功能 的服务器。 1.4. 事件驱动模型基于 异步及非阻塞 的 事件驱动模型，可以说是 Nginx 得以获得 高并发、高性能 的关键因素，同时也得益于对 Linux、Solaris 及类 BSD 等操作系统内核中 事件通知 及 I/O 性能增强功能 的采用，如 kqueue、epoll 及 event ports。 1.5. 代理（proxy）设计代理设计，可以说是 Nginx 深入骨髓的设计，无论是对于 HTTP，还是对于 FastCGI、Memcache、Redis 等的网络请求或响应，本质上都采用了 代理机制。所以，Nginx 天生就是高性能的 代理服务器。 2. Nginx的模块化设计高度模块化 的设计是 Nginx 的架构基础。Nginx 服务器被分解为 多个模块，每个模块就是一个 功能模块，只负责自身的功能，模块之间严格遵循 “高内聚，低耦合” 的原则。 2.1. 核心模块核心模块 是 Nginx 服务器正常运行 必不可少 的模块，提供 错误日志记录、配置文件解析、事件驱动机制、进程管理 等核心功能。 2.2. 标准HTTP模块标准 HTTP 模块提供 HTTP 协议解析相关的功能，比如：端口配置、网页编码设置、HTTP 响应头设置 等等。 2.3. 可选HTTP模块可选 HTTP 模块主要用于 扩展 标准的 HTTP 功能，让 Nginx 能处理一些特殊的服务，比如：Flash 多媒体传输、解析 GeoIP 请求、网络传输压缩、安全协议 SSL 支持等。 2.4. 邮件服务模块邮件服务模块 主要用于支持 Nginx 的 邮件服务，包括对 POP3 协议、IMAP 协议和 SMTP 协议的支持。 2.5. 第三方模块第三方模块 是为了扩展 Nginx 服务器应用，完成开发者自定义功能，比如：Json 支持、Lua 支持等。 3. Nginx的请求方式处理Nginx 是一个 高性能 的 Web 服务器，能够同时处理 大量的并发请求。它结合 多进程机制 和 异步机制，异步机制使用的是 异步非阻塞方式，接下来就给大家介绍一下 Nginx 的 多线程机制 和 异步非阻塞机制。 3.1. 多进程机制服务器每当收到一个客户端时，就有 服务器主进程（master process）生成一个 子进程（worker process）出来和客户端建立连接进行交互，直到连接断开，该子进程就结束了。 使用 进程 的好处是 各个进程之间相互独立，不需要加锁，减少了使用锁对性能造成影响，同时降低编程的复杂度，降低开发成本。其次，采用独立的进程，可以让 进程互相之间不会影响，如果一个进程发生异常退出时，其它进程正常工作，master 进程则很快启动新的 worker 进程，确保服务不会中断，从而将风险降到最低。 缺点是操作系统生成一个 子进程 需要进行 内存复制 等操作，在 资源 和 时间 上会产生一定的开销。当有 大量请求 时，会导致 系统性能下降。 3.2. 异步非阻塞机制每个 工作进程 使用 异步非阻塞方式，可以处理 多个客户端请求。 当某个 工作进程 接收到客户端的请求以后，调用 IO 进行处理，如果不能立即得到结果，就去 处理其他请求（即为 非阻塞）；而 客户端 在此期间也 无需等待响应，可以去处理其他事情（即为 异步）。 当 IO 返回时，就会通知此 工作进程；该进程得到通知，暂时 挂起 当前处理的事务去 响应客户端请求。 4. Nginx事件驱动模型在 Nginx 的 异步非阻塞机制 中，工作进程 在调用 IO 后，就去处理其他的请求，当 IO 调用返回后，会 通知 该 工作进程。对于这样的系统调用，主要使用 Nginx 服务器的 事件驱动模型 来实现。 如上图所示，Nginx 的 事件驱动模型 由 事件收集器、事件发送器 和 事件处理器 三部分基本单元组成。 事件收集器：负责收集 worker 进程的各种 IO 请求； 事件发送器：负责将 IO 事件发送到 事件处理器； 事件处理器：负责各种事件的 响应工作。 事件发送器 将每个请求放入一个 待处理事件列表，使用非阻塞 I/O 方式调用 事件处理器 来处理该请求。其处理方式称为 “多路 IO 复用方法”，常见的包括以下三种：select 模型、poll 模型、epoll 模型。 5. Nginx进程处理模型Nginx 服务器使用 master/worker 多进程模式。多线程启动和执行的流程如下： 主程序 Master process 启动后，通过一个 for 循环来 接收 和 处理外部信号； 主进程 通过 fork() 函数产生 worker 子进程，每个 子进程 执行一个 for 循环来实现 Nginx 服务器 对事件的接收 和 处理。 一般推荐 worker 进程数 与 CPU 内核数 一致，这样一来不存在 大量的子进程 生成和管理任务，避免了进程之间 竞争 CPU 资源 和 进程切换 的开销。而且 Nginx 为了更好的利用 多核特性，提供了 CPU 亲缘性 的绑定选项，我们可以将某 一个进程绑定在某一个核 上，这样就不会因为 进程的切换 带来 Cache 的失效。 对于每个请求，有且只有一个 工作进程 对其处理。首先，每个 worker 进程都是从 master 进程 fork 过来。在 master 进程里面，先建立好需要 listen 的 socket（listenfd） 之后，然后再 fork 出多个 worker 进程。 所有 worker 进程的 listenfd 会在 新连接 到来时变得 可读，为保证只有一个进程处理该连接，所有 worker 进程在注册 listenfd 读事件 前 抢占 accept_mutex，抢到 互斥锁 的那个进程 注册 listenfd 读事件，在 读事件 里调用 accept 接受该连接。 当一个 worker 进程在 accept 这个连接之后，就开始 读取请求，解析请求，处理请求，产生数据后，再 返回给客户端，最后才 断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由 worker 进程来处理，而且只在一个 worker 进程中处理。 在 Nginx 服务器的运行过程中，主进程 和 工作进程 需要进程交互。交互依赖于 Socket 实现的 管道 来实现。 5.1. 主进程与工作进程交互这条管道与普通的管道不同，它是由 主进程 指向 工作进程 的 单向管道，包含主进程向工作进程发出的 指令，工作进程 ID 等；同时 主进程 与外界通过 信号通信；每个 子进程 具备 接收信号，并处理相应的事件的能力。 5.2. 工作进程与工作进程交互这种交互是和 主进程-工作进程 交互是基本一致的，但是会通过 主进程 间接完成。工作进程 之间是 相互隔离 的，所以当工作进程 W1 需要向工作进程 W2 发指令时，首先找到 W2 的 进程 ID，然后将正确的指令写入指向 W2 的 通道。W2 收到信号采取相应的措施。 小结通过这篇文章，我们对 Nginx 服务器的 整体架构 有了一个整体的认识。包括其 模块化的设计、多进程 和 异步非阻塞 的请求处理方式、事件驱动模型 等。通过这些理论知识，才能更好地领悟 Nginx 的设计思想。对于我们学习 Nginx 来说有很大的帮助。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"高并发系统系列","slug":"高并发系统系列","permalink":"https://ostenant.coding.me/categories/高并发系统系列/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://ostenant.coding.me/tags/Nginx/"},{"name":"服务器","slug":"服务器","permalink":"https://ostenant.coding.me/tags/服务器/"},{"name":"反向代理","slug":"反向代理","permalink":"https://ostenant.coding.me/tags/反向代理/"},{"name":"负载均衡","slug":"负载均衡","permalink":"https://ostenant.coding.me/tags/负载均衡/"},{"name":"高性能","slug":"高性能","permalink":"https://ostenant.coding.me/tags/高性能/"}]},{"title":"浅谈常见的七种加密算法及实现","slug":"浅谈\b常见的七种加密算法及实现","date":"2018-07-13T12:06:00.000Z","updated":"2018-07-13T14:02:41.657Z","comments":true,"path":"2018/07/13/浅谈\b常见的七种加密算法及实现/","link":"","permalink":"https://ostenant.coding.me/2018/07/13/浅谈\b常见的七种加密算法及实现/","excerpt":"前言数字签名、信息加密 是前后端开发都经常需要使用到的技术，应用场景包括了用户登入、交易、信息通讯、oauth 等等，不同的应用场景也会需要使用到不同的签名加密算法，或者需要搭配不一样的 签名加密算法 来达到业务目标。这里简单的给大家介绍几种常见的签名加密算法和一些典型场景下的应用。","text":"前言数字签名、信息加密 是前后端开发都经常需要使用到的技术，应用场景包括了用户登入、交易、信息通讯、oauth 等等，不同的应用场景也会需要使用到不同的签名加密算法，或者需要搭配不一样的 签名加密算法 来达到业务目标。这里简单的给大家介绍几种常见的签名加密算法和一些典型场景下的应用。 正文1. 数字签名数字签名，简单来说就是通过提供 可鉴别 的 数字信息 验证 自身身份 的一种方式。一套 数字签名 通常定义两种 互补 的运算，一个用于 签名，另一个用于 验证。分别由 发送者 持有能够 代表自己身份 的 私钥 (私钥不可泄露),由 接受者 持有与私钥对应的 公钥 ，能够在 接受 到来自发送者信息时用于 验证 其身份。 注意：图中 加密过程 有别于 公钥加密，更多 介绍戳这里。签名 最根本的用途是要能够唯一 证明发送方的身份，防止 中间人攻击、CSRF 跨域身份伪造。基于这一点在诸如 设备认证、用户认证、第三方认证 等认证体系中都会使用到 签名算法 (彼此的实现方式可能会有差异)。 2. 加密和解密2.1. 加密数据加密 的基本过程，就是对原来为 明文 的文件或数据按 某种算法 进行处理，使其成为 不可读 的一段代码，通常称为 “密文”。通过这样的途径，来达到 保护数据 不被 非法人窃取、阅读的目的。 2.2. 解密加密 的 逆过程 为 解密，即将该 编码信息 转化为其 原来数据 的过程。 3. 对称加密和非对称加密加密算法分 对称加密 和 非对称加密，其中对称加密算法的加密与解密 密钥相同，非对称加密算法的加密密钥与解密 密钥不同，此外，还有一类 不需要密钥 的 散列算法。 常见的 对称加密 算法主要有 DES、3DES、AES 等，常见的 非对称算法 主要有 RSA、DSA 等，散列算法 主要有 SHA-1、MD5 等。 3.1. 对称加密对称加密算法 是应用较早的加密算法，又称为 共享密钥加密算法。在 对称加密算法 中，使用的密钥只有一个，发送 和 接收 双方都使用这个密钥对数据进行 加密 和 解密。这就要求加密和解密方事先都必须知道加密的密钥。 数据加密过程：在对称加密算法中，数据发送方 将 明文 (原始数据) 和 加密密钥 一起经过特殊 加密处理，生成复杂的 加密密文 进行发送。 数据解密过程：数据接收方 收到密文后，若想读取原数据，则需要使用 加密使用的密钥 及相同算法的 逆算法 对加密的密文进行解密，才能使其恢复成 可读明文。 3.2. 非对称加密非对称加密算法，又称为 公开密钥加密算法。它需要两个密钥，一个称为 公开密钥 (public key)，即 公钥，另一个称为 私有密钥 (private key)，即 私钥。 因为 加密 和 解密 使用的是两个不同的密钥，所以这种算法称为 非对称加密算法。 如果使用 公钥 对数据 进行加密，只有用对应的 私钥 才能 进行解密。 如果使用 私钥 对数据 进行加密，只有用对应的 公钥 才能 进行解密。 例子：甲方生成 一对密钥 并将其中的一把作为 公钥 向其它人公开，得到该公钥的 乙方 使用该密钥对机密信息 进行加密 后再发送给甲方，甲方再使用自己保存的另一把 专用密钥 (私钥)，对 加密 后的信息 进行解密。 4. 常见的签名加密算法4.1. MD5算法MD5 用的是 哈希函数，它的典型应用是对一段信息产生 信息摘要，以 防止被篡改。严格来说，MD5 不是一种 加密算法 而是 摘要算法。无论是多长的输入，MD5 都会输出长度为 128bits 的一个串 (通常用 16 进制 表示为 32 个字符)。 12345678public static final byte[] computeMD5(byte[] content) &#123; try &#123; MessageDigest md5 = MessageDigest.getInstance(\"MD5\"); return md5.digest(content); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException(e); &#125;&#125; 4.2. SHA1算法SHA1 是和 MD5 一样流行的 消息摘要算法，然而 SHA1 比 MD5 的 安全性更强。对于长度小于 2 ^ 64 位的消息，SHA1 会产生一个 160 位的 消息摘要。基于 MD5、SHA1 的信息摘要特性以及 不可逆 (一般而言)，可以被应用在检查 文件完整性 以及 数字签名 等场景。 12345678public static byte[] computeSHA1(byte[] content) &#123; try &#123; MessageDigest sha1 = MessageDigest.getInstance(\"SHA1\"); return sha1.digest(content); &#125; catch (NoSuchAlgorithmException e) &#123; throw new RuntimeException(e); &#125;&#125; 4.3. HMAC算法HMAC 是密钥相关的 哈希运算消息认证码（Hash-based Message Authentication Code），HMAC 运算利用 哈希算法 (MD5、SHA1 等)，以 一个密钥 和 一个消息 为输入，生成一个 消息摘要 作为 输出。 HMAC 发送方 和 接收方 都有的 key 进行计算，而没有这把 key 的第三方，则是 无法计算 出正确的 散列值的，这样就可以 防止数据被篡改。 1234567891011121314151617181920212223242526272829303132333435363738394041424344package net.pocrd.util;import net.pocrd.annotation.NotThreadSafe;import net.pocrd.define.ConstField;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import javax.crypto.Mac;import javax.crypto.SecretKey;import javax.crypto.spec.SecretKeySpec;import java.util.Arrays;@NotThreadSafepublic class HMacHelper &#123; private static final Logger logger = LoggerFactory.getLogger(HMacHelper.class); private Mac mac; /** * MAC算法可选以下多种算法 * HmacMD5/HmacSHA1/HmacSHA256/HmacSHA384/HmacSHA512 */ private static final String KEY_MAC = \"HmacMD5\"; public HMacHelper(String key) &#123; try &#123; SecretKey secretKey = new SecretKeySpec(key.getBytes(ConstField.UTF8), KEY_MAC); mac = Mac.getInstance(secretKey.getAlgorithm()); mac.init(secretKey); &#125; catch (Exception e) &#123; logger.error(\"create hmac helper failed.\", e); &#125; &#125; public byte[] sign(byte[] content) &#123; return mac.doFinal(content); &#125; public boolean verify(byte[] signature, byte[] content) &#123; try &#123; byte[] result = mac.doFinal(content); return Arrays.equals(signature, result); &#125; catch (Exception e) &#123; logger.error(\"verify sig failed.\", e); &#125; return false; &#125;&#125; 测试结论：HMAC 算法实例在 多线程环境 下是 不安全的。但是需要在 多线程访问 时，进行同步的辅助类，使用 ThreadLocal 为 每个线程缓存 一个实例可以避免进行锁操作。 4.4. AES/DES/3DES算法AES、DES、3DES 都是 对称 的 块加密算法，加解密 的过程是 可逆的。常用的有 AES128、AES192、AES256 (默认安装的 JDK 尚不支持 AES256，需要安装对应的 jce 补丁进行升级 jce1.7，jce1.8)。 4.4.1. DES算法DES 加密算法是一种 分组密码，以 64 位为 分组对数据 加密，它的 密钥长度 是 56 位，加密解密 用 同一算法。 DES 加密算法是对 密钥 进行保密，而 公开算法，包括加密和解密算法。这样，只有掌握了和发送方 相同密钥 的人才能解读由 DES加密算法加密的密文数据。因此，破译 DES 加密算法实际上就是 搜索密钥的编码。对于 56 位长度的 密钥 来说，如果用 穷举法 来进行搜索的话，其运算次数为 2 ^ 56 次。 4.4.2. 3DES算法是基于 DES 的 对称算法，对 一块数据 用 三个不同的密钥 进行 三次加密，强度更高。 4.4.3. AES算法AES 加密算法是密码学中的 高级加密标准，该加密算法采用 对称分组密码体制，密钥长度的最少支持为 128 位、 192 位、256 位，分组长度 128 位，算法应易于各种硬件和软件实现。这种加密算法是美国联邦政府采用的 区块加密标准。 AES 本身就是为了取代 DES 的，AES 具有更好的 安全性、效率 和 灵活性。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import net.pocrd.annotation.NotThreadSafe;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.spec.IvParameterSpec;import javax.crypto.spec.SecretKeySpec;import java.security.SecureRandom;@NotThreadSafepublic class AesHelper &#123; private SecretKeySpec keySpec; private IvParameterSpec iv; public AesHelper(byte[] aesKey, byte[] iv) &#123; if (aesKey == null || aesKey.length &lt; 16 || (iv != null &amp;&amp; iv.length &lt; 16)) &#123; throw new RuntimeException(\"错误的初始密钥\"); &#125; if (iv == null) &#123; iv = Md5Util.compute(aesKey); &#125; keySpec = new SecretKeySpec(aesKey, \"AES\"); this.iv = new IvParameterSpec(iv); &#125; public AesHelper(byte[] aesKey) &#123; if (aesKey == null || aesKey.length &lt; 16) &#123; throw new RuntimeException(\"错误的初始密钥\"); &#125; keySpec = new SecretKeySpec(aesKey, \"AES\"); this.iv = new IvParameterSpec(Md5Util.compute(aesKey)); &#125; public byte[] encrypt(byte[] data) &#123; byte[] result = null; Cipher cipher = null; try &#123; cipher = Cipher.getInstance(\"AES/CFB/NoPadding\"); cipher.init(Cipher.ENCRYPT_MODE, keySpec, iv); result = cipher.doFinal(data); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; return result; &#125; public byte[] decrypt(byte[] secret) &#123; byte[] result = null; Cipher cipher = null; try &#123; cipher = Cipher.getInstance(\"AES/CFB/NoPadding\"); cipher.init(Cipher.DECRYPT_MODE, keySpec, iv); result = cipher.doFinal(secret); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; return result; &#125; public static byte[] randomKey(int size) &#123; byte[] result = null; try &#123; KeyGenerator gen = KeyGenerator.getInstance(\"AES\"); gen.init(size, new SecureRandom()); result = gen.generateKey().getEncoded(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; return result; &#125;&#125; 4.5. RSA算法RSA 加密算法是目前最有影响力的 公钥加密算法，并且被普遍认为是目前 最优秀的公钥方案 之一。RSA 是第一个能同时用于 加密 和 数字签名 的算法，它能够 抵抗 到目前为止已知的 所有密码攻击，已被 ISO 推荐为公钥数据加密标准。 RSA 加密算法 基于一个十分简单的数论事实：将两个大 素数 相乘十分容易，但想要对其乘积进行 因式分解 却极其困难，因此可以将 乘积 公开作为 加密密钥。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157import net.pocrd.annotation.NotThreadSafe;import org.bouncycastle.jce.provider.BouncyCastleProvider;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import javax.crypto.Cipher;import java.io.ByteArrayOutputStream;import java.security.KeyFactory;import java.security.Security;import java.security.Signature;import java.security.interfaces.RSAPrivateCrtKey;import java.security.interfaces.RSAPublicKey;import java.security.spec.PKCS8EncodedKeySpec;import java.security.spec.X509EncodedKeySpec;@NotThreadSafepublic class RsaHelper &#123; private static final Logger logger = LoggerFactory.getLogger(RsaHelper.class); private RSAPublicKey publicKey; private RSAPrivateCrtKey privateKey; static &#123; Security.addProvider(new BouncyCastleProvider()); //使用bouncycastle作为加密算法实现 &#125; public RsaHelper(String publicKey, String privateKey) &#123; this(Base64Util.decode(publicKey), Base64Util.decode(privateKey)); &#125; public RsaHelper(byte[] publicKey, byte[] privateKey) &#123; try &#123; KeyFactory keyFactory = KeyFactory.getInstance(\"RSA\"); if (publicKey != null &amp;&amp; publicKey.length &gt; 0) &#123; this.publicKey = (RSAPublicKey)keyFactory.generatePublic(new X509EncodedKeySpec(publicKey)); &#125; if (privateKey != null &amp;&amp; privateKey.length &gt; 0) &#123; this.privateKey = (RSAPrivateCrtKey)keyFactory.generatePrivate(new PKCS8EncodedKeySpec(privateKey)); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public RsaHelper(String publicKey) &#123; this(Base64Util.decode(publicKey)); &#125; public RsaHelper(byte[] publicKey) &#123; try &#123; KeyFactory keyFactory = KeyFactory.getInstance(\"RSA\"); if (publicKey != null &amp;&amp; publicKey.length &gt; 0) &#123; this.publicKey = (RSAPublicKey)keyFactory.generatePublic(new X509EncodedKeySpec(publicKey)); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public byte[] encrypt(byte[] content) &#123; if (publicKey == null) &#123; throw new RuntimeException(\"public key is null.\"); &#125; if (content == null) &#123; return null; &#125; try &#123; Cipher cipher = Cipher.getInstance(\"RSA/ECB/PKCS1Padding\"); cipher.init(Cipher.ENCRYPT_MODE, publicKey); int size = publicKey.getModulus().bitLength() / 8 - 11; ByteArrayOutputStream baos = new ByteArrayOutputStream((content.length + size - 1) / size * (size + 11)); int left = 0; for (int i = 0; i &lt; content.length; ) &#123; left = content.length - i; if (left &gt; size) &#123; cipher.update(content, i, size); i += size; &#125; else &#123; cipher.update(content, i, left); i += left; &#125; baos.write(cipher.doFinal()); &#125; return baos.toByteArray(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public byte[] decrypt(byte[] secret) &#123; if (privateKey == null) &#123; throw new RuntimeException(\"private key is null.\"); &#125; if (secret == null) &#123; return null; &#125; try &#123; Cipher cipher = Cipher.getInstance(\"RSA/ECB/PKCS1Padding\"); cipher.init(Cipher.DECRYPT_MODE, privateKey); int size = privateKey.getModulus().bitLength() / 8; ByteArrayOutputStream baos = new ByteArrayOutputStream((secret.length + size - 12) / (size - 11) * size); int left = 0; for (int i = 0; i &lt; secret.length; ) &#123; left = secret.length - i; if (left &gt; size) &#123; cipher.update(secret, i, size); i += size; &#125; else &#123; cipher.update(secret, i, left); i += left; &#125; baos.write(cipher.doFinal()); &#125; return baos.toByteArray(); &#125; catch (Exception e) &#123; logger.error(\"rsa decrypt failed.\", e); &#125; return null; &#125; public byte[] sign(byte[] content) &#123; if (privateKey == null) &#123; throw new RuntimeException(\"private key is null.\"); &#125; if (content == null) &#123; return null; &#125; try &#123; Signature signature = Signature.getInstance(\"SHA1WithRSA\"); signature.initSign(privateKey); signature.update(content); return signature.sign(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public boolean verify(byte[] sign, byte[] content) &#123; if (publicKey == null) &#123; throw new RuntimeException(\"public key is null.\"); &#125; if (sign == null || content == null) &#123; return false; &#125; try &#123; Signature signature = Signature.getInstance(\"SHA1WithRSA\"); signature.initVerify(publicKey); signature.update(content); return signature.verify(sign); &#125; catch (Exception e) &#123; logger.error(\"rsa verify failed.\", e); &#125; return false; &#125;&#125; 4.6. ECC算法ECC 也是一种 非对称加密算法，主要优势是在某些情况下，它比其他的方法使用 更小的密钥，比如 RSA 加密算法，提供 相当的或更高等级 的安全级别。不过一个缺点是 加密和解密操作 的实现比其他机制 时间长 (相比 RSA 算法，该算法对 CPU 消耗严重)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144import net.pocrd.annotation.NotThreadSafe;import org.bouncycastle.jcajce.provider.asymmetric.ec.BCECPrivateKey;import org.bouncycastle.jcajce.provider.asymmetric.ec.BCECPublicKey;import org.bouncycastle.jce.provider.BouncyCastleProvider;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import javax.crypto.Cipher;import java.io.ByteArrayOutputStream;import java.security.KeyFactory;import java.security.Security;import java.security.Signature;import java.security.spec.PKCS8EncodedKeySpec;import java.security.spec.X509EncodedKeySpec;@NotThreadSafepublic class EccHelper &#123; private static final Logger logger = LoggerFactory.getLogger(EccHelper.class); private static final int SIZE = 4096; private BCECPublicKey publicKey; private BCECPrivateKey privateKey; static &#123; Security.addProvider(new BouncyCastleProvider()); &#125; public EccHelper(String publicKey, String privateKey) &#123; this(Base64Util.decode(publicKey), Base64Util.decode(privateKey)); &#125; public EccHelper(byte[] publicKey, byte[] privateKey) &#123; try &#123; KeyFactory keyFactory = KeyFactory.getInstance(\"EC\", \"BC\"); if (publicKey != null &amp;&amp; publicKey.length &gt; 0) &#123; this.publicKey = (BCECPublicKey)keyFactory.generatePublic(new X509EncodedKeySpec(publicKey)); &#125; if (privateKey != null &amp;&amp; privateKey.length &gt; 0) &#123; this.privateKey = (BCECPrivateKey)keyFactory.generatePrivate(new PKCS8EncodedKeySpec(privateKey)); &#125; &#125; catch (ClassCastException e) &#123; throw new RuntimeException(\"\", e); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public EccHelper(String publicKey) &#123; this(Base64Util.decode(publicKey)); &#125; public EccHelper(byte[] publicKey) &#123; try &#123; KeyFactory keyFactory = KeyFactory.getInstance(\"EC\", \"BC\"); if (publicKey != null &amp;&amp; publicKey.length &gt; 0) &#123; this.publicKey = (BCECPublicKey)keyFactory.generatePublic(new X509EncodedKeySpec(publicKey)); &#125; &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public byte[] encrypt(byte[] content) &#123; if (publicKey == null) &#123; throw new RuntimeException(\"public key is null.\"); &#125; try &#123; Cipher cipher = Cipher.getInstance(\"ECIES\", \"BC\"); cipher.init(Cipher.ENCRYPT_MODE, publicKey); int size = SIZE; ByteArrayOutputStream baos = new ByteArrayOutputStream((content.length + size - 1) / size * (size + 45)); int left = 0; for (int i = 0; i &lt; content.length; ) &#123; left = content.length - i; if (left &gt; size) &#123; cipher.update(content, i, size); i += size; &#125; else &#123; cipher.update(content, i, left); i += left; &#125; baos.write(cipher.doFinal()); &#125; return baos.toByteArray(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public byte[] decrypt(byte[] secret) &#123; if (privateKey == null) &#123; throw new RuntimeException(\"private key is null.\"); &#125; try &#123; Cipher cipher = Cipher.getInstance(\"ECIES\", \"BC\"); cipher.init(Cipher.DECRYPT_MODE, privateKey); int size = SIZE + 45; ByteArrayOutputStream baos = new ByteArrayOutputStream((secret.length + size + 44) / (size + 45) * size); int left = 0; for (int i = 0; i &lt; secret.length; ) &#123; left = secret.length - i; if (left &gt; size) &#123; cipher.update(secret, i, size); i += size; &#125; else &#123; cipher.update(secret, i, left); i += left; &#125; baos.write(cipher.doFinal()); &#125; return baos.toByteArray(); &#125; catch (Exception e) &#123; logger.error(\"ecc decrypt failed.\", e); &#125; return null; &#125; public byte[] sign(byte[] content) &#123; if (privateKey == null) &#123; throw new RuntimeException(\"private key is null.\"); &#125; try &#123; Signature signature = Signature.getInstance(\"SHA1withECDSA\", \"BC\"); signature.initSign(privateKey); signature.update(content); return signature.sign(); &#125; catch (Exception e) &#123; throw new RuntimeException(e); &#125; &#125; public boolean verify(byte[] sign, byte[] content) &#123; if (publicKey == null) &#123; throw new RuntimeException(\"public key is null.\"); &#125; try &#123; Signature signature = Signature.getInstance(\"SHA1withECDSA\", \"BC\"); signature.initVerify(publicKey); signature.update(content); return signature.verify(sign); &#125; catch (Exception e) &#123; logger.error(\"ecc verify failed.\", e); &#125; return false; &#125;&#125; 5. 各种加密算法对比5.1. 散列算法比较 名称 安全性 速度 SHA-1 高 慢 MD5 中 快 5.2. 对称加密算法比较 名称 密钥名称 运行速度 安全性 资源消耗 DES 56位 较快 低 中 3DES 112位或168位 慢 中 高 AES 128、192、256位 快 高 低 5.3. 非对称加密算法比较 名称 成熟度 安全性 运算速度 资源消耗 RSA \b高 高 中 中 ECC 高 高 慢 高 5.4. 对称算法与非对称加密算法5.4.1. 对称算法 密钥管理：比较难，不适合互联网，一般用于内部系统 安全性：中 加密速度：快好 几个数量级 (软件加解密速度至少快 100 倍，每秒可以加解密数 M 比特 数据)，适合大数据量的加解密处理 5.4.2. 非对称算法 密钥管理：密钥容易管理 安全性：高 加密速度：比较慢，适合 小数据量 加解密或数据签名 小结本文介绍了 数字签名，加密和解密，对称加密和非对称加密，然后详细介绍了 MD5，SHA-1，HMAC，DES/AES，RSA 和 ECC 这几种加密算法和代码示例。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"加密算法系列","slug":"加密算法系列","permalink":"https://ostenant.coding.me/categories/加密算法系列/"}],"tags":[{"name":"MD5","slug":"MD5","permalink":"https://ostenant.coding.me/tags/MD5/"},{"name":"SHA1","slug":"SHA1","permalink":"https://ostenant.coding.me/tags/SHA1/"},{"name":"DES","slug":"DES","permalink":"https://ostenant.coding.me/tags/DES/"},{"name":"AES","slug":"AES","permalink":"https://ostenant.coding.me/tags/AES/"},{"name":"RSA","slug":"RSA","permalink":"https://ostenant.coding.me/tags/RSA/"}]},{"title":"浅谈消息队列及常见的消息中间件","slug":"浅谈消息队列及常见的消息中间件","date":"2018-07-07T15:27:00.000Z","updated":"2018-07-19T09:52:38.717Z","comments":true,"path":"2018/07/07/浅谈消息队列及常见的消息中间件/","link":"","permalink":"https://ostenant.coding.me/2018/07/07/浅谈消息队列及常见的消息中间件/","excerpt":"前言消息队列 已经逐渐成为企业应用系统 内部通信 的核心手段。它具有 低耦合、可靠投递、广播、流量控制、最终一致性 等一系列功能。 当前使用较多的 消息队列 有 RabbitMQ、RocketMQ、ActiveMQ、Kafka、ZeroMQ、MetaMQ 等，而部分 数据库 如 Redis、MySQL 以及 phxsql 也可实现消息队列的功能。","text":"前言消息队列 已经逐渐成为企业应用系统 内部通信 的核心手段。它具有 低耦合、可靠投递、广播、流量控制、最终一致性 等一系列功能。 当前使用较多的 消息队列 有 RabbitMQ、RocketMQ、ActiveMQ、Kafka、ZeroMQ、MetaMQ 等，而部分 数据库 如 Redis、MySQL 以及 phxsql 也可实现消息队列的功能。 正文1. 消息队列概述消息队列 是指利用 高效可靠 的 消息传递机制 进行与平台无关的 数据交流，并基于 数据通信 来进行分布式系统的集成。 通过提供 消息传递 和 消息排队 模型，它可以在 分布式环境 下提供 应用解耦、弹性伸缩、冗余存储、流量削峰、异步通信、数据同步 等等功能，其作为 分布式系统架构 中的一个重要组件，有着举足轻重的地位。 2. 消息队列的特点2.1. 采用异步处理模式消息发送者 可以发送一个消息而无须等待响应。消息发送者 将消息发送到一条 虚拟的通道（主题 或 队列）上，消息接收者 则 订阅 或是 监听 该通道。一条信息可能最终转发给 一个或多个 消息接收者，这些接收者都无需对 消息发送者 做出 同步回应。整个过程都是 异步的。 2.2. 应用系统之间解耦合主要体现在如下两点： 发送者和接受者不必了解对方、只需要 确认消息； 发送者和接受者 不必同时在线。 比如在线交易系统为了保证数据的 最终一致，在 支付系统 处理完成后会把 支付结果 放到 消息中间件 里，通知 订单系统 修改 订单支付状态。两个系统是通过消息中间件解耦的。 3. 消息队列的传递服务模型消息队列的 传递服务模型 如下图所示： 4. 消息队列的的传输模式4.1. 点对点模型点对点模型 用于 消息生产者 和 消息消费者 之间 点到点 的通信。消息生产者将消息发送到由某个名字标识的特定消费者。这个名字实际上对于消费服务中的一个 队列（Queue），在消息传递给消费者之前它被 存储 在这个队列中。队列消息 可以放在 内存 中也可以 持久化，以保证在消息服务出现故障时仍然能够传递消息。 传统的点对点消息中间件通常由 消息队列服务、消息传递服务、消息队列 和 消息应用程序接口 API 组成，其典型的结构如下图所示。 特点： 每个消息只用一个消费者； 发送者和接受者没有时间依赖； 接受者确认消息接受和处理成功。 示意图如下所示： 4.2. 发布/订阅模型（Pub/Sub）发布者/订阅者 模型支持向一个特定的 消息主题 生产消息。0 或 多个订阅者 可能对接收来自 特定消息主题 的消息感兴趣。 在这种模型下，发布者和订阅者彼此不知道对方，就好比是匿名公告板。这种模式被概况为：多个消费者可以获得消息，在 发布者 和 订阅者 之间存在 时间依赖性。发布者需要建立一个 订阅（subscription），以便能够消费者订阅。订阅者 必须保持 持续的活动状态 并 接收消息。 在这种情况下，在订阅者 未连接时，发布的消息将在订阅者 重新连接 时 重新发布，如下图所示： 特性： 每个消息可以有多个订阅者； 客户端只有订阅后才能接收到消息； 持久订阅和非持久订阅。 注意： 发布者和订阅者有时间依赖：接受者和发布者只有建立订阅关系才能收到消息； 持久订阅：订阅关系建立后，消息就不会消失，不管订阅者是否都在线； 非持久订阅：订阅者为了接受消息，必须一直在线。当只有一个订阅者时约等于点对点模式 5. 消息队列应用场景当你需要使用 消息队列 时，首先需要考虑它的必要性。可以使用消息队列的场景有很多，最常用的几种，是做 应用程序松耦合、异步处理模式、发布与订阅、最终一致性、错峰流控 和 日志缓冲 等。反之，如果需要 强一致性，关注业务逻辑的处理结果，则使用 RPC 显得更为合适。 5.1. 异步处理非核心 流程 异步化，减少系统 响应时间，提高 \b吞吐量。例如：短信通知、终端状态推送、App 推送、用户注册 等。 消息队列 一般都内置了 高效的通信机制，因此也可以用于单纯的消息通讯，比如实现 点对点消息队列 或者 聊天室 等。 应用案例网站用户注册，注册成功后会过一会发送邮件确认或者短息。 5.2. 系统解耦 系统之间不是 强耦合的，消息接受者 可以随意增加，而不需要修改 消息发送者的代码。消息发送者 的成功不依赖 消息接受者（比如：有些银行接口不稳定，但调用方并不需要依赖这些接口）。 不强依赖 于非本系统的核心流程，对于 非核心流程，可以放到消息队列中让 消息消费者 去按需消费，而 不影响核心主流程。 5.3. 最终一致性最终一致性 不是 消息队列 的必备特性，但确实可以依靠 消息队列 来做 最终一致性 的事情。 先写消息再操作，确保操作完成后再修改消息状态。定时任务补偿机制 实现消息 可靠发送接收、业务操作的可靠执行，要注意 消息重复 与 幂等设计。 所有不保证 100% 不丢消息 的消息队列，理论上无法实现 最终一致性。 像 Kafka 一类的设计，在设计层面上就有 丢消息 的可能（比如 定时刷盘，如果掉电就会丢消息）。哪怕只丢千分之一的消息，业务也必须用其他的手段来保证结果正确。 5.4. 广播生产者/消费者 模式，只需要关心消息是否 送达队列，至于谁希望订阅和需要消费，是 下游 的事情，无疑极大地减少了开发和联调的工作量。 5.5. 流量削峰和流控当 上下游系统 处理能力存在差距的时候，利用 消息队列 做一个通用的 “漏斗”，进行 限流控制。在下游有能力处理的时候，再进行分发。 举个例子：用户在支付系统成功结账后，订单系统会通过短信系统向用户推送扣费通知。短信系统 可能由于 短板效应，速度卡在 网关 上（每秒几百次请求），跟 前端的并发量 不是一个数量级。于是，就造成 支付系统 和 短信系统 的处理能力出现差异化。 然而用户晚上个半分钟左右收到短信，一般是不会有太大问题的。如果没有消息队列，两个系统之间通过 协商、滑动窗口 等复杂的方案也不是说不能实现。但 系统复杂性 指数级增长，势必在 上游 或者 下游 做 存储，并且要处理 定时、拥塞 等一系列问题。而且每当有 处理能力有差距 的时候，都需要 单独 开发一套逻辑来维护这套逻辑。 所以，利用中间系统转储两个系统的通信内容，并在下游系统有能力处理这些消息的时候，再处理这些消息，是一套相对较通用的方式。 应用案例 把消息队列当成可靠的 消息暂存地，进行一定程度的 消息堆积； 定时进行消息投递，比如模拟 用户秒杀 访问，进行 系统性能压测。 5.6. 日志处理将消息队列用在 日志处理 中，比如 Kafka 的应用，解决 海量日志 传输和缓冲的问题。 应用案例把日志进行集中收集，用于计算 PV、用户行为分析 等等。 5.7. 消息通讯消息队列一般都内置了 高效的通信机制，因此也可以用于单纯的 消息通讯，比如实现 点对点消息队列 或者 聊天室 等。 6. 消息队列的推拉模型6.1. Push推消息模型消息生产者 将消息发送给 消息队列，消息队列 又将消息推给 消息消费者。 6.2. Pull拉消息模型消费者 请求 消息队列 接受消息，消息生产者 从 消息队列 中拉该消息。 6.3. 两种类型的区别 7. 消息队列技术对比本部分主要介绍四种常用的消息队列（ActiveMQ / RabbitMQ / RocketMQ / Kafka）的主要特性、优点、缺点。 7.1. ActiveMQActiveMQ 是由 Apache 出品，ActiveMQ 是一个完全支持JMS1.1 和 J2EE 1.4 规范的 JMS Provider 实现。它非常快速，支持 多种语言的客户端 和 协议，而且可以非常容易的嵌入到企业的应用环境中，并有许多高级功能。 (a) 主要特性 服从JMS规范：JMS 规范提供了良好的标准和保证，包括：同步 或 异步 的消息分发，一次和仅一次的消息分发，消息接收 和 订阅 等等。遵从 JMS 规范的好处在于，不论使用什么 JMS 实现提供者，这些基础特性都是可用的； 连接灵活性：ActiveMQ 提供了广泛的 连接协议，支持的协议有：HTTP/S，IP 多播，SSL，TCP，UDP 等等。对众多协议的支持让 ActiveMQ 拥有了很好的灵活性； 支持的协议种类多：OpenWire、STOMP、REST、XMPP、AMQP； 持久化插件和安全插件：ActiveMQ 提供了 多种持久化 选择。而且，ActiveMQ 的安全性也可以完全依据用户需求进行 自定义鉴权 和 授权； 支持的客户端语言种类多：除了 Java 之外，还有：C/C++，.NET，Perl，PHP，Python，Ruby； 代理集群：多个 ActiveMQ 代理 可以组成一个 集群 来提供服务； 异常简单的管理：ActiveMQ 是以开发者思维被设计的。所以，它并不需要专门的管理员，因为它提供了简单又使用的管理特性。有很多中方法可以 监控 ActiveMQ 不同层面的数据，包括使用在 JConsole 或者在 ActiveMQ 的 Web Console 中使用 JMX。通过处理 JMX 的告警消息，通过使用 命令行脚本，甚至可以通过监控各种类型的 日志。 (b) 部署环境ActiveMQ 可以运行在 Java 语言所支持的平台之上。使用 ActiveMQ 需要： Java JDK ActiveMQ 安装包 (c) 优点 跨平台 (JAVA 编写与平台无关，ActiveMQ 几乎可以运行在任何的 JVM 上)； 可以用 JDBC：可以将 数据持久化 到数据库。虽然使用 JDBC 会降低 ActiveMQ 的性能，但是数据库一直都是开发人员最熟悉的存储介质； 支持 JMS 规范：支持 JMS 规范提供的 统一接口; 支持 自动重连 和 错误重试机制； 有安全机制：支持基于 shiro，jaas 等多种 安全配置机制，可以对 Queue/Topic 进行 认证和授权； 监控完善：拥有完善的 监控，包括 Web Console，JMX，Shell 命令行，Jolokia 的 RESTful API； 界面友善：提供的 Web Console 可以满足大部分情况，还有很多 第三方的组件 可以使用，比如 hawtio； (d) 缺点 社区活跃度不及 RabbitMQ 高； 根据其他用户反馈，会出莫名其妙的问题，会 丢失消息； 目前重心放到 activemq 6.0 产品 Apollo，对 5.x 的维护较少； 不适合用于 上千个队列 的应用场景； 7.2. RabbitMQRabbitMQ 于 2007 年发布，是一个在 AMQP (高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。 (a) 主要特性 可靠性：提供了多种技术可以让你在 性能 和 可靠性 之间进行 权衡。这些技术包括 持久性机制、投递确认、发布者证实 和 高可用性机制； 灵活的路由：消息在到达队列前是通过 交换机 进行 路由 的。RabbitMQ 为典型的路由逻辑提供了 多种内置交换机 类型。如果你有更复杂的路由需求，可以将这些交换机组合起来使用，你甚至可以实现自己的交换机类型，并且当做 RabbitMQ 的 插件 来使用； 消息集群：在相同局域网中的多个 RabbitMQ 服务器可以 聚合 在一起，作为一个独立的逻辑代理来使用； 队列高可用：队列可以在集群中的机器上 进行镜像，以确保在硬件问题下还保证 消息安全； 支持多种协议：支持 多种消息队列协议； 支持多种语言：用 Erlang 语言编写，支持只要是你能想到的 所有编程语言； 管理界面： RabbitMQ 有一个易用的 用户界面，使得用户可以 监控 和 管理 消息 Broker 的许多方面； 跟踪机制：如果 消息异常，RabbitMQ 提供消息跟踪机制，使用者可以找出发生了什么； 插件机制：提供了许多 插件，来从多方面进行扩展，也可以编写自己的插件。 (b) 部署环境RabbitMQ 可以运行在 Erlang 语言所支持的平台之上，包括 Solaris，BSD，Linux，MacOSX，TRU64，Windows 等。使用 RabbitMQ 需要： ErLang 语言包 RabbitMQ 安装包 (c) 优点 由于 Erlang 语言的特性，消息队列性能较好，支持 高并发； 健壮、稳定、易用、跨平台、支持 多种语言、文档齐全； 有消息 确认机制 和 持久化机制，可靠性高； 高度可定制的 路由； 管理界面 较丰富，在互联网公司也有较大规模的应用，社区活跃度高。 (d) 缺点 尽管结合 Erlang 语言本身的并发优势，性能较好，但是不利于做 二次开发和维护； 实现了 代理架构，意味着消息在发送到客户端之前可以在 中央节点 上排队。此特性使得 RabbitMQ 易于使用和部署，但是使得其 运行速度较慢，因为中央节点 增加了延迟，消息封装后 也比较大； 需要学习 比较复杂 的 接口和协议，学习和维护成本较高。 7.3. RocketMQRocketMQ 出自 阿里 的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进，消息可靠性上 比 Kafka 更好。RocketMQ 在阿里内部\b被广泛应用在 订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发 等场景。 (a) 主要特性 基于 队列模型：具有 高性能、高可靠、高实时、分布式 等特点； Producer、Consumer、队列 都支持 分布式； Producer 向一些队列轮流发送消息，队列集合 称为 Topic。Consumer 如果做 广播消费，则一个 Consumer 实例消费这个 Topic 对应的 所有队列；如果做 集群消费，则 多个 Consumer 实例 平均消费 这个 Topic 对应的队列集合； 能够保证 严格的消息顺序； 提供丰富的 消息拉取模式； 高效的订阅者 水平扩展能力； 实时 的 消息订阅机制； 亿级 消息堆积 能力； 较少的外部依赖。 (b) 部署环境RocketMQ 可以运行在 Java 语言所支持的平台之上。使用 RocketMQ 需要： Java JDK 安装 git、Maven RocketMQ 安装包 (c) 优点 单机 支持 1 万以上 持久化队列； RocketMQ 的所有消息都是 持久化的，先写入系统 PAGECACHE，然后 刷盘，可以保证 内存 与 磁盘 都有一份数据，而 访问 时，直接 从内存读取。 模型简单，接口易用（JMS 的接口很多场合并不太实用）； 性能非常好，可以允许 大量堆积消息 在 Broker 中； 支持 多种消费模式，包括 集群消费、广播消费等； 各个环节 分布式扩展设计，支持 主从 和 高可用； 开发度较活跃，版本更新很快。 (d) 缺点 支持的 客户端语言 不多，目前是 Java 及 C++，其中 C++ 还不成熟； RocketMQ 社区关注度及成熟度也不及前两者； 没有 Web 管理界面，提供了一个 CLI (命令行界面) 管理工具带来 查询、管理 和 诊断各种问题； 没有在 MQ 核心里实现 JMS 等接口； 7.4. KafkaApache Kafka 是一个 分布式消息发布订阅 系统。它最初由 LinkedIn 公司基于独特的设计实现为一个 分布式的日志提交系统 (a distributed commit log)，之后成为 Apache 项目的一部分。Kafka 性能高效、可扩展良好 并且 可持久化。它的 分区特性，可复制 和 可容错 都是其不错的特性。 (a) 主要特性 快速持久化：可以在 O(1) 的系统开销下进行 消息持久化； 高吞吐：在一台普通的服务器上既可以达到 10W/s 的 吞吐速率； 完全的分布式系统：Broker、Producer 和 Consumer 都原生自动支持 分布式，自动实现 负载均衡； 支持 同步 和 异步 复制两种 高可用机制； 支持 数据批量发送 和 拉取； 零拷贝技术(zero-copy)：减少 IO 操作步骤，提高 系统吞吐量； 数据迁移、扩容 对用户透明； 无需停机 即可扩展机器； 其他特性：丰富的 消息拉取模型、高效 订阅者水平扩展、实时的 消息订阅、亿级的 消息堆积能力、定期删除机制； (b) 部署环境使用 Kafka 需要： Java JDK Kafka 安装包 (c) 优点 客户端语言丰富：支持 Java、.Net、PHP、Ruby、Python、Go 等多种语言； 高性能：单机写入 TPS 约在 100 万条/秒，消息大小 10 个字节； 提供 完全分布式架构，并有 replica 机制，拥有较高的 可用性 和 可靠性，理论上支持 消息无限堆积； 支持批量操作； 消费者 采用 Pull 方式获取消息。消息有序，通过控制 能够保证所有消息被消费且仅被消费 一次； 有优秀的第三方 Kafka Web 管理界面 Kafka-Manager； 在 日志领域 比较成熟，被多家公司和多个开源项目使用。 (d) 缺点 Kafka 单机超过 64 个 队列/分区 时，Load 时会发生明显的飙高现象。队列 越多，负载 越高，发送消息 响应时间变长； 使用 短轮询方式，实时性 取决于 轮询间隔时间； 消费失败 不支持重试； 支持 消息顺序，但是 一台代理宕机 后，就会产生 消息乱序； 社区更新较慢。 7.5. 几种消息队列对比这里列举了上述四种消息队列的差异对比： Kafka 在于 分布式架构，RabbitMQ 基于 AMQP 协议 来实现，RocketMQ 的思路来源于 Kafka，改成了 主从结构，在 事务性 和 可靠性 方面做了优化。广泛来说，电商、金融 等对 事务一致性 要求很高的，可以考虑 RabbitMQ 和 RocketMQ，对 性能要求高 的可考虑 Kafka。 小结本文介绍了消息队列的特点，消息队列的 传递服务模型，消息的 传输方式，消息的 推拉模式。然后介绍了 ActiveMQ，RabbitMQ，RocketMQ 和 Kafka 几种常见的消息队列，阐述了 各种消息队列 的 主要特点 和 优缺点。通过本文，对于消息队列及相关技术选型，相信你会有了更深入的理解和认识。更多细节和原理性的东西，还需在实践中见真知！ 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"消息队列系列","slug":"消息队列系列","permalink":"https://ostenant.coding.me/categories/消息队列系列/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"https://ostenant.coding.me/tags/消息队列/"},{"name":"ActiveMQ","slug":"ActiveMQ","permalink":"https://ostenant.coding.me/tags/ActiveMQ/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://ostenant.coding.me/tags/RabbitMQ/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://ostenant.coding.me/tags/RocketMQ/"},{"name":"Kafka","slug":"Kafka","permalink":"https://ostenant.coding.me/tags/Kafka/"}]},{"title":"浅谈SAML, OAuth, OpenID和SSO, JWT和Session","slug":"浅谈SAML, OAuth, OpenID和SSO, JWT和Session","date":"2018-07-05T05:50:00.000Z","updated":"2018-07-05T14:27:53.562Z","comments":true,"path":"2018/07/05/浅谈SAML, OAuth, OpenID和SSO, JWT和Session/","link":"","permalink":"https://ostenant.coding.me/2018/07/05/浅谈SAML, OAuth, OpenID和SSO, JWT和Session/","excerpt":"前言通常为了弄清楚一个概念，我们需要掌握十个概念。在判断 JWT(JsonWebToken) 是否能代替 session 管理之前，我们要了解什么是 token，以及 access token 和 refresh token 的区别。","text":"前言通常为了弄清楚一个概念，我们需要掌握十个概念。在判断 JWT(JsonWebToken) 是否能代替 session 管理之前，我们要了解什么是 token，以及 access token 和 refresh token 的区别。 了解什么是 OAuth，什么是 SSO，SSO 下不同策略 OAuth 和 SAML 的不同，以及 OAuth 与 OpenID 的不同，更重要的是区分 authorisation 和 authentication。 最后我们引出 JSON WEB TOKEN，聊聊 JWT 在 Session 管理方面的优势和劣势，同时尝试解决这些劣势，看看成本和代价有多少。 正文本文关于 OAuth 授权 和 API 调用实例都来自 Google API。 关于TokenToken 即使是在计算机领域中也有不同的定义，这里我们说的 token，是指 访问资源 的凭据。例如当你调用 Google API 时，需要带上有效 token 来表明你请求的 合法性。这个 Token 是 Google 给你的，这代表 Google 给你的 授权 使得你有能力访问 API 背后的 资源。 请求 API 时携带 token 的方式也有很多种，通过 HTTP Header 或者 url 参数或者 google 提供的类库都可以： HTTP Header 1234GET /drive/v2/files HTTP/1.1Authorization: Bearer &lt;token&gt;Host: www.googleapis.com/ URL参数 1GET https://www.googleapis.com/drive/v2/files?token=&lt;token&gt; Python函数库 12from googleapiclient.discovery import builddrive = build('drive', 'v2', credentials=credentials) 更具体的说，上面用于调用 API 的 token，我们称为细分为 access token。通常 access token 是有 有效期限 的，如果 过期 就需要 重新获取。那么如何重新获取？先看看第一次获取 token 的流程是怎样的: 首先需要向 Google API 注册一个应用程序，注册完毕之后就会拿到 认证信息（credentials）包括 ID 和 secret。不是所有的程序类型都有 secret。 接下来就要向 Google 请求 access token。这里先忽略一些细节，例如请求参数（当然需要上面申请到的 secret）。重要的是，如果你想访问的是 用户资源，这里就会提醒用户进行 授权。 如果 用户授权 完毕。Google 就会返回 access token。又或者是返回 授权代码（authorization code），再通过代码取得 access token。 token 获取到之后，就能够带上 token 访问 API 了。 流程如下图所示： 注意：在第三步通过 authorization code 兑换 access token 的过程中，Google 并不会仅仅返回 access token，还会返回额外的信息，这其中和之后更新相关的就是 refresh token。 一旦 access token 过期，你就可以通过 refresh token 再次请求 access token。 以上只是大致的流程，并且故意省略了一些额外的概念。比如更新 access token 当然也可以不需要 refresh token，这要根据你的 请求方式 和访问的 资源类型 而定。 这里又会引起另外的两个问题： 如果 refesh token 也过期了怎么办？这时就需要用户 重新登陆授权。 为什么要区分 refresh token 和 access token？如果合并成一个 token 然后把 过期时间 调整的 更长，并且每次 失效 之后用户 重新登陆授权 就好了？这个问题会和后面谈的相关概念有关，后面会给予解释说明。 OAuth 2.0从获取 token 到使用 token 访问接口。这其实是标准的 OAuth2.0 机制下访问 API 的流程。这里介绍一下 OAuth 里外相关的概念，更深入的理解 token 的作用。 SSO (Single sign-on)通常公司内部会有非常多的平台供大家使用，比如人力资源，代码管理，日志监控，预算申请等等。如果每一个平台都实现自己的用户体系的话无疑是巨大的浪费，所以公司内部会有一套 公用的用户体系，用户只要登陆之后，就能够 访问所有的系统。这就是 单点登录。 SSO 是一类 解决方案 的统称，而在具体的实施方面，我们有两种策略可供选择： SAML 2.0 OAuth 2.0 接下来我们区别这 两种授权方式 有什么不同。但是在描述 不同的策略 之前，我们先叙述几个 共有的特性，并且相当重要的概念。 Authentication VS Authorisation Authentication: 身份鉴别，以下简称 认证； Authorisation: 资源访问 授权。 认证 的作用在于 认可 你能够访问系统，用于 鉴别访问者 是否是 合法用户；而 授权 用于决定你有访问 哪些资源的权限。 大多数人不会区分这两者的区别，因为站在用户的立场上。而作为系统的设计者来说，这两者是有差别的，这是不同的两个工作职责。我们可以只需要 认证功能，而不需要 授权功能，甚至不需要自己实现 认证功能。而借助 Google 的认证系统，即用户可以用 Google 的账号进行登陆。 Authorization Server/Identity Provider(IdP)把负责 认证的服务 称为 AuthorizationServer 或者 IdentityProvider，以下简称 IDP。 Service Provider(SP)/Resource Server把负责 提供资源（API 调用）的服务称为 ResourceServer 或者 ServiceProvider，以下简称 SP。 SAML 2.0下图是 SAML2.0 的流程图，看图说话： 还 未登陆 的用户 打开浏览器 访问你的网站（SP），网站 提供服务 但是并 不负责用户认证。 于是 SP 向 IDP 发送了一个 SAML 认证请求，同时 SP 将 用户浏览器 重定向到 IDP。 IDP 在验证完来自 SP 的 请求无误 之后，在浏览器中呈现 登陆表单 让用户填写 用户名 和 密码 进行登陆。 一旦用户登陆成功， IDP 会生成一个包含 用户信息（用户名 或者 密码）的 SAML token（SAML token 又称为 SAML Assertion，本质上是 XML 节点）。IDP 向 SP 返回 token，并且将 用户重定向 到 SP (token 的返回是在 重定向步骤 中实现的，下面会详细说明)。 SP 对拿到的 token 进行验证，并从中解析出 用户信息，例如 用户是谁 以及 用户的权限 有哪些。此时就能够根据这些信息允许用户访问我们网站的内容。 当用户在 IDP 登陆成功之后，IDP 需要将用户 再次重定向 到 SP 站点，这一步通常有两个办法： HTTP 重定向：这并不推荐，因为 重定向 的 URL 长度 有限制，无法携带更长的信息，比如 SAML Token。 HTTP POST 请求：这个是更常规的做法，当用户登陆完毕之后渲染出一个表单，用户点击后向 SP 提交 POST 请求。又或者可以使用 JavaScript 向 SP 发出一个 POST 请求。 如果你的应用是基于 Web，那么以上的方案没有任何问题。但如果你开发的是一个 iOS 或者 Android 的手机应用，那么问题就来了： 用户在 iPhone 上打开应用，此时用户需要通过 IDP 进行认证。 应用跳转至 Safari 浏览器，在登陆认证完毕之后，需要通过 HTTP POST 的形式将 token 返回至 手机应用。 虽然 POST 的 url 可以 拉起应用，但是 手机应用 无法解析 POST 的内容，我们也就无法读取 SAML Token。 当然还是有办法的，比如在 IDP 授权阶段 不跳转至系统的 Safari 浏览器，在 内嵌 的 Webview 中解决，在想方设法从 Webview 中提取 token，或者利用 代理服务器。 无论如何，SAML 2.0 并 不适用 于当下 跨平台 的场景，这也许与它产生的年代也有关系，它诞生于 2005 年，在那个时刻 HTTP POST 确实是最好的选择方案。 OAuth 2.0我们先简单了解 SSO 下的 OAuth2.0 的流程。 用户通过 客户端（可以是 浏览器 也可以是 手机应用）想要访问 SP 上的资源，但是 SP 告诉用户需要进行 认证，将用户 重定向 至 IDP。 IDP 向 用户 询问 SP 是否可以访问 用户信息。如果用户同意，IDP 向 客户端 返回 authorization code。 客户端拿到 authorization code 向 IDP 交换 access token，并拿着 access token 向 SP 请求资源。 SP 接受到请求之后，拿着附带的 token 向 IDP 验证 用户的身份。确认身份无误后，SP 向 客户端 发放相关资源。 那么 OAuth 是如何避免 SAML 流程下 无法解析 POST 内容的信息的呢？ 一方面是用户从 IDP 返回 客户端 的方式，也是通过 URL 重定向，这里的 URL 允许 自定义 schema，所以即使在 手机 上也能 拉起应用； 另一方面因为 IDP 向 客户端 传递的是 authorization code，而不是 XML 信息，所以 code 可以很轻易的附着在 重定向 URL 上进行传递。 但以上的 SSO 流程体现不出 OAuth 的本意。OAuth 的本意是 一个应用 允许 另一个应用 在 用户授权 的情况下 访问自己的数据。 OAuth 的设计本意更倾向于 授权而非认证（当然授权用户信息就间接实现了认证），虽然 Google 的 OAuth 2.0 API 同时支持 授权 和 认证。所以你在使用 Facebook 或者 Gmail 账号登陆第三方站点时，会出现 授权对话框，告诉你 第三方站点 可以访问你的哪些信息，需要征得你的同意。 在上面 SSO 的 OAuth 流程中涉及三方角色: SP, IDP 以及 Client。但在实际工作中 Client 可以是不存在的，例如你编写了一个 后端程序 定时的通过 Google API 从 Youtube 拉取最新的节目数据，那么你的 后端程序 需要得到 Youtube 的 OAuth 授权 即可。 OAuth VS OpenId如果你有留心的话，你会在某些站点看到允许以 OpenID 的方式登陆，其实也就是以 Facebook 账号或者 Google 账号登陆站点： OpenID 和 OAuth 很像。但本质上来说它们是截然不同的两个东西： OpenID: 只用于 身份认证（Authentication），允许你以 同一个账户 在 多个网站登陆。它仅仅是为你的 合法身份 背书，当你以 Facebook 账号登陆某个站点之后，该站点 无权访问 你的在 Facebook 上的 数据。 OAuth: 用于 授权（Authorisation），允许 被授权方 访问 授权方 的 用户数据。 Refresh Token现在可以回答上面的问题了，为什么我们需要 refresh token？ 这样的处理是为了 职责的分离： refresh token: 负责 身份认证； access token: 负责 请求资源。 虽然 refresh token 和 access token 都由 IDP 发出，但是 access token 还要和 SP 进行 数据交换，如果 公用的话 这样就会有 身份泄露 的可能。并且 IDP 和 SP 可能是 完全不同 的 服务提供 的。而在上文，我们之所以没有这样的顾虑是因为 IDP 和 SP 都是 Google。 JWT初步认识本质上来说 JWT 也是 token，正如我们在上文提到的，它是 访问资源 的 凭证。 Google 的一些 API 诸如 Prediction API 或者 Google Cloud Storage，是不需要 访问 用户的 个人数据 的。因而不需要经过 用户的授权 这一步骤，应用程序可以直接访问。就像上面 OAuth 中没有 Client 没有参与的流程类似。这就要借助 JWT 完成访问了, 具体流程如下： 首先需要在 Google API 上创建一个服务账号（service account）。 获取 服务账号 的 认证信息（credential），包括 邮箱地址，client ID，以及一对 公钥/私钥。 使用 Client ID 和 私钥 创一个 签名 的 JWT，然后将这个 JWT 发送给 Google 交换 access token。 Google 返回 access token。 程序通过 access token 访问 API。 甚至你可以不需要向 Google 索要 access token，而是携带 JWT 作为 HTTP header 里的 bearer token 直接访问 API 也是可以的。这才是 JWT 的最大魅力。 理性认识JWT 顾名思义，它是 JSON 结构的 token，由三部分组成： header payload signature headerheader 用于描述 元信息，例如产生 signature 的算法： 1234&#123; \"typ\": \"JWT\", \"alg\": \"HS256\"&#125; 其中 alg 关键字就指定了使用哪一种 哈希算法 来创建 signature。 payloadpayload 用于携带你希望 向服务端传递 的信息。你既可以往里添加 官方字段，例如：iss(Issuer), sub(Subject), exp(Expirationtime)，也可以塞入 自定义的字段，比如 userId: 123&#123; \"userId\": \"b08f86af-35da-48f2-8fab-cef3904660bd\"&#125; signaturesignature 译为 签名，创建签名要分以下几个步骤： 从 接口服务端 拿到 密钥，假设为 secret。 对 header 进行 base64 编码，假设结果为 headerStr。 将 payload 进行 base64 编码，假设结果为 payloadStr。 将 headerStr 和 payloadStr 用 . 字符 拼装起来成为字符 data。 以 data 和 secret 作为参数，使用 哈希算法 计算出 签名。 如果上述描述还不直观，用 伪代码 表示就是： 123// Signature algorithmdata = base64urlEncode( header ) + “.” + base64urlEncode( payload )signature = Hash( data, secret ); 假设我们的原始 JSON 结构是这样的： 12345678910// Header&#123; \"typ\": \"JWT\", \"alg\": \"HS256\"&#125;// Payload&#123; \"userId\": \"b08f86af-35da-48f2-8fab-cef3904660bd\"&#125; 如果 密钥 是字符串 secret 的话，那么最终 JWT 的结果就是这样的： 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ1c2VySWQiOiJiMDhmODZhZi0zNWRhLTQ4ZjItOGZhYi1jZWYzOTA0NjYwYmQifQ.-xN_h82PHVTCMA9vdoHrcZxH-x5mb11y1537t3rGzcM 可以在 jwt.io 上 验证 这个结果。 JWT究竟带来了什么确保数据完整性JWT 的目的不是为了 隐藏 或者 保密数据，而是为了确保 数据 确实来自被 授权的人 创建的，以防止 中途篡改。 回想一下，当你拿到 JWT 时候，你完全可以在没有 secret 的情况下解码出 header 和 payload，因为 header 和 payload 只是经过了 base64 编码（encode）而已，编码的目的在于 利于数据结构的传输。 虽然创建 signature 的过程近似于 加密 (encrypt)，但本质其实是一种 签名 (sign) 的行为，用于保证 数据的完整性，实际上也并且并 没有加密任何数据。 用于接口调用接下来在 API 调用中就可以附上 JWT（通常是在 HTTP Header 中）。又因为 SP 会与程序 共享 一个 secret，所以 程序 可以通过 header 提供的相同的 hash 算法来 验证签名 是否正确，从而判断应用是否有权力调用 API。 有状态的对话Session因为 HTTP 是 无状态 的，所以 客户端 和 服务端 需要解决的问题是，如何让它们之间的对话变得有状态。例如只有是 登陆状态 的 用户 才有权限调用某些接口，那么在 用户登陆 之后，需要记住该用户是 已经登陆 的状态。常见的方法是使用 session 机制。 常见的 session 模型是这样工作的： 用户在浏览器 登陆 之后，服务端为用户生成 唯一 的 session id，存储在 服务端 的 存储服务（例如 MySQL, Redis）中。 该 session id 也同时 返回给浏览器，以 SESSION_ID 为 KEY 存储在浏览器的 cookie 中。 如果用户再次访问该网站，cookie 里的 SESSION_ID 会随着 请求 一同发往 服务端。 服务端通过判断 SESSION_ID 是否已经在 Redis 中判断用户是否处于 登陆状态。 相信你已经察觉了，理论上来说，JWT 机制可以取代 session 机制。用户不需要提前进行登陆，后端也不需要 Redis 记录用户的登陆信息。客户端的本地保存一份合法的 JWT，当用户需要调用接口时，附带上该合法的 JWT，每一次调用接口，后端都使用请求中附带的 JWT 做一次 合法性的验证。这样也间接达到了 认证用户 的目的。 然而 JWT 真的能取代 session 机制吗？这么做有哪些好处和坏处？这些问题将留在下一篇再讨论。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"认证与授权系列","slug":"认证与授权系列","permalink":"https://ostenant.coding.me/categories/认证与授权系列/"}],"tags":[{"name":"SAML","slug":"SAML","permalink":"https://ostenant.coding.me/tags/SAML/"},{"name":"OAuth","slug":"OAuth","permalink":"https://ostenant.coding.me/tags/OAuth/"},{"name":"SSO","slug":"SSO","permalink":"https://ostenant.coding.me/tags/SSO/"},{"name":"JWT","slug":"JWT","permalink":"https://ostenant.coding.me/tags/JWT/"},{"name":"Session","slug":"Session","permalink":"https://ostenant.coding.me/tags/Session/"}]},{"title":"浅谈分布式存储系统的数据分布算法","slug":"浅谈分布式存储系统的数\b据分布算法","date":"2018-07-01T09:43:00.000Z","updated":"2018-07-01T13:01:25.154Z","comments":true,"path":"2018/07/01/浅谈分布式存储系统的数\b据分布算法/","link":"","permalink":"https://ostenant.coding.me/2018/07/01/浅谈分布式存储系统的数\b据分布算法/","excerpt":"前言分布式存储系统 面临着的首要问题，就是如何将 大量的数据 分布在 不同的存储节点 上。无论上层接口是 KV 存储、对象存储、块存储、亦或是 列存储，在这个问题上大体是一致的。本文将介绍如何 分布式存储系统 中 做数据分布目标 及可选的 方案，并试着总结和权衡他们之间的关系及。","text":"前言分布式存储系统 面临着的首要问题，就是如何将 大量的数据 分布在 不同的存储节点 上。无论上层接口是 KV 存储、对象存储、块存储、亦或是 列存储，在这个问题上大体是一致的。本文将介绍如何 分布式存储系统 中 做数据分布目标 及可选的 方案，并试着总结和权衡他们之间的关系及。 正文(一) 指标这里假设 目标数据 是以 key 标识的 数据块 或 对象。在一个包含 多个存储节点 的集群中，数据分布算法 需要为每一个给定的 key 指定 一个 或 多个 对应的 存储节点 负责，数据分布算法 有两个基本目标： 均匀性(Uniformity)：不同存储节点的 负载 应该 均衡； 稳定性(Consistency)：每次一个 key 通过 数据分布算法 得到的 分布结果 应该保持 基本稳定，即使再有存储节点发生变化的情况下。 可以看出，这两个目标在一定程度上是 相互矛盾 的。当有 存储节点增加或删除 时，为了保持稳定应该 尽量少 的进行 数据的移动 和 重新分配，而这样又势必会带来 负载不均衡。同样追求 极致均匀 也会导致较多的 数据迁移。 所以我们希望在这两个极端之间，找到一个点以获得合适的均匀性和稳定性。除了上述两个基本目标外，工程中还需要从以下几个方面考虑数据分布算法的优劣： 性能可扩展性：这个主要考虑的是算法相对于 存储节点规模 的 时间复杂度。为了整个系统的可扩展性，数据分布算法不应该在集群规模扩大后显著的增加运行时间。 考虑节点异构：实际工程中，不同 存储节点 之间可能会有很大的 性能 或 容量差异，好的数据分布算法应该能很好的应对这种 异构，提供 加权的数据均匀。 隔离故障域：为了 数据的高可用，数据分布算法应该为每个 key 找到 一组存储节点，这些节点可能提供的是 数据的镜像副本，也可能是类似 擦除码 的副本方式。数据分布算法应该尽量 隔离 这些副本的故障域，如 不同机房、不同机架、不同交换机、不同机器。 (二) 演进看完算法的评价指标后，接下来介绍一些可能的方案演进，并分析他们的优劣。这里假设 key 的值足够分散。 1. Hash一个简单直观的想法是直接用 Hash 来计算，简单的以 Key 做 哈希 后 对节点数取模。可以看出，在 key 足够分散的情况下，均匀性 可以获得，但一旦有 节点加入 或 退出 时，所有的原有节点都会受到影响。稳定性 无从谈起。 2. 一致性Hash 一致性 Hash 可以很好的解决 稳定性问题，可以将所有的 存储节点 排列在收尾相接的 Hash 环上，每个 key 在计算 Hash 后会 顺时针 找到先遇到的 存储节点 存放。而当有节点 加入 或 退出 时，仅影响该节点在 Hash 环上 顺时针相邻 的 后续节点。但这有带来 均匀性 的问题，即使可以将存储节点等距排列，也会在 存储节点个数 变化时带来 数据的不均匀。而这种可能 成倍数的不均匀 在实际工程中是不可接受的。 3. 带负载上限的一致性Hash一致性 Hash 有 节点变化时不均匀的问题。Google 在 2017 年提出了 Consistent Hashing with Bounded Loads 来控制这种 不均匀的程度。简单的说，该算法给 Hash 环上的每个节点一个 负载上限 为 1 + e 倍的 平均负载，这个 e可以自定义。当 key 在 Hash 环上 顺时针 找到合适的节点后，会判断这个节点的 负载 是否已经 到达上限，如果 已达上限，则需要继续找 之后的节点 进行分配。 如上图所示，假设每个桶 当前上限 是 2，红色的小球按序号访问，当编号为 6 的红色小球到达时，发现顺时针首先遇到的 B（3，4），C（1，5）都已经 达到上限，因此最终放置在桶 A 里。 这个算法最吸引人的地方在于 当有节点变化 时，需要迁移的数据量是 1/e^2 相关，而与 节点数 或 数据数量 均无关。 也就是说当 集群规模扩大 时，数据迁移量 并不会随着显著增加。另外，使用者可以通过调整 e 的值来控制 均匀性 和 稳定性 之间的权衡，就是一种 以时间换\b空间 的算法。总体来说，无论是 一致性 Hash 还是 带负载限制 的 一致性 Hash，都无法解决 节点异构 的问题。 4. 带虚拟节点的一致性Hash为了解决 负载不均匀 和 异构 的问题，可以在 一致性 Hash 的基础上引入 虚拟节点。即 hash 环上的 每个节点 并不是 实际 的 存储节点，而是一个 虚拟节点。实际的 存储节点 根据其 不同的权重，对应 一个 或 多个虚拟节点，所有落到相应虚拟节点上的 key 都由该 存储节点负责。 如下图所示，存储节点 A 负责 (1,3]，(4,8]，(10, 14]，存储节点 B 负责 (14,1]，(8,10]。 这个算法的问题在于，一个 实际存储节点 的 加入 或 退出，会影响 多个虚拟节点的重新分配，进而引起 很多节点 参与到 数据迁移 中来。 另外，实践中将一个 虚拟节点 重新分配给 新的实际节点 时，需要将这部分数据 遍历 出来 发送给新节点。我们需要一个更合适的 虚拟节点切分 和 分配方式，那就是 分片。 5. 分片分片 将 哈希环 切割为 相同大小的分片，然后将这些 分片 交给 不同的节点 负责。 注意这里跟上面提到的 虚拟节点 有着很 本质的区别：分片的划分和分片的分配被解耦。 一个 节点退出 时，其所负责的 分片 并不需要 顺时针合并 给之后节点，而是可以更灵活的 将整个分片 作为一个 整体 交给 任意节点。在实践中，一个 分片 多作为 最小的数据迁移 和 备份单位。 而也正是由于上面提到的 解耦，相当于将原先的 key 到 节点 的 映射 拆成了两层。需要一个 新的机制 来进行 分片 到 存储节点 的 映射。由于 分片数 相对 key 空间已经很小并且 数量确定，可以更精确地初始设置，并引入 中心目录服务 来根据 节点存活 修改 分片的映射关系。同时将这个 映射信息 通知给所有的 存储节点 和 客户端。 上图是 分布式KV存储 Zeppelin中的 分片方式，Key Space 通过 Hash 到 分片，分片及其副本 又通过一层映射到 最终的存储节点 Node Server。 6. CRUSH算法CRUSH 算法本质上也是一种 基于分片 的数据分布方式，其试图在以下几个方面进行优化： 分片映射信息量：避免 中心目录服务 和 存储节点 及 客户端之间 交互\b大量的 分片映射信息，而改由 存储节点 或 客户端 自己根据 少量 且 稳定 的集群节点拓扑和确定的规则自己计算分片映射。 完善的故障域划分：支持 层级 的 故障域控制，将 同一分片 的 不同副本 按照配置划分到 不同层级 的 故障域中。 客户端 或 存储节点 利用 key、存储节点 的 拓扑结构 和 分配算法，独立的进行 分片位置 的计算，得到一组负责对应 分片 及 副本 的 存储位置。 如图所示是 一次定位 的过程，最终选择了一个 row 下的 cab21，cab23，cab24 三个机柜下的三个存储节点。 当 节点变化 时，由于 节点拓扑 的变化，会影响 少量分片 数据进行迁移，如下图是加入 新节点 引起的 数据迁移。通过良好的 分配算法，可以得到很好的 负载均衡 和 稳定性，CRUSH 提供了 Uniform、List、Tree、Straw 四种分配算法。 (三) 应用案例常见的 分布式存储系统 大多采用类似于 分片 的 数据分布和定位方式： Cassandra/Dynamo：采用 分片 的方式并通过 Gossip 协议在对等节点间通信； Redis Cluster：将 key Space 划分为 slots，同样利用 Gossip 协议通信； Zeppelin：将数据分片为 Partition，通过 Meta 集群提供 中心目录服务； Bigtable：将数据切割为 Tablet，类似于可变的分片，Tablet Server 可以进行分片的切割，最终分片信息记录在 Chubby 中； Ceph：采用 CRUSH 方式，由 中心集群 Monitor 提供并维护 集群拓扑 的变化。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"分布式存储","slug":"分布式存储","permalink":"https://ostenant.coding.me/tags/分布式存储/"},{"name":"一致性哈希","slug":"一致性哈希","permalink":"https://ostenant.coding.me/tags/一致性哈希/"},{"name":"分片","slug":"分片","permalink":"https://ostenant.coding.me/tags/分片/"}]},{"title":"从零开始学习Quartz任务调度框架","slug":"从零开始学习Quartz任务调度框架","date":"2018-06-27T04:17:00.000Z","updated":"2018-06-29T04:50:45.047Z","comments":true,"path":"2018/06/27/从零开始学习Quartz任务调度框架/","link":"","permalink":"https://ostenant.coding.me/2018/06/27/从零开始学习Quartz任务调度框架/","excerpt":"前言Quartz 是个 任务调度工具，就是 定时 执行指定的任务。Quartz 提供了极为广泛的特性如 持久化任务，集群 和 分布式任务 等。Quartz 是用 Java 构建的，与 Spring 集成方便，伸缩性，负载均衡，高可用性。","text":"前言Quartz 是个 任务调度工具，就是 定时 执行指定的任务。Quartz 提供了极为广泛的特性如 持久化任务，集群 和 分布式任务 等。Quartz 是用 Java 构建的，与 Spring 集成方便，伸缩性，负载均衡，高可用性。 本文只关注基于 数据库 的 Quartz 集群，基于 Quartz 2.2.x 来说明。 正文Quartz的核心组件Quartz 大致有三个核心的组件： 1. 调度器Scheduler一个 计划调度器容器，容器里面可以装载众多的 JobDetail 和 Trigger。当容器启动后，里面的每个 JobDetail 都会根据 Trigger 按部就班地 自动 去执行. 2. 任务JobJob 表示要执行的 具体内容。JobDetail 表示具体的、可执行的调度程序，包含了这个任务的 调度方案 和 策略。 3. 触发器Trigger调度参数 的配置，配置任务执行触发的 时间间隔。 几者的关系：调度器 就相当于一个 容器，装载着 任务 和 触发器。任务和触发器又是绑定在一起的，然而一个任务可以对应多个触发器，但一个触发器却只能对应一个任务。当 JobDetail 和 Trigger 在 Scheduler 容器上 注册 后，形成了装配好的 任务作业（JobDetail 和 Trigger 所组成的一对），伴随 容器启动 而调度执行。 Quartz的核心类1. SchedulerQuartz 中 独立运行 的容器，Trigger 和 JobDetail 可以注册到 Scheduler 上。Scheduler 定义了多个 接口方法，允许外部通过 组及名称 访问和控制 容器 中 Trigger 和 JobDetail。 2. Job任务接口，任务类 代表要调度执行的 业务逻辑实现，任务 必须实现该接口。 如果任务不允许 并发执行，则 任务类 必须添加注解 @DisallowConcurrentExecution。 该接口只定义了一个方法： 1void execute(JobExecutionContext context) throws JobExecutionException; 通过 context 可以访问配置给任务的 数据 context.getJobDetail().getJobDataMap()，如果这个 JobDataMap 需要在修改后 持久化 到 数据库 里，则需要给 任务类 加上注解 @PersistJobDataAfterExecution。Quartz 在下次调度执行这个任务时，会把 持久化 的数据 反序列化 成 JobDataMap 供应用使用。 不建议通过 Quartz 的这个机制 持久化 任何与 业务有关 的数据。因为 业务数据 应该由 应用 来存储，Quartz 只关注于调度执行。 3. JobDetail任务在 内存 的标示。表示 任务详细信息 的接口，\b如 Job 名字、描述信息、关联监听器 等信息。任务用调度器名称、任务名称和任务所归属的组名来作为 唯一标识。 4. Trigger触发器，用调度器名称、触发器名称和触发器所归属的组名来做 唯一标识。用于定义在什么情况、什么时间点执行任务。最常用的触发器类型就是基于 cron 表达式 的触发器。 5. JobStore数据存储抽象，该接口定义了 任务、触发器 的 存储、检索、更新 的钩子函数，该接口还定义了任务执行完成后的 回调方法。 Quartz 内建支持把 任务、触发器 等数据存储在 JVM 内存、文件、数据库 中。通过这个接口，就隔离了 底层存储机制 的差异。可以在配置文件里通过 org.quartz.JobStore.class 属性来指定该接口的实现，比如基于 Redis 做 数据存储 的实现。 5.1. RAMJobStore 优点：不依赖 外部数据库，配置容易，运行速度快。 缺点：程序停止运行时，所有 调度信息 丢失。调度信息的 \b存储容量 也会被限制。 5.2. JDBCJobStore 优点：支持 集群模式，所有的任务信息都会保存到 数据库 中。 缺点：配置复杂。运行速度的快慢，取决于连接数据库的快慢。 6. JobFactory任务工厂，接口抽象了如何生成 任务实例，以便让应用来决定如何实例化任务类。 7. JobStoreSupport提供了 基于数据库 的 JobStore 实现，通过 MisfireHandler 来检查错过发射的 触发器。如果是以 集群方式部署，还会通过内部类 ClusterManager 提供 集群健康检查 与 恢复。 8. MisfireHandlerJobStoreSupport 有个内部类 MisfireHandler，用于检查是否有 触发器 错过发射，它是用 单独的线程 执行。 但检测到有触发器 错过发射 时，该处理器只是 更新 触发器的状态为 WAITING，然后通知 监听器、通知 调度器 去处理。 9. ClusterManager用于 管理集群 的 线程。JobStoreSupport 有个 内部类 ClusterManager 用于进行 集群管理，它也是用 单独的线程 来执行，以防止 任务阻塞，其核心逻辑有： 签入，向其他节点传达它所在的 调度器实例 还处于存活状态。 检查失败的节点，进行 恢复。Quartz 认为在一定时间后 没有签入 的节点是失败的，需要恢复。 10. Calendarorg.quartz.Calendar 和 java.util.Calendar 不同，它是一些 特定时间点 的 集合。一个 Trigger 可以和 多个 Calendar 关联，以便 排除 或包含 某些时间点。 Quartz 在 org.quartz.impl.calendar 包下提供了若干个 Calendar 的 实现类，比如: AnnualCalendar、MonthlyCalendar、WeeklyCalendar 分别针对每年、每月和每周进行定义。 11. 工作线程池Quartz 可以配置一个 线程池 来执行任务，线程池里的 线程用完 后，后续到期需要执行的任务就会 被阻塞。 12. 调度器线程每个 调度器 都有自己的名称，对应一个 org.quartz.core.QuartzSchedulerThread 调度器线程实例，调度逻辑就在这个线程类的 run() 方法里。 Quartz的核心表1. job_details存储 任务 的信息，每一条记录表示一个任务。 2. triggers存储 触发器 的信息，TRIGGER_STATE 字段表示\b 触发器状态，用来控制这个 触发器 能不能被调度器 处理。 3. fired_triggers已发射触发器 的记录表，STATE 列用来表示任务的 执行状态。该表的作用是 跟踪任务 的 执行进度，用于 失败处理。 4. lockslocks 表里的每条记录作为一个 悲观锁，要 加锁 时，用 for update 语句锁住对应的记录。 5. scheduler_state调度器状态表，集群的节点通过这个表来检查 其他节点 是否存活。 小结","categories":[{"name":"任务调度框架系列","slug":"任务调度框架系列","permalink":"https://ostenant.coding.me/categories/任务调度框架系列/"}],"tags":[{"name":"Quartz","slug":"Quartz","permalink":"https://ostenant.coding.me/tags/Quartz/"}]},{"title":"实战Spring Boot 2.0系列(六) - 单机定时任务的几种实现","slug":"实战Spring Boot 2.0系列(六) - 单机定时任务的几种实现","date":"2018-06-25T10:20:00.000Z","updated":"2018-06-26T06:09:32.482Z","comments":true,"path":"2018/06/25/实战Spring Boot 2.0系列(六) - 单机定时任务的几种实现/","link":"","permalink":"https://ostenant.coding.me/2018/06/25/实战Spring Boot 2.0系列(六) - 单机定时任务的几种实现/","excerpt":"前言定时任务 一般会存在 中大型企业级 项目中，为了减少 服务器、数据库 的压力，往往会以 定时任务 的方式去完成某些业务逻辑。","text":"前言定时任务 一般会存在 中大型企业级 项目中，为了减少 服务器、数据库 的压力，往往会以 定时任务 的方式去完成某些业务逻辑。 常见的就是 金融服务系统 推送回调，一般支付系统订单在没有收到成功的回调返回内容时会 持续性的回调，这种回调一般都是 定时任务 来完成。 还有就是 报表的生成，我们一般会在客户 访问量小 时完成这个操作，也可以采用 定时任务 来完成。 正文定时任务的几种方式Timer这是 Java 自带的 java.util.Timer 类，这个类允许调度一个名为 java.util.TimerTask 任务。使用这种方式可以让你的程序按照某一个 频度 执行，但不能在 指定时间 运行。现在一般用的较少。 ScheduledExecutorServiceJDK 自带的一个类，是基于 线程池 设计的定时任务类，每个 调度任务 都会分配到 线程池 中的一个 线程 去执行。也就是说，任务是 并发执行，互不影响的。 Spring TaskSpring 3.0 以后自带的 Task，支持 多线程 调度，可以将它看成一个 轻量级 的 Quartz，而且使用起来比 Quartz 简单许多，但是适用于 单节点 的 定时任务调度。 Quartz这是一个 功能比较强大 的的调度器，可以让你的程序在指定时间执行，也可以按照某一个频度执行，配置起来 稍显复杂。Quartz 功能强大，可以结合 数据库 做 持久化，进行 分布式 的 任务延时调度。 Cron表达式简介Cron 表达式是一个字符串，字符串以 5 或 6 个 空格 隔开，分为 6 或 7 个 域，每一个域代表一个含义，Cron 有如下两种语法格式： Seconds Minutes Hours DayofMonth Month DayofWeek Year Seconds Minutes Hours DayofMonth Month DayofWeek 每个域对应的含义、域值范围和特殊表示符，从左到右依次如下： 字段 允许值 允许的特殊字符 秒 0-59 , - * / 分 0-59 , - * / 小时 0-23 , - * / 日期 1-31 , - * / L W C 月份 1-12 或者 JAN-DEC , - * / 星期 1-7 或者 SUN-SAT , - * / L C # 年（可选） 留空, 1970-2099 , - * / 如上面的表达式所示: “”字符: 被用来指定所有的值。如：在分钟的字段域里表示”每分钟”。 “-“字符: 被用来指定一个范围。如：”10-12” 在小时域意味着 “10点、11点、12点”。 “,”字符: 被用来指定另外的值。如：”MON,WED,FRI” 在星期域里表示 “星期一、星期三、星期五”。 “?”字符: 只在日期域和星期域中使用。它被用来指定”非明确的值”。当你需要通过在这两个域中的一个来指定一些东西的时候，它是有用的。看下面的例子你就会明白。 “L”字符: 指定在月或者星期中的某天（最后一天）。即 “Last” 的缩写。但是在星期和月中 “Ｌ” 表示不同的意思，如：在月子段中 “L” 指月份的最后一天 - 1月31日，2月28日。 如果在星期字段中则简单的表示为 “7” 或者 “SAT” 字符。 如果在星期字段中在某个 value 值得后面，则表示 “某月的最后一个星期value”，如 “6L” 表示某月的最后一个星期五。 “W”字符: 只能用在月份字段中，该字段指定了离指定日期最近的那个星期日。 “#”字符: 只能用在星期字段，该字段指定了第几个星期 value 在某月中 每一个元素都可以显式地规定一个值（如 6），一个区间（如 9-12），一个列表（如 9，11，13）或一个通配符（如 *）。“月份中的日期” 和 “星期中的日期” 这两个元素是 互斥的，因此应该通过设置一个 问号（?）来表明你不想设置的那个字段。下表显示了一些 cron 表达式的 例子 和它们的意义： 表达式 意义 “0 0 12 ?” 每天中午12点触发 “0 15 10 ? “ 每天上午10:15触发 “0 15 10 ?” 每天上午10:15触发 “0 15 10 ? *” 每天上午10:15触发 “0 15 10 ? 2005” 2005年的每天上午10:15触发 “0 14 * ?” 在每天下午2点到下午2:59期间的每1分钟触发 “0 0/5 14 ?” 在每天下午2点到下午2:55期间的每5分钟触发 “0 0/5 14,18 ?” 在每天下午2点到2:55期间和下午6点到6:55期间的每5分钟触发 “0 0-5 14 ?” 在每天下午2点到下午2:05期间的每1分钟触发 “0 10,44 14 ? 3 WED” 每年三月的星期三的下午2:10和2:44触发 “0 15 10 ? * MON-FRI” 周一至周五的上午10:15触发 “0 15 10 15 * ?” 每月15日上午10:15触发 “0 15 10 L * ?” 每月最后一日的上午10:15触发 “0 15 10 ? * 6L” 每月的最后一个星期五上午10:15触发 “0 15 10 ? * 6L 2002-2005” 2002年至2005年的每月的最后一个星期五上午10:15触发 “0 15 10 ? * 6#3” 每月的第三个星期五上午10:15触发 0 6 * 每天早上6点 0 /2 每两个小时 0 23-7/2，8 * 晚上11点到早上8点之间每两个小时，早上八点 0 11 4 * 1-3 每个月的4号和每个礼拜的礼拜一到礼拜三的早上11点 0 4 1 1 * 1月1日早上4点 环境准备配置gradle依赖利用 Spring Initializer 创建一个 gradle 项目 spring-boot-scheduler-task-management，创建时添加相关依赖。得到的初始 build.gradle 如下： 12345678910111213141516171819202122232425262728293031buildscript &#123; ext &#123; springBootVersion = '2.0.3.RELEASE' &#125; repositories &#123; mavenCentral() &#125; dependencies &#123; classpath(\"org.springframework.boot:spring-boot-gradle-plugin:$&#123;springBootVersion&#125;\") &#125;&#125;apply plugin: 'java'apply plugin: 'eclipse'apply plugin: 'org.springframework.boot'apply plugin: 'io.spring.dependency-management'group = 'io.ostenant.springboot.sample'version = '0.0.1-SNAPSHOT'sourceCompatibility = 1.8repositories &#123; mavenCentral()&#125;dependencies &#123; compile('org.springframework.boot:spring-boot-starter') compile('org.springframework.boot:spring-boot-starter-web') testCompile('org.springframework.boot:spring-boot-starter-test')&#125; 在 Spring Boot 入口类上配置 @EnableScheduling 注解开启 Spring 自带的定时处理功能。 1234567@SpringBootApplication@EnableSchedulingpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 配置Timer任务这个 API 目前在项目中很少用，直接给出示例代码。具体的介绍可以查看 API。Timer 的内部只有 一个线程，如果有 多个任务 的话就会 顺序执行，这样任务的 延迟时间 和 循环时间 就会出现问题。 TimerService.java 12345678910111213141516public class TimerService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(TimerService.class); private AtomicLong counter = new AtomicLong(); public void schedule() &#123; TimerTask timerTask = new TimerTask() &#123; @Override public void run() &#123; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule timerTask &#123;&#125; times\", count); &#125; &#125;; Timer timer = new Timer(); timer.schedule(timerTask, 1000L, 10 * 1000L; &#125;&#125; 上面的代码定义了一个 TimerTask，在 TimerTask 中累加 执行次数，并通过 slf4j 进行打印 (自带执行时间)。然后通过 Timer 调度工具类调度 TimerTask 任务，设置 初始化延迟时间 为 1s，定时执行间隔 为 10s，测试代码如下： 1234public static void main(String[] args) &#123; TimerService timerService = new TimerService(); timerService.schedule();&#125; 观察测试结果，能够发现 TimerTask 配置的任务\b每隔 10s \b被执行了一次，\b执行线程默认都是 Timer-0 这个线程。 1234517:48:18.731 [Timer-0] INFO io.ostenant.springboot.sample.timer.TimerService - Schedule timerTask 1 times17:48:28.730 [Timer-0] INFO io.ostenant.springboot.sample.timer.TimerService - Schedule timerTask 2 times17:48:38.736 [Timer-0] INFO io.ostenant.springboot.sample.timer.TimerService - Schedule timerTask 3 times17:48:48.738 [Timer-0] INFO io.ostenant.springboot.sample.timer.TimerService - Schedule timerTask 4 times17:48:58.743 [Timer-0] INFO io.ostenant.springboot.sample.timer.TimerService - Schedule timerTask 5 times 配置ScheduledExecutorService任务ScheduledExecutorService 是 延时执行 的线程池，对于 多线程 环境下的 定时任务，推荐用 ScheduledExecutorService 代替 Timer 定时器。 创建一个线程数量为 4 的 任务线程池，同一时刻并向它提交 4 个定时任务，用于测试延时任务的 并发处理。执行 ScheduledExecutorService 的 scheduleWithFixedDelay() 方法，设置任务线程池的 初始任务延迟时间 为 2 秒，并在上一次 执行完毕时间点 之后 10 秒再执行下一次任务。 123456789101112131415public void scheduleWithFixedDelay() &#123; ScheduledExecutorService scheduledExecutor = Executors.newScheduledThreadPool(4); for (int i = 0; i &lt; 4; i++) &#123; scheduledExecutor.scheduleWithFixedDelay(() -&gt; &#123; try &#123; TimeUnit.MILLISECONDS.sleep(10 * 1000L); &#125; catch (InterruptedException e) &#123; LOGGER.error(\"Interrupted exception\", e); &#125; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule executor &#123;&#125; times with fixed delay\", count); &#125;, 2000L, 10 * 1000L, TimeUnit.MILLISECONDS); &#125; LOGGER.info(\"Start to schedule\");&#125; 测试结果如下，我们可以发现每隔 20 秒的时间间隔，就会有 4 个定时任务同时执行。因为在任务线程池初始化时，我们同时向线程池提交了 4 个任务，这 四个任务 会完全利用线程池中的 4 个线程进行任务执行。 20 秒是怎么来的？首先每个任务的 时间间隔 设置为 10 秒。其次因为采用的是 withFixedDelay 策略，即当前任务执行的 结束时间，作为下次延时任务的 开始计时节点，并且每个任务在执行过程中睡眠了 10 秒的时间，累计起来就是 20 秒的时间。 12345678919:42:02.444 [main] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Start to schedule19:42:14.449 [pool-1-thread-1] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 3 times with fixed delay19:42:14.449 [pool-1-thread-2] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 1 times with fixed delay19:42:14.449 [pool-1-thread-3] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 2 times with fixed delay19:42:14.449 [pool-1-thread-4] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 4 times with fixed delay19:42:34.458 [pool-1-thread-4] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 7 times with fixed delay19:42:34.458 [pool-1-thread-3] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 5 times with fixed delay19:42:34.458 [pool-1-thread-2] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 8 times with fixed delay19:42:34.458 [pool-1-thread-1] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 6 times with fixed delay 创建一个线程数量为 4 的 任务线程池，同一时刻并向它提交 4 个定时任务，用于测试延时任务的 并发处理。每个任务分别执行 ScheduledExecutorService 的 scheduleAtFixedRate() 方法，设置任务线程池的 初始任务延迟时间 为 2 秒，并在上一次 开始执行时间点 之后 10 秒再执行下一次任务。 12345678910public void scheduleAtFixedRate() &#123; ScheduledExecutorService scheduledExecutor = Executors.newScheduledThreadPool(4); for (int i = 0; i &lt; 4; i++) &#123; scheduledExecutor.scheduleAtFixedRate(() -&gt; &#123; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule executor &#123;&#125; times at fixed rate\", count); &#125;, 2000L, 10 * 1000L, TimeUnit.MILLISECONDS); &#125; LOGGER.info(\"Start to schedule\");&#125; 测试结果如下，我们可以发现每隔 10 秒的时间间隔，就会有 4 个定时任务同时执行，因为在任务线程池初始化时，我们同时向线程池提交了 4 个任务，这 四个任务 会完全利用线程池中的 4 个线程进行任务执行。 12345678919:31:46.837 [main] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Start to schedule19:31:48.840 [pool-1-thread-1] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 1 times at fixed rate19:31:48.840 [pool-1-thread-3] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 3 times at fixed rate19:31:48.840 [pool-1-thread-2] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 2 times at fixed rate19:31:48.840 [pool-1-thread-4] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 4 times at fixed rate19:31:58.839 [pool-1-thread-2] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 6 times at fixed rate19:31:58.840 [pool-1-thread-4] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 8 times at fixed rate19:31:58.839 [pool-1-thread-3] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 7 times at fixed rate19:31:58.839 [pool-1-thread-1] INFO io.ostenant.springboot.sample.executor.ScheduledExecutorsService - Schedule executor 5 times at fixed rate 配置Spring Task任务Spring 提供了 @Scheduled 注解来实现 定时任务，@Scheduled 参数可以接受 两种 定时的设置，一种是我们常用的 格林时间表达式 cron = &quot;*/10 * * * * *&quot;，另一种是 fixedRate = 10 * 1000L，两种都表示每隔 10 秒执行一次目标任务。 参数说明： @Scheduled(fixedRate = 10 * 1000L)：上一次 开始执行时间点 之后 10 秒再执行。 12345@Scheduled(fixedRate = 10 * 1000L)public void scheduleAtFixedRate() throws Exception &#123; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule executor &#123;&#125; times at fixed rate\", count);&#125; @Scheduled(fixedDelay = 10 * 1000L)：上一次 执行完毕时间点 之后 10 秒再执行。 12345678910@Scheduled(fixedDelay = 10 * 1000L)public void scheduleWithFixedDelay() throws Exception &#123; try &#123; TimeUnit.MILLISECONDS.sleep(10 * 1000L); &#125; catch (InterruptedException e) &#123; LOGGER.error(\"Interrupted exception\", e); &#125; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule executor &#123;&#125; times with fixed delay\", count);&#125; @Scheduled(initialDelay = 2000L, fixedRate = 10 * 1000L)：第一次延迟 2 秒后执行，之后按 fixedRate 的规则每 10 秒执行一次。 12345678910@Scheduled(initialDelay = 2000L, fixedDelay = 10 * 1000L)public void scheduleWithinitialDelayAndFixedDelay() throws Exception &#123; try &#123; TimeUnit.MILLISECONDS.sleep(10 * 1000L); &#125; catch (InterruptedException e) &#123; LOGGER.error(\"Interrupted exception\", e); &#125; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule executor &#123;&#125; times with fixed delay\", count);&#125; @Scheduled(cron = “0/10 *”)：根据 cron 表达式定义，每隔 10 秒执行一次。 12345@Scheduled(cron = \"0/10 * * * * *\")public void scheduleWithCronExpression() throws Exception &#123; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule executor &#123;&#125; times with \", count);&#125; 完整的代码如下： SpringTaskService.java 123456789101112131415161718192021222324252627282930313233343536373839@Componentpublic class SpringTaskService &#123; private static final Logger LOGGER = LoggerFactory.getLogger(SpringTaskService.class); private AtomicLong counter = new AtomicLong(); @Scheduled(fixedDelay = 10 * 1000L) public void scheduleWithFixedDelay() throws Exception &#123; try &#123; TimeUnit.MILLISECONDS.sleep(10 * 1000L); &#125; catch (InterruptedException e) &#123; LOGGER.error(\"Interrupted exception\", e); &#125; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule executor &#123;&#125; times with fixed delay\", count); &#125; @Scheduled(initialDelay = 2000L, fixedDelay = 10 * 1000L) public void scheduleWithinitialDelayAndFixedDelay() throws Exception &#123; try &#123; TimeUnit.MILLISECONDS.sleep(10 * 1000L); &#125; catch (InterruptedException e) &#123; LOGGER.error(\"Interrupted exception\", e); &#125; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule executor &#123;&#125; times with fixed delay\", count); &#125; @Scheduled(fixedRate = 10 * 1000L) public void scheduleAtFixedRate() throws Exception &#123; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule executor &#123;&#125; times at fixed rate\", count); &#125; @Scheduled(cron = \"0/10 * * * * *\") public void scheduleWithCronExpression() throws Exception &#123; long count = counter.incrementAndGet(); LOGGER.info(\"Schedule executor &#123;&#125; times with \", count); &#125;&#125; 查看日志，任务每 20 秒的时间间隔执行一次。每次定时任务在上次 执行完毕时间点 之后 10 秒再执行，在任务中设置 睡眠时间 为 10 秒。这里只验证了 @Scheduled(initialDelay = 2000L, fixedDelay = 10 * 1000L)。 123452018-06-25 18:00:53.051 INFO 5190 --- [pool-1-thread-1] i.o.s.sample.spring.SpringTaskService : Schedule executor 1 times with fixed delay2018-06-25 18:01:13.056 INFO 5190 --- [pool-1-thread-1] i.o.s.sample.spring.SpringTaskService : Schedule executor 2 times with fixed delay2018-06-25 18:01:33.061 INFO 5190 --- [pool-1-thread-1] i.o.s.sample.spring.SpringTaskService : Schedule executor 3 times with fixed delay2018-06-25 18:01:53.071 INFO 5190 --- [pool-1-thread-1] i.o.s.sample.spring.SpringTaskService : Schedule executor 4 times with fixed delay2018-06-25 18:02:13.079 INFO 5190 --- [pool-1-thread-1] i.o.s.sample.spring.SpringTaskService : Schedule executor 5 times with fixed delay 配置任务线程池上述配置都是基于 单线程 的任务调度，如何引入 多线程 提高 延时任务 的 并发处理 能力？ Spring Boot 提供了一个 SchedulingConfigurer 配置接口。我们通过 ScheduleConfig 配置文件实现 ScheduleConfiguration 接口，并重写 configureTasks() 方法，向 ScheduledTaskRegistrar 注册一个 ThreadPoolTaskScheduler 任务线程对象即可。 1234567891011121314151617181920@Configurationpublic class ScheduleConfiguration implements SchedulingConfigurer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ScheduleConfiguration.class); @Override public void configureTasks(ScheduledTaskRegistrar taskRegistrar) &#123; taskRegistrar.setTaskScheduler(taskScheduler()); &#125; @Bean public ThreadPoolTaskScheduler taskScheduler() &#123; ThreadPoolTaskScheduler taskScheduler = new ThreadPoolTaskScheduler(); taskScheduler.setPoolSize(4); taskScheduler.setWaitForTasksToCompleteOnShutdown(true); taskScheduler.setThreadNamePrefix(\"schedule\"); taskScheduler.setRemoveOnCancelPolicy(true); taskScheduler.setErrorHandler(t -&gt; LOGGER.error(\"Error occurs\", t)); return taskScheduler; &#125;&#125; 启动 Spring Boot 引用，上面 SpringTaskService 配置的 4 个定时任务会同时生效。 123456782018-06-20 20:37:50.746 INFO 8142 --- [ schedule1] i.o.s.sample.spring.SpringTaskService : Schedule executor 1 times at fixed rate2018-06-20 20:38:00.001 INFO 8142 --- [ schedule3] i.o.s.sample.spring.SpringTaskService : Schedule executor 2 times with 2018-06-20 20:38:00.751 INFO 8142 --- [ schedule1] i.o.s.sample.spring.SpringTaskService : Schedule executor 3 times at fixed rate2018-06-20 20:38:02.748 INFO 8142 --- [ schedule2] i.o.s.sample.spring.SpringTaskService : Schedule executor 4 times with fixed delay2018-06-20 20:38:10.005 INFO 8142 --- [ schedule4] i.o.s.sample.spring.SpringTaskService : Schedule executor 5 times with 2018-06-20 20:38:10.747 INFO 8142 --- [ schedule3] i.o.s.sample.spring.SpringTaskService : Schedule executor 6 times at fixed rate2018-06-20 20:38:20.002 INFO 8142 --- [ schedule2] i.o.s.sample.spring.SpringTaskService : Schedule executor 7 times with 2018-06-20 20:38:20.747 INFO 8142 --- [ schedule4] i.o.s.sample.spring.SpringTaskService : Schedule executor 8 times at fixed rate 观察日志，线程名前缀 为 schedule，可以发现 Spring Task 将 @Scheduled 注解配置的 4 个任务，分发给我们配置的 ThreadPoolTaskScheduler 中的 4 个线程并发执行。 小结本文介绍了基于单节点的定时任务调度及实现，包括 JDK 原生的 Timer 和 ScheduledExecutorService，以及 Spring 3.0 以后自带的基于注解的 Spring Task 任务调度方式。除此之外，重点阐述了基于 固定延时、固定频率 和 cron 表达式 的不同之处，并对 ScheduledExecutorService 和 Spring Scheduler 的 线程池并发处理 进行了测试。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"实战Spring Boot 2.0系列","slug":"实战Spring-Boot-2-0系列","permalink":"https://ostenant.coding.me/categories/实战Spring-Boot-2-0系列/"}],"tags":[{"name":"Quartz","slug":"Quartz","permalink":"https://ostenant.coding.me/tags/Quartz/"},{"name":"Spring Boot 2.0","slug":"Spring-Boot-2-0","permalink":"https://ostenant.coding.me/tags/Spring-Boot-2-0/"},{"name":"定时任务","slug":"定时任务","permalink":"https://ostenant.coding.me/tags/定时任务/"},{"name":"Spring Task","slug":"Spring-Task","permalink":"https://ostenant.coding.me/tags/Spring-Task/"},{"name":"Timer","slug":"Timer","permalink":"https://ostenant.coding.me/tags/Timer/"},{"name":"ScheduledExecutorService","slug":"ScheduledExecutorService","permalink":"https://ostenant.coding.me/tags/ScheduledExecutorService/"}]},{"title":"实战Spring Boot 2.0系列(五) - Listener, Servlet和Filter, Controller和Interceptor","slug":"实战Spring Boot 2.0系列(五) - Listener, Servlet和Filter, Controller和Interceptor","date":"2018-06-20T11:20:00.000Z","updated":"2018-07-05T12:46:15.992Z","comments":true,"path":"2018/06/20/实战Spring Boot 2.0系列(五) - Listener, Servlet和Filter, Controller和Interceptor/","link":"","permalink":"https://ostenant.coding.me/2018/06/20/实战Spring Boot 2.0系列(五) - Listener, Servlet和Filter, Controller和Interceptor/","excerpt":"前言用户认证授权、日志记录 MDC、编码解码、UA 检查、多端对应等都需要通过 拦截请求 来进行处理。这时就需要 Servlet、Filter、Listener、Interceptor 这几种组件。而把非 Spring Boot 项目转换成 Spring Boot 项目，需要沿用以前的这些代码，所以有必要了解这它们的 用法 和 生命周期。","text":"前言用户认证授权、日志记录 MDC、编码解码、UA 检查、多端对应等都需要通过 拦截请求 来进行处理。这时就需要 Servlet、Filter、Listener、Interceptor 这几种组件。而把非 Spring Boot 项目转换成 Spring Boot 项目，需要沿用以前的这些代码，所以有必要了解这它们的 用法 和 生命周期。 正文1. 几种组件介绍1.1. 监听器ListenerListener 可以监听 web 服务器中某一个 事件操作，并触发注册的 回调函数。通俗的语言就是在 application，session，request 三个对象 创建\b/消亡 或者 增删改 属性时，自动执行代码的功能组件。 1.2. ServletServlet 是一种运行 服务器端 的 java 应用程序，具有 独立于平台和协议 的特性，并且可以动态的生成 web 页面，它工作在 客户端请求 与 服务器响应 的中间层。 1.3. 过滤器FilterFilter 对 用户请求 进行 预处理，接着将请求交给 Servlet 进行 处理 并 生成响应，最后 Filter 再对 服务器响应 进行 后处理。Filter 是可以复用的代码片段，常用来转换 HTTP 请求、响应 和 头信息。Filter 不像 Servlet，它不能产生 响应，而是只 修改 对某一资源的 请求 或者 响应。 1.4. 拦截器Interceptor类似 面向切面编程 中的 切面 和 通知，我们\b通过 动态代理 对一个 service() 方法添加 通知 进行功能增强。比如说在方法执行前进行 初始化处理，在方法执行后进行 后置处理。拦截器 的思想和 AOP 类似，区别就是 拦截器 只能对 Controller 的 HTTP 请求进行拦截。 2. 过滤器 VS 拦截器2.1. 两者的区别 Filter 是基于 函数回调的，而 Interceptor 则是基于 Java 反射 和 动态代理。 Filter 依赖于 Servlet 容器，而 Interceptor 不依赖于 Servlet 容器。 Filter 对几乎 所有的请求 起作用，而 Interceptor 只对 Controller\b 对请求起作用。 2.2. \b执行顺序对于自定义 Servlet 对请求分发流程： Filter 过滤请求处理； Servlet 处理请求； Filter 过滤响应处理。 对于自定义 Controller 的请求分发流程： Filter 过滤请求处理； Interceptor 拦截请求处理； 对应的 HandlerAdapter 处理请求； Interceptor 拦截响应处理； Interceptor 的最终处理； Filter 过滤响应处理。 3. 环境准备配置gradle依赖利用 Spring Initializer 创建一个 gradle 项目 spring-boot-web-async-task，创建时添加相关依赖。得到的初始 build.gradle 如下： 123456789101112131415161718192021222324252627282930buildscript &#123; ext &#123; springBootVersion = '2.0.3.RELEASE' &#125; repositories &#123; mavenCentral() &#125; dependencies &#123; classpath(\"org.springframework.boot:spring-boot-gradle-plugin:$&#123;springBootVersion&#125;\") &#125;&#125;apply plugin: 'java'apply plugin: 'eclipse'apply plugin: 'org.springframework.boot'apply plugin: 'io.spring.dependency-management'group = 'io.ostenant.springboot.sample'version = '0.0.1-SNAPSHOT'sourceCompatibility = 1.8repositories &#123; mavenCentral()&#125;dependencies &#123; compile('org.springframework.boot:spring-boot-starter-web') testCompile('org.springframework.boot:spring-boot-starter-test')&#125; 配置启动入口类配置一个 Spring Boot 启动入口类，这里需要配置两个注解。 @ServletComponentScan: 允许 Spring Boot 扫描和装载当前 包路径 和 子路径 下配置的 Servlet。 @EnableWvc: 允许 Spring Boot 配置 Spring MVC 相关自定义的属性，比如：拦截器、资源处理器、消息转换器等。 12345678@EnableWebMvc@ServletComponentScan@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 4. 配置监听器Listener配置一个 ServletContext 监听器，使用 @WebListener 标示即可。在 Servlet 容器 初始化 过程中，contextInitialized() 方法会被调用，在容器 销毁 时会调用 contextDestroyed()。 1234567891011121314151617@WebListenerpublic class IndexServletContextListener implements ServletContextListener &#123; private static final Logger LOGGER = LoggerFactory.getLogger(IndexServletContextListener.class); public static final String INITIAL_CONTENT = \"Content created in servlet Context\"; @Override public void contextInitialized(ServletContextEvent sce) &#123; LOGGER.info(\"Start to initialize servlet context\"); ServletContext servletContext = sce.getServletContext(); servletContext.setAttribute(\"content\", INITIAL_CONTENT); &#125; @Override public void contextDestroyed(ServletContextEvent sce) &#123; LOGGER.info(\"Destroy servlet context\"); &#125;&#125; 这里在容器初始化时，往 ServletContext 上下文设置了参数名称为 INITIAL_CONTENT，可以全局直接访问。 5. 配置Servlet配置 IndexHttpServlet，重写 HttpServlet 的 doGet() 方法，直接输出 IndexHttpServlet 定义的 初始化参数 和在 IndexServletContextListener 设置的 ServletContext 上下文参数。 123456789101112131415161718@WebServlet(name = \"IndexHttpServlet\", displayName = \"indexHttpServlet\", urlPatterns = &#123;\"/index/IndexHttpServlet\"&#125;, initParams = &#123; @WebInitParam(name = \"createdBy\", value = \"Icarus\"), @WebInitParam(name = \"createdOn\", value = \"2018-06-20\") &#125;)public class IndexHttpServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws IOException &#123; resp.getWriter().println(format(\"Created by %s\", getInitParameter(\"createdBy\"))); resp.getWriter().println(format(\"Created on %s\", getInitParameter(\"createdOn\"))); resp.getWriter().println(format(\"Servlet context param: %s\", req.getServletContext().getAttribute(\"content\"))); &#125;&#125; 配置 @WebServlet 注解用于注册这个 Servlet，@WebServlet 注解的 各个参数 分别对应 web.xml 中的配置： 12345678910111213141516&lt;servlet-mapping&gt; &lt;servlet-name&gt;IndexHttpServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/index/IndexHttpServlet&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;servlet&gt; &lt;servlet-name&gt;IndexHttpServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;io.ostenant.springboot.sample.servlet.IndexHttpServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;createdBy&lt;/param-name&gt; &lt;param-value&gt;Icarus&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;createdOn&lt;/param-name&gt; &lt;param-value&gt;2018-06-20&lt;/param-value&gt; &lt;/init-param&gt;&lt;/servlet&gt; 6. 配置过滤器Filter一个 Servlet 请求可以经由多个 Filter 进行过滤，最终由 Servlet 处理并响应客户端。这里配置两个过滤器示例： FirstIndexFilter.java 12345678910111213141516171819202122232425262728293031323334@WebFilter(filterName = \"firstIndexFilter\", displayName = \"firstIndexFilter\", urlPatterns = &#123;\"/index/*\"&#125;, initParams = @WebInitParam( name = \"firstIndexFilterInitParam\", value = \"io.ostenant.springboot.sample.filter.FirstIndexFilter\"))public class FirstIndexFilter implements Filter &#123; private static final Logger LOGGER = LoggerFactory.getLogger(FirstIndexFilter.class); @Override public void init(FilterConfig filterConfig) throws ServletException &#123; LOGGER.info(\"Register a new filter &#123;&#125;\", filterConfig.getFilterName()); &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; LOGGER.info(\"FirstIndexFilter pre filter the request\"); String filter = request.getParameter(\"filter1\"); if (isEmpty(filter)) &#123; response.getWriter().println(\"Filtered by firstIndexFilter, \" + \"please set request parameter \\\"filter1\\\"\"); return; &#125; chain.doFilter(request, response); LOGGER.info(\"FirstIndexFilter post filter the response\"); &#125; @Override public void destroy() &#123; LOGGER.info(\"Destroy filter &#123;&#125;\", getClass().getName()); &#125;&#125; 以上 @WebFilter 相关的配置属性，对应于 web.xml 的配置如下： 123456789&lt;filter-mapping&gt; &lt;filter-name&gt;firstIndexFilter&lt;/filter-name&gt; &lt;filter-class&gt;io.ostenant.springboot.sample.filter.FirstIndexFilter&lt;/filter-class&gt; &lt;url-pattern&gt;/index/*&lt;/url-pattern&gt; &lt;init-param&gt; &lt;param-name&gt;firstIndexFilterInitParam&lt;/param-name&gt; &lt;param-value&gt;io.ostenant.springboot.sample.filter.FirstIndexFilter&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter-mapping&gt; 配置 FirstIndexFilter，使用 @WebFilter 注解进行标示。当 FirstIndexFilter 初始化时，会执行 init() 方法。每次请求路径匹配 urlPatterns 配置的路径时，就会进入 doFilter() 方法进行具体的 请求 和 响应过滤。 当 HTTP 请求携带 filter1 参数时，请求会被放行；否则，直接 过滤中断，结束请求处理。 SecondIndexFilter.java 1234567891011121314151617181920212223242526272829303132333435@WebFilter(filterName = \"secondIndexFilter\", displayName = \"secondIndexFilter\", urlPatterns = &#123;\"/index/*\"&#125;, initParams = @WebInitParam( name = \"secondIndexFilterInitParam\", value = \"io.ostenant.springboot.sample.filter.SecondIndexFilter\"))public class SecondIndexFilter implements Filter &#123; private static final Logger LOGGER = LoggerFactory.getLogger(SecondIndexFilter.class); @Override public void init(FilterConfig filterConfig) throws ServletException &#123; LOGGER.info(\"Register a new filter &#123;&#125;\", filterConfig.getFilterName()); &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; LOGGER.info(\"SecondIndexFilter pre filter the request\"); String filter = request.getParameter(\"filter2\"); if (isEmpty(filter)) &#123; response.getWriter().println(\"Filtered by firstIndexFilter, \" + \"please set request parameter \\\"filter2\\\"\"); return; &#125; chain.doFilter(request, response); LOGGER.info(\"SecondIndexFilter post filter the response\"); &#125; @Override public void destroy() &#123; LOGGER.info(\"Destroy filter &#123;&#125;\", getClass().getName()); &#125;&#125; 以上 @WebFilter 相关的配置属性，对应于 web.xml 的配置如下： 123456789&lt;filter-mapping&gt; &lt;filter-name&gt;secondIndexFilter&lt;/filter-name&gt; &lt;filter-class&gt;io.ostenant.springboot.sample.filter.SecondIndexFilter&lt;/filter-class&gt; &lt;url-pattern&gt;/index/*&lt;/url-pattern&gt; &lt;init-param&gt; &lt;param-name&gt;secondIndexFilterInitParam&lt;/param-name&gt; &lt;param-value&gt;io.ostenant.springboot.sample.filter.SecondIndexFilter&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter-mapping&gt; 配置 SecondIndexFilter，使用 @WebFilter 注解进行标示。当 SecondIndexFilter 初始化时，会执行 init() 方法。每次请求路径匹配 urlPatterns 配置的路径时，就会进入 doFilter() 方法进行具体的 请求 和 响应过滤。 当 HTTP 请求携带 filter2 参数时，请求会被放行；否则，直接 过滤中断，结束请求处理。 来看看 doFilter() 最核心的三个参数： ServletRequest: 未到达 Servlet 的 HTTP 请求； ServletResponse: 由 Servlet 处理并生成的 HTTP 响应； FilterChain: 过滤器链 对象，可以按顺序注册多个 过滤器。 1FilterChain.doFilter(request, response); 解释： 一个 过滤器链 对象可以按顺序注册多个 过滤器。符合当前过滤器过滤条件，即请求 过滤成功 直接放行，则交由下一个 过滤器 进行处理。所有请求过滤完成以后，由 IndexHttpServlet 处理并生成 响应，然后在 过滤器链 以相反的方向对 响应 进行后置过滤处理。 配置控制器Controller配置 IndexController，用于测试 /index/IndexController 路径是否会被 Filter 过滤和 Interceptor 拦截，并验证两者的先后顺序。 12345678@RestController@RequestMapping(\"index\")public class IndexController &#123; @GetMapping(\"IndexController\") public String index() throws Exception &#123; return \"IndexController\"; &#125;&#125; 7. 配置拦截器Interceptor拦截器 Interceptor 只对 Handler 生效。Spring MVC 会为 Controller 中的每个 请求方法 实例化为一个 Handler对象，由 HandlerMapping 对象路由请求到具体的 Handler，然后由 HandlerAdapter 通过反射进行请求 处理 和 响应，这中间就穿插着 拦截处理。 编写拦截器为了区分日志，下面同样对 IndexController 配置两个拦截器类： FirstIndexInterceptor.java 12345678910111213141516171819202122232425public class FirstIndexInterceptor implements HandlerInterceptor &#123; private static final Logger LOGGER = LoggerFactory.getLogger(FirstIndexInterceptor.class); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; LOGGER.info(\"FirstIndexInterceptor pre intercepted the request\"); String interceptor = request.getParameter(\"interceptor1\"); if (isEmpty(interceptor)) &#123; response.getWriter().println(\"Filtered by FirstIndexFilter, \" + \"please set request parameter \\\"interceptor1\\\"\"); return false; &#125; return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; LOGGER.info(\"FirstIndexInterceptor post intercepted the response\"); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; LOGGER.info(\"FirstIndexInterceptor do something after request completed\"); &#125;&#125; SecondIndexInterceptor.java 12345678910111213141516171819202122232425public class SecondIndexInterceptor implements HandlerInterceptor &#123; private static final Logger LOGGER = LoggerFactory.getLogger(SecondIndexInterceptor.class); @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; LOGGER.info(\"SecondIndexInterceptor pre intercepted the request\"); String interceptor = request.getParameter(\"interceptor2\"); if (isEmpty(interceptor)) &#123; response.getWriter().println(\"Filtered by SecondIndexInterceptor, \" + \"please set request parameter \\\"interceptor2\\\"\"); return false; &#125; return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; LOGGER.info(\"SecondIndexInterceptor post intercepted the response\"); &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; LOGGER.info(\"SecondIndexInterceptor do something after request completed\"); &#125;&#125; 配置拦截器在 Spring Boot 中 配置拦截器 很简单，只需要实现 WebMvcConfigurer 接口，在 addInterceptors() 方法中通过 InterceptorRegistry 添加 拦截器 和 匹配路径 即可。 1234567891011@Configurationpublic class WebConfiguration implements WebMvcConfigurer &#123; private static final Logger LOGGER = LoggerFactory.getLogger(WebConfiguration.class); @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new FirstIndexInterceptor()).addPathPatterns(\"/index/**\"); registry.addInterceptor(new SecondIndexInterceptor()).addPathPatterns(\"/index/**\"); LOGGER.info(\"Register FirstIndexInterceptor and SecondIndexInterceptor onto InterceptorRegistry\"); &#125;&#125; 对应的 Spring XML 配置方式如下： 123456789101112131415&lt;bean id=\"firstIndexInterceptor\"class=\"io.ostenant.springboot.sample.interceptor.FirstIndexInterceptor\"&gt;&lt;/bean&gt;&lt;bean id=\"secondIndexInterceptor\"class=\"io.ostenant.springboot.sample.interceptor.SecondIndexInterceptor\"&gt;&lt;/bean&gt;&lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=\"/index/**\" /&gt; &lt;ref local=\"firstIndexInterceptor\" /&gt; &lt;/mvc:interceptor&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=\"/index/**\" /&gt; &lt;ref local=\"secondIndexInterceptor\" /&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 原理剖析我们通过实现 HandlerInterceptor 接口来开发一个 拦截器，来看看 HandlerInterceptor 接口的三个重要的方法： preHandle(): 在 controller 接收请求、处理 request 之前执行，返回值为 boolean，返回值为 true 时接着执行 postHandle() 和 afterCompletion() 方法；如果返回 false 则 中断 执行。 postHandle(): 在 controller 处理请求之后， ModelAndView 处理前执行，可以对 响应结果 进行修改。 afterCompletion(): 在 DispatchServlet 对本次请求处理完成，即生成 ModelAndView 之后执行。 下面简单的看一下 Spring MVC 中心调度器 DispatcherServlet 的 doDispatch() 方法的原理，重点关注 拦截器 的以上三个方法的执行顺序。 doDispatch(): DispatchServlet 处理请求分发的核心方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try &#123; ModelAndView mv = null; Exception dispatchException = null; try &#123; processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); // Determine handler for the current request. mappedHandler = getHandler(processedRequest); if (mappedHandler == null) &#123; noHandlerFound(processedRequest, response); return; &#125; // Determine handler adapter for the current request. HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = \"GET\".equals(method); if (isGet || \"HEAD\".equals(method)) &#123; long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (logger.isDebugEnabled()) &#123; logger.debug(\"Last-Modified value for [\" + getRequestUri(request) + \"] is: \" + lastModified); &#125; if (new ServletWebRequest(request, response).checkNotModified(lastModified) &amp;&amp; isGet) &#123; return; &#125; &#125; // 1. 按从前往后的顺序调用各个拦截器preHandle()方法 if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123; return; &#125; // 2. HandlerAdapter开始真正的请求处理并生产响应视图对象 mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); if (asyncManager.isConcurrentHandlingStarted()) &#123; return; &#125; applyDefaultViewName(processedRequest, mv); // 3. 按照从后往前的顺序依次调用各个拦截器的postHandle()方法 mappedHandler.applyPostHandle(processedRequest, response, mv); &#125; catch (Exception ex) &#123; dispatchException = ex; &#125; catch (Throwable err) &#123; dispatchException = new NestedServletException(\"Handler dispatch failed\", err); &#125; processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); &#125; catch (Exception ex) &#123; // 4. 最终会调用拦截器的afterCompletion()方法 triggerAfterCompletion(processedRequest, response, mappedHandler, ex); &#125; catch (Throwable err) &#123; // 4. 最终会调用拦截器的afterCompletion()方法 triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\"Handler processing failed\", err)); &#125; finally &#123; if (asyncManager.isConcurrentHandlingStarted()) &#123; if (mappedHandler != null) &#123; mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); &#125; &#125; else &#123; if (multipartRequestParsed) &#123; cleanupMultipart(processedRequest); &#125; &#125; &#125;&#125; 上面注释的几个 HandlerExecutionChain 的方法: applyPreHandle()、applyPostHandle() 和 triggerAfterCompletion()。 applyPreHandle(): 按 从前往后 的顺序调用各个拦截器的 preHandle() 方法。任意一个 HandlerInterceptor 拦截返回 false ，则 preHandle() 返回 false，记录拦截器的位置 interceptorIndex，然后中断拦截处理，最终触发 AfterCompletion() 方法并返回 false。 1234567891011121314boolean applyPreHandle(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; HandlerInterceptor[] interceptors = getInterceptors(); if (!ObjectUtils.isEmpty(interceptors)) &#123; for (int i = 0; i &lt; interceptors.length; i++) &#123; HandlerInterceptor interceptor = interceptors[i]; if (!interceptor.preHandle(request, response, this.handler)) &#123; triggerAfterCompletion(request, response, null); return false; &#125; this.interceptorIndex = i; &#125; &#125; return true;&#125; applyPostHandle(): 按照 从后往前 的顺序依次调用各个拦截器的 postHandle() 方法。只有当所有 HandlerInterceptor 的 preHandle() 方法返回 true 时，才有机会执行到 applyPostHandle() 方法。 12345678910void applyPostHandle(HttpServletRequest request, HttpServletResponse response, @Nullable ModelAndView mv) throws Exception &#123; HandlerInterceptor[] interceptors = getInterceptors(); if (!ObjectUtils.isEmpty(interceptors)) &#123; for (int i = interceptors.length - 1; i &gt;= 0; i--) &#123; HandlerInterceptor interceptor = interceptors[i]; interceptor.postHandle(request, response, this.handler, mv); &#125; &#125;&#125; triggerAfterCompletion: triggerAfterCompletion() 只在 preHandle() 方法返回 false 和 程序抛出异常 时执行。在 preHandle() 方法中，通过 interceptorIndex 记录了返回 false 的 拦截器索引。一旦 applyPreHandle() 方法返回 false，则从当前返回 false 的拦截器 从后往前 的执行 afterCompletion() 方法。 123456789101112131415void triggerAfterCompletion(HttpServletRequest request, HttpServletResponse response, @Nullable Exception ex) throws Exception &#123; HandlerInterceptor[] interceptors = getInterceptors(); if (!ObjectUtils.isEmpty(interceptors)) &#123; for (int i = this.interceptorIndex; i &gt;= 0; i--) &#123; HandlerInterceptor interceptor = interceptors[i]; try &#123; interceptor.afterCompletion(request, response, this.handler, ex); &#125; catch (Throwable ex2) &#123; logger.error(\"HandlerInterceptor.afterCompletion threw exception\", ex2); &#125; &#125; &#125;&#125; 8. 开始测试生命周期测试启动 Spring Boot 应用程序，观察启动时的程序日志，下面我按照 顺序 来分析启动过程中完成了哪些事情。 注册 Spring MVC 的 dispatcherServlet 和自定义的 IndexHttpServlet。 122018-06-23 09:39:55.400 INFO 12301 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Servlet dispatcherServlet mapped to [/]2018-06-23 09:39:55.404 INFO 12301 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Servlet IndexHttpServlet mapped to [/index/IndexHttpServlet] 注意: dispatcherServlet 的 load-up-onstartup 为 1，会优先于其他 Servlet 进行加载。 按照先后顺序，将所有的过滤器 Filter 对象与路径进行映射，其中 characterEncodingFilter 是 Spring MVC 自带的解决乱码的 Filter。 1232018-06-23 09:39:55.408 INFO 12301 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*]2018-06-23 09:39:55.409 INFO 12301 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: 'firstIndexFilter' to urls: [/index/*]2018-06-23 09:39:55.409 INFO 12301 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: 'secondIndexFilter' to urls: [/index/*] 初始化 IndexServletContextListener，并执行 contextInitialized() 方法进行上下文初始化操作。 12018-06-23 09:39:55.429 INFO 12301 --- [ost-startStop-1] i.o.s.s.l.IndexServletContextListener : Start to initialize servlet context 依次执行 Filter 的 init() 方法进行初始化处理。 122018-06-23 09:39:55.432 INFO 12301 --- [ost-startStop-1] i.o.s.sample.filter.SecondIndexFilter : Register a new filter secondIndexFilter2018-06-23 09:39:55.434 INFO 12301 --- [ost-startStop-1] i.o.s.sample.filter.FirstIndexFilter : Register a new filter firstIndexFilter 创建、初始化拦截器，并统一注册到 InterceptorRegistry 上。 12018-06-23 09:39:55.502 INFO 13150 --- [ main] i.o.s.s.interceptor.WebConfiguration : Register FirstIndexInterceptor and SecondIndexInterceptor onto InterceptorRegistry 对 IndexController 进行处理，把 请求 URI 和 处理方法 映射到 HandlerMapping 上并进行缓存。 12018-06-23 09:39:55.541 INFO 12301 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \"&#123;[/index/IndexController],methods=[GET]&#125;\" onto public java.lang.String io.ostenant.springboot.sample.controller.IndexController.index() throws java.lang.Exception 关闭 Spring Boot 应用程序时，观察输出日志如下: 1232018-06-23 10:07:03.294 INFO 12301 --- [ost-startStop-2] i.o.s.sample.filter.FirstIndexFilter : Destroy filter io.ostenant.springboot.sample.filter.SecondIndexFilter2018-06-23 10:07:03.294 INFO 12301 --- [ost-startStop-2] i.o.s.sample.filter.FirstIndexFilter : Destroy filter io.ostenant.springboot.sample.filter.FirstIndexFilter2018-06-23 10:07:03.294 INFO 12301 --- [ost-startStop-2] i.o.s.s.l.IndexServletContextListener : Destroy servlet context 可以看到上面配置的过滤器的 destroy() 方法和 IndexServletContextListener 的 contextDestroyed() 方法都被调用了。 访问控制测试Servlet测试访问 http://localhost:8080/index/IndexHttpServlet，响应页面内容如下： 访问 http://localhost:8080/index/IndexHttpServlet?filter1=filter1，响应页面内容如下： 访问 http://localhost:8080/index/IndexHttpServlet?filter1=filter1&amp;filter2=filter2，响应页面内容如下： 观察控制台输出日志，验证 过滤器 的过滤顺序正确。 12342018-06-23 10:19:47.944 INFO 13150 --- [nio-8080-exec-1] i.o.s.sample.filter.FirstIndexFilter : FirstIndexFilter pre filter the request2018-06-23 10:19:47.944 INFO 13150 --- [nio-8080-exec-1] i.o.s.sample.filter.SecondIndexFilter : SecondIndexFilter pre filter the request2018-06-23 10:19:47.944 INFO 13150 --- [nio-8080-exec-1] i.o.s.sample.filter.SecondIndexFilter : SecondIndexFilter post filter the response2018-06-23 10:19:47.944 INFO 13150 --- [nio-8080-exec-1] i.o.s.sample.filter.FirstIndexFilter : FirstIndexFilter post filter the response 结论： 自定义的 过滤器 对 IndexHttpServlet 生效， 而 自定义 的拦截器生效。 controller测试访问 http://localhost:8080/index/IndexController，响应页面内容如下： 访问 http://localhost:8080/index/IndexController?filter1=filter1，响应页面内容如下： 访问 http://localhost:8080/index/IndexController?filter1=filter1&amp;filter2=filter2，响应页面内容如下： 访问 http://localhost:8080/index/IndexController?filter1=filter1&amp;filter2=filter2&amp;interceptor1=interceptor1，响应页面内容如下： 访问 http://localhost:8080/index/IndexController?filter1=filter1&amp;filter2=filter2&amp;interceptor1=interceptor1&amp;interceptor2=interceptor2，响应页面内容如下： 123456789102018-06-23 10:21:42.533 INFO 13150 --- [nio-8080-exec-4] i.o.s.sample.filter.FirstIndexFilter : FirstIndexFilter pre filter the request2018-06-23 10:21:42.533 INFO 13150 --- [nio-8080-exec-4] i.o.s.sample.filter.SecondIndexFilter : SecondIndexFilter pre filter the request2018-06-23 10:21:42.534 INFO 13150 --- [nio-8080-exec-4] i.o.s.s.i.FirstIndexInterceptor : FirstIndexInterceptor pre intercepted the request2018-06-23 10:21:42.534 INFO 13150 --- [nio-8080-exec-4] i.o.s.s.i.SecondIndexInterceptor : SecondIndexInterceptor pre intercepted the request2018-06-23 10:21:42.535 INFO 13150 --- [nio-8080-exec-4] i.o.s.s.i.SecondIndexInterceptor : SecondIndexInterceptor post intercepted the response2018-06-23 10:21:42.535 INFO 13150 --- [nio-8080-exec-4] i.o.s.s.i.FirstIndexInterceptor : FirstIndexInterceptor post intercepted the response2018-06-23 10:21:42.535 INFO 13150 --- [nio-8080-exec-4] i.o.s.s.i.SecondIndexInterceptor : SecondIndexInterceptor do something after request completed2018-06-23 10:21:42.535 INFO 13150 --- [nio-8080-exec-4] i.o.s.s.i.FirstIndexInterceptor : FirstIndexInterceptor do something after request completed2018-06-23 10:21:42.535 INFO 13150 --- [nio-8080-exec-4] i.o.s.sample.filter.SecondIndexFilter : SecondIndexFilter post filter the response2018-06-23 10:21:42.535 INFO 13150 --- [nio-8080-exec-4] i.o.s.sample.filter.FirstIndexFilter : FirstIndexFilter post filter the response 结论： 自定义的 过滤器 和 拦截器 对 控制器 Controller 生效。而 过滤器 的优先级高于 拦截器。 小结本文详细介绍了 Listener，Servlet，Filter，Controller 和 Interceptor 等 Web 多种组件的功能、方法、顺序、作用域和生命周期。给出了详细的示例代码，结合 源码 分析了流程，结合 测试 验证了结论。长篇大论，希望大家对 Servlet 组件和 Spring MVC 的框架组件有了更清晰的认识。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"实战Spring Boot 2.0系列","slug":"实战Spring-Boot-2-0系列","permalink":"https://ostenant.coding.me/categories/实战Spring-Boot-2-0系列/"}],"tags":[{"name":"Spring Boot 2.0","slug":"Spring-Boot-2-0","permalink":"https://ostenant.coding.me/tags/Spring-Boot-2-0/"},{"name":"Listener","slug":"Listener","permalink":"https://ostenant.coding.me/tags/Listener/"},{"name":"Servlet","slug":"Servlet","permalink":"https://ostenant.coding.me/tags/Servlet/"},{"name":"Filter","slug":"Filter","permalink":"https://ostenant.coding.me/tags/Filter/"},{"name":"Interceptor","slug":"Interceptor","permalink":"https://ostenant.coding.me/tags/Interceptor/"}]},{"title":"实战Spring Boot 2.0系列(四) - 使用WebAsyncTask处理异步任务","slug":"实战Spring Boot 2.0系列(四) - 使用WebAsyncTask处理异步任务","date":"2018-06-18T00:20:00.000Z","updated":"2018-06-18T14:08:49.695Z","comments":true,"path":"2018/06/18/实战Spring Boot 2.0系列(四) - 使用WebAsyncTask处理异步任务/","link":"","permalink":"https://ostenant.coding.me/2018/06/18/实战Spring Boot 2.0系列(四) - 使用WebAsyncTask处理异步任务/","excerpt":"前言上文介绍了基于 @Async 注解的 异步调用编程，本文将继续引入 Spring Boot 的 WebAsyncTask 进行更灵活异步任务处理，包括 异步回调，超时处理 和 异常处理。","text":"前言上文介绍了基于 @Async 注解的 异步调用编程，本文将继续引入 Spring Boot 的 WebAsyncTask 进行更灵活异步任务处理，包括 异步回调，超时处理 和 异常处理。 正文1. 处理线程和异步线程在开始下面的讲解之前，在这里先区别下两个概念： 处理线程：处理线程 属于 web 服务器线程，负责 处理用户请求，采用 线程池 管理。 异步线程：异步线程 属于 用户自定义的线程，可采用 线程池管理。 Spring 提供了对 异步任务 API，采用 WebAsyncTask 类即可实现 异步任务。对异步任务设置相应的 回调处理，如当 任务超时、异常抛出 等。异步任务通常非常实用，比如：当一笔订单支付完成之后，开启异步任务查询订单的支付结果。 2. 环境准备配置gradle依赖利用 Spring Initializer 创建一个 gradle 项目 spring-boot-web-async-task，创建时添加相关依赖。得到的初始 build.gradle 如下： 1234567891011121314151617181920212223242526272829buildscript &#123; ext &#123; springBootVersion = '2.0.3.RELEASE' &#125; repositories &#123; mavenCentral() &#125; dependencies &#123; classpath(\"org.springframework.boot:spring-boot-gradle-plugin:$&#123;springBootVersion&#125;\") &#125;&#125;apply plugin: 'java'apply plugin: 'eclipse'apply plugin: 'org.springframework.boot'apply plugin: 'io.spring.dependency-management'group = 'io.ostenant.springboot.sample'version = '0.0.1-SNAPSHOT'sourceCompatibility = 1.8repositories &#123; mavenCentral()&#125;dependencies &#123; compile('org.springframework.boot:spring-boot-starter-web') testCompile('org.springframework.boot:spring-boot-starter-test')&#125; 配置服务类配置一个用于异步任务调度的 Mock 服务。 123456@Servicepublic class WebAsyncService &#123; public String generateUUID() &#123; return UUID.randomUUID().toString(); &#125;&#125; 配置异步处理控制器并注入以上服务 Bean。 1234567891011@RestControllerpublic class WebAsyncController &#123; private final WebAsyncService asyncService; private final static String ERROR_MESSAGE = \"Task error\"; private final static String TIME_MESSAGE = \"Task timeout\"; @Autowired public WebAsyncController(WebAsyncService asyncService) &#123; this.asyncService = asyncService; &#125;&#125; 3. 正常异步任务配置一个正常的 WebAsyncTask 任务对象，设置任务 超时时间 为 10s。异步任务执行采用 Thread.sleep(long) 模拟，这里设置 异步线程 睡眠时间为 5s。 123456789101112131415161718@GetMapping(\"/completion\")public WebAsyncTask&lt;String&gt; asyncTaskCompletion() &#123; // 打印处理线程名 out.println(format(\"请求处理线程：%s\", currentThread().getName())); // 模拟开启一个异步任务，超时时间为10s WebAsyncTask&lt;String&gt; asyncTask = new WebAsyncTask&lt;&gt;(10 * 1000L, () -&gt; &#123; out.println(format(\"异步工作线程：%s\", currentThread().getName())); // 任务处理时间5s，不超时 sleep(5 * 1000L); return asyncService.generateUUID(); &#125;); // 任务执行完成时调用该方法 asyncTask.onCompletion(() -&gt; out.println(\"任务执行完成\")); out.println(\"继续处理其他事情\"); return asyncTask;&#125; 启动 Spring Boot 项目，访问 http://localhost:8080/completion ，发起 正常 的异步任务请求。 观察控制台输出，可以验证 WebAsyncTask 的异步处理流程正常。 1234请求处理线程：http-nio-8080-exec-2继续处理其他事情异步工作线程：MvcAsync1任务执行完成 Web 页面正常响应，页面响应消息如下： 注意：WebAsyncTask.onCompletion(Runnable) ：在当前任务执行结束以后，无论是执行成功还是异常中止，onCompletion的回调最终都会被调用。 4. 抛出异常异步任务配置一个 错误 的 WebAsyncTask 任务对象，设置任务 超时时间 为 10s。在异步任务执行方法中 抛出异常。 1234567891011121314151617181920212223@GetMapping(\"/exception\")public WebAsyncTask&lt;String&gt; asyncTaskException() &#123; // 打印处理线程名 out.println(format(\"请求处理线程：%s\", currentThread().getName())); // 模拟开启一个异步任务，超时时间为10s WebAsyncTask&lt;String&gt; asyncTask = new WebAsyncTask&lt;&gt;(10 * 1000L, () -&gt; &#123; out.println(format(\"异步工作线程：%s\", currentThread().getName())); // 任务处理时间5s，不超时 sleep(5 * 1000L); throw new Exception(ERROR_MESSAGE); &#125;); // 任务执行完成时调用该方法 asyncTask.onCompletion(() -&gt; out.println(\"任务执行完成\")); asyncTask.onError(() -&gt; &#123; out.println(\"任务执行异常\"); return ERROR_MESSAGE; &#125;); out.println(\"继续处理其他事情\"); return asyncTask;&#125; 启动 Spring Boot 项目，访问 http://localhost:8080/exception ，发起 异常 的异步任务请求。 Web 页面响应异常信息如下： 观察控制台输出，可以验证 WebAsyncTask 对于 异常请求 的异步处理过程。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546请求处理线程：http-nio-8080-exec-1继续处理其他事情异步工作线程：MvcAsync22018-06-18 21:12:10.110 ERROR 89875 --- [nio-8080-exec-2] o.a.c.c.C.[.[.[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] threw exceptionjava.lang.Exception: Task error at io.ostenant.springboot.sample.controller.WebAsyncController.lambda$asyncTaskException$2(WebAsyncController.java:55) ~[classes/:na] at org.springframework.web.context.request.async.WebAsyncManager.lambda$startCallableProcessing$4(WebAsyncManager.java:317) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_172] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_172] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_172]2018-06-18 21:12:10.111 ERROR 89875 --- [nio-8080-exec-2] o.a.c.c.C.[.[.[/].[dispatcherServlet] : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.Exception: Task error] with root causejava.lang.Exception: Task error at io.ostenant.springboot.sample.controller.WebAsyncController.lambda$asyncTaskException$2(WebAsyncController.java:55) ~[classes/:na] at org.springframework.web.context.request.async.WebAsyncManager.lambda$startCallableProcessing$4(WebAsyncManager.java:317) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_172] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_172] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_172]任务执行异常2018-06-18 21:12:10.144 WARN 89875 --- [nio-8080-exec-2] o.apache.catalina.core.AsyncContextImpl : onError() failed for listener of type [org.apache.catalina.core.AsyncListenerWrapper]java.lang.IllegalArgumentException: Cannot dispatch without an AsyncContext at org.springframework.util.Assert.notNull(Assert.java:193) ~[spring-core-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.context.request.async.StandardServletAsyncWebRequest.dispatch(StandardServletAsyncWebRequest.java:131) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.context.request.async.WebAsyncManager.setConcurrentResultAndDispatch(WebAsyncManager.java:353) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.context.request.async.WebAsyncManager.lambda$startCallableProcessing$2(WebAsyncManager.java:304) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.springframework.web.context.request.async.StandardServletAsyncWebRequest.lambda$onError$0(StandardServletAsyncWebRequest.java:146) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at java.util.ArrayList.forEach(ArrayList.java:1257) ~[na:1.8.0_172] at org.springframework.web.context.request.async.StandardServletAsyncWebRequest.onError(StandardServletAsyncWebRequest.java:146) ~[spring-web-5.0.7.RELEASE.jar:5.0.7.RELEASE] at org.apache.catalina.core.AsyncListenerWrapper.fireOnError(AsyncListenerWrapper.java:49) ~[tomcat-embed-core-8.5.31.jar:8.5.31] at org.apache.catalina.core.AsyncContextImpl.setErrorState(AsyncContextImpl.java:397) ~[tomcat-embed-core-8.5.31.jar:8.5.31] at org.apache.catalina.connector.CoyoteAdapter.asyncDispatch(CoyoteAdapter.java:239) [tomcat-embed-core-8.5.31.jar:8.5.31] at org.apache.coyote.AbstractProcessor.dispatch(AbstractProcessor.java:232) [tomcat-embed-core-8.5.31.jar:8.5.31] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:53) [tomcat-embed-core-8.5.31.jar:8.5.31] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:790) [tomcat-embed-core-8.5.31.jar:8.5.31] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1468) [tomcat-embed-core-8.5.31.jar:8.5.31] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.31.jar:8.5.31] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [na:1.8.0_172] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [na:1.8.0_172] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.31.jar:8.5.31] at java.lang.Thread.run(Thread.java:748) [na:1.8.0_172]任务执行完成 注意：WebAsyncTask.onError(Callable&lt;?&gt;) ：当异步任务抛出异常的时候，onError()方法即会被调用。 5. 超时异步任务配置一个正常的 WebAsyncTask 任务对象，设置任务 超时时间 为 10s。异步任务执行采用 Thread.sleep(long) 模拟，这里设置 异步线程 睡眠时间为 15s，引发异步任务超时。 1234567891011121314151617181920212223@GetMapping(\"/timeout\")public WebAsyncTask&lt;String&gt; asyncTaskTimeout() &#123; // 打印处理线程名 out.println(format(\"请求处理线程：%s\", currentThread().getName())); // 模拟开启一个异步任务，超时时间为10s WebAsyncTask&lt;String&gt; asyncTask = new WebAsyncTask&lt;&gt;(10 * 1000L, () -&gt; &#123; out.println(format(\"异步工作线程：%s\", currentThread().getName())); // 任务处理时间5s，不超时 sleep(15 * 1000L); return TIME_MESSAGE; &#125;); // 任务执行完成时调用该方法 asyncTask.onCompletion(() -&gt; out.println(\"任务执行完成\")); asyncTask.onTimeout(() -&gt; &#123; out.println(\"任务执行超时\"); return TIME_MESSAGE; &#125;); out.println(\"继续处理其他事情\"); return asyncTask;&#125; 启动 Spring Boot 项目，访问 http://localhost:8080/timeout ，发起 超时 的异步任务请求。 观察控制台输出，可以验证 WebAsyncTask 的异步超时处理的过程。 12345请求处理线程：http-nio-8080-exec-1继续处理其他事情异步工作线程：MvcAsync3任务执行超时任务执行完成 Web 页面常响应超时提示信息，页面响应消息如下： 注意：WebAsyncTask.onTimeout(Callable&lt;?&gt;) ：当异步任务发生超时的时候，onTimeout()方法即会被调用。 6. 线程池异步任务上面的三种情况中的 异步任务 默认不是采用 线程池机制 进行管理的。 也就是说，一个请求进来，虽然释放了处理线程，但是系统依旧会为每个请求创建一个 异步任务线程，也就是上面看到的 MvcAsync 开头的 异步任务线程。 后果就是开销严重，所以通常采用 线程池 进行统一的管理，直接在 WebAsyncTask 类构造器传入一个 ThreadPoolTaskExecutor 对象实例即可。 构造一个线程池 Bean 对象： 123456789101112@Configurationpublic class TaskConfiguration &#123; @Bean(\"taskExecutor\") public ThreadPoolTaskExecutor taskExecutor() &#123; ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor(); taskExecutor.setCorePoolSize(5); taskExecutor.setMaxPoolSize(10); taskExecutor.setQueueCapacity(10); taskExecutor.setThreadNamePrefix(\"asyncTask\"); return taskExecutor; &#125;&#125; 在控制器中注入 ThreadPoolTaskExecutor 对象，重新配置基于 线程池 的 异步任务处理。 123456789101112@Autowired@Qualifier(\"taskExecutor\")private ThreadPoolTaskExecutor executor;@GetMapping(\"/threadPool\")public WebAsyncTask&lt;String&gt; asyncTaskThreadPool() &#123; return new WebAsyncTask&lt;&gt;(10 * 1000L, executor, () -&gt; &#123; out.println(format(\"异步工作线程：%s\", currentThread().getName())); return asyncService.generateUUID(); &#125;);&#125; 并发地请求 http://localhost:8080/threadPool ，观察控制台输出的 异步线程 信息，可以发现 异步任务 直接从 线程池 中获取 异步线程。 12345678910异步工作线程：asyncTask1异步工作线程：asyncTask2异步工作线程：asyncTask3异步工作线程：asyncTask4异步工作线程：asyncTask5异步工作线程：asyncTask1异步工作线程：asyncTask2异步工作线程：asyncTask3异步工作线程：asyncTask4异步工作线程：asyncTask5 小结本文介绍了 Spring Boot 提供的 WebAsyncTask 的异步编程 API。相比上问介绍的 @Async 注解，WebAsyncTask 提供更加健全的 超时处理 和 异常处理 支持。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"实战Spring Boot 2.0系列","slug":"实战Spring-Boot-2-0系列","permalink":"https://ostenant.coding.me/categories/实战Spring-Boot-2-0系列/"}],"tags":[{"name":"异步","slug":"异步","permalink":"https://ostenant.coding.me/tags/异步/"},{"name":"Spring Boot 2.0","slug":"Spring-Boot-2-0","permalink":"https://ostenant.coding.me/tags/Spring-Boot-2-0/"}]},{"title":"实战Spring Boot 2.0系列(三) - 使用@Async进行异步调用详解","slug":"实战Spring Boot 2.0系列(三) - 使用@Async进行异步调用详解","date":"2018-06-17T01:40:00.000Z","updated":"2018-06-18T01:57:16.309Z","comments":true,"path":"2018/06/17/实战Spring Boot 2.0系列(三) - 使用@Async进行异步调用详解/","link":"","permalink":"https://ostenant.coding.me/2018/06/17/实战Spring Boot 2.0系列(三) - 使用@Async进行异步调用详解/","excerpt":"前言异步调用 对应的是 同步调用，同步调用 指程序按照 定义顺序 依次执行，每一行程序都必须等待上一行程序执行完成之后才能执行；异步调用 指程序在顺序执行时，不等待 异步调用的语句 返回结果 就执行后面的程序。","text":"前言异步调用 对应的是 同步调用，同步调用 指程序按照 定义顺序 依次执行，每一行程序都必须等待上一行程序执行完成之后才能执行；异步调用 指程序在顺序执行时，不等待 异步调用的语句 返回结果 就执行后面的程序。 正文1. 环境准备利用 Spring Initializer 创建一个 gradle 项目 spring-boot-async-task，创建时添加相关依赖。得到的初始 build.gradle 如下： 123456789101112131415161718192021222324252627282930buildscript &#123; ext &#123; springBootVersion = '2.0.3.RELEASE' &#125; repositories &#123; mavenCentral() &#125; dependencies &#123; classpath(\"org.springframework.boot:spring-boot-gradle-plugin:$&#123;springBootVersion&#125;\") &#125;&#125;apply plugin: 'java'apply plugin: 'eclipse'apply plugin: 'org.springframework.boot'apply plugin: 'io.spring.dependency-management'group = 'io.ostenant.springboot.sample'version = '0.0.1-SNAPSHOT'sourceCompatibility = 1.8repositories &#123; mavenCentral()&#125;dependencies &#123; compile('org.springframework.boot:spring-boot-starter-web') compileOnly('org.projectlombok:lombok') testCompile('org.springframework.boot:spring-boot-starter-test')&#125; 在 Spring Boot 入口类上配置 @EnableAsync 注解开启异步处理。 1234567@SpringBootApplication@EnableAsyncpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 创建任务抽象类 AbstractTask，并分别配置三个任务方法 doTaskOne()，doTaskTwo()，doTaskThree()。 123456789101112131415161718192021222324252627public abstract class AbstractTask &#123; private static Random random = new Random(); public void doTaskOne() throws Exception &#123; out.println(\"开始做任务一\"); long start = currentTimeMillis(); sleep(random.nextInt(10000)); long end = currentTimeMillis(); out.println(\"完成任务一，耗时：\" + (end - start) + \"毫秒\"); &#125; public void doTaskTwo() throws Exception &#123; out.println(\"开始做任务二\"); long start = currentTimeMillis(); sleep(random.nextInt(10000)); long end = currentTimeMillis(); out.println(\"完成任务二，耗时：\" + (end - start) + \"毫秒\"); &#125; public void doTaskThree() throws Exception &#123; out.println(\"开始做任务三\"); long start = currentTimeMillis(); sleep(random.nextInt(10000)); long end = currentTimeMillis(); out.println(\"完成任务三，耗时：\" + (end - start) + \"毫秒\"); &#125;&#125; 2. 同步调用下面通过一个简单示例来直观的理解什么是同步调用： 定义 Task 类，继承 AbstractTask，三个处理函数分别模拟三个执行任务的操作，操作消耗时间随机取（10 秒内）。 123@Componentpublic class Task extends AbstractTask &#123;&#125; 在 单元测试 用例中，注入 Task 对象，并在测试用例中执行 doTaskOne()，doTaskTwo()，doTaskThree() 三个方法。 12345678910111213@RunWith(SpringRunner.class)@SpringBootTestpublic class TaskTest &#123; @Autowired private Task task; @Test public void testSyncTasks() throws Exception &#123; task.doTaskOne(); task.doTaskTwo(); task.doTaskThree(); &#125;&#125; 执行单元测试，可以看到类似如下输出： 123456开始做任务一完成任务一，耗时：4059毫秒开始做任务二完成任务二，耗时：6316毫秒开始做任务三完成任务三，耗时：1973毫秒 任务一、任务二、任务三顺序的执行完了，换言之 doTaskOne()，doTaskTwo()，doTaskThree() 三个方法顺序的执行完成。 3. 异步调用上述的 同步调用 虽然顺利的执行完了三个任务，但是可以看到 执行时间比较长，若这三个任务本身之间 不存在依赖关系，可以 并发执行 的话，同步调用在 执行效率 方面就比较差，可以考虑通过 异步调用 的方式来 并发执行。 创建 AsyncTask类，分别在方法上配置 @Async 注解，将原来的 同步方法 变为 异步方法。 1234567891011121314151617@Componentpublic class AsyncTask extends AbstractTask &#123; @Async public void doTaskOne() throws Exception &#123; super.doTaskOne(); &#125; @Async public void doTaskTwo() throws Exception &#123; super.doTaskTwo(); &#125; @Async public void doTaskThree() throws Exception &#123; super.doTaskThree(); &#125;&#125; 在 单元测试 用例中，注入 AsyncTask 对象，并在测试用例中执行 doTaskOne()，doTaskTwo()，doTaskThree() 三个方法。 12345678910111213@RunWith(SpringRunner.class)@SpringBootTestpublic class AsyncTaskTest &#123; @Autowired private AsyncTask task; @Test public void testAsyncTasks() throws Exception &#123; task.doTaskOne(); task.doTaskTwo(); task.doTaskThree(); &#125;&#125; 执行单元测试，可以看到类似如下输出： 123开始做任务三开始做任务一开始做任务二 如果反复执行单元测试，可能会遇到各种不同的结果，比如： 没有任何任务相关的输出 有部分任务相关的输出 乱序的任务相关的输出 原因是目前 doTaskOne()，doTaskTwo()，doTaskThree() 这三个方法已经 异步执行 了。主程序在 异步调用 之后，主程序并不会理会这三个函数是否执行完成了，由于没有其他需要执行的内容，所以程序就 自动结束 了，导致了 不完整 或是 没有输出任务 相关内容的情况。 注意：@Async所修饰的函数不要定义为static类型，这样异步调用不会生效。 4. 异步回调为了让 doTaskOne()，doTaskTwo()，doTaskThree() 能正常结束，假设我们需要统计一下三个任务 并发执行 共耗时多少，这就需要等到上述三个函数都完成动用之后记录时间，并计算结果。 那么我们如何判断上述三个 异步调用 是否已经执行完成呢？我们需要使用 Future&lt;T&gt; 来返回 异步调用 的 结果。 创建 AsyncCallBackTask 类，\b声明 doTaskOneCallback()，doTaskTwoCallback()，doTaskThreeCallback() 三个方法，对原有的\b三个方法进行包装。 1234567891011121314151617181920@Componentpublic class AsyncCallBackTask extends AbstractTask &#123; @Async public Future&lt;String&gt; doTaskOneCallback() throws Exception &#123; super.doTaskOne(); return new AsyncResult&lt;&gt;(\"任务一完成\"); &#125; @Async public Future&lt;String&gt; doTaskTwoCallback() throws Exception &#123; super.doTaskTwo(); return new AsyncResult&lt;&gt;(\"任务二完成\"); &#125; @Async public Future&lt;String&gt; doTaskThreeCallback() throws Exception &#123; super.doTaskThree(); return new AsyncResult&lt;&gt;(\"任务三完成\"); &#125;&#125; 在 单元测试 用例中，注入 AsyncCallBackTask 对象，并在测试用例中执行 doTaskOneCallback()，doTaskTwoCallback()，doTaskThreeCallback() 三个方法。循环调用 Future 的 isDone() 方法\b等待三个 并发任务 执行完成，记录\b最终执行时间。 12345678910111213141516171819202122@RunWith(SpringRunner.class)@SpringBootTestpublic class AsyncCallBackTaskTest &#123; @Autowired private AsyncCallBackTask task; @Test public void testAsyncCallbackTask() throws Exception &#123; long start = currentTimeMillis(); Future&lt;String&gt; task1 = task.doTaskOneCallback(); Future&lt;String&gt; task2 = task.doTaskTwoCallback(); Future&lt;String&gt; task3 = task.doTaskThreeCallback(); // 三个任务都调用完成，退出循环等待 while (!task1.isDone() || !task2.isDone() || !task3.isDone()) &#123; sleep(1000); &#125; long end = currentTimeMillis(); out.println(\"任务全部完成，总耗时：\" + (end - start) + \"毫秒\"); &#125;&#125; 看看都做了哪些改变： 在测试用例一开始记录开始时间； 在调用三个异步函数的时候，返回Future类型的结果对象； 在调用完三个异步函数之后，开启一个循环，根据返回的Future对象来判断三个异步函数是否都结束了。若都结束，就结束循环；若没有都结束，就等1秒后再判断。 跳出循环之后，根据结束时间 - 开始时间，计算出三个任务并发执行的总耗时。 执行一下上述的单元测试，可以看到如下结果： 1234567开始做任务一开始做任务三开始做任务二完成任务二，耗时：4882毫秒完成任务三，耗时：6484毫秒完成任务一，耗时：8748毫秒任务全部完成，总耗时：9043毫秒 可以看到，通过 异步调用，让任务一、任务二、任务三 并发执行，有效的 减少 了程序的 运行总时间。 5. 定义线程池在上述操作中，创建\b一个 线程池配置类 TaskConfiguration ，\b并配置一个 任务线程池对象 taskExecutor。 1234567891011121314@Configurationpublic class TaskConfiguration &#123; @Bean(\"taskExecutor\") public Executor taskExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(10); executor.setMaxPoolSize(20); executor.setQueueCapacity(200); executor.setKeepAliveSeconds(60); executor.setThreadNamePrefix(\"taskExecutor-\"); executor.setRejectedExecutionHandler(new CallerRunsPolicy()); return executor; &#125;&#125; 上面我们通过使用 ThreadPoolTaskExecutor 创建了一个 线程池，同时设置了以下这些参数： 线程池属性 属性的作用 设置初始值 核心线程数 线程池创建时候初始化的线程数 10 最大线程数 线程池最大的线程数，只有在缓冲队列满了之后，才会申请超过核心线程数的线程 20 缓冲队列 用来缓冲执行任务的队列 200 允许线程的空闲时间 当超过了核心线程之外的线程，在空闲时间到达之后会被销毁 60秒 线程池名的前缀 \b可以用于定位处理任务所在的线程池 taskExecutor- 线程池对拒绝任务的处理策略 这里采用CallerRunsPolicy策略，当线程池没有处理能力的时候，该策略会直接在execute方法的调用线程中运行被拒绝的任务；如果执行程序已关闭，则会丢弃该任务 CallerRunsPolicy 创建 AsyncExecutorTask类，三个任务的配置和 AsyncTask \b一样，不同的是 @Async 注解需要指定前面配置的 线程池的名称 taskExecutor。 1234567891011121314151617181920@Componentpublic class AsyncExecutorTask extends AbstractTask &#123; @Async(\"taskExecutor\") public void doTaskOne() throws Exception &#123; super.doTaskOne(); out.println(\"任务一，当前线程：\" + currentThread().getName()); &#125; @Async(\"taskExecutor\") public void doTaskTwo() throws Exception &#123; super.doTaskTwo(); out.println(\"任务二，当前线程：\" + currentThread().getName()); &#125; @Async(\"taskExecutor\") public void doTaskThree() throws Exception &#123; super.doTaskThree(); out.println(\"任务三，当前线程：\" + currentThread().getName()); &#125;&#125; 在 单元测试 用例中，注入 AsyncExecutorTask 对象，并在测试用例中执行 doTaskOne()，doTaskTwo()，doTaskThree() 三个方法。 123456789101112131415@RunWith(SpringRunner.class)@SpringBootTestpublic class AsyncExecutorTaskTest &#123; @Autowired private AsyncExecutorTask task; @Test public void testAsyncExecutorTask() throws Exception &#123; task.doTaskOne(); task.doTaskTwo(); task.doTaskThree(); sleep(30 * 1000L); &#125;&#125; 执行一下上述的 单元测试，可以看到如下结果： 123456789开始做任务一开始做任务三开始做任务二完成任务二，耗时：3905毫秒任务二，当前线程：taskExecutor-2完成任务一，耗时：6184毫秒任务一，当前线程：taskExecutor-1完成任务三，耗时：9737毫秒任务三，当前线程：taskExecutor-3 执行上面的单元测试，观察到 任务线程池 的 \b线程池名的前缀 被打印，说明 线程池 成功执行 异步任务！ 6. 优雅地关闭线程池 由于在应用关闭的时候异步任务还在执行，导致类似 数据库连接池 这样的对象一并被 销毁了，当 异步任务 中对 数据库 进行操作就会出错。 \b\b解决方案如下，重新设置线程池配置对象，新增线程池\b\b setWaitForTasksToCompleteOnShutdown() 和 setAwaitTerminationSeconds() 配置： 123456789@Bean(\"taskExecutor\")public Executor taskExecutor() &#123; ThreadPoolTaskScheduler executor = new ThreadPoolTaskScheduler(); executor.setPoolSize(20); executor.setThreadNamePrefix(\"taskExecutor-\"); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(60); return executor;&#125; setWaitForTasksToCompleteOnShutdown(true): 该方法用来设置 线程池关闭 的时候 等待 所有任务都完成后，再继续 销毁 其他的 Bean，这样这些 异步任务 的 销毁 就会先于 数据库连接池对象 的销毁。 setAwaitTerminationSeconds(60): 该方法用来设置线程池中 任务的等待时间，如果超过这个\b时间还没有销毁就 强制销毁，以确保应用最后能够被关闭，而不是阻塞住。 小结本文介绍了在 Spring Boot 中如何使用 @Async 注解配置 异步任务、异步回调任务，包括\b结合 任务线程池 的使用，以及如何 正确 并 优雅 地关闭 任务线程池。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"实战Spring Boot 2.0系列","slug":"实战Spring-Boot-2-0系列","permalink":"https://ostenant.coding.me/categories/实战Spring-Boot-2-0系列/"}],"tags":[{"name":"异步","slug":"异步","permalink":"https://ostenant.coding.me/tags/异步/"},{"name":"Spring Boot 2.0","slug":"Spring-Boot-2-0","permalink":"https://ostenant.coding.me/tags/Spring-Boot-2-0/"}]},{"title":"实战Spring Boot 2.0系列(二) - 全局异常处理和测试","slug":"实战Spring Boot 2.0系列(二) - 全局异常处理和测试","date":"2018-06-16T07:35:00.000Z","updated":"2018-06-18T01:57:50.010Z","comments":true,"path":"2018/06/16/实战Spring Boot 2.0系列(二) - 全局异常处理和测试/","link":"","permalink":"https://ostenant.coding.me/2018/06/16/实战Spring Boot 2.0系列(二) - 全局异常处理和测试/","excerpt":"前言在日常 web 开发中发生了异常，往往需要通过一个统一的 异常处理，来保证客户端能够收到友好的提示。本文将会介绍 Spring Boot 中的 全局统一异常处理。","text":"前言在日常 web 开发中发生了异常，往往需要通过一个统一的 异常处理，来保证客户端能够收到友好的提示。本文将会介绍 Spring Boot 中的 全局统一异常处理。 正文1. 创建项目利用 Spring Initializer 创建一个 gradle 项目 spring-boot-global-exception-handle，创建时添加相关依赖。得到的初始 build.gradle 如下： 123456789101112131415161718192021222324252627282930313233buildscript &#123; ext &#123; springBootVersion = '2.0.3.RELEASE' &#125; repositories &#123; mavenCentral() &#125; dependencies &#123; classpath(\"org.springframework.boot:spring-boot-gradle-plugin:$&#123;springBootVersion&#125;\") &#125;&#125;apply plugin: 'java'apply plugin: 'eclipse'apply plugin: 'org.springframework.boot'apply plugin: 'io.spring.dependency-management'group = 'io.ostenant.springboot.sample'version = '0.0.1-SNAPSHOT'sourceCompatibility = 1.8repositories &#123; mavenCentral()&#125;dependencies &#123; compile('org.springframework.boot:spring-boot-starter-web') compile('org.projectlombok:lombok') compile('org.apache.commons:commons-lang3:3.1') compile('com.google.guava:guava:19.0') testCompile('org.springframework.boot:spring-boot-starter-test')&#125; 2. 配置入口类123456@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 3. 配置实体类首先安装 Intellij Idea 的 lombok \b插件，\b这里不做详细的介绍。切记，\b需要在设置中将 Enable annotation processing 勾选上，否则 测试代码 \b在 编译时 会无法\b对 lombok 插件配置的 注解 进行处理。 使用 lombok 工具提供的 注解 配置一个实体类 12345678import lombok.Data;@Datapublic class User implements Serializable &#123; private Long id; private String username; private String accountName;&#125; 4. 配置异常\b响应实体ErrorMessage 实体用于记录具体的 异常信息，并响应 客户端。 123456789101112131415161718import lombok.Getter;import lombok.NoArgsConstructor;import lombok.Setter;import lombok.ToString;@NoArgsConstructor@Setter@Getter@ToStringpublic class ErrorMessage&lt;T&gt; &#123; public static final Integer OK = 0; public static final Integer ERROR = 100; private Integer code; private String message; private String url; private T data;&#125; 5. 配置相关异常类SessionNotFoundException.java 12345678910111213public class SessionNotFoundException extends Exception &#123; @Getter @Setter protected String message; public SessionNotFoundException() &#123; setMessage(\"Session is not found!\"); &#125; public SessionNotFoundException(String message) &#123; this.message = message; &#125;&#125; NullOrEmptyException.java 12345678910111213public class NullOrEmptyException extends Exception &#123; @Getter @Setter protected String message; public NullOrEmptyException() &#123; setMessage(\"Parameter is null or empty!\"); &#125; public NullOrEmptyException(String message) &#123; this.message = message; &#125;&#125; IllegalPropertiesException.java 1234567891011121314public class IllegalPropertiesException extends Exception &#123; @Getter @Setter protected String message; public IllegalPropertiesException() &#123; setMessage(\"Prop is illegal!\"); &#125; public IllegalPropertiesException(String message) &#123; this.message = message; setMessage(String.format(\"Prop: %s is illegal!\", message)); &#125;&#125; 6. 配置全局异常通知从 spring 3.2 开始，新增了 @ControllerAdvice 注解，可以用于定义 @ExceptionHandler，并应用到配置\b了 @RequestMapping 的控制器中。 1234567891011121314151617181920212223242526272829303132333435@ControllerAdvicepublic class GlobalExceptionHandler &#123; @ExceptionHandler(SessionNotFoundException.class) @ResponseBody public ErrorMessage&lt;String&gt; sessionNotFoundExceptionHandler(HttpServletRequest request, SessionNotFoundException exception) throws Exception &#123; return handleErrorInfo(request, exception.getMessage(), exception); &#125; @ExceptionHandler(NullOrEmptyException.class) @ResponseBody public ErrorMessage&lt;String&gt; nullOrEmptyExceptionHandler(HttpServletRequest request, NullOrEmptyException exception) throws Exception &#123; return handleErrorInfo(request, exception.getMessage(), exception); &#125; @ExceptionHandler(IllegalPropertiesException.class) @ResponseBody public ErrorMessage&lt;String&gt; illegalPropExceptionHandler(HttpServletRequest request, IllegalPropertiesException exception) throws Exception &#123; return handleErrorInfo(request, exception.getMessage(), exception); &#125; @ExceptionHandler(Exception.class) @ResponseBody public ErrorMessage&lt;String&gt; exceptionHandler(HttpServletRequest request, Exception exception) throws Exception &#123; return handleErrorInfo(request, exception.getMessage(), exception); &#125; private ErrorMessage&lt;String&gt; handleErrorInfo(HttpServletRequest request, String message, Exception exception) &#123; ErrorMessage&lt;String&gt; errorMessage = new ErrorMessage&lt;&gt;(); errorMessage.setMessage(message); errorMessage.setCode(ErrorMessage.ERROR); errorMessage.setData(message); errorMessage.setUrl(request.getRequestURL().toString()); return errorMessage; &#125;&#125; 上述代码指定了 3 个 特定 的异常处理器和 1 个 默认 的异常处理器。当请求\b处理出现异常时，会根据 异常处理器 的 配置顺序 依次尝试 异常匹配 和 处理。 当异常不在 SessionNotFoundException、NullOrEmptyException、IllegalPropertiesException 中时，\bSpring 会委托 默认 的 exceptionHandler 进行处理。 7. 配置控制器\b根据请求\b数据的差异，控制器能覆盖以上 3 种异常处理路径。 123456789101112131415161718192021222324252627@RestControllerpublic class UserController &#123; @PostMapping(\"user\") public ResponseEntity&lt;?&gt; save(HttpServletRequest request, HttpSession session) throws Exception &#123; String sessionId = (String) session.getAttribute(\"sessionId\"); if (StringUtils.isBlank(sessionId)) &#123; throw new SessionNotFoundException(); &#125; String userPlainText = request.getParameter(\"user\"); if (StringUtils.isBlank(userPlainText) || StringUtils.equalsIgnoreCase(\"&#123;&#125;\", userPlainText)) &#123; throw new NullOrEmptyException(); &#125; ObjectMapper objectMapper = new ObjectMapper(); User user = objectMapper.readValue(userPlainText, User.class); if (StringUtils.isBlank(user.getUsername())) &#123; throw new IllegalPropertiesException(\"username\"); &#125; if (StringUtils.isBlank(user.getAccountName())) &#123; throw new IllegalPropertiesException(\"accountName\"); &#125; return ResponseEntity.ok(\"Successful\"); &#125;&#125; 8. 配置Mock测试类\bSpring Mock 的相关配置这里就不详细介绍了，以下测试类\b覆盖了 UserController 的所有\b执行路径。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120@RunWith(SpringJUnit4ClassRunner.class)@SpringBootApplication@WebAppConfiguration@Slf4j(topic = \"UserControllerTester\")public class ApplicationTests &#123; @Autowired private WebApplicationContext context; private MockMvc mockMvc; private MockHttpSession session; @Autowired private UserController userController; private ImmutableMap&lt;Long, Pair&lt;String, String&gt;&gt; map = new ImmutableMap.Builder&lt;Long, Pair&lt;String, String&gt;&gt;() .put(0x00001L, Pair.of(\"user\", \"\")) .put(0x00002L, Pair.of(\"user\", \"&#123;&#125;\")) .put(0x00003L, Pair.of(\"user\", \"&#123;\\\"username\\\": \\\"\\\", \\\"accountName\\\": \\\"\\\"&#125;\")) .put(0x00004L, Pair.of(\"user\", \"&#123;\\\"username\\\": \\\"Harrison\\\", \\\"accountName\\\": \\\"\\\"&#125;\")) .put(0x00005L, Pair.of(\"user\", \"&#123;\\\"username\\\": \\\"Harrison\\\", \\\"accountName\\\": \\\"ostenant\\\"&#125;\")) .build(); @Before public void setUp() throws Exception &#123; boolean singleRunner = false; if (singleRunner) &#123; this.mockMvc = MockMvcBuilders.standaloneSetup(userController).build(); &#125; else &#123; this.mockMvc = MockMvcBuilders.webAppContextSetup(context).build(); &#125; session = new MockHttpSession(); session.setAttribute(\"sessionId\", StringUtils.replace(UUID.randomUUID().toString(), \"-\", \"\")); log.debug(\"sessionId: &#123;&#125;\", session.getAttribute(\"sessionId\")); &#125; /** * 测试SessionNotFoundException * @throws Exception */ @Test public void testSessionNotFoundException() throws Exception &#123; session.clearAttributes(); // 模拟发送请求 mockMvc.perform( MockMvcRequestBuilders.post(\"/user\") .param(map.get(0x00005L).getKey(), map.get(0x00005L).getValue()) .session(session)) .andExpect(MockMvcResultMatchers.handler().handlerType(UserController.class)) .andExpect(MockMvcResultMatchers.handler().methodName((\"save\"))) .andDo(MockMvcResultHandlers.print()) .andReturn(); &#125; /** * 测试NullOrEmptyException * @throws Exception */ @Test public void testNullOrEmptyException() throws Exception &#123; mockMvc.perform( MockMvcRequestBuilders.post(\"/user\") .param(map.get(0x00001L).getKey(), map.get(0x00001L).getValue()) .session(session)) .andExpect(MockMvcResultMatchers.handler().handlerType(UserController.class)) .andExpect(MockMvcResultMatchers.handler().methodName((\"save\"))) .andDo(MockMvcResultHandlers.print()) .andReturn(); mockMvc.perform( MockMvcRequestBuilders.post(\"/user\") .param(map.get(0x00002L).getKey(), map.get(0x00002L).getValue()) .session(session)) .andExpect(MockMvcResultMatchers.handler().handlerType(UserController.class)) .andExpect(MockMvcResultMatchers.handler().methodName((\"save\"))) .andDo(MockMvcResultHandlers.print()) .andReturn(); &#125; /** * 测试IllegalPropException * @throws Exception */ @Test public void testIllegalPropException() throws Exception &#123; mockMvc.perform( MockMvcRequestBuilders.post(\"/user\") .param(map.get(0x00003L).getKey(), map.get(0x00003L).getValue()) .session(session)) .andExpect(MockMvcResultMatchers.handler().handlerType(UserController.class)) .andExpect(MockMvcResultMatchers.handler().methodName((\"save\"))) .andDo(MockMvcResultHandlers.print()) .andReturn(); mockMvc.perform( MockMvcRequestBuilders.post(\"/user\") .param(map.get(0x00004L).getKey(), map.get(0x00004L).getValue()) .session(session)) .andExpect(MockMvcResultMatchers.handler().handlerType(UserController.class)) .andExpect(MockMvcResultMatchers.handler().methodName((\"save\"))) .andDo(MockMvcResultHandlers.print()) .andReturn(); &#125; /** * 测试正常运行的情况 * @throws Exception */ @Test public void testNormal() throws Exception &#123; mockMvc.perform( MockMvcRequestBuilders.post(\"/user\") .param(map.get(0x00005L).getKey(), map.get(0x00005L).getValue()) .session(session)) .andExpect(MockMvcResultMatchers.handler().handlerType(UserController.class)) .andExpect(MockMvcResultMatchers.handler().methodName((\"save\"))) .andDo(MockMvcResultHandlers.print()) .andReturn(); &#125;&#125; 9. 测试结果\b批量运行测试，测试结果如下，所有的测试用例全部通过。 小结\b使用 @ControllerAdvice 处理异常也有一定的 局限性。只有进入 Controller 层的错误，才会由 @ControllerAdvice 处理。拦截器 抛出的错误，以及 访问错误地址 的情况 @ControllerAdvice 处理不了，由 Spring Boot 默认的 异常处理机制 处理。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"实战Spring Boot 2.0系列","slug":"实战Spring-Boot-2-0系列","permalink":"https://ostenant.coding.me/categories/实战Spring-Boot-2-0系列/"}],"tags":[{"name":"Spring Boot 2.0","slug":"Spring-Boot-2-0","permalink":"https://ostenant.coding.me/tags/Spring-Boot-2-0/"}]},{"title":"实战Spring Boot 2.0系列(一) - 使用Gradle构建Docker镜像","slug":"实战Spring Boot 2.0系列(一) - 使用Gradle构建Docker镜像","date":"2018-06-14T11:35:00.000Z","updated":"2018-06-21T05:42:28.292Z","comments":true,"path":"2018/06/14/实战Spring Boot 2.0系列(一) - 使用Gradle构建Docker镜像/","link":"","permalink":"https://ostenant.coding.me/2018/06/14/实战Spring Boot 2.0系列(一) - 使用Gradle构建Docker镜像/","excerpt":"前言通常我们使用 Dockerfile 来构建项目的 Docker 镜像。但是也有使用 gradle 在编译项目的时候一起把镜像给 构建 并 上传 的需求。本文将会讲解如何使用 gradle 编写并配置 Dockerfile 并生成 镜像。","text":"前言通常我们使用 Dockerfile 来构建项目的 Docker 镜像。但是也有使用 gradle 在编译项目的时候一起把镜像给 构建 并 上传 的需求。本文将会讲解如何使用 gradle 编写并配置 Dockerfile 并生成 镜像。 正文1. 创建项目利用 Spring Initializer 创建一个 gradle 项目 spring-boot-gradle-for-docker，创建时添加一个 web 依赖。得到的初始 build.gradle 如下： 123456789101112131415161718192021222324252627282930buildscript &#123; ext &#123; springBootVersion = '2.0.2.RELEASE' &#125; repositories &#123; mavenCentral() &#125; dependencies &#123; classpath(\"org.springframework.boot:spring-boot-gradle-plugin:$&#123;springBootVersion&#125;\") &#125;&#125;apply plugin: 'java'apply plugin: 'org.springframework.boot'apply plugin: 'io.spring.dependency-management'group = 'io.ostenant.springboot.sample'version = '1.0'sourceCompatibility = 1.8repositories &#123; mavenCentral() jcenter()&#125;dependencies &#123; compile('org.springframework.boot:spring-boot-starter-web') testCompile('org.springframework.boot:spring-boot-starter-test')&#125; 2. 配置入口类为了方便容器部署的测试，在 Spring Boot 启动类上\b配置\b一个控制器，\b响应当前的系统时间。 123456789101112131415@RestController@SpringBootApplicationpublic class Application &#123; private ThreadLocal&lt;SimpleDateFormat&gt; threadLocal = ThreadLocal.withInitial(() -&gt; new SimpleDateFormat(\"yyyy/MM/dd hh:mm:ss\")); public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @GetMapping(\"/\") public String retrieveTime() &#123; return threadLocal.get().format(new Date()); &#125;&#125; 3. 添加插件这里使用 gradle-docker 插件 来实现 docker \b镜像构建。这样，我们就可以直接在 Gradle 的脚本里配置 Dockerfile 达到 构建镜像 功能的目的。 gradle-docker 插件已经被上传到 jCenter 和 MavenCentral\b 上。所以只需要在 dependencies 添加依赖 se.transmode.gradle:gradle-docker:1.2 就能使用 docker 插件。 123456789101112buildscript &#123; ext &#123; springBootVersion = '2.0.2.RELEASE' &#125; repositories &#123; mavenCentral() &#125; dependencies &#123; classpath(\"org.springframework.boot:spring-boot-gradle-plugin:$&#123;springBootVersion&#125;\") classpath(\"se.transmode.gradle:gradle-docker:1.2\") &#125;&#125; 4. 应用插件添加以下代码到 build.gradle中 12apply plugin: 'application'apply plugin: 'docker' 如果添加了 application 插件的话，默认 gradle-docker 插件会添加一个 distDocker 的 gradle task，用来构建一个 包含所有程序文件 的 docker 镜像。 5. 配置镜像构建信息5.1. 配置group1group = 'io.ostenant.springboot.sample' 5.2. 配置镜像名称和版本号1234jar &#123; baseName = \"spring-boot-gradle-for-docker\" version = 1.0&#125; \b其中镜像\b的 tag 默认的构成为：\b项目组/应用名称:版本号 1tag = \"$&#123;project.group&#125;/$&#123;applicationName&#125;:$&#123;tagVersion&#125;\" project.group：标准的 gradle \b属性，如果不进行定义，插件默认会 省略 ${project.group} 这个属性。 applicationName：应用被容器化时的 名称。 tagVersion：可选属性，会作为镜像的 标签。默认值为 project.version，如果未指定 project.version，则使用 latest 作为标记。 5.3. 配置docker构建基础信息1234distDocker &#123; baseImage = \"openjdk\" maintainer = \"harrison\"&#125; 其中，baseImage 相当于 Dockerfile 中声明的 FROM。声明了在 构建镜像 是基于的 Image，maintainer 相当于 MAINTAINER ，声明了 镜像作者。如果声明了 registry 地址，插件在 镜像射生成后 可以自动 push 到该地址。其他的配置还包括 docker hub 的 地址、用户名 和 密码。 更详细的配置案例如下： 123456789docker &#123; baseImage 'openjdk' maintainer 'harrison' useApi true hostUrl 'http://myserver:4243' apiUsername 'user' apiPassword 'password' apiEmail 'me@mycompany.com'&#125; 6. 添加task任务完成了基本的配置，我们还需要添加一个 task 用来在 gradle 编译的时候 执行镜像构建。 插件提供了一些 转换方法，用来指代 Dockerfile 中的 关键词语法，如下表，可以按照需求对照着来： Dockerfile关键词 gradle task方法 ADD addFile(Closure copySpec) addFile(String source, String dest) addFile(File source, String dest) CMD defaultCommand(List cmd) ENTRYPOINT entryPoint(List entryPoint) ENV setEnvironment(String key, String val) EXPOSE exposePort(Integer port) exposePort(String port) RUN runCommand(String cmd) USER switchUser(String userNameOrUid) VOLUME volume(String… paths) WORKDIR workingDir(String dir) 下面是本项目的 taskBuilder 的任务配置 1234567891011121314task dockerBuilder(type: Docker) &#123; applicationName = jar.baseName tagVersion = jar.version volume('/tmp') addFile(\"$&#123;jar.baseName&#125;-$&#123;jar.version&#125;.jar\", \"app.jar\") entryPoint([\"java\", \"-Djava.security.egd=file:/dev/./urandom\", \"-jar\", 'app.jar']) exposePort(8080) doFirst &#123; copy &#123; from jar into stageDir &#125; &#125;&#125; 构建完成y以后，项目根目录的 build/docker 文件夹下面会出现 Dockerfile 和 spring-boot-gradle-for-docker-1.0.jar 文件。其中，以上的 task 等同于以下的 Dockerfile。 12345FROM aglover/java8-pierVOLUME [\"/tmp\"]ADD spring-boot-gradle-for-docker-1.0.jar app.jarENTRYPOINT [\"java\", \"-Djava.security.egd=file:/dev/./urandom\", \"-jar\", \"app.jar\"]EXPOSE 8080 如果觉的在 task 中编写 Dockerfile 替换脚本 非常别扭，也可以直接在 task 中指定 Dockfile 的 文件路径，直接使用已有的文件来生成镜像： 1234567891011task buildDocker(type: Docker) &#123; applicationName = jar.baseName tagVersion = jar.version dockerfile = file('Dockerfile') doFirst &#123; copy &#123; from jar into stageDir &#125; &#125;&#125; 通过 file() 指定 task 使用位于 项目根目录 的 Dockerfile 来生产镜像。 7. 编译并构建Docker镜像进入项目根目录，运行 gradle 命令进行打包构建。 1$ ./gradlew clean build dockerBuilder --info gradle 首先会运行 本地测试，\b\b然后进行 项目打包，进一步根据 docker-gradle 插件进行 镜像构建。 等待出现 BUILD SUCCESSFUL 就表明任务运行成功。可以观察到镜像的名称为 1io.ostenant.springboot.sample/spring-boot-gradle-for-docker:1.0 运行 docker images 查看本地镜像，进一步验证镜像构建成功。 下面给出 build.gradle 完整的 配置文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960buildscript &#123; ext &#123; springBootVersion = '2.0.2.RELEASE' &#125; repositories &#123; mavenCentral() &#125; dependencies &#123; classpath(\"org.springframework.boot:spring-boot-gradle-plugin:$&#123;springBootVersion&#125;\") classpath(\"se.transmode.gradle:gradle-docker:1.2\") &#125;&#125;apply plugin: 'java'apply plugin: 'org.springframework.boot'apply plugin: 'io.spring.dependency-management'apply plugin: 'application'apply plugin: 'docker'group = 'io.ostenant.springboot.sample'version = '1.0'sourceCompatibility = 1.8targetCompatibility = 1.8mainClassName = \"io.ostenant.springboot.sample.Application\"repositories &#123; mavenCentral() jcenter()&#125;dependencies &#123; compile('org.springframework.boot:spring-boot-starter-web') testCompile('org.springframework.boot:spring-boot-starter-test')&#125;jar &#123; baseName 'spring-boot-gradle-for-docker' version '1.0'&#125;distDocker &#123; baseImage 'openjdk' maintainer 'harrison'&#125;task dockerBuilder(type: Docker) &#123; applicationName = jar.baseName tagVersion = jar.version volume('/tmp') addFile(\"$&#123;jar.baseName&#125;-$&#123;jar.version&#125;.jar\", \"app.jar\") entryPoint([\"java\", \"-Djava.security.egd=file:/dev/./urandom\", \"-jar\", 'app.jar']) exposePort(8080) doFirst &#123; copy &#123; from jar into stageDir &#125; &#125;&#125; 8. 使用镜像启动容器运行如下命令，根据镜像启动容器，对外暴露 8080 \b访问端口。 1$ docker run -d --name gradle-boot -p 8080:8080 io.ostenant.springboot.sample/spring-boot-gradle-for-docker:1.0 访问 http://127.0.0.1:8080/ ，页面会输出当前系统时间，如图所示： 小结gradle-docker 插件还提供了配置 镜像仓库地址、配置使用 Docker Remote Api 和 Docker Hub 等用法，可以参考该项目的 GitHub 地址来进行配置使用：https://github.com/Transmode/gradle-docker。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"实战Spring Boot 2.0系列","slug":"实战Spring-Boot-2-0系列","permalink":"https://ostenant.coding.me/categories/实战Spring-Boot-2-0系列/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://ostenant.coding.me/tags/Docker/"},{"name":"Spring Boot 2.0","slug":"Spring-Boot-2-0","permalink":"https://ostenant.coding.me/tags/Spring-Boot-2-0/"},{"name":"Gradle","slug":"Gradle","permalink":"https://ostenant.coding.me/tags/Gradle/"}]},{"title":"微服务的反模式和陷阱(三) - 共享反模式","slug":"微服务的反模式和陷阱(三) - 共享反模式","date":"2018-06-12T11:40:00.000Z","updated":"2018-06-18T01:58:34.833Z","comments":true,"path":"2018/06/12/微服务的反模式和陷阱(三) - 共享反模式/","link":"","permalink":"https://ostenant.coding.me/2018/06/12/微服务的反模式和陷阱(三) - 共享反模式/","excerpt":"前言微服务是一种 无共享的架构，另一层意思是 “尽量不共享” 模式(share-as-little-as-possible)， 因为总有一些 代码 会在微服务之间共享。然后如果太过频繁的使用 共享代码 最终会出现 依赖噩梦\b，这就是共享反模式。","text":"前言微服务是一种 无共享的架构，另一层意思是 “尽量不共享” 模式(share-as-little-as-possible)， 因为总有一些 代码 会在微服务之间共享。然后如果太过频繁的使用 共享代码 最终会出现 依赖噩梦\b，这就是共享反模式。 正文共享反模式微服务是一种 无共享的架构，另一层意思是 “尽量不共享” 模式(share-as-little-as-possible)， 因为总有一些 代码 会在微服务之间共享。比如 不提供一个身份验证的微服务，而是将身份验证的代码打包成一个 jar 文件：security.jar，保证其它服务都能使用。如果安全检查是 服务级别 的功能，每个服务接收到请求都会检查安全性，这种方式可以很好的提高性能。 然后如果太过频繁的使用最终会出现 依赖噩梦，如图 1-1 所示，其中每个服务都依赖于 多个自定义共享库。 这种共享级别不仅破坏了每个 服务的限界上下文，而且还引入了几个问题，包括整体 可靠性、变更控制、可测试性 和 部署能力。 1. 过多依赖在面向对象的软件开发过程中，经常会遇到 共享 的问题，特别是从 单一分层 结构迁移到 微服务结构 时，图 1-2 展示 抽象类和共享，它们最终在多数单块分层体系结构中共享。 微服务架构 的主要目标就是共享要尽可能的少，这有助于维护服务的 限界上下文，使我们能够快速的 测试 和 布署。服务之间 依赖越强，服务隔离 也就 越困难，因此也就越难单独进行 测试 和 布署。 创建 抽象类 和 接口 是 面向对象编程 的最重要做法，那我们如何来处理数百个服务共享的代码？ 2. 共享代码的技术要避免这个 反模式 的最好办法就是 代码不共享，但是实际工作中总会有一些代码需要进行共享，那这些共享代码应该放到哪里呢？ 图 1-3 给了四个最基本的技术： 共享项目 共享库 复制 服务合并 相关链接 微服务的反模式和陷阱(一) - 数据驱动的迁移反模式 微服务的反模式和陷阱(二) - 超时反模式 微服务的反模式和陷阱(三) - 共享反模式 微服务的反模式和陷阱(四) - 到达报告反模式 微服务的反模式和陷阱(五) - 沙粒陷阱 微服务的反模式和陷阱(六) - 无因的开发者陷阱 微服务的反模式和陷阱(七) - 随大流陷阱 微服务的反模式和陷阱(八) - 其它架构模式 微服务的反模式和陷阱(九) - 静态契约陷阱 微服务的反模式和陷阱(十) - 通信协议使用的陷阱 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"微服务系列","slug":"微服务系列","permalink":"https://ostenant.coding.me/categories/微服务系列/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://ostenant.coding.me/tags/微服务/"},{"name":"反模式","slug":"反模式","permalink":"https://ostenant.coding.me/tags/反模式/"}]},{"title":"微服务的反模式和陷阱(二) - 超时反模式","slug":"微服务的反模式和陷阱(二) - 超时反模式","date":"2018-06-11T11:40:00.000Z","updated":"2018-07-05T12:46:16.012Z","comments":true,"path":"2018/06/11/微服务的反模式和陷阱(二) - 超时反模式/","link":"","permalink":"https://ostenant.coding.me/2018/06/11/微服务的反模式和陷阱(二) - 超时反模式/","excerpt":"前言分布式应用的挑战之一就是如何管理 远程服务 的 可用性 和它们的 响应。虽然服务可用性和服务响应都涉及到服务的通信，但它们是两个完全不同的东西。服务可用性 是服务消费者 连接服务 并能够 发送请求 的能力，服务响应 则关注服务的 响应时间。\b\b这里就涉及微服务中的 超时反模式。","text":"前言分布式应用的挑战之一就是如何管理 远程服务 的 可用性 和它们的 响应。虽然服务可用性和服务响应都涉及到服务的通信，但它们是两个完全不同的东西。服务可用性 是服务消费者 连接服务 并能够 发送请求 的能力，服务响应 则关注服务的 响应时间。\b\b这里就涉及微服务中的 超时反模式。 正文超时反模式微服务是一种 分布式的架构，它所有的组件（也就是服务）会被部署为单独的应用程序，并通过某种 远程访问协议 进行通讯。分布式应用的挑战之一就是如何管理 远程服务 的 可用性 和它们的 响应。虽然服务可用性和服务响应都涉及到服务的通信，但它们是两个完全不同的东西。服务可用性 是服务消费者 连接服务 并能够 发送请求 的能力，服务响应 则关注服务的 响应时间。 如图 1-1 的所示，如果此时服务消费者 无法连接 到服务提供者的时候，通过会在毫秒级的时间里得到通知和反馈。这时候 服务消费者 可以选择是 直接返回错误信息 还是 进行重试。但是如果服务提供者接收了请求却 不进行响应 该怎么办？在这种情况下服务消费者可以选择 无限期等待 或者 设置超时时间，使用超时时间看起来是个好办法，但是它会导致 超时反模式。 1. 使用超时你可能感觉非常困惑，难道设置一个超时时间不是一件好事吗？在大部分的情况下超时时间的错误设置都会带来问题。比如当你上网购物的时候，你提交了订单，服务一直在处理没有返回，你在超时的时候再提交订单，显然服务器需要更复杂的逻辑来处理重复提交订单的问题。 那么超时时间设置多少合适呢？ 第一种是基于 数据库的超时 来计算服务的超时时间。 第二种是计算 负载下最长的处理时间，把它乘以 2 作为 超时时间。 在图 2-2 中，通常的情况下 平均响应时间 是 2 秒，在 高并发 的情况下 最长时间 是 5 秒，因为可以使用加倍技术服务的超时时间设置为 10 秒。 图 1-2 的解决方案似乎看起来很完美，它使每一个服务消费者必须等待 10 秒，其实只是为了 判断服务没有响应。在大多数情况下，用户在等待提交按钮或放弃和关闭屏幕之前不会等待超过 2 到 3 秒。那就必须要有更好的办法来解决。 2. 使用断路器模式与上面 超时 的方法相比，使用 断路器 的方式更为稳妥。这种设计模式就像家里的电器的保险丝一样，当负载过大，或者电路发生故障或异常时，电流会不断升高，为防止升高的电流有可能损坏电路中的某些重要器件或贵重器件，烧毁电路甚至造成火灾。保险丝会在电流异常升高到一定的高度和热度的时候，自身熔断切断电流，从而起到保护电路安全运行的作用。 图 1-3 说明了 断路器模式 是如何工作的。当服务保持响应时，断路器将关闭，允许通过请求。如果远程服务突然变得不能响应，断路器就会打开，从而阻止请求通过，直到服务再次响应。当然这并不像你家中的保险丝，断路器 本身可以 持续监测服务。 断路器模式 相比 设置超时 的优点是，使用者可以 立即 知道服务已变得不响应，而不必等待超时，使用者将在 毫秒内 服务不响应，而不是等待 10 秒获得相同的信息。 另外断路器可以通过几种方式进行 监控。最简单的方法是 对远程服务 进行简单的 心跳检查，这种方式只是告诉断路器服务是活的，但是要想获取服务存活的详细信息，就需要 定期（比如 10 秒）获取一次服务的详细信息。还有一种方式是 实时用户监控，这种方式可以 动态调整，一旦达到 阈值，断路器可以进入 半开放状态，可以设置 一定数量的请求是通过（说 10 个请求中有 8 个通过）。 相关链接 微服务的反模式和陷阱(一) - 数据驱动的迁移反模式 微服务的反模式和陷阱(二) - 超时反模式 微服务的反模式和陷阱(三) - 共享反模式 微服务的反模式和陷阱(四) - 到达报告反模式 微服务的反模式和陷阱(五) - 沙粒陷阱 微服务的反模式和陷阱(六) - 无因的开发者陷阱 微服务的反模式和陷阱(七) - 随大流陷阱 微服务的反模式和陷阱(八) - 其它架构模式 微服务的反模式和陷阱(九) - 静态契约陷阱 微服务的反模式和陷阱(十) - 通信协议使用的陷阱 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"微服务系列","slug":"微服务系列","permalink":"https://ostenant.coding.me/categories/微服务系列/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://ostenant.coding.me/tags/微服务/"},{"name":"反模式","slug":"反模式","permalink":"https://ostenant.coding.me/tags/反模式/"}]},{"title":"微服务的反模式和陷阱(一) - 数据驱动的迁移反模式","slug":"微服务的反模式和陷阱(一) - 数据驱动的迁移反模式\b","date":"2018-06-10T10:20:00.000Z","updated":"2018-06-18T01:58:16.876Z","comments":true,"path":"2018/06/10/微服务的反模式和陷阱(一) - 数据驱动的迁移反模式\b/","link":"","permalink":"https://ostenant.coding.me/2018/06/10/微服务的反模式和陷阱(一) - 数据驱动的迁移反模式\b/","excerpt":"前言采用 数据驱动迁移反模式 主要发生在当你从一个 单体应用 向 微服务架构 做迁移的时候。之所以称之为反模式主要原因是，刚开始我们觉得创建微服务是一个不错的主意，服务和相应的数据 都独立成 微服务，但这可能会将你带向一个错误的道路上，导致高风险、过剩成本和额外的迁移工作。","text":"前言采用 数据驱动迁移反模式 主要发生在当你从一个 单体应用 向 微服务架构 做迁移的时候。之所以称之为反模式主要原因是，刚开始我们觉得创建微服务是一个不错的主意，服务和相应的数据 都独立成 微服务，但这可能会将你带向一个错误的道路上，导致高风险、过剩成本和额外的迁移工作。 正文数据驱动的迁移反模式微服务会创建 大量小的、分布式的、单一用途 的服务，每个服务拥有自己的数据。这种 服务和数据耦合 支持一个 有界的上下文 和 一个无共享数据 的架构。其中，每个服务及其对应的数据是独立一块，完全独立于所有其他服务。服务只暴露了一个明确的接口（服务契约）。有界的上下文可以允许开发者以最小的依赖快速轻松地开发，测试和部署。 采用 数据驱动迁移反模式 主要发生在当你从一个 单体应用 向 微服务架构 做迁移的时候。我们之所以称之为反模式主要原因是，刚开始我们觉得创建微服务是一个不错的主意，服务和相应的数据 都独立成 微服务，但这可能会将你带向一个错误的道路上，导致高风险、过剩成本和额外的迁移工作。 单体应用迁移到微服务架构有两个主要目标： 第一个目标是单体应用程序的 功能 分割成 小的，单一用途 的服务。 第二个目标是单体应用的 数据 迁移到每个服务自己 独占的小数据库（或独立的服务）。 下图展示了一个典型的迁移，看起来像服务代码和相应的数据同时进行迁移。 上图中有三个服务是从单体应用中划分而来，并且还划分独立的三个数据库，这是一个自然演变的过程，因为在每个 服务 和 数据库 之间都使用了最为关键的 限界上下文，然而我们遇到的问题也正是基于这一过程将带领我们进入 数据迁移的反模式。 1. 太多的数据迁移这种迁移路径的主要问题是，我们很难在一次就能够划分清楚每个服务的粒度。从一个 更粗粒度 的服务开始着手，一步步的进行 细化工作，并且要多了解相关业务知识，不断的 对服务的粒度进行调整。 我们来看图 1-1 发现最左边的 服务粒度太粗，需要再 拆分 成二个小的服务，或者你发现左边的二个 服务粒度划分的太细，需要进行 合并。而 数据迁移 要比 源代码迁移 更复杂，更容易出错，我们最好只为数据进行一次迁移工作，因为数据迁移是一个 高风险 的工作。 我们的微服务划分也就是应用代码的迁移和数据的迁移。如图 1-2 所示。 2. 功能分割优先，数据迁移最后此模式主要采用的是一种避免的手段，以 迁移服务的功能 为第一，同时也需要注意服务和数据之间的 限界上下文。我们可以通过 合并 与 拆分 的手段对服务进行调整直到满意为止，这时候就可以进行 数据迁移。 如图 1-3 所示，左边所有三个服务都已经进行了 迁移 和 拆分，但是所有服务仍然使用的是 同一个数据库。如果这是一个临时中间方案还可以作为一个选择，这时候我们就需要更多的了解服务如何使用，以及接受什么类型的请求数据等。 在图 1-3 中，我们要注意最左边的服务是如何发现 粒度太粗 而 拆分 成两个服务的。服务粒度最终确定完成之后，下一步就开始 迁移数据 了，采用这种方式可以避免重复的数据迁移。 相关链接 微服务的反模式和陷阱(一) - 数据驱动的迁移反模式 微服务的反模式和陷阱(二) - 超时反模式 微服务的反模式和陷阱(三) - 共享反模式 微服务的反模式和陷阱(四) - 到达报告反模式 微服务的反模式和陷阱(五) - 沙粒陷阱 微服务的反模式和陷阱(六) - 无因的开发者陷阱 微服务的反模式和陷阱(七) - 随大流陷阱 微服务的反模式和陷阱(八) - 其它架构模式 微服务的反模式和陷阱(九) - 静态契约陷阱 微服务的反模式和陷阱(十) - 通信协议使用的陷阱 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"微服务系列","slug":"微服务系列","permalink":"https://ostenant.coding.me/categories/微服务系列/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://ostenant.coding.me/tags/微服务/"},{"name":"反模式","slug":"反模式","permalink":"https://ostenant.coding.me/tags/反模式/"}]},{"title":"Docker Compose搭建MySQL主从复制集群","slug":"Docker Compose搭建MySQL主从集群","date":"2018-06-10T02:33:00.000Z","updated":"2018-06-18T01:46:07.184Z","comments":true,"path":"2018/06/10/Docker Compose搭建MySQL主从集群/","link":"","permalink":"https://ostenant.coding.me/2018/06/10/Docker Compose搭建MySQL主从集群/","excerpt":"前言随着应用业务数据不断的增大，应用的 响应速度不断下降，在检测过程中我们不难发现大多数的请求都是 查询操作。此时，我们可以将数据库扩展成 主从复制模式，将 读操作 和 写操作 分离开来，多台数据库 分摊请求，从而 减少单库 的 访问压力，进而应用得到优化。","text":"前言随着应用业务数据不断的增大，应用的 响应速度不断下降，在检测过程中我们不难发现大多数的请求都是 查询操作。此时，我们可以将数据库扩展成 主从复制模式，将 读操作 和 写操作 分离开来，多台数据库 分摊请求，从而 减少单库 的 访问压力，进而应用得到优化。 正文主从复制的方式MySQL 5.6 开始主从复制有两种方式：基于日志（binlog）和 基于 GTID（全局事务标示符）。 本文只涉及基于日志 binlog 的 主从配置。 主从复制的流程 MySQL 同步操作通过 3 个线程实现，其基本步骤如下： 主服务器 将数据的更新记录到 二进制日志（Binary log）中，用于记录二进制日志事件，这一步由 主库线程 完成； 从库\b 将 主库 的 二进制日志 复制到本地的 中继日志（Relay log），这一步由 从库 I/O 线程 完成； 从库 读取 中继日志 中的 事件，将其重放到数据中，这一步由 从库 SQL 线程 完成。 主从模式的优点1. 负载均衡通常情况下，会使用 主服务器 对数据进行 更新、删除 和 新建 等操作，而将 查询 工作落到 从库 头上。 2. 异地容灾备份可以将主服务器上的数据同步到 异地从服务器 上，极大地提高了 数据安全性。 3. 高可用数据库的复制功能实现了 主服务器 与 从服务器间 的数据同步，一旦主服务器出了 故障，从服务器立即担当起主服务器的角色，保障系统持续稳定运作。 4. 高扩展性主从复制 模式支持 2 种扩展方式: scale-up 向上扩展或者 纵向扩展，主要是提供比现在服务器 性能更好 的服务器，比如 增加 CPU 和 内存 以及 磁盘阵列等，因为有多台服务器，所以可扩展性比单台更大。 scale-out 向外扩展或者 横向扩展，是指增加 服务器数量 的扩展，这样主要能分散各个服务器的压力。 主从模式的缺点1. 成本增加搭建主从肯定会增加成本，毕竟一台服务器和两台服务器的成本完全不同，另外由于主从必须要开启 二进制日志，所以也会造成额外的 性能消耗。 2. 数据延迟从库 从 主库 复制数据肯定是会有一定的 数据延迟 的。所以当刚插入就出现查询的情况，可能查询不出来。当然如果是插入者自己查询，那么可以直接从 主库 中查询出来，当然这个也是需要用代码来控制的。 3. 写入更慢主从复制 主要是针对 读远大于写 或者对 数据备份实时性 要求较高的系统中。因为 主服务器 在写中需要更多操作，而且 只有一台 可以写入的 主库，所以写入的压力并不能被分散。 主从复制的前提条件 主从服务器 操作系统版本 和 位数 一致。 主数据库和从数据库的 版本 要一致。 主数据库和从数据库中的 数据 要一致。 主数据库 开启 二进制日志，主数据库和从数据库的 server_id 在局域网内必须 唯一。 具体配置1. 环境准备 名称 版本号 Docker 18.03.1-ce Docker Compose 1.21.1 MySQL 5.7.17 2. 配置docker-compose.ymldocker-compose.yml 1234567891011121314151617181920212223242526version: '2'services: mysql-master: build: context: ./ dockerfile: master/Dockerfile environment: - \"MYSQL_ROOT_PASSWORD=root\" - \"MYSQL_DATABASE=replicas_db\" links: - mysql-slave ports: - \"33065:3306\" restart: always hostname: mysql-master mysql-slave: build: context: ./ dockerfile: slave/Dockerfile environment: - \"MYSQL_ROOT_PASSWORD=root\" - \"MYSQL_DATABASE=replicas_db\" ports: - \"33066:3306\" restart: always hostname: mysql-slave 3. 主数据库配置3.1. 配置DockerfileDockerfile 123FROM mysql:5.7.17MAINTAINER harrisonADD ./master/my.cnf /etc/mysql/my.cnf 3.2. 配置my.cnf文件my.cnf 12345678910111213141516[mysqld]## 设置server_id，一般设置为IP，注意要唯一server_id=100 ## 复制过滤：也就是指定哪个数据库不用同步（mysql库一般不同步）binlog-ignore-db=mysql ## 开启二进制日志功能，可以随便取，最好有含义（关键就是这里了）log-bin=replicas-mysql-bin ## 为每个session分配的内存，在事务过程中用来存储二进制日志的缓存binlog_cache_size=1M ## 主从复制的格式（mixed,statement,row，默认格式是statement）binlog_format=mixed ## 二进制日志自动删除/过期的天数。默认值为0，表示不自动删除。expire_logs_days=7 ## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致slave_skip_errors=1062 4. 从数据库配置4.1. 配置DockerfileDockerfile 123FROM mysql:5.7.17MAINTAINER harrisonADD ./slave/my.cnf /etc/mysql/my.cnf 4.2. 配置my.cnf文件12345678910111213141516171819202122[mysqld]## 设置server_id，一般设置为IP，注意要唯一server_id=101 ## 复制过滤：也就是指定哪个数据库不用同步（mysql库一般不同步）binlog-ignore-db=mysql ## 开启二进制日志功能，以备Slave作为其它Slave的Master时使用log-bin=replicas-mysql-slave1-bin ## 为每个session 分配的内存，在事务过程中用来存储二进制日志的缓存binlog_cache_size=1M ## 主从复制的格式（mixed,statement,row，默认格式是statement）binlog_format=mixed ## 二进制日志自动删除/过期的天数。默认值为0，表示不自动删除。expire_logs_days=7 ## 跳过主从复制中遇到的所有错误或指定类型的错误，避免slave端复制中断。## 如：1062错误是指一些主键重复，1032错误是因为主从数据库数据不一致slave_skip_errors=1062 ## relay_log配置中继日志relay_log=replicas-mysql-relay-bin ## log_slave_updates表示slave将复制事件写进自己的二进制日志log_slave_updates=1 ## 防止改变数据(除了特殊的线程)read_only=1 5. 创建容器进入 docker 目录，运行 docker-compose 启动命令。 1$ docker-compose up -d 如图所示，MySQL 主数据库 和 从数据库 的容器创建成功。 分别\b配置 主数据库 和 从数据库 的连接信息如下： 主数据库 从数据库 \b 6. 配置从数据库检查从库的起始状态1$ show master status; 如图所示，从数据库处于 未同步复制状态。 检查主库的状态1$ show master status; 记录 主数据库\b binary-log 的\b 文件名称 和 数据同步\b起\b始位置。\b File: replicas-mysql-bin.000003 Position: 154 从库配置主库信息在 从数据库 上运行 主数据库 的相关配置 sql 进行主从关联 123456CHANGE MASTER TO MASTER_HOST='mysql-master', MASTER_USER='root', MASTER_PASSWORD='root', MASTER_LOG_FILE='replicas-mysql-bin.000003', MASTER_LOG_POS=154; 重新启动 slave \b服务 12$ stop slave$ start slave 进一步检查 从数据库 的状态信息，两者已经进行 数据同步 关联。 7. 创建目标表在 主数据库 中创建一张测试数据表 course 12345678910111213SET FOREIGN_KEY_CHECKS=0;-- ------------------------------ Table structure for course-- ----------------------------DROP TABLE IF EXISTS `course`;CREATE TABLE `course` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(20) NOT NULL, `lesson_period` double(5,0) DEFAULT NULL, `score` double(10,0) DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 主数据库 和 从数据库 的 数据处于 同步状态，主从\b复制集群搭建完成。 MySQL的复制类型基于语句的复制主服务器上面执行的语句在从服务器上面再执行一遍，在 MySQL-3.23 版本以后支持。 问题：时间上可能不完全同步造成偏差，执行语句的用户也可能是不同一个用户。 基于行的复制把主服务器上面改变后的内容直接复制过去，而不关心到底改变该内容是由哪条语句引发的，在 MySQL-5.0 版本以后引入。 问题：比如一个工资表中有一万个用户，我们把每个用户的工资+1000，那么基于行的复制则要复制一万行的内容，由此造成的开销比较大，而基于语句的复制仅仅一条语句就可以了。 混合类型的复制MySQL 默认使用 基于语句的复制，当 基于语句的复制 会引发问题的时候就会使用 基于行的复制，MySQL 会自动进行选择。 欢迎关注公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"MySQL学习系列","slug":"MySQL学习系列","permalink":"https://ostenant.coding.me/categories/MySQL学习系列/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://ostenant.coding.me/tags/Docker/"},{"name":"Docker Compose","slug":"Docker-Compose","permalink":"https://ostenant.coding.me/tags/Docker-Compose/"},{"name":"MySQL","slug":"MySQL","permalink":"https://ostenant.coding.me/tags/MySQL/"},{"name":"主从复制","slug":"主从复制","permalink":"https://ostenant.coding.me/tags/主从复制/"}]},{"title":"并发三剑客之限流方案总结","slug":"并发三剑客之限流方案总结","date":"2018-06-09T00:20:00.000Z","updated":"2018-06-18T01:58:05.210Z","comments":true,"path":"2018/06/09/并发三剑客之限流方案总结/","link":"","permalink":"https://ostenant.coding.me/2018/06/09/并发三剑客之限流方案总结/","excerpt":"前言对于高并发的系统，有三把利器用来保护系统：缓存、降级 和 限流。限流常见的应用场景是秒杀、下单和评论等 突发性 并发问题。","text":"前言对于高并发的系统，有三把利器用来保护系统：缓存、降级 和 限流。限流常见的应用场景是秒杀、下单和评论等 突发性 并发问题。 缓存 的目的是提升 系统访问速度 和 系统吞吐量。 降级 是当服务 出问题 或者影响到核心流程的性能，则需要 暂时屏蔽掉，待 高峰 或者 问题解决后 再打开。 有些场景并不能用 缓存 和 降级 来解决，比如稀缺资源（秒杀、抢购）、写服务（如评论、下单）、频繁的复杂查询（最新的评论）。因此需有一种手段来限制这些场景的 并发/请求量，即 限流。 正文限流的目的限流的目的是通过对 并发访问/请求进行 限速，或者一个 时间窗口 内的的请求进行限速来 保护系统，一旦达到限制速率则可以 拒绝服务（定向到错误页或告知资源没有了）、排队 或 等待（比如秒杀、评论、下单）、降级（返回托底数据或默认数据，如商品详情页库存默认有货）。 限流的方式 限制 总并发数（比如 数据库连接池、线程池） 限制 瞬时并发数（如 nginx 的 limit_conn 模块，用来限制 瞬时并发连接数） 限制 时间窗口内的平均速率（如 Guava 的 RateLimiter、nginx 的 limit_req 模块，限制每秒的平均速率） 限制 远程接口 调用速率 限制 MQ 的消费速率 可以根据 网络连接数、网络流量、CPU 或 内存负载 等来限流 \b限流的算法1. 令牌桶 2. 漏桶 3. 计数器有时候还可以使用 计数器 来进行限流，主要用来限制 总并发数，比如 数据库连接池、线程池、秒杀的并发数。通过 全局总请求数 或者 一定时间段的总请求数 设定的 阀值 来限流。这是一种 简单粗暴 的限流方式，而不是 平均速率限流。 令牌桶 vs 漏桶令牌桶限制的是 平均流入速率，允许突发请求，并允许一定程度 突发流量。 漏桶限制的是 常量流出速率，从而平滑 突发流入速率。 应用级别限流1. 限流总资源数可以使用池化技术来限制总资源数：连接池、线程池。比如分配给每个应用的数据库连接是 100，那么本应用最多可以使用 100 个资源，超出了可以 等待 或者 抛异常。 2. 限流总并发/连接/请求数如果你使用过 Tomcat，其 Connector 其中一种配置有如下几个参数: maxThreads: Tomcat 能启动用来处理请求的 最大线程数，如果请求处理量一直远远大于最大线程数，可能会僵死。 maxConnections: 瞬时最大连接数，超出的会 排队等待。 acceptCount: 如果 Tomcat 的线程都忙于响应，新来的连接会进入 队列排队，如果 超出排队大小，则 拒绝连接。 3. 限流某个接口的总并发/请求数使用 Java 中的 AtomicLong，示意代码： 123456789try&#123; if(atomic.incrementAndGet() &gt; 限流数) &#123; //拒绝请求 &#125; else &#123; //处理请求 &#125;&#125; finally &#123; atomic.decrementAndGet();&#125; 4. 限流某个接口的时间窗请求数使用 Guava 的 Cache，示意代码： 12345678910111213141516171819LoadingCache counter = CacheBuilder.newBuilder() .expireAfterWrite(2, TimeUnit.SECONDS) .build(newCacheLoader() &#123; @Override public AtomicLong load(Long seconds) throws Exception &#123; return newAtomicLong(0); &#125; &#125;);longlimit =1000;while(true) &#123; // 得到当前秒 long currentSeconds = System.currentTimeMillis() /1000; if(counter.get(currentSeconds).incrementAndGet() &gt; limit) &#123; System.out.println(\"限流了: \" + currentSeconds); continue; &#125; // 业务处理&#125; 5. 平滑限流某个接口的请求数之前的限流方式都不能很好地应对 突发请求，即 瞬间请求 可能都被允许从而导致一些问题。因此在一些场景中需要对突发请求进行改造，改造为 平均速率 请求处理。 Guava RateLimiter 提供了 令牌桶算法实现： 平滑突发限流 (SmoothBursty) 平滑预热限流 (SmoothWarmingUp) 实现 平滑突发限流(SmoothBursty)1234567RateLimiter limiter = RateLimiter.create(5);System.out.println(limiter.acquire());System.out.println(limiter.acquire());System.out.println(limiter.acquire());System.out.println(limiter.acquire());System.out.println(limiter.acquire());System.out.println(limiter.acquire()); 将得到类似如下的输出： 1234560.00.1982390.1960830.2006090.1995990.19961 平滑预热限流(SmoothWarmingUp)123456789RateLimiter limiter = RateLimiter.create(5, 1000, TimeUnit.MILLISECONDS);for(inti = 1; i &lt; 5; i++) &#123; System.out.println(limiter.acquire());&#125;Thread.sleep(1000L);for(inti = 1; i &lt; 5; i++) &#123; System.out.println(limiter.acquire());&#125; 将得到类似如下的输出： 123456789100.00.517670.3578140.2199920.1999840.00.3608260.2201660.1997230.199555 SmoothWarmingUp 的创建方式： 1RateLimiter.create(doublepermitsPerSecond, long warmupPeriod, TimeUnit unit); permitsPerSecond: 表示 每秒新增 的令牌数 warmupPeriod: 表示在从 冷启动速率 过渡到 平均速率 的时间间隔 速率是 梯形上升 速率的，也就是说 冷启动 时会以一个比较大的速率慢慢到平均速率；然后趋于 平均速率（梯形下降到平均速率）。可以通过调节 warmupPeriod 参数实现一开始就是平滑固定速率。 分布式限流分布式限流最关键的是要将 限流服务 做成 原子化，而解决方案可以使用 redis + lua 或者 nginx + lua 技术进行实现。 接入层限流接入层 通常指请求流量的入口，该层的主要目的有： 负载均衡 非法请求过滤 请求聚合 缓存、降级、限流 A/B测试 服务质量监控 对于 Nginx 接入层限流 可以使用 Nginx 自带了两个模块：连接数限流模块 ngx_http_limit_conn_module 和 漏桶 算法实现的 请求限流模块 ngx_http_limit_req_module。还可以使用 OpenResty 提供的 Lua 限流模块 lua-resty-limit-traffic 进行 更复杂的 限流场景。 limit_conn: 用来对某个 KEY 对应的 总的网络连接数 进行限流，可以按照如 IP、域名维度 进行限流。 limit_req: 用来对某个 KEY 对应的 请求的平均速率 进行限流，并有两种用法：平滑模式（delay）和 允许突发模式 (nodelay)。 OpenResty 提供的 Lua 限流模块 lua-resty-limit-traffic 可以进行更复杂的限流场景。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"高并发系统系列","slug":"高并发系统系列","permalink":"https://ostenant.coding.me/categories/高并发系统系列/"}],"tags":[{"name":"高并发","slug":"高并发","permalink":"https://ostenant.coding.me/tags/高并发/"},{"name":"限流","slug":"限流","permalink":"https://ostenant.coding.me/tags/限流/"}]},{"title":"分布式理论(六) - 一致性协议Raft","slug":"分布式理论(六) - 一致性协议Raft","date":"2018-06-05T13:20:00.000Z","updated":"2018-06-18T01:54:52.119Z","comments":true,"path":"2018/06/05/分布式理论(六) - 一致性协议Raft/","link":"","permalink":"https://ostenant.coding.me/2018/06/05/分布式理论(六) - 一致性协议Raft/","excerpt":"前言Raft 也是一个 一致性算法，和 Paxos 目标相同。但它还有另一个名字 - 易于理解的一致性算法。Paxos 和 Raft 都是为了实现 一致性 产生的。这个过程如同选举一样，参选者 需要说服 大多数选民 (服务器) 投票给他，一旦选定后就跟随其操作。Paxos 和 Raft 的区别在于选举的 具体过程 不同。","text":"前言Raft 也是一个 一致性算法，和 Paxos 目标相同。但它还有另一个名字 - 易于理解的一致性算法。Paxos 和 Raft 都是为了实现 一致性 产生的。这个过程如同选举一样，参选者 需要说服 大多数选民 (服务器) 投票给他，一旦选定后就跟随其操作。Paxos 和 Raft 的区别在于选举的 具体过程 不同。 正文小试牛刀在进入正题前，给大家分享一个《数学发散思维》中的一个故事，\b站在不同思维角度上，了解对一个问题理解的差异性。 问题: 甲乙两人轮流在一张圆桌上平放黑白围棋子，每次放一子，棋子不许重叠，谁先没有地方放就输。请问怎样放才能赢？ 这个问题有两层意思，第一，有没有一种放法保证必赢？第二，如果有怎么证明？ 上图回答了这个问题，\b那就是先行者必胜，这里使用了三种不同的思维方式来阐述: 假如桌子只有一个围棋子那么大。 假如桌子无限大，先行者先占住圆心。由于圆是对称图形，所以只要对手还能找到位置放，你总能在对称的另一面找到位置放。 一个圆中可画单数个直径相等且互切的小圆。 三种不同的思维方式在可理解性难度上逐渐加深。 第一种是 极简化思维，但数学上是 不严谨 的。 第二种是 极限思维，和第一种结合起来就是 数学归纳法，在数学上是 严谨 的。 第三种是 形象思维，使用了 几何学概念，但对于没有几何学基础知识的人就很难理解了。 什么是Raft协议Raft 协议将 Server 进程分成三类，分别是 Leader，Candidate，Follower。一个 Server 进程在某一时刻，只能是其中 一种类型，但这不是固定的。不同的时刻，它可能拥有不同的类型，一个 Server 进程的类型是如何改变的，后面会有解释。 在一个由 Raft 协议组织的集群中有三类角色： Leader（领袖） Follower（群众） Candidate（候选人） 就像一个民主社会，领袖由民众投票选出。刚开始没有 领袖，所有集群中的 参与者 都是 群众，那么首先开启一轮大选。在大选期间 所有群众 都能参与竞选，这时所有群众的角色就变成了 候选人，民主投票选出领袖后就开始了这届领袖的任期，然后选举结束，所有除 领袖 的 候选人 又变回 群众角色 服从领袖领导。 这里提到一个概念 「任期」，用术语 Term 表达。关于 Raft 协议的核心概念和术语就这么多，而且和现实民主制度非常匹配，所以很容易理解。 三类角色的变迁图如下，结合后面的选举过程来看很容易理解。 Leader选举过程在极简的思维下，一个最小的 Raft 民主集群需要 三个参与者（如下图：A、B、C），这样才可能投出多数票。 初始状态 ABC 都是 Follower，然后发起选举这时有 三种 可能的情形发生。下图中前二种都能选出 Leader，第三种则表明 本轮投票无效（Split Votes）。对于第三种，每方都投给了自己，结果没有任何一方获得多数票。之后 每个参与方 随机休息一阵（Election Timeout）重新发起投票直到一方获得多数票。这里的关键就是随机 timeout，最先从 timeout 中恢复发起投票的一方，向还在 timeout 中的另外两方 请求投票，这时它就只能投给自己，导致很快达成一致。 选出 Leader 后，Leader 通过 定期 向所有 Follower 发送 心跳信息 维持其统治。若 Follower 一段时间未收到 Leader 的 心跳，则认为 Leader 可能已经挂了，然后再次发起 选举 过程。 Leader对一致性的影响Raft 协议 强依赖 Leader 节点的 可用性，以确保集群 数据的一致性。数据的流向 只能从 Leader 节点向 Follower 节点转移。具体过程如下： 当 Client 向集群 Leader 节点 提交数据 后，Leader 节点 接收到的数据 处于 未提交状态（Uncommitted）。 接着 Leader 节点会 并发地 向所有 Follower 节点 复制数据 并 等待接收响应。 集群中至少 超过半数 的节点 已接收 到数据后， Leader 再向 Client 确认数据 已接收。 一旦向 Client 发出数据接收 Ack 响应后，表明此时 数据状态 进入 已提交（Committed），Leader 节点再向 Follower 节点发通知告知该 数据状态已提交。 在这个过程中，主节点 可能在 任意阶段 挂掉，看下 Raft 协议如何针对不同阶段保障 数据一致性 的。 1. 情形1 数据到达 Leader 节点前，这个阶段 Leader 挂掉不影响一致性，不用多说。 2. 情形\b2 数据到达 Leader 节点，但未复制到 Follower 节点。 这个阶段 Leader 挂掉，数据属于 未提交状态，Client 不会收到 Ack 会认为 超时失败 可安全发起 重试。 Follower 节点上没有该数据，重新选主 后 Client 重试 重新提交 可成功。原来的 Leader 节点 恢复 后作为 Follower 加入集群，重新从 当前任期 的新 Leader 处 同步数据，强制保持和 Leader 数据一致。 3. 情形3 数据到达 Leader 节点，成功复制到 Follower 所有节点，但 Follower 还未向 Leader 响应接收。 这个阶段 Leader 挂掉，虽然数据在 Follower 节点处于 未提交状态（Uncommitted），但是 保持一致 的。重新选出 Leader 后可完成 数据提交。 此时 Client 由于不知到底提交成功没有，可重试提交。针对这种情况 Raft 要求 RPC 请求实现 幂等性，也就是要实现 内部去重机制。 4. 情形4 数据到达 Leader 节点，成功复制到 Follower 的部分节点，但这部分 Follower 节点还未向 Leader 响应接收。 这个阶段 Leader 挂掉，数据在 Follower 节点处于 未提交状态（Uncommitted）且 不一致。 Raft 协议要求投票只能投给拥有 最新数据 的节点。所以拥有最新数据的节点会被选为 Leader，然后再 强制同步数据 到其他 Follower，保证 数据不会丢失并 最终一致。 5. \b情形5 数据到达 Leader 节点，成功复制到 Follower 所有或多数节点，数据在 Leader 处于已提交状态，但在 Follower 处于未提交状态。 这个阶段 Leader 挂掉，重新选出 新的 Leader 后的处理流程和阶段 3 一样。 6. 情形6 数据到达 Leader 节点，成功复制到 Follower 所有或多数节点，数据在所有节点都处于已提交状态，但还未响应 Client。 这个阶段 Leader 挂掉，集群内部数据其实已经是 一致的，Client 重复重试基于幂等策略对 一致性无影响。 7. 情形7 网络分区导致的脑裂情况，出现双 Leader 的现象。 网络分区 将原先的 Leader 节点和 Follower 节点分隔开，Follower 收不到 Leader 的 心跳 将 重新 发起选举产生新的 Leader，这时就产生了 双Leader 现象。 原先的 Leader 独自在一个区，向它提交数据不可能复制到多数节点所以永远提交不成功。向新的 Leader 提交数据可以提交成功。 网络恢复 后，旧的 Leader 发现集群中有 更新任期（Term）的新 Leader ，则 自动降级 为 Follower 并从新 Leader 处 同步数据 达成集群 数据一致。 验证结果综上穷举分析了 最小集群（3 节点）面临的所有情况，可以看出 Raft 协议都能很好的应对 一致性问题，并且很容易理解。 小结Paxos 算法是 Leslie Lamport 在 1990 年就公开发表在了自己的网站上，想想我们是什么时候才听说的？什么时候才有一个可用的实现？而 Raft 算法是 2013 年发表的，大家在参考 Raft\b开源实现库，可以看到有很多基于不同语言的 开源实现库，这就是 可理解性 的重要性。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"Raft","slug":"Raft","permalink":"https://ostenant.coding.me/tags/Raft/"}]},{"title":"分布式理论(五) - 一致性算法Paxos","slug":"分布式理论(五) - 一致性算法Paxos","date":"2018-06-03T13:30:00.000Z","updated":"2018-06-18T01:54:36.736Z","comments":true,"path":"2018/06/03/分布式理论(五) - 一致性算法Paxos/","link":"","permalink":"https://ostenant.coding.me/2018/06/03/分布式理论(五) - 一致性算法Paxos/","excerpt":"前言世界上只有一种一致性算法，就是 Paxos。出自一位 Google 大神之口。Paxos 也是出名的 晦涩难懂，推理过程极其复杂。","text":"前言世界上只有一种一致性算法，就是 Paxos。出自一位 Google 大神之口。Paxos 也是出名的 晦涩难懂，推理过程极其复杂。 Paxos 有点类似之前说的 2PC，3PC，但是解决了这两种算法\b各种硬伤。该算法在很多大厂都得到了工程实践，比如阿里的 OceanBase 的 分布式数据库，底层就是使用的 Paxos 算法。再比如 Google 的 chubby 分布式锁 也是用的这个算法。可见该算法在分布式系统中的地位，甚至于，Paxos 就是 分布式一致性 的代名词。 正文1. Paxos算法是什么Paxos 算法是 基于消息传递 且具有 高效容错特性 的一致性算法，目前公认的解决 分布式一致性问题 最有效的算法之一. 2. Paxos算法产生背景2.1. 拜占庭将军问题拜占庭是古代东罗马帝国的首都，由于地域宽广，守卫边境的多个将军（系统中的多个节点）需要通过信使来传递消息，达成某些一致的决定。但由于信使中可能存在叛徒（系统中节点出错），这些叛徒将努力向不同的将军发送不同的消息，试图会干扰一致性的达成。 2.2. Paxos算法由来故事背景是古希腊 Paxos 岛上的多个法官在一个大厅内对一个议案进行表决，如何达成统一的结果。他们之间通过服务人员来传递纸条，但法官可能离开或进入大厅，服务人员可能偷懒去睡觉。 2.3 产生背景在常见的 分布式系统 中，总会发生 节点宕机 或 网络异常 (包括消息的 重复、丢失、延迟、乱序、网络分区) 等情况。 Paxos 算法主要就是解决如何在一个 发生如上故障 的分布式系统中，快速正确的在集群内 对某个值达成一致，并且保证 整个系统的一致性。 3. 算法详解3.1 角色 &amp; 提案提案 (Proposal) 注意：提案的范围&gt;value.后面会讲到，[提案=编号+Value].也可表示为[M,V].以下描述中暂定: 提案=P，Value=V. 角色 Proposer : Proposer 可以 提出提案 (Proposal)。 Accecptor : Acceptor 可以 接受提案。一旦接受提案，提案 里面的 value 值就被选定了。 Learner : Acceptor 告诉 Learner 哪个提案被选定了，那么 Learner 就学习这个被选择的 value。 在具体的实现中，一个进程即可能是Proposer,也可能是Acceptor，也可能是Learner。 3.2. 问题描述Paxos 算法的核心是 一致性。所以将从一致性问题的描述来讲解该算法怎么解决实际问题。 3.2.1. 一致性算法的前置条件 在被提出的 P 中，只有一个 V 被选中。 如果没有 P 被提出，就没有 V 被选中。 在 P 被选定后，进程都可以学习被选中的 P。 3.2.2. 不同角色通过发送消息进行通信 每个角色以任意的速度执行，可能因出错而停止，也可能会重启。一个 value 被选定后，所有的角色可能失败然后重启，除非那些失败后重启的角色能记录某些信息，否则等他们重启后无法确定被选定的值。 消息在传递过程中可能出现 任意时长的延迟，可能会 重复，也可能 丢失，但是消息不会被 损坏。 3.3. 推导过程3.3.1. 只有一个Acceptor 一个 Acceptor 接受一个 P，那么只有一个 V 被选定。 问题：\b如果这个 Acceptor 宕机，那么整个系统服务不可用。 3.3.2. 多个Acceptor 问题：如何在多 Proposer 和多 Acceptor 情况下，选定一个 value？ 讲解步骤分两阶段：约定 P1 和 约定 P2。 3.3.2.1. 约定P1 P1 ：一个 Acceptor 必须接受一个它收到的第一个 P。 如果每个 Proposer 会产生不同的 P，那么多个 Proposer 必定产生多个 P，发给多个 Acceptor。根据 约定 P1，Acceptor 分别接受到 P，就会导致不同的 V 被选定，如下图所示： 如上图所示，P1 会产生的问题: v1、v2、v3 都没有被选定，因为他们只有被一个 Acceptor 接受。 对于上述问题，我们需要一个额外的约定: P1a : 一个提案 P 被选定，需要被半数以上 Acceptor 接受. 对于 P1a，其实就意味着 一个Acceptor必须接受不止一个提案。 显然，这与 P1 相矛盾，所以需要重新设计提案。原来的设计是: [提案P = value]，现在重新设计 [提案P = 提案编号 + value]，可表示为 [M，V]。 新问题：多提案被选定，如何保证被选定的提案 P 具有相同的value? 3.3.2.2. 约定P2 P2 : 如果提案 P[M0,V0] 被选定了，那么所有比 M0 编号更高的，且被选定的 P，其 value 的值也是 V0。 对于 P2 中的 “被选定”：一个提案要被选定，首先至少要被一个 Acceptor 批准。因此，可以理解 P2 为： P2a : 如果提案 P[M0,V0] 被选定了，那么所有比 M0 编号更高的，且 [被Acceptor批准] 的P，其 value 值也是 V0。 只要满足 P2a，就能满足 P2。多提案被选择 的问题解决了，但是由于 网络不稳定 或者 宕机 的原因（不可避免），会产生新问题： 假设有 5 个 Acceptor。Proposer2 提出 [M1,V1]的提案，Acceptor2~5（半数以上）均接受了该提案，于是对于 Acceptor2~5 和 Proposer2 来讲，它们都认为 V1 被选定。Acceptor1 刚刚从 宕机状态 恢复过来（之前 Acceptor1 没有收到过任何提案），此时 Proposer1 向 Acceptor1 发送了 [M2,V2] 的提案 （V2≠V1且M2&gt;M1）。对于 Acceptor1 来讲，这是它收到的 第一个提案。根据 P1（一个 Acceptor 必须接受它收到的 第一个提案），Acceptor1 必须接受该提案。同时 Acceptor1 认为 V2 被选定。 这就出现了两个问题： Acceptor1 认为 V2 被选定，Acceptor2~5 和Proposer2 认为 V1 被选定。出现了不一致。 V1 被选定了，但是 编号更高 的被 Acceptor1 接受的提案 [M2,V2] 的 value 为 V2，且 V2≠V1。这就跟 P2a（如果某个 value 为 v的提案被选定了，那么每个 编号更高 的被 Acceptor 接受的提案的 value 必须也是 v）矛盾了。 基于以上问题，所有就有了 P2b: P2b : 如果 P[M0,V0] 被选定后，任何 Proposer 产生的 P，其值也是 V0。 对于 P2b 中的描述，怎样保证 任何Proposer产生的P，其值也是V0 ？只要满足 P2c 即可： P2c: 对于任意的 M、V，如果 [M,V] 被提出，那么存在一个半数以上的 Acceptor 组成的组合 S，满足以下两个条件中的任何一个：① S 中没有一个接受过编号小于 M 的提案。② S 中的 Acceptor 接受过的最大编号的提案的 value 为 V。 推导完毕。。。 3.4. 算法流程3.4.1. Proposer提出提案总体思路如下： (一). 学习阶段：Prepare请求Proposer 选择一个新的提案 P[MN,?] 向 Acceptor 集合 S（数目在半数以上）发送请求，要求 S 中的每一个 Acceptor 做出如下响应： 如果 Acceptor 没有接受过提案，则向 Proposer 保证 不再接受编号小于N的提案。 如果 Acceptor 接受过请求，则向 Proposer 返回 已经接受过的编号小于N的编号最大的提案。 (二). 接受阶段：Acceptor请求 如果 Proposer 收到 半数以上 的 Acceptor 响应，则 生成编号为 N，value 为 V 的提案 [MN,V]，V 为所有响应中 编号最大 的提案的 value。 如果 Proposer 收到的响应中 没有提案，那么 value 由 Proposer 自己生成，生成后将此提案发给 S，并期望 Acceptor 能接受此提案。 3.4.2. Acceptor接受提案Acceptor 可以忽略任何请求（包括 Prepare 请求和 Accept 请求）而不用担心破坏 算法的安全性。因此，我们这里要讨论的是什么时候 Acceptor 可以响应一个请求。 对 Acceptor 接受提案给出如下约束： P1b：一个 Acceptor 只要尚未响应过任何编号大于 N 的 Prepare 请求，那么就可以接受这个编号为 N 的提案。 如果 Acceptor 收到一个编号为 N 的 Prepare 请求，在此之前它已经 响应过 编号大于 N 的 Prepare 请求。根据 P1b，该 Acceptor 不可能接受编号为 N 的提案。因此，该 Acceptor 可以 忽略 编号为 N 的 Prepare 请求。当然，也可以回复一个 error，让 Proposer 尽早知道自己的提案 不会被接受。 因此，一个 Acceptor 只需记住： 已接受的编号最大的提案； 已响应的请求的最大编号。 4. Paxos算法描述 5. Learner学习提案Learner 学习（获取）被选定的 value 有如下三种方案: 6. 如何保证Paxos算法的活性 小结Paxos 在 节点宕机恢复、消息无序或丢失、网络分化 的场景下能保证 数据的一致性。而 Paxos 的描述侧重于 理论，在实际项目应用中，处理了 N 多实际细节后，可能已经变成了另外一种算法，这时候正确性已经无法得到理论的保证。 要证明分布式一致性算法的正确性通常比实现算法还困难。所以很多系统实际中使用的都是以 Paxos 理论 为基础而 衍生 出来的变种和简化版。例如 Google 的 Chubby、MegaStore、Spanner 等系统，ZooKeeper 的 ZAB 协议，还有更加容易理解的 Raft 协议。 大部分系统都是靠在实践中运行很长一段时间，经过验证发现系统已可以基本运行，没有发现大的问题才能上生产环境。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"Paxos","slug":"Paxos","permalink":"https://ostenant.coding.me/tags/Paxos/"}]},{"title":"单元测试利器Mockito框架","slug":"单元测试\b利器Mockito框架","date":"2018-05-31T15:30:00.000Z","updated":"2018-06-18T01:55:40.276Z","comments":true,"path":"2018/05/31/单元测试\b利器Mockito框架/","link":"","permalink":"https://ostenant.coding.me/2018/05/31/单元测试\b利器Mockito框架/","excerpt":"前言Mockito 是当前最流行的 单元测试 Mock 框架。采用 Mock 框架，我们可以 虚拟 出一个 外部依赖，降低测试 组件 之间的 耦合度，只注重代码的 流程与结果，真正地实现测试目的。","text":"前言Mockito 是当前最流行的 单元测试 Mock 框架。采用 Mock 框架，我们可以 虚拟 出一个 外部依赖，降低测试 组件 之间的 耦合度，只注重代码的 流程与结果，真正地实现测试目的。 正文什么是MockMock 的中文译为仿制的，模拟的，虚假的。对于测试框架来说，即构造出一个模拟/虚假的对象，使我们的测试能顺利进行下去。 Mock 测试就是在测试过程中，对于某些 不容易构造（如 HttpServletRequest 必须在 Servlet 容器中才能构造出来）或者不容易获取 比较复杂 的对象（如 JDBC 中的 ResultSet 对象），用一个 虚拟 的对象（Mock 对象）来创建，以便测试方法。 为什么使用Mock测试单元测试 是为了验证我们的代码运行正确性，我们注重的是代码的流程以及结果的正确与否。 对比真实运行代码，可能其中有一些 外部依赖 的构建步骤相对麻烦，如果我们还是按照真实代码的构建规则构造出外部依赖，会大大增加单元测试的工作，代码也会参杂太多非测试部分的内容，测试用例显得复杂难懂。 采用 Mock 框架，我们可以 虚拟 出一个 外部依赖，只注重代码的 流程与结果，真正地实现测试目的。 Mock测试框架的好处 可以很简单的虚拟出一个复杂对象（比如虚拟出一个接口的实现类）； 可以配置 mock 对象的行为； 可以使测试用例只注重测试流程与结果； 减少外部类、系统和依赖给单元测试带来的耦合。 Mockito的流程 如图所示，使用 Mockito 的大致流程如下: 创建 外部依赖 的 Mock 对象, 然后将此 Mock 对象注入到 测试类 中； 执行 测试代码； 校验 测试代码 是否执行正确。 Mockito的使用在 Module 的 build.gradle 中添加如下内容： 123456dependencies &#123; //Mockito for unit tests testImplementation \"org.mockito:mockito-core:2.+\" //Mockito for Android tests androidTestImplementation 'org.mockito:mockito-android:2.+'&#125; 这里稍微解释下： mockito-core: 用于 本地单元测试，其测试代码路径位于 module-name/src/test/java/ mockito-android: 用于 设备测试，即需要运行 android 设备进行测试，其测试代码路径位于 module-name/src/androidTest/java/ mockito-core最新版本可以在 Maven 中查询：mockito-core。mockito-android最新版本可以在 Maven 中查询：mockito-android Mockito的使用示例普通单元测试使用 mockito（mockito-core），路径：module-name/src/test/java/ 这里摘用官网的 Demo: 检验调对象相关行为是否被调用123456789101112import static org.mockito.Mockito.*;// Mock creationList mockedList = mock(List.class);// Use mock object - it does not throw any \"unexpected interaction\" exceptionmockedList.add(\"one\"); //调用了add(\"one\")行为mockedList.clear(); //调用了clear()行为// Selective, explicit, highly readable verificationverify(mockedList).add(\"one\"); // 检验add(\"one\")是否已被调用verify(mockedList).clear(); // 检验clear()是否已被调用 这里 mock 了一个 List（这里只是为了用作 Demo 示例，通常对于 List 这种简单的类对象创建而言，直接 new 一个真实的对象即可，无需进行 mock），verify() 会检验对象是否在前面已经执行了相关行为，这里 mockedList 在 verify 之前已经执行了 add(&quot;one&quot;) 和 clear() 行为，所以verify() 会通过。 配置/方法行为12345678// you can mock concrete classes, not only interfacesLinkedList mockedList = mock(LinkedList.class);// stubbing appears before the actual executionwhen(mockedList.get(0)).thenReturn(\"first\");// the following prints \"first\"System.out.println(mockedList.get(0));// the following prints \"null\" because get(999) was not stubbedSystem.out.println(mockedList.get(999)); 这里对几个比较重要的点进行解析： when(mockedList.get(0)).thenReturn(“first”) 这句话 Mockito 会解析为：当对象 mockedList 调用 get()方法，并且参数为 0 时，返回结果为&quot;first&quot;，这相当于定制了我们 mock 对象的行为结果（mock LinkedList 对象为 mockedList，指定其行为 get(0)，则返回结果为 &quot;first&quot;)。 mockedList.get(999) 由于 mockedList 没有指定 get(999) 的行为，所以其结果为 null。因为 Mockito 的底层原理是使用 cglib 动态生成一个 代理类对象，因此，mock 出来的对象其实质就是一个 代理，该代理在 没有配置/指定行为 的情况下，默认返回 空值。 上面的 Demo 使用的是 静态方法 mock() 模拟出一个实例，我们还可以通过注解 @Mock 也模拟出一个实例： 123456789101112131415161718@Mockprivate Intent mIntent;@Rulepublic MockitoRule mockitoRule = MockitoJUnit.rule();@Testpublic void mockAndroid()&#123; Intent intent = mockIntent(); assertThat(intent.getAction()).isEqualTo(\"com.yn.test.mockito\"); assertThat(intent.getStringExtra(\"Name\")).isEqualTo(\"Whyn\");&#125;private Intent mockIntent()&#123; when(mIntent.getAction()).thenReturn(\"com.yn.test.mockito\"); when(mIntent.getStringExtra(\"Name\")).thenReturn(\"Whyn\"); return mIntent;&#125; 对于标记有 @Mock, @Spy, @InjectMocks 等注解的成员变量的 初始化 到目前为止有 2 种方法： 对 JUnit 测试类添加 @RunWith(MockitoJUnitRunner.class) 在标示\b有 @Before 方法内调用初始化方法：MockitoAnnotations.initMocks(Object) 上面的测试用例，对于 @Mock 等注解的成员变量的初始化又多了一种方式 MockitoRule。规则 MockitoRule 会自动帮我们调用 MockitoAnnotations.initMocks(this) 去 实例化 出 注解 的成员变量，我们就无需手动进行初始化了。 Mockito的重要方法实例化虚拟对象123456789101112131415161718// You can mock concrete classes, not just interfacesLinkedList mockedList = mock(LinkedList.class);// Stubbingwhen(mockedList.get(0)).thenReturn(\"first\");when(mockedList.get(1)).thenThrow(new RuntimeException());// Following prints \"first\"System.out.println(mockedList.get(0));// Following throws runtime exceptionSystem.out.println(mockedList.get(1));// Following prints \"null\" because get(999) was not stubbedSystem.out.println(mockedList.get(999));// Although it is possible to verify a stubbed invocation, usually it's just redundant// If your code cares what get(0) returns, then something else breaks (often even before verify() gets executed).// If your code doesn't care what get(0) returns, then it should not be stubbed. Not convinced? See here.verify(mockedList).get(0); 对于所有方法，mock 对象默认返回 null，原始类型/原始类型包装类 默认值，或者 空集合。比如对于 int/Integer 类型，则返回 0，对于 boolean/Boolean 则返回 false。 行为配置（stub）是可以被复写的：比如通常的对象行为是具有一定的配置，但是测试方法可以复写这个行为。请谨记行为复写可能表明潜在的行为太多了。 一旦配置了行为，方法总是会返回 配置值，无论该方法被调用了多少次。 最后一次行为配置是更加重要的，当你为一个带有相同参数的相同方法配置了很多次，最后一次起作用。 参数匹配Mockito 通过参数对象的 equals() 方法来验证参数是否一致，当需要更多的灵活性时，可以使用参数匹配器： 12345678910// Stubbing using built-in anyInt() argument matcherwhen(mockedList.get(anyInt())).thenReturn(\"element\");// Stubbing using custom matcher (let's say isValid() returns your own matcher implementation):when(mockedList.contains(argThat(isValid()))).thenReturn(\"element\");// Following prints \"element\"System.out.println(mockedList.get(999));// You can also verify using an argument matcherverify(mockedList).get(anyInt());// Argument matchers can also be written as Java 8 Lambdasverify(mockedList).add(argThat(someString -&gt; someString.length() &gt; 5)); 参数匹配器 允许更加灵活的 验证 和 行为配置。更多 内置匹配器 和 自定义参数匹配器 例子请参考：ArgumentMatchers，MockitoHamcrest 注意：如果使用了参数匹配器，那么所有的参数都需要提供一个参数匹配器。 1234verify(mock).someMethod(anyInt(), anyString(), eq(\"third argument\"));// Above is correct - eq() is also an argument matcherverify(mock).someMethod(anyInt(), anyString(), \"third argument\");// Above is incorrect - exception will be thrown because third argument is given without an argument matcher. 类似 anyObject()，eq() 这类匹配器并不返回匹配数值。他们内部记录一个 匹配器堆栈 并返回一个空值（通常为 null）。这个实现是为了匹配 java 编译器的 静态类型安全，这样做的后果就是你不能在 检验/配置方法 外使用 anyObject()，eq() 等方法。 校验次数123456789101112131415161718192021222324LinkedList mockedList = mock(LinkedList.class);// Use mockmockedList.add(\"once\");mockedList.add(\"twice\");mockedList.add(\"twice\");mockedList.add(\"three times\");mockedList.add(\"three times\");mockedList.add(\"three times\");// Follow two verifications work exactly the same - times(1) is used by defaultverify(mockedList).add(\"once\");verify(mockedList, times(1)).add(\"once\");// Exact number of invocations verificationverify(mockedList, times(2)).add(\"twice\");verify(mockedList, times(3)).add(\"three times\");// Verification using never(). never() is an alias to times(0)verify(mockedList, never()).add(\"never happened\");// Verification using atLeast()/atMost()verify(mockedList, atLeastOnce()).add(\"three times\");verify(mockedList, atLeast(2)).add(\"three times\");verify(mockedList, atMost(5)).add(\"three times\"); 校验次数方法常用的有如下几个： Method Meaning times(n) 次数为n，默认为1（times(1)） never() 次数为0，相当于times(0) atLeast(n) 最少n次 atLeastOnce() 最少一次 atMost(n) 最多n次 抛出异常123doThrow(new RuntimeException()).when(mockedList).clear();// following throws RuntimeExceptionmockedList.clear(); 按顺序校验有时对于一些行为，有先后顺序之分，所以，当我们在校验时，就需要考虑这个行为的先后顺序： 12345678910111213141516171819202122// A. Single mock whose methods must be invoked in a particular orderList singleMock = mock(List.class);// Use a single mocksingleMock.add(\"was added first\");singleMock.add(\"was added second\");// Create an inOrder verifier for a single mockInOrder inOrder = inOrder(singleMock);// Following will make sure that add is first called with \"was added first, then with \"was added second\"inOrder.verify(singleMock).add(\"was added first\");inOrder.verify(singleMock).add(\"was added second\");// B. Multiple mocks that must be used in a particular orderList firstMock = mock(List.class);List secondMock = mock(List.class);// Use mocksfirstMock.add(\"was called first\");secondMock.add(\"was called second\");// Create inOrder object passing any mocks that need to be verified in orderInOrder inOrder = inOrder(firstMock, secondMock);// Following will make sure that firstMock was called before secondMockinOrder.verify(firstMock).add(\"was called first\");inOrder.verify(secondMock).add(\"was called second\"); 存根连续调用对于同一个方法，如果我们想让其在 多次调用 中分别 返回不同 的数值，那么就可以使用存根连续调用： 12345678910when(mock.someMethod(\"some arg\")) .thenThrow(new RuntimeException()) .thenReturn(\"foo\");// First call: throws runtime exception:mock.someMethod(\"some arg\");// Second call: prints \"foo\"System.out.println(mock.someMethod(\"some arg\"));// Any consecutive call: prints \"foo\" as well (last stubbing wins).System.out.println(mock.someMethod(\"some arg\")); 也可以使用下面更简洁的存根连续调用方法： 1when(mock.someMethod(\"some arg\")).thenReturn(\"one\", \"two\", \"three\"); 注意：存根连续调用要求必须使用链式调用，如果使用的是同个方法的多个存根配置，那么只有最后一个起作用（覆盖前面的存根配置）。 123// All mock.someMethod(\"some arg\") calls will return \"two\"when(mock.someMethod(\"some arg\").thenReturn(\"one\")when(mock.someMethod(\"some arg\").thenReturn(\"two\") 无返回值函数对于 返回类型 为 void 的方法，存根要求使用另一种形式的 when(Object) 函数，因为编译器要求括号内不能存在 void 方法。 例如，存根一个返回类型为 void 的方法，要求调用时抛出一个异常： 123doThrow(new RuntimeException()).when(mockedList).clear();// Following throws RuntimeException:mockedList.clear(); 监视真实对象前面使用的都是 mock 出来一个对象。这样，当 没有配置/存根 其具体行为的话，结果就会返回 空类型。而如果使用 特务对象（spy），那么对于 没有存根 的行为，它会调用 原来对象 的方法。可以把 spy 想象成局部 mock。 12345678910111213141516List list = new LinkedList();List spy = spy(list);// Optionally, you can stub out some methods:when(spy.size()).thenReturn(100);// Use the spy calls *real* methodsspy.add(\"one\");spy.add(\"two\");// Prints \"one\" - the first element of a listSystem.out.println(spy.get(0));// Size() method was stubbed - 100 is printedSystem.out.println(spy.size());// Optionally, you can verifyverify(spy).add(\"one\");verify(spy).add(\"two\"); 注意：由于 spy 是局部 mock，所以有时候使用 when(Object) 时，无法做到存根作用。此时，就可以考虑使用 doReturn() | Answer() | Throw() 这类方法进行存根： 123456List list = new LinkedList();List spy = spy(list);// Impossible: real method is called so spy.get(0) throws IndexOutOfBoundsException (the list is yet empty)when(spy.get(0)).thenReturn(\"foo\");// You have to use doReturn() for stubbingdoReturn(\"foo\").when(spy).get(0); spy 并不是 真实对象 的 代理。相反的，它对传递过来的 真实对象 进行 克隆。所以，对 真实对象 的任何操作，spy 对象并不会感知到。同理，对 spy 对象的任何操作，也不会影响到 真实对象。 当然，如果使用 mock 进行对象的 局部 mock，通过 doCallRealMethod() | thenCallRealMethod() 方法也是可以的： 12345// You can enable partial mock capabilities selectively on mocks:Foo mock = mock(Foo.class);// Be sure the real implementation is 'safe'.// If real implementation throws exceptions or depends on specific state of the object then you're in trouble.when(mock.someMethod()).thenCallRealMethod(); 测试驱动开发以 行为驱动开发 的格式使用 //given //when //then 注释为测试用法基石编写测试用例，这正是 Mockito 官方编写测试用例方法，强烈建议使用这种方式测试编写。 12345678910111213import static org.mockito.BDDMockito.*;Seller seller = mock(Seller.class);Shop shop = new Shop(seller);public void shouldBuyBread() throws Exception &#123; // Given given(seller.askForBread()).willReturn(new Bread()); // When Goods goods = shop.buyBread(); // Then assertThat(goods, containBread());&#125; 自定义错误校验输出信息1234// Will print a custom message on verification failureverify(mock, description(\"This will print on failure\")).someMethod();// Will work with any verification modeverify(mock, times(2).description(\"someMethod should be called twice\")).someMethod(); @InjectMock构造器，方法，成员变量依赖注入使用 @InjectMock 注解时，Mockito 会检查 类构造器，方法 或 成员变量，依据它们的 类型 进行自动 mock。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class InjectMockTest &#123; @Mock private User user; @Mock private ArticleDatabase database; @InjectMocks private ArticleManager manager; @Rule public MockitoRule mockitoRule = MockitoJUnit.rule(); @Test public void testInjectMock() &#123; // Calls addListener with an instance of ArticleListener manager.initialize(); // Validate that addListener was called verify(database).addListener(any(ArticleListener.class)); &#125; public static class ArticleManager &#123; private User user; private ArticleDatabase database; public ArticleManager(User user, ArticleDatabase database) &#123; super(); this.user = user; this.database = database; &#125; public void initialize() &#123; database.addListener(new ArticleListener()); &#125; &#125; public static class User &#123; &#125; public static class ArticleListener &#123; &#125; public static class ArticleDatabase &#123; public void addListener(ArticleListener listener) &#123; &#125; &#125;&#125; 成员变量 manager 类型为 ArticleManager，它的上面标识别了 @InjectMocks。这意味着要 mock 出 manager，Mockito 需要先自动 mock 出 ArticleManager 所需的 构造参数（即：user 和 database），最终 mock 得到一个 ArticleManager，赋值给 manager。 参数捕捉ArgumentCaptor 允许在 verify 的时候获取 方法参数内容，这使得我们能在 测试过程 中能对 调用方法参数 进行 捕捉 并 测试。 1234567891011121314@Rulepublic MockitoRule mockitoRule = MockitoJUnit.rule();@Captorprivate ArgumentCaptor&lt;List&lt;String&gt;&gt; captor;@Testpublic void testArgumentCaptor()&#123; List&lt;String&gt; asList = Arrays.asList(\"someElement_test\", \"someElement\"); final List&lt;String&gt; mockedList = mock(List.class); mockedList.addAll(asList); verify(mockedList).addAll(captor.capture()); // When verify,you can capture the arguments of the calling method final List&lt;String&gt; capturedArgument = captor.getValue(); assertThat(capturedArgument, hasItem(\"someElement\"));&#125; Mocktio的局限 不能 mock 静态方法； 不能 mock 构造器； 不能 mock equals() 和 hashCode() 方法。 欢迎关注技术公众号：零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"测试框架系列","slug":"测试框架系列","permalink":"https://ostenant.coding.me/categories/测试框架系列/"}],"tags":[{"name":"Mockito","slug":"Mockito","permalink":"https://ostenant.coding.me/tags/Mockito/"}]},{"title":"2018服务端架构师技术图谱","slug":"2018服务端架构师技术图谱","date":"2018-05-30T14:46:00.000Z","updated":"2018-06-18T01:47:17.430Z","comments":true,"path":"2018/05/30/2018服务端架构师技术图谱/","link":"","permalink":"https://ostenant.coding.me/2018/05/30/2018服务端架构师技术图谱/","excerpt":"本文摘自 github 上的一篇长约 10 万字服务端架构师技术总结归纳文档，覆盖广度包括数据结构、算法、并发、操作系统、设计模式、运维、中间件、网络、数据库、搜索引擎、性能、大数据、安全、常见开源框架、分布式、设计思想、项目管理和技术资源等。","text":"本文摘自 github 上的一篇长约 10 万字服务端架构师技术总结归纳文档，覆盖广度包括数据结构、算法、并发、操作系统、设计模式、运维、中间件、网络、数据库、搜索引擎、性能、大数据、安全、常见开源框架、分布式、设计思想、项目管理和技术资源等。 目录 数据结构 队列 集合 链表、数组 字典、关联数组 栈 树 二叉树 完全二叉树 平衡二叉树 二叉查找树（BST） 红黑树 B-，B+，B*树 LSM 树 BitSet 常用算法 排序、查找算法 选择排序 冒泡排序 插入排序 快速排序 归并排序 希尔排序 堆排序 计数排序 桶排序 基数排序 二分查找 Java 中的排序工具 布隆过滤器 字符串比较 KMP 算法 深度优先、广度优先 贪心算法 回溯算法 剪枝算法 动态规划 朴素贝叶斯 推荐算法 最小生成树算法 最短路径算法 并发 多线程 线程安全 一致性、事务 事务 ACID 特性 事务的隔离级别 MVCC 锁 Java中的锁和同步类 公平锁 &amp; 非公平锁 悲观锁 乐观锁 &amp; CAS ABA 问题 CopyOnWrite容器 RingBuffer 可重入锁 &amp; 不可重入锁 互斥锁 &amp; 共享锁 死锁 操作系统 计算机原理 CPU 多级缓存 进程 线程 协程 Linux 设计模式 设计模式的六大原则 23种常见设计模式 应用场景 单例模式 责任链模式 MVC IOC AOP UML 微服务思想 康威定律 运维 &amp; 统计 &amp; 技术支持 常规监控 APM 统计分析 持续集成(CI/CD) Jenkins 环境分离 自动化运维 Ansible puppet chef 测试 TDD 理论 单元测试 压力测试 全链路压测 A/B 、灰度、蓝绿测试 虚拟化 KVM Xen OpenVZ 容器技术 Docker 云技术 OpenStack DevOps 文档管理 中间件 Web Server Nginx OpenResty Apache Httpd Tomcat 架构原理 调优方案 Jetty 缓存 本地缓存 客户端缓存 服务端缓存 Web缓存 Memcached Redis 架构 回收策略 Tair 消息队列 消息总线 消息的顺序 RabbitMQ RocketMQ ActiveMQ Kafka Redis 消息推送 ZeroMQ 定时调度 单机定时调度 分布式定时调度 RPC Dubbo Thrift gRPC 数据库中间件 Sharding Jdbc 日志系统 日志搜集 配置中心 API 网关 网络 协议 OSI 七层协议 TCP/IP HTTP HTTP2.0 HTTPS 网络模型 Epoll Java NIO kqueue 连接和短连接 框架 零拷贝（Zero-copy） 序列化(二进制协议) Hessian Protobuf 数据库 基础理论 数据库设计的三大范式 MySQL 原理 InnoDB 优化 索引 聚集索引, 非聚集索引 复合索引 自适应哈希索引(AHI) explain NoSQL MongoDB Hbase 搜索引擎 搜索引擎原理 Lucene Elasticsearch Solr sphinx 性能 性能优化方法论 容量评估 CDN 网络 连接池 性能调优 大数据 流式计算 Storm Flink Kafka Stream 应用场景 Hadoop HDFS MapReduce Yarn Spark 安全 web 安全 XSS CSRF SQL 注入 Hash Dos 脚本注入 漏洞扫描工具 验证码 DDoS 防范 用户隐私信息保护 序列化漏洞 加密解密 对称加密 哈希算法 非对称加密 服务器安全 数据安全 数据备份 网络隔离 内外网分离 登录跳板机 授权、认证 RBAC OAuth2.0 双因素认证（2FA） 单点登录(SSO) 常用开源框架 开源协议 日志框架 Log4j、Log4j2 Logback ORM 网络框架 Web 框架 Spring 家族 工具框架 分布式设计 扩展性设计 稳定性 &amp; 高可用 硬件负载均衡 软件负载均衡 限流 应用层容灾 跨机房容灾 容灾演练流程 平滑启动 数据库扩展 读写分离模式 分片模式 服务治理 服务注册与发现 服务路由控制 分布式一致 CAP 与 BASE 理论 分布式锁 分布式一致性算法 PAXOS Zab Raft Gossip 两阶段提交、多阶段提交 幂等 分布式一致方案 分布式 Leader 节点选举 TCC(Try/Confirm/Cancel) 柔性事务 分布式文件系统 唯一ID 生成 全局唯一ID 一致性Hash算法 设计思想 &amp; 开发模式 DDD(Domain-driven Design - 领域驱动设计) 命令查询职责分离(CQRS) 贫血，充血模型 Actor 模式 响应式编程 Reactor RxJava Vert.x DODAF2.0 Serverless Service Mesh 项目管理 架构评审 重构 代码规范 代码 Review RUP 看板管理 SCRUM 敏捷开发 极限编程（XP） 结对编程 FMEA管理模式 通用业务术语 技术趋势 政策、法规 法律 严格遵守刑法253法条 架构师素质 团队管理 招聘 资讯 行业资讯 公众号列表 博客 团队博客 个人博客 综合门户、社区 问答、讨论类社区 行业数据分析 专项网站 其他类 推荐参考书 在线电子书 纸质书 开发方面 架构方面 技术管理方面 基础理论 工具方面 大数据方面 技术资源 开源资源 手册、文档、教程 在线课堂 会议、活动 常用APP 找工作 工具 代码托管 文件服务 \b正文数据结构队列 《java队列——queue详细分析》 非阻塞队列：ConcurrentLinkedQueue(无界线程安全)，采用CAS机制（compareAndSwapObject原子操作）。 阻塞队列：ArrayBlockingQueue(有界)、LinkedBlockingQueue（无界）、DelayQueue、PriorityBlockingQueue，采用锁机制；使用 ReentrantLock 锁。 《LinkedList、ConcurrentLinkedQueue、LinkedBlockingQueue对比分析》 集合 《Java Set集合的详解》 链表、数组 《Java集合详解–什么是List》 字典、关联数组 《Java map 详解 - 用法、遍历、排序、常用API等》 栈 《java数据结构与算法之栈（Stack）设计与实现》 《Java Stack 类》 《java stack的详细实现分析》 Stack 是线程安全的。 内部使用数组保存数据，不够时翻倍。 树二叉树每个节点最多有两个叶子节点。 《二叉树》 完全二叉树 《完全二叉树》 叶节点只能出现在最下层和次下层，并且最下面一层的结点都集中在该层最左边的若干位置的二叉树。 平衡二叉树左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 《浅谈数据结构-平衡二叉树》 《浅谈算法和数据结构: 八 平衡查找树之2-3树》 二叉查找树（BST）二叉查找树（Binary Search Tree），也称有序二叉树（ordered binary tree）,排序二叉树（sorted binary tree）。 《浅谈算法和数据结构: 七 二叉查找树》 红黑树 《最容易懂得红黑树》 添加阶段后，左旋或者右旋从而再次达到平衡。 《浅谈算法和数据结构: 九 平衡查找树之红黑树》 B-，B+，B*树MySQL是基于B+树聚集索引组织表 《B-树，B+树，B*树详解》 《B-树，B+树与B*树的优缺点比较》 B+ 树的叶子节点链表结构相比于 B- 树便于扫库，和范围检索。LSM 树 LSM（Log-Structured Merge-Trees）和 B+ 树相比，是牺牲了部分读的性能来换取写的性能(通过批量写入)，实现读写之间的。Hbase、LevelDB、Tair（Long DB）、nessDB 采用 LSM 树的结构。LSM可以快速建立索引。 《LSM树 VS B+树》 B+ 树读性能好，但由于需要有序结构，当key比较分散时，磁盘寻道频繁，造成写性能。 LSM 是将一个大树拆分成N棵小树，先写到内存（无寻道问题，性能高），在内存中构建一颗有序小树（有序树），随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历（二分查找）所有的小树，但在每颗小树内部数据是有序的。 《LSM树（Log-Structured Merge Tree）存储引擎》 极端的说，基于LSM树实现的HBase的写性能比MySQL高了一个数量级，读性能低了一个数量级。 优化方式：Bloom filter 替代二分查找；compact 小数位大树，提高查询性能。 Hbase 中，内存中达到一定阈值后，整体flush到磁盘上、形成一个文件（B+数），HDFS不支持update操作，所以Hbase做整体flush而不是merge update。flush到磁盘上的小树，定期会合并成一个大树。 BitSet经常用于大规模数据的排重检查。 《Java Bitset类》 《Java BitSet（位集）》 常用算法 《常见排序算法及对应的时间复杂度和空间复杂度》 排序、查找算法 《常见排序算法及对应的时间复杂度和空间复杂度》 选择排序 《Java中的经典算法之选择排序（SelectionSort）》 每一趟从待排序的记录中选出最小的元素，顺序放在已排好序的序列最后，直到全部记录排序完毕。 冒泡排序 《冒泡排序的2种写法》 相邻元素前后交换、把最大的排到最后。 时间复杂度 O(n²) 插入排序 《排序算法总结之插入排序》 快速排序 《坐在马桶上看算法：快速排序》 一侧比另外一次都大或小。 归并排序 《图解排序算法(四)之归并排序》 分而治之，分成小份排序，在合并(重建一个新空间进行复制)。 希尔排序TODO 堆排序 《图解排序算法(三)之堆排序》 排序过程就是构建最大堆的过程，最大堆：每个结点的值都大于或等于其左右孩子结点的值，堆顶元素是最大值。 计数排序 《计数排序和桶排序》 和桶排序过程比较像，差别在于桶的数量。 桶排序 《【啊哈！算法】最快最简单的排序——桶排序》 《排序算法（三）：计数排序与桶排序》 桶排序将[0,1)区间划分为n个相同的大小的子区间，这些子区间被称为桶。 每个桶单独进行排序，然后再遍历每个桶。 基数排序按照个位、十位、百位、…依次来排。 《排序算法系列：基数排序》 《基数排序》 二分查找 《二分查找(java实现)》 要求待查找的序列有序。 时间复杂度 O(logN)。 《java实现二分查找-两种方式》 while + 递归。Java 中的排序工具 《Arrays.sort和Collections.sort实现原理解析》 Collections.sort算法调用的是合并排序。 Arrays.sort() 采用了2种排序算法 – 基本类型数据使用快速排序法，对象数组使用归并排序。 布隆过滤器常用于大数据的排重，比如email，url 等。核心原理：将每条数据通过计算产生一个指纹（一个字节或多个字节，但一定比原始数据要少很多），其中每一位都是通过随机计算获得，在将指纹映射到一个大的按位存储的空间中。注意：会有一定的错误率。优点：空间和时间效率都很高。缺点：随着存入的元素数量增加，误算率随之增加。 《布隆过滤器 – 空间效率很高的数据结构》 《大量数据去重：Bitmap和布隆过滤器(Bloom Filter)》 《基于Redis的布隆过滤器的实现》 基于 Redis 的 Bitmap 数据结构。 《网络爬虫：URL去重策略之布隆过滤器(BloomFilter)的使用》 使用Java中的 BitSet 类 和 加权和hash算法。 字符串比较KMP 算法KMP：Knuth-Morris-Pratt算法（简称KMP）核心原理是利用一个“部分匹配表”，跳过已经匹配过的元素。 《字符串匹配的KMP算法》 深度优先、广度优先 《广度优先搜索BFS和深度优先搜索DFS》 贪心算法 《算法：贪婪算法基础》 《常见算法及问题场景——贪心算法》 回溯算法 《 五大常用算法之四：回溯法》 剪枝算法 《α-β剪枝算法》 动态规划 《详解动态规划——邹博讲动态规划》 《动态规划算法的个人理解》 朴素贝叶斯 《带你搞懂朴素贝叶斯分类算法》 P(B|A)=P(A|B)P(B)/P(A) 《贝叶斯推断及其互联网应用1》 《贝叶斯推断及其互联网应用2》 推荐算法 《推荐算法综述》 《TOP 10 开源的推荐系统简介》 最小生成树算法 《算法导论–最小生成树（Kruskal和Prim算法）》 最短路径算法 《Dijkstra算法详解》 并发Java 并发 Java 并发知识合集 JAVA并发知识图谱 多线程 《40个Java多线程问题总结》 线程安全 《Java并发编程——线程安全及解决机制简介》 一致性、事务事务 ACID 特性 《数据库事务ACID特性》 事务的隔离级别 未提交读：一个事务可以读取另一个未提交的数据，容易出现脏读的情况。 读提交：一个事务等另外一个事务提交之后才可以读取数据，但会出现不可重复读的情况（多次读取的数据不一致），读取过程中出现UPDATE操作，会多。（大多数数据库默认级别是RC，比如SQL Server，Oracle），读取的时候不可以修改。 可重复读： 同一个事务里确保每次读取的时候，获得的是同样的数据，但不保障原始数据被其他事务更新（幻读），Mysql InnoDB 就是这个级别。 序列化：所有事物串行处理（牺牲了效率） 《理解事务的4种隔离级别》 数据库事务的四大特性及事务隔离级别 《MySQL的InnoDB的幻读问题 》 幻读的例子非常清楚。 通过 SELECT … FOR UPDATE 解决。 《一篇文章带你读懂MySQL和InnoDB》 图解脏读、不可重复读、幻读问题。 MVCC 《【mysql】关于innodb中MVCC的一些理解》 innodb 中 MVCC 用在 Repeatable-Read 隔离级别。 MVCC 会产生幻读问题（更新时异常。） 《轻松理解MYSQL MVCC 实现机制》 通过隐藏版本列来实现 MVCC 控制，一列记录创建时间、一列记录删除时间，这里的时间 每次只操作比当前版本小（或等于）的 行。 锁Java中的锁和同步类 《Java中的锁分类》 主要包括 synchronized、ReentrantLock、和 ReadWriteLock。 《Java并发之AQS详解》 《Java中信号量 Semaphore》 有数量控制 申请用 acquire，申请不要则阻塞；释放用 release。 《java开发中的Mutex vs Semaphore》 简单的说 就是Mutex是排它的，只有一个可以获取到资源， Semaphore也具有排它性，但可以定义多个可以获取的资源的对象。 公平锁 &amp; 非公平锁公平锁的作用就是严格按照线程启动的顺序来执行的，不允许其他线程插队执行的；而非公平锁是允许插队的。 《公平锁与非公平锁》 默认情况下 ReentrantLock 和 synchronized 都是非公平锁。ReentrantLock 可以设置成公平锁。 悲观锁悲观锁如果使用不当（锁的条数过多），会引起服务大面积等待。推荐优先使用乐观锁+重试。 《【MySQL】悲观锁&amp;乐观锁》 乐观锁的方式：版本号+重试方式 悲观锁：通过 select … for update 进行行锁(不可读、不可写，share 锁可读不可写)。 《Mysql查询语句使用select.. for update导致的数据库死锁分析》 mysql的innodb存储引擎实务锁虽然是锁行，但它内部是锁索引的。 锁相同数据的不同索引条件可能会引起死锁。 《Mysql并发时经典常见的死锁原因及解决方法》 乐观锁 &amp; CAS 《乐观锁的一种实现方式——CAS》 和MySQL乐观锁方式相似，只不过是通过和原值进行比较。 ABA 问题由于高并发，在CAS下，更新后可能此A非彼A。通过版本号可以解决，类似于上文Mysql 中提到的的乐观锁。 《Java CAS 和ABA问题》 《Java 中 ABA问题及避免》 AtomicStampedReference 和 AtomicStampedReference。 CopyOnWrite容器可以对CopyOnWrite容器进行并发的读，而不需要加锁。CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，不适合需要数据强一致性的场景。 《JAVA中写时复制(Copy-On-Write)Map实现》 实现读写分离，读取发生在原始数据上，写入发生在副本上。 不用加锁，通过最终一致实现一致性。 《聊聊并发-Java中的Copy-On-Write容器》 RingBuffer 《线程安全的无锁RingBuffer的实现【一个读线程，一个写线程】》 可重入锁 &amp; 不可重入锁 《可重入锁和不可重入锁》 通过简单代码举例说明可重入锁和不可重入锁。 可重入锁指同一个线程可以再次获得之前已经获得的锁。 可重入锁可以用户避免死锁。 Java中的可重入锁：synchronized 和 java.util.concurrent.locks.ReentrantLock 《ReenTrantLock可重入锁（和synchronized的区别）总结》 synchronized 使用方便，编译器来加锁，是非公平锁。 ReenTrantLock 使用灵活，锁的公平性可以定制。 相同加锁场景下，推荐使用 synchronized。 互斥锁 &amp; 共享锁互斥锁：同时只能有一个线程获得锁。比如，ReentrantLock 是互斥锁，ReadWriteLock 中的写锁是互斥锁。共享锁：可以有多个线程同时或的锁。比如，Semaphore、CountDownLatch 是共享锁，ReadWriteLock 中的读锁是共享锁。 《ReadWriteLock场景应用》 死锁 《“死锁”四个必要条件的合理解释》 互斥、持有、不可剥夺、环形等待。 Java如何查看死锁？ JConsole 可以识别死锁。 java多线程系列：死锁及检测 jstack 可以显示死锁。 操作系统计算机原理 《操作系统基础知识——操作系统的原理，类型和结构》 CPU多级缓存典型的 CPU 有三级缓存，距离核心越近，速度越快，空间越小。L1 一般 32k，L2 一般 256k，L3 一般12M。内存速度需要200个 CPU 周期，CPU 缓存需要1个CPU周期。 《从Java视角理解CPU缓存和伪共享》 进程TODO 线程 《线程的生命周期及状态转换详解》 协程 《终结python协程—-从yield到actor模型的实现》 线程的调度是由操作系统负责，协程调度是程序自行负责 与线程相比，协程减少了无谓的操作系统切换. 实际上当遇到IO操作时做切换才更有意义，（因为IO操作不用占用CPU），如果没遇到IO操作，按照时间片切换. Linux 《Linux 命令大全》 设计模式设计模式的六大原则 《设计模式的六大原则》 开闭原则：对扩展开放,对修改关闭，多使用抽象类和接口。 里氏替换原则：基类可以被子类替换，使用抽象类继承,不使用具体类继承。 依赖倒转原则：要依赖于抽象,不要依赖于具体，针对接口编程,不针对实现编程。 接口隔离原则：使用多个隔离的接口,比使用单个接口好，建立最小的接口。 迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用，通过中间类建立联系。 合成复用原则：尽量使用合成/聚合,而不是使用继承。 23种常见设计模式 《设计模式》 《23种设计模式全解析》 应用场景 《细数JDK里的设计模式》 结构型模式： 适配器：用来把一个接口转化成另一个接口，如 java.util.Arrays#asList()。 桥接模式：这个模式将抽象和抽象操作的实现进行了解耦，这样使得抽象和实现可以独立地变化，如JDBC； 组合模式：使得客户端看来单个对象和对象的组合是同等的。换句话说，某个类型的方法同时也接受自身类型作为参数，如 Map.putAll，List.addAll、Set.addAll。 装饰者模式：动态的给一个对象附加额外的功能，这也是子类的一种替代方式，如 java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap。 享元模式：使用缓存来加速大量小对象的访问时间，如 valueOf(int)。 代理模式：代理模式是用一个简单的对象来代替一个复杂的或者创建耗时的对象，如 java.lang.reflect.Proxy 创建模式: 抽象工厂模式：抽象工厂模式提供了一个协议来生成一系列的相关或者独立的对象，而不用指定具体对象的类型，如 java.util.Calendar#getInstance()。 建造模式(Builder)：定义了一个新的类来构建另一个类的实例，以简化复杂对象的创建，如：java.lang.StringBuilder#append()。 工厂方法：就是 一个返* 回具体对象的方法，而不是多个，如 java.lang.Object#toString()、java.lang.Class#newInstance()。 原型模式：使得类的实例能够生成自身的拷贝、如：java.lang.Object#clone()。 单例模式：全局只有一个实例，如 java.lang.Runtime#getRuntime()。 行为模式： 责任链模式：通过把请求从一个对象传递到链条中下一个对象的方式，直到请求被处理完毕，以实现对象间的解耦。如 javax.servlet.Filter#doFilter()。 命令模式：将操作封装到对象内，以便存储，传递和返回，如：java.lang.Runnable。 解释器模式：定义了一个语言的语法，然后解析相应语法的语句，如，java.text.Format，java.text.Normalizer。 迭代器模式：提供一个一致的方法来顺序访问集合中的对象，如 java.util.Iterator。 中介者模式：通过使用一个中间对象来进行消息分发以及减少类之间的直接依赖，java.lang.reflect.Method#invoke()。 空对象模式：如 java.util.Collections#emptyList()。 观察者模式：它使得一个对象可以灵活的将消息发送给感兴趣的对象，如 java.util.EventListener。 模板方法模式：让子类可以重写方法的一部分，而不是整个重写，如 java.util.Collections#sort()。 《Spring-涉及到的设计模式汇总》 《Mybatis使用的设计模式》 单例模式 《单例模式的三种实现 以及各自的优缺点》 《单例模式－－反射－－防止序列化破坏单例模式》 使用枚举类型。 责任链模式TODO MVC 《MVC 模式》 模型(model)－视图(view)－控制器(controller) IOC 《理解 IOC》 《IOC 的理解与解释》 正向控制：传统通过new的方式。反向控制，通过容器注入对象。 作用：用于模块解耦。 DI：Dependency Injection，即依赖注入，只关心资源使用，不关心资源来源。 AOP 《轻松理解AOP(面向切面编程)》 《Spring AOP详解》 《Spring AOP的实现原理》 Spring AOP使用的动态代理，主要有两种方式：JDK动态代理和CGLIB动态代理。 《Spring AOP 实现原理与 CGLIB 应用》 Spring AOP 框架对 AOP 代理类的处理原则是：如果目标对象的实现类实现了接口，Spring AOP 将会采用 JDK 动态代理来生成 AOP 代理类；如果目标对象的实现类没有实现接口，Spring AOP 将会采用 CGLIB 来生成 AOP 代理类 UML 《UML教程》 微服务思想 《微服务架构设计》 《微服务架构技术栈选型手册》 康威定律 《微服务架构的理论基础 - 康威定律》 定律一：组织沟通方式会通过系统设计表达出来，就是说架构的布局和组织结构会有相似。 定律二：时间再多一件事情也不可能做的完美，但总有时间做完一件事情。一口气吃不成胖子，先搞定能搞定的。 定律三：线型系统和线型组织架构间有潜在的异质同态特性。种瓜得瓜，做独立自治的子系统减少沟通成本。 定律四：大的系统组织总是比小系统更倾向于分解。合久必分，分而治之。 《微服务架构核⼼20讲》 运维 &amp; 统计 &amp; 技术支持常规监控 《腾讯业务系统监控的修炼之路》 监控的方式：主动、被动、旁路(比如舆情监控) 监控类型： 基础监控、服务端监控、客户端监控、监控、用户端监控 监控的目标：全、块、准 核心指标：请求量、成功率、耗时 《开源还是商用？十大云运维监控工具横评》 Zabbix、Nagios、Ganglia、Zenoss、Open-falcon、监控宝、 360网站服务监控、阿里云监控、百度云观测、小蜜蜂网站监测等。 《监控报警系统搭建及二次开发经验》 命令行监控工具 《常用命令行监控工具》 top、sar、tsar、nload 《20个命令行工具监控 Linux 系统性能》 《JVM性能调优监控工具jps、jstack、jmap、jhat、jstat、hprof使用详解》 APMAPM — Application Performance Management 《Dapper，大规模分布式系统的跟踪系统》 CNCF OpenTracing，中文版 主要开源软件，按字母排序 Apache SkyWalking CAT CNCF jaeger Pinpoint Zipkin 《开源APM技术选型与实战》 主要基于 Google的Dapper（大规模分布式系统的跟踪系统） 思想。 统计分析 《流量统计的基础：埋点》 常用指标：访问与访客、停留时长、跳出率、退出率、转化率、参与度 《APP埋点常用的统计工具、埋点目标和埋点内容》 第三方统计：友盟、百度移动、魔方、App Annie、talking data、神策数据等。 《美团点评前端无痕埋点实践》 所谓无痕、即通过可视化工具配置采集节点，在前端自动解析配置并上报埋点数据，而非硬编码。 持续集成(CI/CD) 《持续集成是什么？》 《8个流行的持续集成工具》 Jenkins 《使用Jenkins进行持续集成》 环境分离开发、测试、生成环境分离。 《开发环境、生产环境、测试环境的基本理解和区》 自动化运维Ansible 《Ansible中文权威指南》 《Ansible基础配置和企业级项目实用案例》 puppet 《自动化运维工具——puppet详解》 chef 《Chef 的安装与使用》 测试TDD 理论 《深度解读 - TDD（测试驱动开发）》 基于测试用例编码功能代码，XP（Extreme Programming）的核心实践. 好处：一次关注一个点，降低思维负担；迎接需求变化或改善代码的设计；提前澄清需求；快速反馈； 单元测试 《Java单元测试之JUnit篇》 《JUnit 4 与 TestNG 对比》 TestNG 覆盖 JUnit 功能，适用于更复杂的场景。 《单元测试主要的测试功能点》 模块接口测试、局部数据结构测试、路径测试 、错误处理测试、边界条件测试 。 压力测试 《Apache ab 测试使用指南》 《大型网站压力测试及优化方案》 《10大主流压力/负载/性能测试工具推荐》 《真实流量压测工具 tcpcopy应用浅析》 《nGrinder 简易使用教程》 全链路压测 《京东618：升级全链路压测方案，打造军演机器人ForceBot》 《饿了么全链路压测的探索与实践》 《四大语言，八大框架｜滴滴全链路压测解决之道》 《全链路压测经验》 A/B 、灰度、蓝绿测试 《技术干货 | AB 测试和灰度发布探索及实践》 《nginx 根据IP 进行灰度发布》 《蓝绿部署、A/B 测试以及灰度发布》 虚拟化 《VPS的三种虚拟技术OpenVZ、Xen、KVM优缺点比较》 KVM 《KVM详解，太详细太深入了，经典》 《【图文】KVM 虚拟机安装详解》 Xen 《Xen虚拟化基本原理详解》 OpenVZ 《开源Linux容器 OpenVZ 快速上手指南》 容器技术Docker 《几张图帮你理解 docker 基本原理及快速入门》 《Docker 核心技术与实现原理》 《Docker 教程》 云技术OpenStack 《OpenStack构架知识梳理》 DevOps 《一分钟告诉你究竟DevOps是什么鬼？》 《DevOps详解》 文档管理 Confluence-收费文档管理系统 GitLab? Wiki 中间件Web ServerNginx 《Ngnix的基本学习-多进程和Apache的比较》 Nginx 通过异步非阻塞的事件处理机制实现高并发。Apache 每个请求独占一个线程，非常消耗系统资源。 事件驱动适合于IO密集型服务(Nginx)，多进程或线程适合于CPU密集型服务(Apache)，所以Nginx适合做反向代理，而非web服务器使用。 《nginx与Apache的对比以及优缺点》 nginx只适合静态和反向代理，不适合处理动态请求。 OpenResty 官方网站 《浅谈 OpenResty》 通过 Lua 模块可以在Nginx上进行开发。 Apache Httpd 官方网站 Tomcat架构原理 《TOMCAT原理详解及请求过程》 《Tomcat服务器原理详解》 《Tomcat 系统架构与设计模式,第 1 部分: 工作原理》 《四张图带你了解Tomcat系统架构》 《JBoss vs. Tomcat: Choosing A Java Application Server》 Tomcat 是轻量级的 Serverlet 容器，没有实现全部 JEE 特性（比如持久化和事务处理），但可以通过其他组件代替，比如Srping。 Jboss 实现全部了JEE特性，软件开源免费、文档收费。 调优方案 《Tomcat 调优方案》 启动NIO模式（或者APR）；调整线程池；禁用AJP连接器（Nginx+tomcat的架构，不需要AJP）； 《tomcat http协议与ajp协议》 《AJP与HTTP比较和分析》 AJP 协议（8009端口）用于降低和前端Server（如Apache，而且需要支持AJP协议）的连接数(前端)，通过长连接提高性能。 并发高时，AJP协议优于HTTP协议。 Jetty 《Jetty 的工作原理以及与 Tomcat 的比较》 《jetty和tomcat优势比较》 架构比较:Jetty的架构比Tomcat的更为简单。 性能比较：Jetty和Tomcat性能方面差异不大，Jetty默认采用NIO结束在处理I/O请求上更占优势，Tomcat默认采用BIO处理I/O请求，Tomcat适合处理少数非常繁忙的链接，处理静态资源时性能较差。 其他方面：Jetty的应用更加快速，修改简单，对新的Servlet规范的支持较好;Tomcat 对JEE和Servlet 支持更加全面。 缓存 《缓存失效策略（FIFO 、LRU、LFU三种算法的区别）》 本地缓存 《HashMap本地缓存》 《EhCache本地缓存》 堆内、堆外、磁盘三级缓存。 可按照缓存空间容量进行设置。 按照时间、次数等过期策略。 《Guava Cache》 简单轻量、无堆外、磁盘缓存。 《Nginx本地缓存》 《Pagespeed—懒人工具，服务器端加速》 客户端缓存 《浏览器端缓存》 主要是利用 Cache-Control 参数。 《H5 和移动端 WebView 缓存机制解析与实战》 服务端缓存Web缓存 nuster - nuster cache varnish - varnish cache squid - squid cache Memcached 《Memcached 教程》 《深入理解Memcached原理》 采用多路复用技术提高并发性。 slab分配算法： memcached给Slab分配内存空间，默认是1MB。分配给Slab之后 把slab的切分成大小相同的chunk，Chunk是用于缓存记录的内存空间，Chunk 的大小默认按照1.25倍的速度递增。好处是不会频繁申请内存，提高IO效率，坏处是会有一定的内存浪费。 《Memcached软件工作原理》 《Memcache技术分享：介绍、使用、存储、算法、优化、命中率》 《memcache 中 add 、 set 、replace 的区别》 区别在于当key存在还是不存在时，返回值是true和false的。 《memcached全面剖析》 Redis 《Redis 教程》 《redis底层原理》 使用 ziplist 存储链表，ziplist是一种压缩链表，它的好处是更能节省内存空间，因为它所存储的内容都是在连续的内存区域当中的。 使用 skiplist(跳跃表)来存储有序集合对象、查找上先从高Level查起、时间复杂度和红黑树相当，实现容易，无锁、并发性好。 《Redis持久化方式》 RDB方式：定期备份快照，常用于灾难恢复。优点：通过fork出的进程进行备份，不影响主进程、RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。缺点：会丢数据。 AOF方式：保存操作日志方式。优点：恢复时数据丢失少，缺点：文件大，回复慢。 也可以两者结合使用。 《分布式缓存–序列3–原子操作与CAS乐观锁》 架构 《Redis单线程架构》 回收策略 《redis的回收策略》 Tair 官方网站 《Tair和Redis的对比》 特点：可以配置备份节点数目，通过异步同步到备份节点 一致性Hash算法。 架构：和Hadoop 的设计思想类似，有Configserver，DataServer，Configserver 通过心跳来检测，Configserver也有主备关系。 几种存储引擎: MDB，完全内存性，可以用来存储Session等数据。 Rdb（类似于Redis），轻量化，去除了aof之类的操作，支持Restfull操作 LDB（LevelDB存储引擎），持久化存储，LDB 作为rdb的持久化，google实现，比较高效，理论基础是LSM(Log-Structured-Merge Tree)算法，现在内存中修改数据，达到一定量时（和内存汇总的旧数据一同写入磁盘）再写入磁盘，存储更加高效，县比喻Hash算法。 Tair采用共享内存来存储数据，如果服务挂掉（非服务器），重启服务之后，数据亦然还在。 消息队列 《消息队列-推/拉模式学习 &amp; ActiveMQ及JMS学习》 RabbitMQ 消费者默认是推模式（也支持拉模式）。 Kafka 默认是拉模式。 Push方式：优点是可以尽可能快地将消息发送给消费者，缺点是如果消费者处理能力跟不上，消费者的缓冲区可能会溢出。 Pull方式：优点是消费端可以按处理能力进行拉去，缺点是会增加消息延迟。 《Kafka、RabbitMQ、RocketMQ等消息中间件的对比 —— 消息发送性能和区别》 消息总线消息总线相当于在消息队列之上做了一层封装，统一入口，统一管控、简化接入成本。 《消息总线VS消息队列》 消息的顺序 《如何保证消费者接收消息的顺序》 RabbitMQ支持事务，推拉模式都是支持、适合需要可靠性消息传输的场景。 《RabbitMQ的应用场景以及基本原理介绍》 《消息队列之 RabbitMQ》 《RabbitMQ之消息确认机制（事务+Confirm）》 RocketMQJava实现，推拉模式都是支持，吞吐量逊于Kafka。可以保证消息顺序。 《RocketMQ 实战之快速入门》 《RocketMQ 源码解析》 ActiveMQ纯Java实现，兼容JMS，可以内嵌于Java应用中。 《ActiveMQ消息队列介绍》 Kafka高吞吐量、采用拉模式。适合高IO场景，比如日志同步。 官方网站 《各消息队列对比，Kafka深度解析，众人推荐，精彩好文！》 《Kafka分区机制介绍与示例》 Redis 消息推送生产者、消费者模式完全是客户端行为，list 和 拉模式实现，阻塞等待采用 blpop 指令。 《Redis学习笔记之十：Redis用作消息队列》 ZeroMQ TODO 定时调度单机定时调度 《linux定时任务cron配置》 《Linux cron运行原理》 fork 进程 + sleep 轮询 《Quartz使用总结》 《Quartz源码解析 —- 触发器按时启动原理》 《quartz原理揭秘和源码解读》 定时调度在 QuartzSchedulerThread 代码中，while()无限循环，每次循环取出时间将到的trigger，触发对应的job，直到调度器线程被关闭。 分布式定时调度 《这些优秀的国产分布式任务调度系统，你用过几个？》 opencron、LTS、XXL-JOB、Elastic-Job、Uncode-Schedule、Antares 《Quartz任务调度的基本实现原理》 Quartz集群中，独立的Quartz节点并不与另一其的节点或是管理节点通信，而是通过相同的数据库表来感知到另一Quartz应用的 《Elastic-Job-Lite 源码解析》 《Elastic-Job-Cloud 源码解析》 RPC 《从零开始实现RPC框架 - RPC原理及实现》 核心角色：Server: 暴露服务的服务提供方、Client: 调用远程服务的服务消费方、Registry: 服务注册与发现的注册中心。 《分布式RPC框架性能大比拼 dubbo、motan、rpcx、gRPC、thrift的性能比较》 Dubbo 官方网站 dubbo实现原理简单介绍 SPITODO Thrift 官方网站 《Thrift RPC详解》 支持多语言，通过中间语言定义接口。 gRPC服务端可以认证加密，在外网环境下，可以保证数据安全。 官方网站 《你应该知道的RPC原理》 数据库中间件Sharding Jdbc 官网 日志系统日志搜集 《从零开始搭建一个ELKB日志收集系统》 《用ELK搭建简单的日志收集分析系统》 《日志收集系统-探究》 配置中心 Apollo - 携程开源的配置中心应用 Spring Boot 和 Spring Cloud 支持推、拉模式更新配置 支持多种语言 《基于zookeeper实现统一配置管理》 《 Spring Cloud Config 分布式配置中心使用教程》 servlet 3.0 异步特性可用于配置中心的客户端 《servlet3.0 新特性——异步处理》 API 网关主要职责：请求转发、安全认证、协议转换、容灾。 《API网关那些儿》 《谈API网关的背景、架构以及落地方案》 《使用Zuul构建API Gateway》 《Spring Cloud Gateway 源码解析》 《HTTP API网关选择之一Kong介绍》 网络协议OSI 七层协议 《OSI七层协议模型、TCP/IP四层模型学习笔记》 TCP/IP 《深入浅出 TCP/IP 协议》 《TCP协议中的三次握手和四次挥手》 HTTP 《http协议详解(超详细)》 HTTP2.0 《HTTP 2.0 原理详细分析》 《HTTP2.0的基本单位为二进制帧》 利用二进制帧负责传输。 多路复用。 HTTPS 《https原理通俗了解》 使用非对称加密协商加密算法 使用对称加密方式传输数据 使用第三方机构签发的证书，来加密公钥，用于公钥的安全传输、防止被中间人串改。 《八大免费SSL证书-给你的网站免费添加Https安全加密》 网络模型 《web优化必须了解的原理之I/o的五种模型和web的三种工作模式》 五种I/O模型：阻塞I/O，非阻塞I/O，I/O复用、事件(信号)驱动I/O、异步I/O，前四种I/O属于同步操作，I/O的第一阶段不同、第二阶段相同，最后的一种则属于异步操作。 三种 Web Server 工作方式：Prefork(多进程)、Worker方式(线程方式)、Event方式。 《select、poll、epoll之间的区别总结》 select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。 select 有打开文件描述符数量限制，默认1024（2048 for x64），100万并发，就要用1000个进程、切换开销大；poll采用链表结构，没有数量限制。 select，poll “醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，通过回调机制节省大量CPU时间；select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，而epoll只要一次拷贝。 poll会随着并发增加，性能逐渐下降，epoll采用红黑树结构，性能稳定，不会随着连接数增加而降低。 《select，poll，epoll比较 》 在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 《深入理解Java NIO》 NIO 是一种同步非阻塞的 IO 模型。同步是指线程不断轮询 IO 事件是否就绪，非阻塞是指线程在等待 IO 的时候，可以同时做其他任务 《BIO与NIO、AIO的区别》 《两种高效的服务器设计模型：Reactor和Proactor模型》 Epoll 《epoll使用详解（精髓）》 Java NIO 《深入理解Java NIO》 《Java NIO编写Socket服务器的一个例子》 kqueue 《kqueue用法简介》 连接和短连接 《TCP/IP系列——长连接与短连接的区别》 框架 《Netty原理剖析》 Reactor 模式介绍。 Netty 是 Reactor 模式的一种实现。 零拷贝（Zero-copy） 《对于 Netty ByteBuf 的零拷贝(Zero Copy) 的理解》 多个物理分离的buffer，通过逻辑上合并成为一个，从而避免了数据在内存之间的拷贝。 序列化(二进制协议)Hessian 《Hessian原理分析》Binary-RPC;不仅仅是序列化 Protobuf 《Protobuf协议的Java应用例子》Goolge出品、占用空间和效率完胜其他序列化类库，如Hessian；需要编写 .proto 文件。 《Protocol Buffers序列化协议及应用》 * 关于协议的解释；缺点：可读性差; 《简单的使用 protobuf 和 protostuff》 protostuff 的好处是不用写 .proto 文件，Java 对象直接就可以序列化。 数据库基础理论数据库设计的三大范式 《数据库的三大范式以及五大约束》 第一范式：数据表中的每一列（每个字段）必须是不可拆分的最小单元，也就是确保每一列的原子性； 第二范式（2NF）：满足1NF后，要求表中的所有列，都必须依赖于主键，而不能有任何一列与主键没有关系，也就是说一个表只描述一件事情； 第三范式：必须先满足第二范式（2NF），要求：表中的每一列只与主键直接相关而不是间接相关，（表中的每一列只能依赖于主键）； MySQL原理 《MySQL的InnoDB索引原理详解》 《MySQL存储引擎－－MyISAM与InnoDB区别》 两种类型最主要的差别就是Innodb 支持事务处理与外键和行级锁 《myisam和innodb索引实现的不同》 InnoDB 《一篇文章带你读懂Mysql和InnoDB》 优化 《MySQL36条军规》 《MYSQL性能优化的最佳20+条经验》 《SQL优化之道》 《mysql数据库死锁的产生原因及解决办法》 《导致索引失效的可能情况》 《 MYSQL分页limit速度太慢优化方法》 原则上就是缩小扫描范围。 索引聚集索引, 非聚集索引 《MySQL 聚集索引/非聚集索引简述》 《MyISAM和InnoDB的索引实现》 MyISAM 是非聚集，InnoDB 是聚集 复合索引 《复合索引的优点和注意事项》 自适应哈希索引(AHI) 《InnoDB存储引擎——自适应哈希索引》 explain 《MySQL 性能优化神器 Explain 使用分析》 NoSQLMongoDB MongoDB 教程 《Mongodb相对于关系型数据库的优缺点》 优点：弱一致性（最终一致），更能保证用户的访问速度；内置GridFS，支持大容量的存储；Schema-less 数据库，不用预先定义结构；内置Sharding；相比于其他NoSQL，第三方支持丰富；性能优越； 缺点：mongodb不支持事务操作；mongodb占用空间过大；MongoDB没有如MySQL那样成熟的维护工具，这对于开发和IT运营都是个值得注意的地方； Hbase 《简明 HBase 入门教程（开篇）》 《深入学习HBase架构原理》 《传统的行存储和（HBase）列存储的区别》 《Hbase与传统数据库的区别》 空数据不存储，节省空间，且适用于并发。 《HBase Rowkey设计》 rowkey 按照字典顺序排列，便于批量扫描。 通过散列可以避免热点。 搜索引擎搜索引擎原理 《倒排索引–搜索引擎入门》 Lucene 《Lucene入门简介》 Elasticsearch 《Elasticsearch学习，请先看这一篇！》 《Elasticsearch索引原理》 Solr 《 Apache Solr入门教程》 《elasticsearch与solr比较》 sphinx 《Sphinx 的介绍和原理探索》 性能性能优化方法论 《15天的性能优化工作，5方面的调优经验》 代码层面、业务层面、数据库层面、服务器层面、前端优化。 《系统性能优化的几个方面》 容量评估 《联网性能与容量评估的方法论和典型案例》 《互联网架构，如何进行容量设计？》 评估总访问量、评估平均访问量QPS、评估高峰QPS、评估系统、单机极限QPS CDN 网络 《CDN加速原理》 《国内有哪些比较好的 CDN？》 连接池 《主流Java数据库连接池比较与开发配置实战》 性能调优 《九大Java性能调试工具，必备至少一款》 大数据流式计算Storm 官方网站 《最详细的Storm入门教程》 Flink 《Flink之一 Flink基本原理介绍》 Kafka Stream 《Kafka Stream调研：一种轻量级流计算模式》 应用场景例如： 广告相关实时统计； 推荐系统用户画像标签实时更新； 线上服务健康状况实时监测； 实时榜单； 实时数据统计。 Hadoop 《用通俗易懂的话说下hadoop是什么,能做什么》 《史上最详细的Hadoop环境搭建》 HDFS 《【Hadoop学习】HDFS基本原理》 MapReduce 《用通俗易懂的大白话讲解Map/Reduce原理》 《 简单的map-reduce的java例子》 Yarn 《初步掌握Yarn的架构及原理》 Spark 《Spark(一): 基本架构及原理》 安全web 安全XSS 《xss攻击原理与解决方法》CSRF 《CSRF原理及防范》 SQL 注入 《SQL注入》 Hash Dos 《邪恶的JAVA HASH DOS攻击》 利用JsonObjet 上传大Json，JsonObject 底层使用HashMap；不同的数据产生相同的hash值，使得构建Hash速度变慢，耗尽CPU。 《一种高级的DoS攻击-Hash碰撞攻击》 《关于Hash Collision DoS漏洞：解析与解决方案》 脚本注入 《上传文件漏洞原理及防范》 漏洞扫描工具 《DVWA》 W3af OpenVAS详解 验证码 《验证码原理分析及实现》 《详解滑动验证码的实现原理》 滑动验证码是根据人在滑动滑块的响应时间，拖拽速度，时间，位置，轨迹，重试次数等来评估风险。 《淘宝滑动验证码研究》 DDoS 防范 《学习手册：DDoS的攻击方式及防御手段》 《免费DDoS攻击测试工具大合集》 用户隐私信息保护 用户密码非明文保存，加动态salt。 身份证号，手机号如果要显示，用 “*” 替代部分字符。 联系方式在的显示与否由用户自己控制。 TODO 《个人隐私包括哪些》 《在互联网上，隐私的范围包括哪些？》 《用户密码保存》 序列化漏洞 《Lib之过？Java反序列化漏洞通用利用分析》 加密解密对称加密 《常见对称加密算法》 DES、3DES、Blowfish、AES DES 采用 56位秘钥，Blowfish 采用1到448位变长秘钥，AES 128，192和256位长度的秘钥。 DES 秘钥太短（只有56位）算法目前已经被 AES 取代，并且 AES 有硬件加速，性能很好。 哈希算法 《常用的哈希算法》 MD5 和 SHA-1 已经不再安全，已被弃用。 目前 SHA-256 是比较安全的。 《基于Hash摘要签名的公网URL签名验证设计方案》 非对称加密 《常见非对称加密算法》 RSA、DSA、ECDSA(螺旋曲线加密算法) 和 RSA 不同的是 DSA 仅能用于数字签名，不能进行数据加密解密，其安全性和RSA相当，但其性能要比RSA快。 256位的ECC秘钥的安全性等同于3072位的RSA秘钥。 《区块链的加密技术》 服务器安全 《Linux强化论：15步打造一个安全的Linux服务器》 数据安全数据备份TODO 网络隔离内外网分离TODO 登录跳板机在内外环境中通过跳板机登录到线上主机。 《搭建简易堡垒机》 授权、认证RBAC 《基于组织角色的权限设计》 《权限系统与RBAC模型概述》 《Spring整合Shiro做权限控制模块详细案例分析》 OAuth2.0 《理解OAuth 2.0》 《一张图搞定OAuth2.0》 双因素认证（2FA）2FA - Two-factor authentication，用于加强登录验证 常用做法是 登录密码 + 手机验证码（或者令牌Key，类似于与网银的 USB key） 【《双因素认证（2FA）教程》】(http://www.ruanyifeng.com/blog/2017/11/2fa-tutorial.html) 单点登录(SSO) 《单点登录原理与简单实现》 CAS单点登录框架 常用开源框架开源协议 《开源协议的选择》 如何选择一个开源软件协议 日志框架Log4j、Log4j2 《log4j 详细讲解》 《log4j2 实际使用详解》 《Log4j1,Logback以及Log4j2性能测试对比》 Log4J 异步日志性能优异。 Logback 《最全LogBack 详解、含java案例和配置说明》 ORM 《ORM框架使用优缺点》 主要目的是为了提高开发效率。 MyBatis： 《mybatis缓存机制详解》 一级缓存是SqlSession级别的缓存，缓存的数据只在SqlSession内有效 二级缓存是mapper级别的缓存，同一个namespace公用这一个缓存，所以对SqlSession是共享的；使用 LRU 机制清理缓存，通过 cacheEnabled 参数开启。 《MyBatis学习之代码生成器Generator》 网络框架TODO Web 框架Spring 家族Spring Spring 简明教程 Spring Boot 官方网站 《Spring Boot基础教程》 Spring Cloud Spring Boot 中文索引站 Spring Cloud 中文文档 《Spring Cloud基础教程》 工具框架 《Apache Commons 工具类介绍及简单使用》 《Google guava 中文教程》 分布式设计扩展性设计 《架构师不可不知的十大可扩展架构》 总结下来，通用的套路就是分布、缓存及异步处理。 《可扩展性设计之数据切分》 水平切分+垂直切分 利用中间件进行分片如，MySQL Proxy。 利用分片策略进行切分，如按照ID取模。 《说说如何实现可扩展性的大型网站架构》 分布式服务+消息队列。 《大型网站技术架构（七）–网站的可扩展性架构》 稳定性 &amp; 高可用 《系统设计：关于高可用系统的一些技术方案》 可扩展：水平扩展、垂直扩展。 通过冗余部署，避免单点故障。 隔离：避免单一业务占用全部资源。避免业务之间的相互影响 2. 机房隔离避免单点故障。 解耦：降低维护成本，降低耦合风险。减少依赖，减少相互间的影响。 限流：滑动窗口计数法、漏桶算法、令牌桶算法等算法。遇到突发流量时，保证系统稳定。 降级：紧急情况下释放非核心功能的资源。牺牲非核心业务，保证核心业务的高可用。 熔断：异常情况超出阈值进入熔断状态，快速失败。减少不稳定的外部依赖对核心服务的影响。 自动化测试：通过完善的测试，减少发布引起的故障。 灰度发布：灰度发布是速度与安全性作为妥协，能够有效减少发布故障。 《关于高可用的系统》 设计原则：数据不丢(持久化)；服务高可用(服务副本)；绝对的100%高可用很难，目标是做到尽可能多的9，如99.999%（全年累计只有5分钟）。 硬件负载均衡 《转！！负载均衡器技术Nginx和F5的优缺点对比》 主要是和F5对比。 《软/硬件负载均衡产品 你知多少？》 软件负载均衡 《几种负载均衡算法》 轮寻、权重、负载、最少连接、QoS 《DNS负载均衡》 配置简单，更新速度慢。 《Nginx负载均衡》 简单轻量、学习成本低；主要适用于web应用。 《借助LVS+Keepalived实现负载均衡 》 配置比较负载、只支持到4层，性能较高。 《HAProxy用法详解 全网最详细中文文档》 支持到七层（比如HTTP）、功能比较全面，性能也不错。 《Haproxy+Keepalived+MySQL实现读均衡负载》 主要是用户读请求的负载均衡。 《rabbitmq+haproxy+keepalived实现高可用集群搭建》 限流 《谈谈高并发系统的限流》 计数器：通过滑动窗口计数器，控制单位时间内的请求次数，简单粗暴。 漏桶算法：固定容量的漏桶，漏桶满了就丢弃请求，比较常用。 令牌桶算法：固定容量的令牌桶，按照一定速率添加令牌，处理请求前需要拿到令牌，拿不到令牌则丢弃请求，或进入丢队列，可以通过控制添加令牌的速率，来控制整体速度。Guava 中的 RateLimiter 是令牌桶的实现。 Nginx 限流：通过 limit_req 等模块限制并发连接数。 应用层容灾 《防雪崩利器：熔断器 Hystrix 的原理与使用》 雪崩效应原因：硬件故障、硬件故障、程序Bug、重试加大流量、用户大量请求。 雪崩的对策：限流、改进缓存模式(缓存预加载、同步调用改异步)、自动扩容、降级。 Hystrix设计原则： 资源隔离：Hystrix通过将每个依赖服务分配独立的线程池进行资源隔离, 从而避免服务雪崩。 熔断开关：服务的健康状况 = 请求失败数 / 请求总数，通过阈值设定和滑动窗口控制开关。 命令模式：通过继承 HystrixCommand 来包装服务调用逻辑。 《缓存穿透，缓存击穿，缓存雪崩解决方案分析》 《缓存击穿、失效以及热点key问题》 主要策略：失效瞬间：单机使用锁；使用分布式锁；不过期； 热点数据：热点数据单独存储；使用本地缓存；分成多个子key； 跨机房容灾 《“异地多活”多机房部署经验谈》 通过自研中间件进行数据同步。 《异地多活（异地双活）实践经验》 注意延迟问题，多次跨机房调用会将延时放大数倍。 建房间专线很大概率会出现问题，做好运维和程序层面的容错。 不能依赖于程序端数据双写，要有自动同步方案。 数据永不在高延迟和较差网络质量下，考虑同步质量问题。 核心业务和次要业务分而治之，甚至只考虑核心业务。 异地多活监控部署、测试也要跟上。 业务允许的情况下考虑用户分区，尤其是游戏、邮箱业务。 控制跨机房消息体大小，越小越好。 考虑使用docker容器虚拟化技术，提高动态调度能力。 容灾技术及建设经验介绍 容灾演练流程 《依赖治理、灰度发布、故障演练，阿里电商故障演练系统的设计与实战经验》 常见故障画像 案例：预案有效性、预案有效性、故障复现、架构容灾测试、参数调优、参数调优、故障突袭、联合演练。 平滑启动 平滑重启应用思路1.端流量（如vip层）、2. flush 数据(如果有)、3, 重启应用 《JVM安全退出（如何优雅的关闭java服务）》推荐推出方式：System.exit，Kill SIGTERM；不推荐 kill-9；用 Runtime.addShutdownHook 注册钩子。 《常见Java应用如何优雅关闭》Java、Srping、Dubbo 优雅关闭方式。 数据库扩展读写分离模式 《Mysql主从方案的实现》 《搭建MySQL主从复制经典架构》 《Haproxy+多台MySQL从服务器(Slave) 实现负载均衡》 《DRBD+Heartbeat+Mysql高可用读写分离架构》 DRDB 进行磁盘复制，避免单点问题。 《MySQL Cluster 方式》 分片模式 《分库分表需要考虑的问题及方案》 中间件： 轻量级：sharding-jdbc、TSharding；重量级：Atlas、MyCAT、Vitess等。 问题：事务、Join、迁移、扩容、ID、分页等。 事务补偿：对数据进行对帐检查;基于日志进行比对;定期同标准数据来源进行同步等。 分库策略：数值范围；取模；日期等。 分库数量：通常 MySQL 单库 5千万条、Oracle 单库一亿条需要分库。 《MySql分表和表分区详解》 分区：是MySQL内部机制，对客户端透明，数据存储在不同文件中，表面上看是同一个表。 分表：物理上创建不同的表、客户端需要管理分表路由。 服务治理服务注册与发现 《永不失联！如何实现微服务架构中的服务发现？》 客户端服务发现模式：客户端直接查询注册表，同时自己负责负载均衡。Eureka 采用这种方式。 服务器端服务发现模式：客户端通过负载均衡查询服务实例。 《SpringCloud服务注册中心比较:Consul vs Zookeeper vs Etcd vs Eureka》 CAP支持：Consul（CA）、zookeeper（cp）、etcd（cp） 、euerka（ap） 作者认为目前 Consul 对 Spring cloud 的支持比较好。 《基于Zookeeper的服务注册与发现》 优点：API简单、Pinterest，Airbnb 在用、多语言、通过watcher机制来实现配置PUSH，能快速响应配置变化。 服务路由控制 《分布式服务框架学习笔记4 服务路由》 原则：透明化路由 负载均衡策略：随机、轮询、服务调用延迟、一致性哈希、粘滞连接 本地路由有限策略：injvm(优先调用jvm内部的服务)，innative(优先使用相同物理机的服务),原则上找距离最近的服务。 配置方式：统一注册表；本地配置；动态下发。 分布式一致CAP 与 BASE 理论 《从分布式一致性谈到CAP理论、BASE理论》 一致性分类：强一致(立即一致)；弱一致(可在单位时间内实现一致，比如秒级)；最终一致(弱一致的一种，一定时间内最终一致) CAP：一致性、可用性、分区容错性(网络故障引起) BASE：Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性） BASE理论的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。 分布式锁 《分布式锁的几种实现方式》 基于数据库的分布式锁：优点：操作简单、容易理解。缺点：存在单点问题、数据库性能够开销较大、不可重入； 基于缓存的分布式锁：优点：非阻塞、性能好。缺点：操作不好容易造成锁无法释放的情况。 Zookeeper 分布式锁：通过有序临时节点实现锁机制，自己对应的节点需要最小，则被认为是获得了锁。优点：集群可以透明解决单点问题，避免锁不被释放问题，同时锁可以重入。缺点：性能不如缓存方式，吞吐量会随着zk集群规模变大而下降。 《基于Zookeeper的分布式锁》 清楚的原理描述 + Java 代码示例。 《jedisLock—redis分布式锁实现》 基于 setnx(set if ont exists)，有则返回false，否则返回true。并支持过期时间。 《Memcached 和 Redis 分布式锁方案》 利用 memcached 的 add（有别于set）操作，当key存在时，返回false。 分布式一致性算法PAXOS 《分布式系列文章——Paxos算法原理与推导》 《Paxos–&gt;Fast Paxos–&gt;Zookeeper分析》 《【分布式】Zookeeper与Paxos》 Zab 《Zab：Zookeeper 中的分布式一致性协议介绍》 Raft 《Raft 为什么是更易理解的分布式一致性算法》 三种角色：Leader（领袖）、Follower（群众）、Candidate（候选人） 通过随机等待的方式发出投票，得票多的获胜。 Gossip 《Gossip算法》 两阶段提交、多阶段提交 《关于分布式事务、两阶段提交协议、三阶提交协议》 幂等 《分布式系统—幂等性设计》 幂等特性的作用：该资源具备幂等性，请求方无需担心重复调用会产生错误。 常见保证幂等的手段：MVCC（类似于乐观锁）、去重表(唯一索引)、悲观锁、一次性token、序列号方式。 分布式一致方案 《分布式系统事务一致性解决方案》 《保证分布式系统数据一致性的6种方案》 分布式 Leader 节点选举 《利用zookeeper实现分布式leader节点选举》 TCC(Try/Confirm/Cancel) 柔性事务 《传统事务与柔性事务》 基于BASE理论：基本可用、柔性状态、最终一致。 解决方案：记录日志+补偿（正向补充或者回滚）、消息重试(要求程序要幂等)；“无锁设计”、采用乐观锁机制。 分布式文件系统 说说分布式文件存储系统-基本架构 ？ 《各种分布式文件系统的比较》 ？ HDFS：大批量数据读写，用于高吞吐量的场景，不适合小文件。 FastDFS：轻量级、适合小文件。 唯一ID 生成全局唯一ID 《高并发分布式系统中生成全局唯一Id汇总》 Twitter 方案（Snowflake 算法）：41位时间戳+10位机器标识（比如IP，服务器名称等）+12位序列号(本地计数器) Flicker 方案：MySQL自增ID + “REPLACE INTO XXX:SELECT LAST_INSERT_ID();” UUID：缺点，无序，字符串过长，占用空间，影响检索性能。 MongoDB 方案：利用 ObjectId。缺点：不能自增。 《TDDL 在分布式下的SEQUENCE原理》 在数据库中创建 sequence 表，用于记录，当前已被占用的id最大值。 每台客户端主机取一个id区间（比如 1000~2000）缓存在本地，并更新 sequence 表中的id最大值记录。 客户端主机之间取不同的id区间，用完再取，使用乐观锁机制控制并发。 一致性Hash算法 《一致性哈希算法》 设计思想 &amp; 开发模式DDD(Domain-driven Design - 领域驱动设计) 《浅谈我对DDD领域驱动设计的理解》 概念：DDD 主要对传统软件开发流程(分析-设计-编码)中各阶段的割裂问题而提出，避免由于一开始分析不明或在软件开发过程中的信息流转不一致而造成软件无法交付（和需求方设想不一致）的问题。DDD 强调一切以领域（Domain）为中心，强调领域专家（Domain Expert）的作用，强调先定义好领域模型之后在进行开发，并且领域模型可以指导开发（所谓的驱动）。 过程：理解领域、拆分领域、细化领域，模型的准确性取决于模型的理解深度。 设计：DDD 中提出了建模工具，比如聚合、实体、值对象、工厂、仓储、领域服务、领域事件来帮助领域建模。 《领域驱动设计的基础知识总结》 领域（Doamin）本质上就是问题域，比如一个电商系统，一个论坛系统等。 界限上下文（Bounded Context）：阐述子域之间的关系，可以简单理解成一个子系统或组件模块。 领域模型（Domain Model）：DDD的核心是建立（用通用描述语言、工具—领域通用语言）正确的领域模型；反应业务需求的本质，包括实体和过程；其贯穿软件分析、设计、开发 的整个过程；常用表达领域模型的方式：图、代码或文字； 领域通用语言：领域专家、开发设计人员都能立即的语言或工具。 经典分层架构：用户界面/展示层、应用层、领域层、基础设施层，是四层架构模式。 使用的模式： 关联尽量少，尽量单项，尽量降低整体复杂度。 实体（Entity）：领域中的唯一标示，一个实体的属性尽量少，少则清晰。 值对象（Value Object）：没有唯一标识，且属性值不可变，小二简单的对象，比如Date。 领域服务（Domain Service）： 协调多个领域对象，只有方法没有状态(不存数据)；可以分为应用层服务，领域层服务、基础层服务。 聚合及聚合根（Aggregate，Aggregate Root）：聚合定义了一组具有内聚关系的相关对象的集合；聚合根是对聚合引用的唯一元素；当修改一个聚合时，必须在事务级别；大部分领域模型中，有70%的聚合通常只有一个实体，30%只有2~3个实体；如果一个聚合只有一个实体，那么这个实体就是聚合根；如果有多个实体，那么我们可以思考聚合内哪个对象有独立存在的意义并且可以和外部直接进行交互； 工厂（Factory）：类似于设计模式中的工厂模式。 仓储（Repository）：持久化到DB，管理对象，且只对聚合设计仓储。 《领域驱动设计(DDD)实现之路》 聚合：比如一辆汽车（Car）包含了引擎（Engine）、车轮（Wheel）和油箱（Tank）等组件，缺一不可。 《领域驱动设计系列（2）浅析VO、DTO、DO、PO的概念、区别和用处》 命令查询职责分离(CQRS)CQRS — Command Query Responsibility Seperation 《领域驱动设计系列 (六)：CQRS》 核心思想：读写分离（查询和更新在不同的方法中），不同的流程只是不同的设计方式，CQ代码分离，分布式环境中会有明显体现（有冗余数据的情况下），目的是为了高性能。 《DDD CQRS架构和传统架构的优缺点比较》 最终一致的设计理念；依赖于高可用消息中间件。 《CQRS架构简介》 一个实现 CQRS 的抽象案例。 《深度长文：我对CQRS/EventSourcing架构的思考》 CQRS 模式分析 + 12306 抢票案例 贫血，充血模型 《贫血，充血模型的解释以及一些经验》 失血模型：老子和儿子分别定义，相互不知道，二者实体定义中完全没有业务逻辑，通过外部Service进行关联。 贫血模型：老子知道儿子，儿子也知道老子；部分业务逻辑放到实体中；优点：各层单项依赖，结构清楚，易于维护；缺点：不符合OO思想，相比于充血模式，Service层较为厚重； 充血模型：和贫血模型类似，区别在于如何划分业务逻辑。优点：Service层比较薄，只充当Facade的角色，不和DAO打交道、复合OO思想；缺点：非单项依赖，DO和DAO之间双向依赖、和Service层的逻辑划分容易造成混乱。 肿胀模式：是一种极端情况，取消Service层、全部业务逻辑放在DO中；优点：符合OO思想、简化了分层；缺点：暴露信息过多、很多非DO逻辑也会强行并入DO。这种模式应该避免。 作者主张使用贫血模式。 Actor 模式TODO 响应式编程ReactorTODO RxJavaTODO Vert.xTODO DODAF2.0 《DODAF2.0方法论》 《DODAF2.0之能力视角如何落地》 Serverless无需过多关系服务器的服务架构理念。 《什么是Serverless无服务器架构？》 Serverless 不代表出去服务器，而是去除对服务器运行状态的关心。 Serverless 代表一思维方式的转变，从“构建一套服务在一台服务器上，对对个事件进行响应转变为构建一个为服务器，来响应一个事件”。 Serverless 不代表某个具体的框架。 《如何理解Serverless？》 依赖于 Baas （(Mobile) Backend as a Service） 和 Faas （Functions as a service） Service Mesh 《什么是Service Mesh？》 《初识 Service Mesh》 《什么是Service Mesh？》 项目管理架构评审 《架构设计之如何评审架构设计说明书》 《人人都是架构师：非功能性需求》 重构 《架构之重构的12条军规》 代码规范 《阿里巴巴Java开发手册》 代码 Review制度还是制度!另外，每个公司需要根据自己的需求和目标制定自己的 check list 《为什么你做不好 Code Review？》 代码 review 做的好，在于制度建设。 《从零开始Code Review》 《Code Review Checklist》 《Java Code Review Checklist》 《如何用 gitlab 做 code review》 RUP 《运用RUP 4+1视图方法进行软件架构设计》 看板管理 《说说看板在项目中的应用》 SCRUMSCRUM - 争球 3个角色:Product Owner(PO) 产品负责人;Scrum Master（SM），推动Scrum执行;Team 开发团队。 3个工件：Product Backlog 产品TODOLIST，含优先级;Sprint Backlog 功能开发 TODO LIST；燃尽图； 五个价值观：专注、勇气、公开、承诺、尊重。 《敏捷项目管理流程-Scrum框架最全总结！》 《敏捷其实很简单3—敏捷方法之scrum》 敏捷开发TODO 极限编程（XP）XP - eXtreme Programming 《主流敏捷开发方法：极限编程XP》 是一种指导开发人员的方法论。 4大价值： 沟通：鼓励口头沟通，提高效率。 简单：够用就好。 反馈：及时反馈、通知相关人。 勇气：提倡拥抱变化，敢于重构。 5个原则：快速反馈、简单性假设、逐步修改、提倡更改（小步快跑）、优质工作（保证质量的前提下保证小步快跑）。 5个工作：阶段性冲刺；冲刺计划会议；每日站立会议；冲刺后review；回顾会议。 结对编程边写码，边review。能够增强代码质量、减少bug。 《结对编程》 PDCA 循环质量管理P——PLAN 策划，D——DO 实施，C——CHECK 检查，A——ACT 改进 《PDCA》 FMEA管理模式TODO 通用业务术语TODO 技术趋势TODO 政策、法规TODO 法律严格遵守刑法253法条我国刑法第253条之一规定： 国家机关或者金融、电信、交通、教育、医疗等单位的工作人员，违反国家规定，将本单位在履行职责或者提供服务过程中获得的公民个人信息，出售或者非法提供给他人，情节严重的，处3年以下有期徒刑或者拘役，并处或者单处罚金。 窃取或者以其他方法非法获取上述信息，情节严重的，依照前款的规定处罚。 单位犯前两款罪的，对单位判处罚金，并对其直接负责的主管人员和其他直接责任人员，依照各该款的规定处罚。 最高人民法院、最高人民检察院关于执行《中华人民共和国刑法》确定罪名的补充规定（四）规定：触犯刑法第253条之一第1款之规定，构成“出售、非法提供公民个人信息罪”；触犯刑法第253条之一第2款之规定，构成“非法获取公民个人信息罪” 《非法获取公民个人信息罪》 架构师素质 《架构师画像》 业务理解和抽象能力 NB的代码能力 全面：1. 在面对业务问题上，架构师脑海里是否会浮现出多种技术方案；2. 在做系统设计时是否考虑到了足够多的方方面面；3. 在做系统设计时是否考虑到了足够多的方方面面； 全局：是否考虑到了对上下游的系统的影响。 权衡：权衡投入产出比；优先级和节奏控制； 《关于架构优化和设计，架构师必须知道的事情》 要去考虑的细节：模块化、轻耦合、无共享架构；减少各个组件之前的依赖、注意服务之间依赖所有造成的链式失败及影响等。 基础设施、配置、测试、开发、运维综合考虑。 考虑人、团队、和组织的影响。 《如何才能真正的提高自己，成为一名出色的架构师？》 《架构师的必备素质和成长途径》 素质：业务理解、技术广度、技术深度、丰富经验、沟通能力、动手能力、美学素养。 成长路径：2年积累知识、4年积累技能和组内影响力、7年积累部门内影响力、7年以上积累跨部门影响力。 《架构设计师—你在哪层楼？》 第一层的架构师看到的只是产品本身 第二层的架构师不仅看到自己的产品，还看到了整体的方案 第三层的架构师看到的是商业价值 团队管理TODO 招聘资讯行业资讯 36kr Techweb 公众号列表TODO 博客团队博客 阿里中间件博客 美团点评技术团队博客 个人博客 阮一峰的网络日志 酷壳 - COOLSHELL-陈皓 hellojava-阿里毕玄 Cm’s Blog 程序猿DD-翟永超-《Spring Cloud微服务实战》作者 综合门户、社区国内： CSDN 老牌技术社区、不必解释。 51cto.com ITeye 偏 Java 方向 博客园 ChinaUnix 偏 Linux 方向 开源中国社区 深度开源 伯乐在线 涵盖 IT职场、Web前端、后端、移动端、数据库等方面内容，偏技术端。 ITPUB 腾讯云— 云+社区 阿里云— 云栖社区 IBM DeveloperWorks 开发者头条 LinkedKeeper 国外： DZone Reddit 问答、讨论类社区 segmentfault 问答+专栏 知乎 stackoverflow 行业数据分析 艾瑞网 QUEST MOBILE 国家数据 TalkingData 专项网站 测试: 领测国际 测试窝 TesterHome 运维: * [运维派](http://www.yunweipai.com/) * [Abcdocker](https://www.abcdocker.com/) Java: ImportNew 专注于 Java 技术分享 HowToDoInJava 英文博客 安全 红黑联盟 FreeBuf 大数据 中国大数据 其他专题网站： DockerInfo 专注于 Docker 应用及咨询、教程的网站。 Linux公社 Linux 主题社区 其他类 程序员技能图谱 推荐参考书在线电子书 《深入理解Spring Cloud与微服务构建》 《阿里技术参考图册-研发篇》 《阿里技术参考图册-算法篇》 《2018美团点评技术年货（合辑）》70M InfoQ《架构师》月刊 《架构师之路》 纸质书开发方面 《阿里巴巴Java开发手册》京东 淘宝 架构方面 《软件架构师的12项修炼：技术技能篇》京东 淘宝 《架构之美》京东 淘宝 《分布式服务架构》京东 淘宝 《聊聊架构》 京东 淘宝 《云原生应用架构实践》京东 淘宝 《亿级流量网站架构核心技术》京东 淘宝 《淘宝技术这十年》京东 淘宝 《企业IT架构转型之道-中台战略思想与架构实战》 京东 淘宝 《高可用架构（第1卷）》京东 淘宝 技术管理方面 《CTO说》京东 淘宝 《技术管理之巅》京东 淘宝 《网易一千零一夜：互联网产品项目管理实战》京东 淘宝 基础理论 《数学之美》京东 淘宝 《编程珠玑》京东 淘宝 工具方面TODO 大数据方面技术资源开源资源 github Apache 软件基金会 手册、文档、教程国内： W3Cschool Runoob.com HTML 、 CSS、XML、Java、Python、PHP、设计模式等入门手册。 Love2.io 很多很多中文在线电子书，是一个全新的开源技术文档分享平台。 gitbook.cn 付费电子书。 ApacheCN AI、大数据方面系列中文文档。 国外： Quick Code 免费在线技术教程。 gitbook.com 有部分中文电子书。 Cheatography Cheat Sheets 大全，单页文档网站。 Tutorialspoint 知名教程网站，提供Java、Python、JS、SQL、大数据等高质量入门教程。 在线课堂 学徒无忧 极客时间 segmentfault 斯达克学院 牛客网 极客学院 51CTO学院 会议、活动 QCon ArchSummit GITC全球互联网技术大会 活动发布平台: 活动行 常用APP 极客时间 得到 找工作 Boss直聘 拉勾网 猎聘 100Offer 工具 极客搜索 技术文章搜索引擎。 代码托管 Coding 码云 文件服务 七牛 又拍云 综合云服务商 阿里云 腾讯云 百度云 新浪云 金山云 亚马逊云(AWS) 谷歌云 微软云","categories":[{"name":"技术知识图谱","slug":"技术知识图谱","permalink":"https://ostenant.coding.me/categories/技术知识图谱/"}],"tags":[]},{"title":"实战Spring Boot 2.0 Reactive编程系列(一) - WebFlux初体验","slug":"实战Spring Boot 2.0 Reactive编程系列(一) - WebFlux初体验","date":"2018-05-27T07:25:00.000Z","updated":"2018-06-18T01:57:04.779Z","comments":true,"path":"2018/05/27/实战Spring Boot 2.0 Reactive编程系列(一) - WebFlux初体验/","link":"","permalink":"https://ostenant.coding.me/2018/05/27/实战Spring Boot 2.0 Reactive编程系列(一) - WebFlux初体验/","excerpt":"前言上文引入了 反应式编程模型 相关概念，对 Spring Reactor 的核心 API 进行了简单归纳。本文会对 Spring 5 WebFlux 进行相关介绍，包括引入 Servlet 3.1 +，各个功能组件 Router Functions、WebFlux 和 Reactive Streams 等，以及如何在 Spring Boot 2.0 中分别以 全局功能路由 和 MVC 控制器 的方式配置 HTTP 请求处理。","text":"前言上文引入了 反应式编程模型 相关概念，对 Spring Reactor 的核心 API 进行了简单归纳。本文会对 Spring 5 WebFlux 进行相关介绍，包括引入 Servlet 3.1 +，各个功能组件 Router Functions、WebFlux 和 Reactive Streams 等，以及如何在 Spring Boot 2.0 中分别以 全局功能路由 和 MVC 控制器 的方式配置 HTTP 请求处理。 正文Spring 5 WebFlux介绍关于 Spring 5 的 WebFlux \b响应式编程，下图是传统 Spring Web MVC 结构以及Spring 5 中新增加的基于 Reactive Streams 的 Spring WebFlux 框架。可以使用 webFlux 模块来构建 异步的、非堵塞的、事件驱动 的服务，其在 伸缩性方面 表现非常好。 如图所示，WebFlux 模块从上到下依次是 Router Functions、WebFlux、Reactive Streams 三个新组件。 Servlet 3.1+ API介绍WebFlux 模块需要运行在实现了 Servlet 3.1+ 规范 的容器之上。Servlet 3.1 规范中新增了对 异步处理 的支持，在新的 Servlet 规范中，Servlet 线程不需要一直 阻塞等待 到业务处理完成。 在 Servlet 3.1 中，其请求处理的线程模型大致如下： Servlet 线程接收到新的请求后，不需要等待业务处理完成再进行结果输出，而是将这个请求委托给另外一个线程（业务线程）来完成。 Servlet 线程将委托完成之后变返回到容器中去接收新的请求。 Servlet 3.1 规范特别适用于那种 业务处理非常耗时 的场景之下，可以减少 服务器资源 的占用，并且提高 并发处理速度 ，而对于那些能 快速响应 的场景收益并不大。 所以 WebFlux 支持的容器有 Tomcat、Jetty 等 同步容器 ，也可以是 Netty 和 Undertow 这类 异步容器。在容器中 Spring WebFlux 会将 输入流 适配成 Mono 或 Flux 格式进行统一处理。 Spring WebFlux的功能模块下面介绍上图中 WebFlux 各个模块： 1. Router Functions对标准的 @Controller，@RequestMapping等的 Spring MVC 注解，提供一套 函数式风格 的 API，用于创建 Router、Handler 和Filter。 2. WebFlux核心组件，协调上下游各个组件提供 响应式编程 支持。 3. Reactive Streams一种支持 背压 (Backpressure) 的 异步数据流处理标准，主流实现有 RxJava 和 Reactor，Spring WebFlux 集成的是Reactor。 FluxFlux 和 Mono 属于 事件发布者，类似于 生产者，对消费者 提供订阅接口。当有事件发生的时候，Flux 或 Mono 会回调 消费者相应的方法来通知 消费者 相应的事件。 下面这张图是 Flux 的工作流程图： 关于 Flux 的工作模式，可以看出 Flux 可以 触发 (emit) 很多 item，而这些 item 可以经过若干 Operators 然后才被 subscribe，下面是使用 Flux 的一个例子： 12345678Flux.fromIterable(getSomeLongList()) .mergeWith(Flux.interval(100)) .doOnNext(serviceA::someObserver) .map(d -&gt; d * 2) .take(3) .onErrorResumeWith(errorHandler::fallback) .doAfterTerminate(serviceM::incrementTerminate) .subscribe(System.out::println); Mono下面的图片是 Mono 的处理流程，可以很直观的看出来 Mono 和 Flux 的区别： Mono 只能触发 (emit) 一个 item，下面是使用 Mono 的一个例子： 12345Mono.fromCallable(System::currentTimeMillis) .flatMap(time -&gt; Mono.first(serviceA.findRecent(time), serviceB.findRecent(time))) .timeout(Duration.ofSeconds(3), errorHandler::fallback) .doOnSuccess(r -&gt; serviceM.incrementSuccess()) .subscribe(System.out::println); \bSpring Boot 2.0 Reactive StackSpring Boot Webflux 就是基于 Reactor 实现的。Spring Boot 2.0 包括一个新的 spring-webflux 模块。该模块包含对 响应式 HTTP 和 WebSocket 客户端的支持，以及对 REST 、HTML 和 WebSocket 交互等程序 的支持。一般来说，Spring MVC 用于 同步处理，Spring Webflux 用于 异步处理。 如上图所示，从 Web 表现层到数据访问，再到容器，Spring Boot 2.0 同时提供了 同步阻塞式 和 异步非阻塞式 \b两套完整的 API Stack。 从上而下对比以下两者的区别: API Stack Sevlet Stack Reactive Stack \bWeb控制层 Spring MVC Spring WebFlux \b安全认证层 Spring Security Spring Security 数据访问层 Spring Data Repositories Spring Data Reactive Repositories 容器API Servlet API Reactive Streams Adapters 内嵌容器 Servlet Containers Netty, Servlet 3.1+ Containers 适用场景控制层一旦使用 Spring WebFlux，它下面的安全认证层、数据访问层都必须使用 Reactive API。其次，Spring Data Reactive Repositories 目前只支持 MongoDB、Redis 和 Couchbase 等几种不支持事务管理的 NOSQL。技术选型时一定要权衡这些弊端和风险，比如： Spring MVC 能满足场景的，就不需要更改为 Spring WebFlux。 要注意容器的支持，可以看看底层 内嵌容器 的支持。 微服务 体系结构，Spring WebFlux 和 Spring MVC 可以混合使用。尤其开发 IO 密集型 服务的时候，可以选择 Spring WebFlux 去实现。 编程模型Spring 5 Web 模块包含了 Spring WebFlux 的 HTTP 抽象。类似 Servlet API\b， WebFlux 提供了 WebHandler API 去定义 非阻塞 API 抽象接口。可以选择以下两种编程模型实现： 注解控制层: 和 MVC 保持一致，WebFlux 也支持 响应性 @RequestBody 注解。 功能性端点: 基于 lambda 轻量级编程模型，用来 建立路由 和 处理请求 的工具。和上面最大的区别就是，这种模型，全程 控制了 请求 - 响应 的生命流程 内嵌容器跟 Spring Boot 大框架一样启动应用，但 Spring WebFlux 默认是通过 Netty 启动，并且自动设置了 默认端口 为 8080。另外还提供了对 Jetty、Undertow 等容器的支持。开发者自行在添加对应的容器 Starter 组件依赖，即可配置并使用对应 内嵌容器实例。 注意: 必须是 Servlet 3.1+ 容器，如 Tomcat、Jetty；或者非 Servlet 容器，如 Netty 和 Undertow。 Starter 组件跟 Spring Boot 大框架一样，Spring Boot Webflux 提供了很多 开箱即用 的 Starter 组件。添加 spring-boot-starter-webflux 依赖，就可用于构建 响应式 API 服务，其包含了 WebFlux 和 Tomcat 内嵌容器 等。 快速开始Spring Initializr构建项目骨架利用 Spring Initializer 快速生成 Spring Boot 应用，配置\b项目信息并设置依赖。 配置Maven依赖12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.0.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; Spring Boot启动类123456@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoApplication.class, args); &#125;&#125; 配置实体类1234567@Data@Builder@AllArgsConstructor@NoArgsConstructorpublic class Message &#123; String body;&#125; 1. MVC控制器方式1.1. 编写控制器1234567891011@RestController@RequestMappingpublic class MessageController &#123; @GetMapping public Flux&lt;Message&gt; allMessages()&#123; return Flux.just( Message.builder().body(\"hello Spring 5\").build(), Message.builder().body(\"hello Spring Boot 2\").build() ); &#125; &#125; 1.2. 编写\b测试类1234567891011@RunWith(SpringRunner.class)@WebFluxTest(controllers = MessageController.class)public class DemoApplicationTests &#123; @Autowired WebTestClient client; @Test public void getAllMessagesShouldBeOk() &#123; client.get().uri(\"/\").exchange().expectStatus().isOk(); &#125;&#125; 1.3. 查看启动日志12342018-05-27 17:37:23.550 INFO 67749 --- [ main] s.w.r.r.m.a.RequestMappingHandlerMapping : Mapped \"&#123;[],methods=[GET]&#125;\" onto reactor.core.publisher.Flux&lt;com.example.demo.Message&gt; com.example.demo.MessageController.allMessages()2018-05-27 17:37:23.998 INFO 67749 --- [ctor-http-nio-1] r.ipc.netty.tcp.BlockingNettyContext : Started HttpServer on /0:0:0:0:0:0:0:0:80802018-05-27 17:37:23.999 INFO 67749 --- [ main] o.s.b.web.embedded.netty.NettyWebServer : Netty started on port(s): 80802018-05-27 17:37:24.003 INFO 67749 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 1.6 seconds (JVM running for 2.274) 从日志里可以看出： 启动时 WebFlux 利用 MVC 原生的 RequestMappingHandlerMapping 将控制器里的 请求路径 和 MVC 中的 处理器 进行\b绑定。 Spring WebFlux 默认采用 Netty 作为 内嵌容器，且启动端口默认为 8080。 访问 http://localhost:8080，返回结果如下： 2. 全局Router API方式2.1. 配置全局Router Bean12345678910111213141516@Configurationpublic class DemoRouterConfig &#123; @Bean public RouterFunction&lt;ServerResponse&gt; routes() &#123; return route(GET(\"/\"), (ServerRequest req)-&gt; ok() .body( BodyInserters.fromObject( Arrays.asList( Message.builder().body(\"hello Spring 5\").build(), Message.builder().body(\"hello Spring Boot 2\").build() ) ) ) ); &#125;&#125; 2.2. 编写测试类1234567891011@RunWith(SpringRunner.class)@WebFluxTestpublic class DemoApplicationTests &#123; @Autowired WebTestClient client; @Test public void getAllMessagesShouldBeOk() &#123; client.get().uri(\"/\").exchange().expectStatus().isOk(); &#125;&#125; \b2.3. 查看启动日志运行 Spring Boot 启动入口类，\b启动日志如下(不重要的省略)： 123452018-05-27 17:20:28.870 INFO 67696 --- [ main] o.s.w.r.f.s.s.RouterFunctionMapping : Mapped (GET &amp;&amp; /) -&gt; com.example.demo.DemoRouterConfig$$Lambda$213/1561745898@3381b4fc2018-05-27 17:20:28.931 INFO 67696 --- [ main] o.s.w.r.r.m.a.ControllerMethodResolver : Looking for @ControllerAdvice: org.springframework.boot.web.reactive.context.AnnotationConfigReactiveWebServerApplicationContext@1460a8c0: startup date [Sun May 27 17:20:27 CST 2018]; root of context hierarchy2018-05-27 17:20:29.311 INFO 67696 --- [ctor-http-nio-1] r.ipc.netty.tcp.BlockingNettyContext : Started HttpServer on /0:0:0:0:0:0:0:0:80802018-05-27 17:20:29.312 INFO 67696 --- [ main] o.s.b.web.embedded.netty.NettyWebServer : Netty started on port(s): 80802018-05-27 17:20:29.316 INFO 67696 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 2.137 seconds (JVM running for 3.169) 从日志里可以看出：启动时 WebFlux 利用 RouterFunctionMapping 将 RouterFunction 里的 全局路径 和 请求处理 进行了映射和绑定。 访问 http://localhost:8080，返回结果如下： 可以看出，无论是使用 Fucntional Router 还是 MVC Controller，都可以产生相同的效果！ 开发运行环境 JDK 1.8 + : Spring Boot 2.x 要求 JDK 1.8 环境及以上版本。另外，Spring Boot 2.x 只兼容 Spring Framework 5.0 及以上版本。 Maven 3.2 + : 为 Spring Boot 2.x 提供了相关依赖构建工具是 Maven，版本需要 3.2 及以上版本。使用 Gradle 则需要 1.12 及以上版本。Maven 和 Gradle 大家各自挑选下喜欢的就好。 小结本文首先对 Spring 5 WebFlux 进行了单独介绍，包括引入 Servlet 3.1 +，各个功能组件 Router Functions、WebFlux 和 Reactive Streams 等。然后在 Spring Boot 2.0 详细地介绍了 Reactive Stack 和 Servlet Stack 的组成区别，并分别给出了 WebFlux 基于 全局功能路由 和 控制器 的配置和使用案例。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Spring Reactive编程系列","slug":"Spring-Reactive编程系列","permalink":"https://ostenant.coding.me/categories/Spring-Reactive编程系列/"}],"tags":[{"name":"Reactive Streams","slug":"Reactive-Streams","permalink":"https://ostenant.coding.me/tags/Reactive-Streams/"},{"name":"Spring WebFlux","slug":"Spring-WebFlux","permalink":"https://ostenant.coding.me/tags/Spring-WebFlux/"},{"name":"Spring Boot 2.0","slug":"Spring-Boot-2-0","permalink":"https://ostenant.coding.me/tags/Spring-Boot-2-0/"}]},{"title":"聊聊Spring Reactor反应式编程","slug":"聊聊Spring Reactor反应式编程","date":"2018-05-26T08:41:00.000Z","updated":"2018-06-18T01:59:19.114Z","comments":true,"path":"2018/05/26/聊聊Spring Reactor反应式编程/","link":"","permalink":"https://ostenant.coding.me/2018/05/26/聊聊Spring Reactor反应式编程/","excerpt":"前言为了应对 高并发环境下 的服务端编程，微软提出了一个实现 异步编程 的方案 - Reactive Programming，中文名称 反应式编程。随后，其它技术也迅速地跟上了脚步，像 ES6 通过 Promise 引入了类似的异步编程方式。Java 社区也没有落后很多，Netflix 和 TypeSafe 公司提供了 RxJava 和 Akka Stream 技术，让 Java 平台也有了能够实现反应式编程的框架。","text":"前言为了应对 高并发环境下 的服务端编程，微软提出了一个实现 异步编程 的方案 - Reactive Programming，中文名称 反应式编程。随后，其它技术也迅速地跟上了脚步，像 ES6 通过 Promise 引入了类似的异步编程方式。Java 社区也没有落后很多，Netflix 和 TypeSafe 公司提供了 RxJava 和 Akka Stream 技术，让 Java 平台也有了能够实现反应式编程的框架。 正文函数式编程函数式编程是种编程方式，它将计算机的运算视为函数的计算。函数编程语言最重要的基础是 λ演算 (lambda calculus)，而λ演算的函数可以接受函数当作 输入(参数) 和 输出(返回值)。lambda 表达式对与大多数程序员已经很熟悉了，jdk8 以及 es6都是引入的 lambda。 函数式编程的特点 惰性计算 函数是“第一等公民” 只使用表达式而不使用语句 没有副作用 反应式编程反应式编程 (reactive programming) 是一种基于 数据流 (data stream) 和 变化传递 (propagation of change) 的 声明式 (declarative) 的编程范式。 反应式编程的特点1. 事件驱动在一个 事件驱动 的应用程序中，组件之间的交互是通过松耦合的 生产者 (production)和 消费者 (consumption) 来实现的。这些事件是以 异步 和 非阻塞 的方式发送和接收的。 事件驱动 的系统依靠 推模式 而不是 拉模式 或 投票表决，即 生产者 是在有消息时才推送数据给 消费者，而不是通过一种浪费资源方式：让 消费者 不断地 轮询 或 等待数据。 2. 实时响应\b程序发起执行以后，\b应该 快速 返回存储 结果的\b上下文，把具体执行交给 后台线程。\b待处理完成\b以后，异步地将 真实返回值 封装在此 上下文 中，而不是 阻塞 程序的执行。\b实时响应\b是通过 异步 编程实现的，例如：发起调用\b后，快速返回类似 java8 中 CompletableFuture 对象。 3. 弹性\b机制事件驱动的 松散耦合 提供了组件在失败下，可以抓获 完全隔离 的上下文场景，作为 消息封装，发送到下游组件。在具体编程时可以 检查错误 ，比如：是否接收到，接收的命令是否可执行等，并决定如何应对。 Reactor简介Reactor 框架是 Pivotal 基于 Reactive Programming 思想实现的。它符合 Reactive Streams 规范 (Reactive Streams 是由 Netflix、TypeSafe、Pivotal 等公司发起的) 的一项技术。其名字有 反应堆 之意，反映了其背后的强大的 性能。 1. Reactive ProgrammingReactive Programming，中文称 反应式编程。Reactive Programming 是一种 非阻塞、事件驱动数据流 的开发方案，使用 函数式编程 的概念来操作数据流，系统中某部分的数据变动后会自动更新其他部分，而且成本极低。 其最早是由微软提出并引入到 .NET 平台中，随后 ES6 也引入了类似的技术。在 Java 平台上，较早采用反应式编程技术的是 Netflix 公司开源的 RxJava 框架。Hystrix 就是以 RxJava 为基础开发的。 反应式编程其实并不神秘，通过与我们熟悉的 迭代器模式 对比，便可了解其基本思想： 事件 Iterable (pull) Observable (push) 获取数据 T next() onNext(T) 发现异常 throws Exception onError(Exception) 处理完成 hasNext() onCompleted() 上面表格的中的 Observable 那一列便代表 反应式编程 的 API 的使用方式。它其实是 观察者模式 的一种延伸。 如果将 迭代器模式 看作是 拉模式，那 观察者模式 便是 推模式。 被订阅者 (Publisher) 主动推送数据给 订阅者 (Subscriber)，触发 onNext() 方法。异常和完成时触发另外两个方法。 \b\b\b被订阅者 (Publisher) 发生异常，则触发 订阅者 (Subscriber) 的 onError() 方法进行异常捕获处理。 被订阅者 (Publisher) 每次推送都会触发一次 onNext() 方法。所有的推送完成且无异常时，\bonCompleted() 方法将 在最后 触发一次。 如果 Publisher 发布消息太快了，超过了 Subscriber 的处理速度，那怎么办？这就是 Backpressure 的由来。Reactive Programming 框架需要提供 背压机制，使得 Subscriber 能够控制 消费消息 的速度。 2. Reactive Streams在 Java 平台上，Netflix（开发了 RxJava）、TypeSafe（开发了 Scala、Akka）、Pivatol（开发了 Spring、Reactor）共同制定了一个被称为 Reactive Streams 项目（规范），用于制定反应式编程相关的规范以及接口。 Reactive Streams 由以下几个组件组成： 发布者：发布元素到订阅者 订阅者：消费元素 订阅：在发布者中，订阅被创建时，将与订阅者共享 处理器：发布者与订阅者之间处理数据 其主要的接口有这三个： Publisher Subscriber Subcription 其中，Subcriber 中便包含了上面表格提到的 onNext、onError、onCompleted 这三个方法。对于 Reactive Streams，只需要理解其思想就可以，包括基本思想以及 Backpressure 等思想即可。 3. Reactor的主要模块Reactor 框架主要有两个主要的模块： reactor-core reactor-ipc 前者主要负责 Reactive Programming 相关的 核心 API 的实现，后者负责 高性能网络通信 的实现，目前是基于 Netty 实现的。 4. Reactor的核心类在 Reactor 中，经常使用的类并不是很多，主要有以下两个： Mono Mono 实现了 org.reactivestreams.Publisher 接口，代表 0 到 1 个元素的 发布者。 Flux Flux 同样实现了 org.reactivestreams.Publisher 接口，代表 0 到 N 个元素的发表者。 Scheduler 代表背后驱动反应式流的调度器，通常由各种线程池实现。 5. WebFluxSpring 5 引入的一个基于 Netty 而不是 Servlet 的高性能的 Web 框架 - Spring WebFlux ，但是使用方式并没有同传统的基于 Servlet 的 Spring MVC 有什么大的不同。 WebFlux 中 MVC 接口的示例： 12345678@RequestMapping(\"/webflux\")@RestControllerpublic class WebFluxTestController &#123; @GetMapping(\"/mono\") public Mono&lt;Foobar&gt; foobar() &#123; return Mono.just(new Foobar()); &#125;&#125; 最大的变化就是返回值从 Foobar 所表示的一个对象变为 Mono&lt;Foobar&gt; 或 Flux&lt;Foobar&gt;。 6. Reactive Streams、Reactor和WebFlux上面介绍了 反应式编程 的一些概念。可能读者看到这里有些乱，梳理一下三者的关系： Reactive Streams 是一套反应式编程 标准 和 规范； Reactor 是基于 Reactive Streams 一套 反应式编程框架； WebFlux 以 Reactor 为基础，实现 Web 领域的 反应式编程框架。 其实，对于业务开发人员来说，当编写反应式代码时，通常只会接触到 Publisher 这个接口，对应到 Reactor 便是 Mono 和 Flux。 对于 Subscriber 和 Subcription 这两个接口，Reactor 也有相应的实现。这些都是 Spring WebFlux 和 Spring Data Reactive 这样的框架用到的。如果 不开发中间件，开发人员是不会接触到的。 Reactor入门接下来介绍一下 Reactor 中 Mono 和 Flux 这两个类中的主要方法的使用。 如同 Java 8 所引入的 Stream 一样，Reactor 的使用方式基本上也是分三步： 开始阶段的创建 中间阶段的处理 最终阶段的消费 只不过创建和消费可能是通过像 Spring 5 这样框架完成的（比如通过 WebFlux 中的 WebClient 调用 HTTP 接口，返回值便是一个 Mono）。但我们还是需要基本了解这些阶段的开发方式。 1. 创建 Mono 和 Flux（开始阶段）使用 Reactor 编程的开始必然是先创建出 Mono 或 Flux。有些时候不需要我们自己创建，而是实现例如 WebFlux 中的 WebClient 或 Spring Data Reactive 得到一个 Mono 或 Flux。 使用 WebFlux WebClient 调用 HTTP 接口 123456789WebClient webClient = WebClient.create(\"http://localhost:8080\");public Mono&lt;User&gt; findById(Long userId) &#123; return webClient .get() .uri(\"/users/\" + userId) .accept(MediaType.APPLICATION_JSON) .exchange() .flatMap(cr -&gt; cr.bodyToMono(User.class));&#125; 使用 ReactiveMongoRepository 查询 User 123public interface UserRepository extends ReactiveMongoRepository&lt;User, Long&gt; &#123; Mono&lt;User&gt; findByUsername(String username);&#125; 但有些时候，我们也需要主动地创建一个 Mono 或 Flux。 普通的创建方式123Mono&lt;String&gt; helloWorld = Mono.just(\"Hello World\");Flux&lt;String&gt; fewWords = Flux.just(\"Hello\", \"World\");Flux&lt;String&gt; manyWords = Flux.fromIterable(words); 这样的创建方式在什么时候用呢？一般是用在经过一系列 非IO型 操作之后，得到了一个对象。接下来要基于这个对象运用 Reactor 进行 高性能 的 IO 操作时，可以用这种方式将之前得到的对象转换为 Mono 或 Flux。 文艺的创建方式上面是通过一个 同步调用 得到的结果创建出 Mono 或 Flux，但有时需要从一个 非 Reactive 的 异步调用 的结果创建出 Mono 或 Flux。 如果这个 异步方法 返回一个 CompletableFuture，那可以基于这个 CompletableFuture 创建一个 Mono： 1Mono.fromFuture(completableFuture); 如果这个 异步调用 不会返回 CompletableFuture，是有自己的 回调方法，那怎么创建 Mono 呢？\b可以使用 static &lt;T&gt; Mono&lt;T&gt; create(Consumer&lt;MonoSink&lt;T&gt;&gt; callback) 方法： 1234567891011121314Mono.create(sink -&gt; &#123; ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; entity = asyncRestTemplate.getForEntity(url, String.class); entity.addCallback(new ListenableFutureCallback&lt;ResponseEntity&lt;String&gt;&gt;() &#123; @Override public void onSuccess(ResponseEntity&lt;String&gt; result) &#123; sink.success(result.getBody()); &#125; @Override public void onFailure(Throwable ex) &#123; sink.error(ex); &#125; &#125;);&#125;); 在使用 WebFlux 之后，AsyncRestTemplate 已经不推荐使用，这里只是做演示。 2. 处理 Mono 和 Flux（中间阶段）中间阶段的 Mono 和 Flux 的方法主要有 filter、map、flatMap、then、zip、reduce 等。这些方法使用方法和 Stream 中的方法类似。 下面举几个 Reactor 开发实际项目的问题，帮大家理解这些方法的使用场景： 问题一: map、flatMap 和 then 在什么时候使用本段内容将涉及到如下类和方法： 方法：Mono.map() 方法：Mono.flatMap() 方法：Mono.then() 类：Function 在 Mono 和 Flux 中间环节的处理过程中，有三个有些类似的方法：map()、flatMap() 和 then()。这三个方法的使用频率很高。\b 传统的命令式编程 123Object result1 = doStep1(params);Object result2 = doStep2(result1);Object result3 = doStep3(result2); 对应的反应式编程 1234Mono.just(params) .flatMap(v -&gt; doStep1(v)) .flatMap(v -&gt; doStep2(v)) .flatMap(v -&gt; doStep3(v)); 从上面两段代码的对比就可以看出来 flatMap() 方法在其中起到的作用，map() 和 then() 方法也有类似的作用。但这些方法之间的区别是什么呢？我们先来看看这三个方法的签名（以 Mono 为例）： flatMap(Function&lt;? super T, ? extends Mono&lt;? extends R&gt;&gt; transformer) map(Function&lt;? super T, ? extends R&gt; mapper) then(Mono other) then()then() 看上去是下一步的意思，但它只表示执行顺序的下一步，不表示下一步依赖于上一步。then() 方法的参数只是一个 Mono，无从接受上一步的执行结果。而 flatMap() 和 map() 的参数都是一个 Function，入参是上一步的执行结果。 flatMap() 和 map()flatMap() 和 map() 的区别在于，flatMap() 中的入参 Function 的返回值要求是一个 Mono 对象，而 map 的入参 Function 只要求返回一个 普通对象。在业务处理中常需要调用 WebClient 或 ReactiveXxxRepository 中的方法，这些方法的 返回值 都是 Mono（或 Flux）。所以要将这些调用串联为一个整体 链式调用，就必须使用 flatMap()，而不是 map()。 问题二：如何实现并发执行本段内容将涉及到如下类和方法： 方法：Mono.zip() 类：Tuple2 类：BiFunction 并发执行 是常见的一个需求。Reactive Programming 虽然是一种 异步编程 方式，但是 异步 不代表就是 并发并行 的。 在 传统的命令式编程 中，并发执行 是通过 线程池 加 Future 的方式实现的。 1234567Future&lt;Result1&gt; result1Future = threadPoolExecutor.submit(() -&gt; doStep1(params));Future&lt;Result2&gt; result2Future = threadPoolExecutor.submit(() -&gt; doStep2(params));// Retrive resultResult1 result1 = result1Future.get();Result2 result2 = result2Future.get();// Do merge;return mergeResult; 上面的代码虽然实现了 \b异步调用，但 Future.get() 方法是 阻塞 的。在使用 Reactor 开发有 并发 执行场景的 反应式代码 时，不能用上面的方式。 这时应该使用 Mono 和 Flux 中的 zip() 方法，以 Mono 为例，代码如下： 12345678Mono&lt;CustomType1&gt; item1Mono = ...;Mono&lt;CustomType2&gt; item2Mono = ...;Mono.zip(items -&gt; &#123; CustomType1 item1 = CustomType1.class.cast(items[0]); CustomType2 item2 = CustomType2.class.cast(items[1]); // Do merge return mergeResult;&#125;, item1Mono, item2Mono); 上述代码中，产生 item1Mono 和 item2Mono 的过程是 并行 的。比如，调用一个 HTTP 接口的同时，执行一个 数据库查询 操作。这样就可以加快程序的执行。 但上述代码存在一个问题，就是 zip() 方法需要做 强制类型转换。而强制类型转换是 不安全的。好在 zip() 方法存在 多种重载 形式。除了最基本的形式以外，还有多种 类型安全 的形式： 123static &lt;T1, T2&gt; Mono&lt;Tuple2&lt;T1, T2&gt;&gt; zip(Mono&lt;? extends T1&gt; p1, Mono&lt;? extends T2&gt; p2);static &lt;T1, T2, O&gt; Mono&lt;O&gt; zip(Mono&lt;? extends T1&gt; p1, Mono&lt;? extends T2&gt; p2, BiFunction&lt;? super T1, ? super T2, ? extends O&gt; combinator); static &lt;T1, T2, T3&gt; Mono&lt;Tuple3&lt;T1, T2, T3&gt;&gt; zip(Mono&lt;? extends T1&gt; p1, Mono&lt;? extends T2&gt; p2, Mono&lt;? extends T3&gt; p3); 对于不超过 7 个元素的合并操作，都有 类型安全 的 zip() 方法可选。以两个元素的合并为例，介绍一下使用方法： 123456Mono.zip(item1Mono, item2Mono).map(tuple -&gt; &#123; CustomType1 item1 = tuple.getT1(); CustomType2 item2 = tuple.getT2(); // Do merge return mergeResult;&#125;); 上述代码中，map() 方法的参数是一个 Tuple2，表示一个 二元数组，相应的还有 Tuple3、Tuple4 等。 对于两个元素的并发执行，也可以通过 zip(Mono&lt;? extends T1&gt; p1, Mono&lt;? extends T2&gt; p2, BiFunction&lt;? super T1, ? super T2, ? extends O&gt; combinator) 方法直接将结果合并。方法是传递 BiFunction 实现 合并算法。 问题三：集合循环之后的汇聚本段内容将涉及到如下类和方法： 方法：Flux.fromIterable() 方法：Flux.reduce() 类：BiFunction 另外一个稍微复杂的场景，对一个对象中的一个类型为集合类的（List 、Set）进行处理之后，再对原本的对象进行处理。使用 迭代器模式 的代码很容易编写： 12345List&lt;SubData&gt; subDataList = data.getSubDataList();for (SubData item : subDataList) &#123; // Do something on data and item&#125;// Do something on data 当我们要用 Reactive 风格的代码实现上述逻辑时，就不是那么简单了。这里会用到 Flux 的 reduce() 方法。reduce() 方法的签名如下： &lt;A&gt; Mono&lt;A&gt; reduce(A initial, BiFunction&lt;A, ? super T, A&gt; accumulator); 可以看出，reduce() 方法的功能是将一个 Flux 聚合 成一个 Mono。 第一个参数: 返回值 Mono 中元素的 初始值。 第二个参数: 是一个 BiFunction，用来实现 聚合操作 的逻辑。对于泛型参数 &lt;A, ? super T, A&gt; 中： 第一个 A: 表示每次 聚合操作 之后的 结果的类型，它作为 BiFunction.apply() 方法的 第一个入参； 第二个 ? super T: 表示集合中的每个元素的类型，它作为 BiFunction.apply() 方法的 第二个入参； 第三个 A: 表示聚合操作的 结果，它作为 BiFunction.apply() 方法的 返回值。 接下来看一下示例： 1234567Data initData = ...;List&lt;SubData&gt; list = ...;Flux.fromIterable(list) .reduce(initData, (data, itemInList) -&gt; &#123; // Do something on data and itemInList return data; &#125;); 上面的示例代码中，initData 和 data 的类型相同。执行完上述代码之后，reduce() 方法会返回 Mono&lt;Data&gt;。 3. 消费 Mono 和 Flux（结束阶段）直接消费的 Mono 或 Flux 的方式就是调用 subscribe() 方法。如果在 WebFlux 接口中开发，直接返回 Mono 或 Flux 即可。WebFlux 框架会完成最后的 Response 输出工作。 小结本文介绍了反应式编程的一些概念和 Spring Reactor 框架的基本用法，还介绍了如何用 Reactor 解决一些稍微复杂一点的问题。Reactor 在 \bSpring 5 中有大量的应用，后面会给大家分享一些 Spring Reactor 实战\b系列的\b博客。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Spring Reactive编程系列","slug":"Spring-Reactive编程系列","permalink":"https://ostenant.coding.me/categories/Spring-Reactive编程系列/"}],"tags":[{"name":"Reactive Streams","slug":"Reactive-Streams","permalink":"https://ostenant.coding.me/tags/Reactive-Streams/"},{"name":"Spring WebFlux","slug":"Spring-WebFlux","permalink":"https://ostenant.coding.me/tags/Spring-WebFlux/"},{"name":"Reactor","slug":"Reactor","permalink":"https://ostenant.coding.me/tags/Reactor/"}]},{"title":"Android异步框架RxJava 1.x系列(三) - 线程调度器Scheduler","slug":"Android异步框架RxJava 1.x系列(三) - 线程调度器\bScheduler","date":"2018-05-23T12:22:00.000Z","updated":"2018-07-05T23:48:19.807Z","comments":true,"path":"2018/05/23/Android异步框架RxJava 1.x系列(三) - 线程调度器\bScheduler/","link":"","permalink":"https://ostenant.coding.me/2018/05/23/Android异步框架RxJava 1.x系列(三) - 线程调度器\bScheduler/","excerpt":"前言RxJava 事件的发出和消费都在同一个线程，基于同步的观察者模式。观察者模式的核心是后台处理，前台回调的异步机制。要实现异步，需要引入 RxJava 的另一个概念 - 线程调度器 Scheduler。","text":"前言RxJava 事件的发出和消费都在同一个线程，基于同步的观察者模式。观察者模式的核心是后台处理，前台回调的异步机制。要实现异步，需要引入 RxJava 的另一个概念 - 线程调度器 Scheduler。 正文在不指定线程的情况下，RxJava 遵循的是线程不变的原则。即在哪个线程调用 subscribe() 方法，就在哪个线程生产事件；在哪个线程生产事件，就在哪个线程消费事件。如果需要切换线程，就需要用到线程调度器 Scheduler。 1. 几种Scheduler介绍在 RxJava 中，Scheduler - 调度器，相当于线程控制器，RxJava 通过它来指定每一段代码应该运行在什么样的线程。RxJava 已经内置了几个 Scheduler ，它们已经适合大多数的使用场景： Schedulers.immediate() 直接在当前线程运行，相当于不指定线程。这是默认的 Scheduler。 Schedulers.newThread() 总是启用新线程，并在新线程执行操作。 Schedulers.io() I/O 操作（读写文件、读写数据库、网络信息交互等）所使用的 Scheduler。行为模式和 newThread() 差不多，区别在于 io() 内部采用的是一个无数量上限的线程池，可以重用空闲的线程。因此多数情况下 io() 比 newThread() 更有效率。 注意：不要把计算任务放在 io() 中，可以避免创建不必要的线程。 Schedulers.computation() 计算任务所使用的 Scheduler。这个计算指的是 CPU 密集型计算，即不会被 I/O 等操作限制性能的操作，例如图形的计算。这个 Scheduler 使用的固定的线程池，大小为 CPU 核数。 注意：不要把 I/O 操作放在 computation() 中，否则 I/O 操作的等待时间会浪费 CPU。 AndroidSchedulers.mainThread() Android 还有一个专用的 AndroidSchedulers.mainThread()，它指定的操作将在 Android 主线程运行。 2. Scheduler的线程切换2.1. 单次线程切换有了这几个 Scheduler，就可以使用 subscribeOn() 和 observeOn() 两个方法来对线程进行控制了。 subscribeOn(): 指定 subscribe() 所发生的线程，即 Observable.OnSubscribe 被激活时所处的线程，或者叫做事件产生的线程。 observeOn(): 指定 Subscriber 所运行在的线程，或者叫做事件消费的线程。 直接看代码： 123456789Observable.just(1, 2, 3, 4) .subscribeOn(Schedulers.io()) // 指定 subscribe() 发生在 IO 线程 .observeOn(AndroidSchedulers.mainThread()) // 指定 Subscriber 的回调发生在主线程 .subscribe(new Action1&lt;Integer&gt;() &#123; @Override public void call(Integer number) &#123; Log.d(tag, \"number:\" + number); &#125; &#125;); 上面这段代码中，由于 subscribeOn(Schedulers.io()) 的指定，被创建的事件的内容 1、2、3、4 将会在 IO 线程发出；由于 observeOn(AndroidScheculers.mainThread()) 的指定，因此 subscriber 数字的打印将发生在主线程。 事实上，这种使用方式非常常见，它适用于多数的 『后台线程取数据，主线程显示』的程序策略。 以下是一个完整的例子： 1234567891011121314151617181920212223242526272829int drawableRes = ...;ImageView imageView = ...;Observable.create(new OnSubscribe&lt;Drawable&gt;() &#123; @Override public void call(Subscriber&lt;? super Drawable&gt; subscriber) &#123; Drawable drawable = getTheme().getDrawable(drawableRes)); subscriber.onNext(drawable); subscriber.onCompleted(); &#125;&#125;)// 指定事件发出，即图片读取发生在 IO 线程.subscribeOn(Schedulers.io())// 指定事件消费 - 回调，即页面图片渲染发生在主线程.observeOn(AndroidSchedulers.mainThread()).subscribe(new Observer&lt;Drawable&gt;() &#123; @Override public void onNext(Drawable drawable) &#123; imageView.setImageDrawable(drawable); &#125; @Override public void onCompleted() &#123; &#125; @Override public void onError(Throwable e) &#123; Toast.makeText(activity, \"Error!\", Toast.LENGTH_SHORT).show(); &#125;&#125;); 这样的好处是，加载图片的过程发生在 IO 线程，而设置图片则发生在了主线程。这就意味着，即使加载图片耗费了几十甚至几百毫秒的时间，也不会造成界面上的丝毫卡顿。 2.2. 多次线程切换上面介绍到可以利用 subscribeOn() 结合 observeOn() 来实现线程控制，让事件的产生和消费发生在不同的线程。在了解了 map() 和 flatMap() 等变换方法后，一个问题就产生了 - 能不能多切换几次线程？ 因为 observeOn() 指定的是 Subscriber 的线程，而这个 Subscriber 并不是 subscribe() 参数中的 Subscriber ，而是 observeOn() 执行时，当前 Observable 所对应的 Subscriber，即它的直接下级 Subscriber。 也就是说，observeOn() 指定的是它之后的操作所在的线程。因此如果有多次切换线程的需求，只要在每个想要切换线程的位置调用一次 observeOn() 即可。 直接查看示例代码： 123456789101112Observable.just(1, 2, 3, 4) // 事件发出的 IO 线程，由 subscribeOn() 指定 .subscribeOn(Schedulers.io()) // 新线程，由 observeOn() 指定 .observeOn(Schedulers.newThread()) .map(mapOperator) // IO 线程，由 observeOn() 指定 .observeOn(Schedulers.io()) .map(mapOperator2) // Android 主线程，由 observeOn() 指定 .observeOn(AndroidSchedulers.mainThread) .subscribe(subscriber); 上面的代码，通过 observeOn() 的多次调用，程序实现了线程的多次切换。不过，不同于 observeOn()的是，subscribeOn() 的位置放在哪里都可以，但它是只能调用一次的。 3. Scheduler的实现原理其实，subscribeOn() 和 observeOn() 的内部实现，也是用的 lift() (见上文)，具体看图（不同颜色的箭头表示不同的线程）： subscribeOn()的原理图 从图中可以看出，subscribeOn() 进行了线程切换的工作（图中的 schedule... 的位置）。 subscribeOn() 的线程切换发生在 OnSubscribe 中，即在它通知上一级 OnSubscribe 时，这时事件还没有开始发送，因此 subscribeOn() 的线程控制只能在事件发出的开端造成影响，即只允许一次线程切换。 observeOn()的原理图 从图中可以看出，和 observeOn() 进行了线程切换的工作（图中的 schedule... 的位置）。 observeOn() 的线程切换则发生在它内建的 Subscriber 中，即发生在它即将给下一级 Subscriber 发送事件时，因此 observeOn() 控制的是它后面的线程，允许多次线程切换。 混合切换原理图 最后用一张图来解释当多个 subscribeOn() 和 observeOn() 混合使用时，线程调度是怎么发生的： 图中共有 5 处对事件的操作，由图中可以看出: ① 和 ② 两处受第一个 subscribeOn() 影响，运行在红色线程； ③ 和 ④ 处受第一个 observeOn() 的影响，运行在绿色线程； ⑤ 处受第二个 onserveOn() 影响，运行在紫色线程； 而第二个 subscribeOn() ，由于在通知过程中线程就被第一个 subscribeOn() 截断，因此对整个流程并没有任何影响。 注意：当使用了多个 subscribeOn() 的时候，只有第一个 subscribeOn() 起作用。 4. 延伸拓展虽然超过一个的 subscribeOn() 对事件处理的流程没有影响，但在流程之前却是有用的。在前面的文章介绍 Subscriber 的时候，提到过 Subscriber 的 onStart() 可以用作流程开始前的初始化处理。 由于 onStart() 在 subscribe() 发生时就被调用了，因此不能指定线程，而是只能执行在 subscribe() 被调用时的线程。这就导致如果 onStart() 中含有对线程有要求的代码（例如：在界面上显示一个 ProgressBar，这必须在主线程执行），将会有线程非法的风险，因为无法预测 subscribe() 会在什么线程执行。 与 Subscriber.onStart() 相对应的，有一个方法 Observable.doOnSubscribe()。它和 Subscriber.onStart() 同样是在 subscribe() 调用后而且在事件发送前执行，但区别在于它可以指定线程。默认情况下，doOnSubscribe() 执行在 subscribe() 发生的线程；而如果在 doOnSubscribe() 之后有 subscribeOn() 的话，它将执行在离它最近的 subscribeOn() 所指定的线程。 示例代码如下： 12345678910111213Observable.create(onSubscribe) .subscribeOn(Schedulers.io()) .doOnSubscribe(new Action0() &#123; @Override public void call() &#123; // 需要在主线程执行 progressBar.setVisibility(View.VISIBLE); &#125; &#125;) .subscribeOn(AndroidSchedulers.mainThread()) // 指定主线程 .observeOn(AndroidSchedulers.mainThread()) .subscribe(subscriber); 上面的代码，在 doOnSubscribe() 的后面跟一个 subscribeOn() ，就能指定特定工作的线程了！ 小结RxJava 的提供的各种事件及事件转换模型，以及基于转换的线程调度器，结合观察者模式，使得 RxJava 在异步编程体验、灵活性和运行效率上领先于其他的开源框架！ 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RxJava异步框架系列","slug":"RxJava异步框架系列","permalink":"https://ostenant.coding.me/categories/RxJava异步框架系列/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://ostenant.coding.me/tags/Android/"},{"name":"RxJava","slug":"RxJava","permalink":"https://ostenant.coding.me/tags/RxJava/"},{"name":"异步","slug":"异步","permalink":"https://ostenant.coding.me/tags/异步/"}]},{"title":"Android异步框架RxJava 1.x系列(二) - 事件及事件序列转换原理","slug":"Android异步框架RxJava 1.x系列(二) - 事件及事件序列转换原理","date":"2018-05-21T11:14:00.000Z","updated":"2018-06-18T01:46:41.894Z","comments":true,"path":"2018/05/21/Android异步框架RxJava 1.x系列(二) - 事件及事件序列转换原理/","link":"","permalink":"https://ostenant.coding.me/2018/05/21/Android异步框架RxJava 1.x系列(二) - 事件及事件序列转换原理/","excerpt":"前言在介绍 RxJava 1.x 线程调度器之前，首先引入一个重要的概念 - 事件序列转换。RxJava 提供了对事件序列进行转换的支持，这是它的核心功能之一。","text":"前言在介绍 RxJava 1.x 线程调度器之前，首先引入一个重要的概念 - 事件序列转换。RxJava 提供了对事件序列进行转换的支持，这是它的核心功能之一。 正文1. 事件序列转换定义所谓转换，就是将事件序列中的对象或整个序列进行加工处理，转换成不同的事件或事件序列，有点类似 Java 1.8 中的流处理。 2. 事件序列转换API首先看一个 map() 的例子： 12345678910111213Observable.just(\"images/logo.png\") // 输入类型 String .map(new Func1&lt;String, Bitmap&gt;() &#123; @Override public Bitmap call(String filePath) &#123; // 参数类型 String return getBitmapFromPath(filePath); // 返回类型 Bitmap &#125; &#125;) .subscribe(new Action1&lt;Bitmap&gt;() &#123; @Override public void call(Bitmap bitmap) &#123; // 参数类型 Bitmap showBitmap(bitmap); &#125; &#125;); 这里出现了一个叫 Func1 的类。它和 Action1 非常相似，也是 RxJava 的一个接口，用于包装含有一个参数的方法。 Func1 和 Action 的区别在于: Func1 包装的是有返回值的方法。另外，和 ActionX 一样，FuncX 也有多个，用于不同参数个数的方法。同理，FuncX 和 ActionX 的区别在 FuncX 包装的是有返回值的方法。 可以看到，map() 方法将参数中的 String 对象转换成一个 Bitmap 对象后返回，而在经过 map() 方法后，事件的参数类型也由 String 转为了 Bitmap。 这种直接转换对象并返回的，是最常见的也最容易理解的变换。不过 RxJava 的转换远不止这样，它不仅可以针对事件对象，还可以针对整个事件队列，这使得 RxJava 变得非常灵活。 下面给出几个示例： map()事件对象的直接变换，具体功能上面已经介绍过。它是 RxJava 最常用的变换。 map() 的示意图如下： flatMap()这是一个很有用但非常难理解的变换。首先假设这么一种需求：假设有一个数据结构『学生』，现在需要打印出一组学生的名字。实现方式很简单： 12345678910111213141516Student[] students = ...;Subscriber&lt;String&gt; subscriber = new Subscriber&lt;String&gt;() &#123; @Override public void onNext(String name) &#123; Log.d(tag, name); &#125;&#125;;Observable.from(students) .map(new Func1&lt;Student, String&gt;() &#123; @Override public String call(Student student) &#123; return student.getName(); &#125; &#125;) .subscribe(subscriber); 如果要打印出每个学生所需要修的所有课程的名称呢？需求的区别在于，每个学生只有一个名字，但却有多个课程，首先可以这样实现： 1234567891011121314Student[] students = ...;Subscriber&lt;Student&gt; subscriber = new Subscriber&lt;Student&gt;() &#123; @Override public void onNext(Student student) &#123; List&lt;Course&gt; courses = student.getCourses(); for (int i = 0; i &lt; courses.size(); i++) &#123; Course course = courses.get(i); Log.d(tag, course.getName()); &#125; &#125;&#125;;Observable.from(students) .subscribe(subscriber); 如果我不想在 Subscriber 中使用 for 循环，而是希望 Subscriber 中直接传入单个的 Course 对象呢（这对于代码复用很重要）？用 map() 显然是不行的，因为 map() 是一对一的转化，而现在需要一对多的转化。问题出现了：怎样把一个 Student 转化成多个 Course ？ 这个时候，flatMap() 就派上了用场： 12345678910111213141516Student[] students = ...;Subscriber&lt;Course&gt; subscriber = new Subscriber&lt;Course&gt;() &#123; @Override public void onNext(Course course) &#123; Log.d(tag, course.getName()); &#125;&#125;;Observable.from(students) .flatMap(new Func1&lt;Student, Observable&lt;Course&gt;&gt;() &#123; @Override public Observable&lt;Course&gt; call(Student student) &#123; return Observable.from(student.getCourses()); &#125; &#125;) .subscribe(subscriber); 从上面的代码可以看出，flatMap() 和 map() 有一个相同点：它也是把传入的参数转化之后返回另一个对象。 flatMap() 和 map() 不同的是，flatMap() 返回的是个 Observable 对象，并且这个 Observable 对象并不是被直接发送到 Subscriber 的回调方法中。 flatMap() 示意图如下： flatMap() 的原理是这样的： 使用传入的事件对象创建一个 Observable 对象； 并不立即发送这个 Observable, 而是将它激活，然后开始发送事件； 将每一个创建出来的 Observable 发送的事件，都被汇入同一个 Observable。 而这个 Observable 负责将这些事件统一交给 Subscriber 的回调方法。这三个步骤，把事件拆成了两级，通过一组新创建的 Observable 将初始的对象『铺平』之后通过统一路径分发了下去。而这个『铺平』就是 flatMap() 所谓的 flat。 3. 事件序列转换原理这些转换虽然功能各有不同，但实质上都是针对事件序列的处理和再发送。而在 RxJava 的内部，它们是基于同一个基础的转换方法：lift(Operator)。 lift()首先看一下 lift() 的内部实现（核心代码）： 12345678910public &lt;R&gt; Observable&lt;R&gt; lift(Operator&lt;? extends R, ? super T&gt; operator) &#123; return Observable.create(new OnSubscribe&lt;R&gt;() &#123; @Override public void call(Subscriber subscriber) &#123; Subscriber newSubscriber = operator.call(subscriber); newSubscriber.onStart(); onSubscribe.call(newSubscriber); &#125; &#125;);&#125; 这段代码实现的功能，简单来说就是创建了一个新的 Observable 并返回。如果看过上篇博客会发现有些蹊跷。重温一下 Observable.subscribe(Subscriber) 的实现(核心代码)： 12345public Subscription subscribe(Subscriber subscriber) &#123; subscriber.onStart(); onSubscribe.call(subscriber); return subscriber;&#125; 对比一下以上两段代码的方法体(忽略返回值)，会发现一行突兀的代码： 1Subscriber newSubscriber = operator.call(subscriber); 解释一下 lift() 方法完成的操作： 利用 Observable.create() 方法创建一个新的 Observable 对象，加上之前的原始 Observable，已经有两个 Observable。 创建 Observable 的同时创建一个新的 OnSubscribe 用于发出事件。 通过 lift() 传入的 Operator 函数的 call() 方法构造一个新的 Subscriber 对象，并将新 Subscriber 和原始 Subscriber 进行关联。 利用这个新 Subscriber 向原始 Observable 进行订阅，实现事件序列的转换。 这种实现基于代理模式，通过事件拦截和处理实现事件序列的变换。 在 Observable 执行了 lift(Operator) 方法之后，会返回一个新的 Observable，这个新的 Observable 会像一个代理一样，负责接收原始的 Observable 发出的事件，并在处理后发送给 Subscriber。 整个过程的思维导图如下： 或者可以看动图： 两次和多次的 lift() 同理，如下图： 举一个具体的 Operator 的实现。下面是一个将事件的 Integer 对象转换成 String 的例子，仅供参考： 12345678910111213141516171819202122observable.lift(new Observable.Operator&lt;String, Integer&gt;() &#123; @Override public Subscriber&lt;? super Integer&gt; call(final Subscriber&lt;? super String&gt; subscriber) &#123; // 将事件序列中的 Integer 对象转换为 String 对象 return new Subscriber&lt;Integer&gt;() &#123; @Override public void onNext(Integer integer) &#123; subscriber.onNext(\"\" + integer); &#125; @Override public void onCompleted() &#123; subscriber.onCompleted(); &#125; @Override public void onError(Throwable e) &#123; subscriber.onError(e); &#125; &#125;; &#125;&#125;); 学习 lift() 的原理只是为了更好地理解 RxJava ，从而可以更好地使用它。然而RxJava 不建议开发者自定义 Operator 来直接使用 lift()，而是尽量使用已有的 lift() 包装方法（如 map() flatMap() 等）进行组合。 compose()除了 lift() 之外，Observable 还有一个转方法叫做 compose()。它和 lift() 的区别在于，lift() 是针对事件项和事件序列的，而 compose() 是针对 Observable 自身进行转换。 举个例子，假设在程序中有多个 Observable 都需要应用一组相同的 lift() 进行转换，通常会这样写： 1234567891011121314151617181920212223observable1.lift1() .lift2() .lift3() .lift4() .subscribe(subscriber1);observable2.lift1() .lift2() .lift3() .lift4() .subscribe(subscriber2);observable3.lift1() .lift2() .lift3() .lift4() .subscribe(subscriber3);observable4.lift1() .lift2() .lift3() .lift4() .subscribe(subscriber1); 可以发现有太多重复代码，代码重构如下： 1234567891011private Observable liftAll(Observable observable) &#123; return observable.lift1() .lift2() .lift3() .lift4();&#125;liftAll(observable1).subscribe(subscriber1);liftAll(observable2).subscribe(subscriber2);liftAll(observable3).subscribe(subscriber3);liftAll(observable4).subscribe(subscriber4); 可读性、可维护性都提高了。可是 Observable 被一个方法包起来，这种方式对于 Observale 的灵活性进行了限制。怎么办？这个时候，就应该用 compose() 来解决了： 123456789101112131415public class LiftAllTransformer implements Observable.Transformer&lt;Integer, String&gt; &#123; @Override public Observable&lt;String&gt; call(Observable&lt;Integer&gt; observable) &#123; return observable.lift1() .lift2() .lift3() .lift4(); &#125;&#125;Transformer liftAll = new LiftAllTransformer();observable1.compose(liftAll).subscribe(subscriber1);observable2.compose(liftAll).subscribe(subscriber2);observable3.compose(liftAll).subscribe(subscriber3);observable4.compose(liftAll).subscribe(subscriber4); 如上，使用 compose() 方法，Observable 可以利用传入的 Transformer 对象的 call 方法直接对自身进行处理，而不是被包在方法的里面。 小结本文主要介绍了 RxJava 事件及事件序列转换原理，其中 lift() 方法的使用方法和实现原理是重点、难点。后续将会介绍的 RxJava 线程调度器底层也是基于它实现的。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RxJava异步框架系列","slug":"RxJava异步框架系列","permalink":"https://ostenant.coding.me/categories/RxJava异步框架系列/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://ostenant.coding.me/tags/Android/"},{"name":"RxJava","slug":"RxJava","permalink":"https://ostenant.coding.me/tags/RxJava/"},{"name":"异步","slug":"异步","permalink":"https://ostenant.coding.me/tags/异步/"}]},{"title":"Android异步框架RxJava 1.x系列(一) - 观察者模式及实现","slug":"Android异步框架RxJava 1.x系列(一) - 观察者模式及实现","date":"2018-05-20T10:14:00.000Z","updated":"2018-06-18T01:46:55.454Z","comments":true,"path":"2018/05/20/Android异步框架RxJava 1.x系列(一) - 观察者模式及实现/","link":"","permalink":"https://ostenant.coding.me/2018/05/20/Android异步框架RxJava 1.x系列(一) - 观察者模式及实现/","excerpt":"前言RxJava 是一款基于 Java VM 实现的响应式编程扩展库 - 基于观察者模式的异步和事件处理框架。RxJava 官方目前同时维护了两个版本，分别是 1.x 和 2.x，区别是它们使用不同的 group id 和 namespaces。","text":"前言RxJava 是一款基于 Java VM 实现的响应式编程扩展库 - 基于观察者模式的异步和事件处理框架。RxJava 官方目前同时维护了两个版本，分别是 1.x 和 2.x，区别是它们使用不同的 group id 和 namespaces。 版本 group id namespaces v1.x io.reactivex io.reactivex v2.x io.reactivex.rxjava2 rx 本系列的文章将针对 RxJava 1.x 进行介绍，先给出 Github 的地址： RxJava：https://github.com/ReactiveX/RxJava RxAndroid：https://github.com/ReactiveX/RxAndroid 通过 Gradle 引入相关依赖： 12compile 'io.reactivex:rxjava:1.0.14' compile 'io.reactivex:rxandroid:1.0.1' 正文1. RxJava的定义一个精准的解释如下：RxJava 是一个运行于 Java VM ，由可观测序列组成的，异步、基于事件的函数库。 2. RxJava的优点换句话说，『同样是做异步，为什么人们用它，而不用现成的 AsyncTask / Handler / XXX / … ？』 一个词：简洁。 异步操作很关键的一点是程序的简洁性，因为在调度过程比较复杂的情况下，异步代码经常会既难写也难被读懂。 Android 创造的 AsyncTask 和Handler，其实都是为了让异步代码更加简洁。RxJava 的优势也是简洁，但它的简洁的与众不同之处在于，随着程序逻辑变得越来越复杂，它依然能够保持简洁。 在 Android 开发中，假设有这样一个需求：界面上有一个自定义的视图 imageCollectorView ，它的作用是显示多张图片，并能使用 addImage(Bitmap) 方法来任意增加显示的图片。现在需要程序将一个给出的目录数组 File[] folders 中每个目录下的 png 图片都加载出来并显示在 imageCollectorView 中。 注意: 由于读取图片的过程较为耗时，需要放在后台执行，而图片的显示则必须在 UI 线程执行。 常用的实现方式有多种，这里给出其中一种： 1234567891011121314151617181920new Thread() &#123; @Override public void run() &#123; super.run(); for (File folder : folders) &#123; File[] files = folder.listFiles(); for (File file : files) &#123; if (file.getName().endsWith(\".png\")) &#123; final Bitmap bitmap = getBitmapFromFile(file); getActivity().runOnUiThread(new Runnable() &#123; @Override public void run() &#123; imageCollectorView.addImage(bitmap); &#125; &#125;); &#125; &#125; &#125; &#125;&#125;.start(); 而如果使用 RxJava，实现方式是这样的： 123456789101112131415161718192021222324252627Observable.from(folders) .flatMap(new Func1&lt;File, Observable&lt;File&gt;&gt;() &#123; @Override public Observable&lt;File&gt; call(File file) &#123; return Observable.from(file.listFiles()); &#125; &#125;) .filter(new Func1&lt;File, Boolean&gt;() &#123; @Override public Boolean call(File file) &#123; return file.getName().endsWith(\".png\"); &#125; &#125;) .map(new Func1&lt;File, Bitmap&gt;() &#123; @Override public Bitmap call(File file) &#123; return getBitmapFromFile(file); &#125; &#125;) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe(new Action1&lt;Bitmap&gt;() &#123; @Override public void call(Bitmap bitmap) &#123; imageCollectorView.addImage(bitmap); &#125; &#125;); 可以发现，使用 RxJava 方式代码量明显大大增加，所谓简洁从何而来？ 这里说的简洁是指的逻辑上的。观察一下你会发现，RxJava 的这个实现，是一条从上到下的链式调用，没有任何嵌套，这在逻辑的简洁性上是具有优势的。当需求变得复杂时，这种优势将更加明显（试想如果还要求只选取前 10 张图片，常规方式要怎么办？如果有更多这样那样的要求呢？再试想，在这一大堆需求实现完两个月之后需要改功能，当你翻回这里看到自己当初写下的那一片迷之缩进，你能保证自己将迅速看懂，而不是对着代码重新捋一遍思路？）。 另外，如果你的 IDE 是 Android Studio，其实每次打开某个 Java 文件的时候，你会看到被自动 Lambda 化的预览，这将让你更加清晰地看到程序逻辑： 1234567Observable.from(folders) .flatMap((Func1) (folder) -&gt; &#123; Observable.from(file.listFiles()) &#125;) .filter((Func1) (file) -&gt; &#123; file.getName().endsWith(\".png\") &#125;) .map((Func1) (file) -&gt; &#123; getBitmapFromFile(file) &#125;) .subscribeOn(Schedulers.io()) .observeOn(AndroidSchedulers.mainThread()) .subscribe((Action1) (bitmap) -&gt; &#123; imageCollectorView.addImage(bitmap) &#125;); 所以，RxJava 有啥优点？就好在简洁，优点就是把复杂逻辑，通过函数式编程模型穿成一条线。 3. 观察者模式的扩展RxJava 的异步实现，是通过一种扩展的观察者模式来实现的。 3.1. 通用的观察者模式观察者模式面向的需求是：A 对象（观察者）对 B 对象（被观察者）的某种变化高度敏感，需要在 B 变化的一瞬间做出反应。 举个例子，新闻里喜闻乐见的警察抓小偷，警察需要在小偷伸手作案的时候实施抓捕。在这个例子里，警察是观察者，小偷是被观察者，警察需要时刻盯着小偷的一举一动，才能保证不会漏过任何瞬间。 程序的观察者模式略有不同，观察者不需要时刻盯着被观察者（例如 A 不需要每过 2ms 就检查一次 B 的状态），而是采用注册( Register )或者称为订阅(Subscribe)的方式，告诉被观察者：我需要你的某种状态，你要在它变化的时候通知我。 采取这样被动的观察方式，既省去了反复检索状态的资源消耗，也能够得到最高的反馈速度。 Android 开发中一个典型的例子是点击监听器 OnClickListener 。对设置 OnClickListener 来说，View 是被观察者，OnClickListener 是观察者，二者通过 setOnClickListener() 方法达成订阅关系。订阅之后用户点击按钮的瞬间，Android Framework 就会将点击事件发送给已注册的 OnClickListener 。 OnClickListener 的观察者模式大致如下图： 如图所示，通过 setOnClickListener() 方法，Button 持有 OnClickListener 的引用（这一过程没有在图上画出）。当用户点击时，Button 自动调用 OnClickListener 的 onClick() 方法。 按照观察者模式抽象出来的各个概念： Button: 被观察者 OnClickListener: 观察者 setOnClickListener(): 订阅 onClick(): 事件处理 就由专用的观察者模式转变成了通用的观察者模式，如下图： 3.2. RxJava的观察者模式RxJava 有四个基本概念： Observable: 可观察者，即被观察者 Observer: 观察者 Subscribe: 订阅 Event: 事件处理 Observable 和 Observer 通过 subscribe() 方法实现订阅关系，使得Observable 可以在需要的时候发出事件来通知 Observer。 与传统观察者模式不同，RxJava 的事件回调方法除了普通事件 onNext() （相当于 onClick()) 之外，还定义了两个特殊的事件：onCompleted() 和 onError()。 onCompleted(): 事件队列完结 RxJava 不仅把每个事件单独处理，还会把它们看做一个队列。RxJava规定，当不会再有新的 onNext() 发出时，需要触发 onCompleted() 方法作为事件完成标志。 onError(): 事件队列异常 在事件处理过程中出异常时，onError() 会被触发，同时队列自动终止，不允许再有事件发出。 在一个正确运行的事件序列中, onCompleted() 和 onError() 有且只有一个被调用，并且是事件序列中的最后一个执行。 RxJava 的观察者模式大致如下图： 4. RxJava的基本使用基于以上的概念，RxJava 的基本使用有 3 个步骤： 4.1. 创建ObseverObserver 即观察者，它决定事件触发的时候将有怎样的行为。 RxJava 中的 Observer 接口的声明方式： 12345678910111213141516Observer&lt;String&gt; observer = new Observer&lt;String&gt;() &#123; @Override public void onNext(String s) &#123; Log.d(tag, \"Item: \" + s); &#125; @Override public void onCompleted() &#123; Log.d(tag, \"Completed!\"); &#125; @Override public void onError(Throwable e) &#123; Log.d(tag, \"Error: \" + e.getMessage()); &#125;&#125;; 除了 Observer 接口之外，RxJava 还内置了一个实现了 Observer 的抽象类：Subscriber。 Subscriber 对 Observer 接口进行了一些扩展，但他们的基本使用方式是完全一样的： 12345678910111213141516Subscriber&lt;String&gt; subscriber = new Subscriber&lt;String&gt;() &#123; @Override public void onNext(String s) &#123; Log.d(tag, \"Item: \" + s); &#125; @Override public void onCompleted() &#123; Log.d(tag, \"Completed!\"); &#125; @Override public void onError(Throwable e) &#123; Log.d(tag, \"Error: \" + e.getMessage()); &#125;&#125;; 实质上，在 RxJava 的 subscribe 过程中，Observer 也总是会先被转换成一个 Subscriber 再使用。所以如果你只想使用基本功能，选择 Observer 和 Subscriber 是完全一样的。它们的区别对于使用者来说主要有两点： onStart() 这是 Subscriber 增加的方法。它会在 subscribe 刚开始，而事件还未发送之前被调用。可以用于做一些准备工作，例如数据的清零或重置。这是一个可选方法，默认情况下它的实现为空。 需要注意的是，如果对准备工作的线程有要求（例如: 弹出一个显示进度的对话框，这必须在主线程执行），onStart() 就不适用了。因为它总是在 subscribe 所发生的线程被调用，而不能指定线程。要在指定的线程来做准备工作，可以使用 doOnSubscribe() 方法，具体可以在后面的章节中看到。 unsubscribe() 这是 Subscriber 所实现的另一个接口 Subscription 的方法，用于取消订阅。在这个方法被调用后，Subscriber 将不再接收事件。一般在这个方法调用前，可以使用 isUnsubscribed() 先判断一下状态。 unsubscribe() 这个方法很重要，因为在 subscribe() 之后， Observable 会持有 Subscriber 的引用。这个引用如果不能及时被释放，将有内存泄露的风险。 注意：在不再使用的时候尽快在合适的地方（例如: onPause() 和 onStop() 等方法中）调用 unsubscribe() 来解除引用关系，以避免内存泄露的发生。 4.2. 创建Obsevable4.2.1. Obsevable.create()Observable 即被观察者，它决定什么时候触发事件以及触发怎样的事件。 RxJava 使用 create() 方法来创建一个 Observable ，并为它定义事件触发规则。示例如下： 123456789Observable observable = Observable.create(new Observable.OnSubscribe&lt;String&gt;() &#123; @Override public void call(Subscriber&lt;? super String&gt; subscriber) &#123; subscriber.onNext(\"Hello\"); subscriber.onNext(\"Hi\"); subscriber.onNext(\"Aloha\"); subscriber.onCompleted(); &#125;&#125;); 可以看到，这里传入了一个 OnSubscribe 对象作为参数。OnSubscribe 会被存储在返回的 Observable 对象中。 它的作用相当于一个计划表，当 Observable 被订阅的时候，OnSubscribe 的 call() 方法会自动被调用，事件序列就会依照设定依次触发（对于上面的代码，就是观察者Subscriber 将会被调用三次 onNext() 和一次 onCompleted()）。 这样，由被观察者调用了观察者的回调方法，就实现了由被观察者向观察者的事件传递，即观察者模式。 4.2.2. Obsevable.just(T…)create() 方法是 RxJava 最基本的创建事件序列的方法。基于这个方法，RxJava 还提供了一些方法用于快捷创建事件队列，例如 just() 方法： 12Observable observable = Observable.just(\"Hello\", \"Hi\", \"Aloha\");// 将会依次调用方法序列：onNext(\"Hello\") -&gt; onNext(\"Hi\") -&gt; onCompleted() 4.2.3. Obsevable.from(T[])和from(Iterable&lt;? extends T&gt;)将传入的数组或 Iterable 拆分成具体对象后，依次发送给观察者，示例如下： 123String[] words = &#123;\"Hello\", \"Hi\", \"Aloha\"&#125;;Observable observable = Observable.from(words);// 将会依次调用方法序列：onNext(\"Hello\") -&gt; onNext(\"Hi\") -&gt; onCompleted() 4.3. Subscribe关联创建了 Observable 和 Observer 之后，再用 subscribe() 方法将它们关联起来，整条链子就可以工作了。代码很简单： 123observable.subscribe(observer);// 或者observable.subscribe(subscriber); 可能会注意到，subscribe() 这个方法有点怪：它看起来是『observable 订阅了 observer / subscriber』，而不是『observer / subscriber 订阅了 observable』。这看起来就像『杂志订阅了读者』一样颠倒了对象关系。 这让人读起来有点别扭，不过如果把 API 设计成 『observer.subscribe(observable) / subscriber.subscribe(observable)』，虽然更加符合思维逻辑，但对流式 API 的设计就造成影响了，比较起来明显是得不偿失的。 Observable.subscribe(Subscriber) 的内部实现是这样的(核心代码): 12345public Subscription subscribe(Subscriber subscriber) &#123; subscriber.onStart(); onSubscribe.call(subscriber); return subscriber;&#125; 可以看到subscriber() 做了3件事： (a). 调用Subscriber.onStart() 这个方法在前面已经介绍过，是一个可选的准备方法。 (b). 调用Observable中的OnSubscribe.call(Subscriber) 事件发送的逻辑开始运行。从这也可以看出，在RxJava中，Observable并不是在创建的时候就立即开始发送事件，而是在它被订阅的时候，即当subscribe()方法执行的时候。 (c). 返回Subscription 将传入的Subscriber作为Subscription返回。这是为了方便后面的unsubscribe()。 整个过程中对象间的关系如下图： 或者可以看动图： 除了 subscribe(Observer) 和 subscribe(Subscriber) ，subscribe() 还支持不完整定义的回调，RxJava 会自动根据定义创建出 Subscriber。形式如下： 12345678910111213141516171819202122232425262728Action1&lt;String&gt; onNextAction = new Action1&lt;String&gt;() &#123; // onNext() @Override public void call(String s) &#123; Log.d(tag, s); &#125;&#125;;Action1&lt;Throwable&gt; onErrorAction = new Action1&lt;Throwable&gt;() &#123; // onError() @Override public void call(Throwable throwable) &#123; // Error handling &#125;&#125;;Action0 onCompletedAction = new Action0() &#123; // onCompleted() @Override public void call() &#123; Log.d(tag, \"completed\"); &#125;&#125;;// 自动创建 Subscriber ，并使用 onNextAction 来定义 onNext()observable.subscribe(onNextAction);// 自动创建 Subscriber ，并使用 onNextAction 和 onErrorAction 来定义 onNext() 和 onError()observable.subscribe(onNextAction, onErrorAction);// 自动创建 Subscriber ，并使用 onNextAction、 onErrorAction 和 onCompletedAction 来定义 onNext()、 onError() 和 onCompleted()observable.subscribe(onNextAction, onErrorAction, onCompletedAction); 简单解释一下这段代码中出现的 Action1 和 Action0。 Action0 Action0 是 RxJava 的一个接口，它只有一个方法 call()，这个方法是无参无返回值的。由于 onCompleted() 方法也是无参无返回值的，因此 Action0 可以被当成一个包装对象，将 onCompleted() 的内容打包起来将自己作为一个参数传入 subscribe() 以实现不完整定义的回调。 Action1 Action1 也是一个接口，它同样只有一个方法 call(T param)，这个方法也无返回值，但有一个参数。与 Action0 同理，由于 onNext(T obj) 和 onError(Throwable error) 也是单参数无返回值的，因此 Action1 可以将 onNext(obj) 和 onError(error) 打包起来传入 subscribe() 以实现不完整定义的回调。 事实上，虽然 Action0 和 Action1 在 API 中使用最广泛，但 RxJava 提供了多个 ActionX 形式的接口 (例如: Action2, Action3)，它们可以被用以包装不同的无返回值的方法。 4.4. 场景示例4.4.1. 打印字符串数组将字符串数组 names 中的所有字符串依次打印出来： 12345678String[] names = ...;Observable.from(names) .subscribe(new Action1&lt;String&gt;() &#123; @Override public void call(String name) &#123; Log.d(tag, name); &#125; &#125;); 4.4.2. 由ID取得图片显示12345678910111213141516171819202122232425int drawableRes = ...;ImageView imageView = ...;Observable.create(new OnSubscribe&lt;Drawable&gt;() &#123; @Override public void call(Subscriber&lt;? super Drawable&gt; subscriber) &#123; Drawable drawable = getTheme().getDrawable(drawableRes)); subscriber.onNext(drawable); subscriber.onCompleted(); &#125;&#125;).subscribe(new Observer&lt;Drawable&gt;() &#123; @Override public void onNext(Drawable drawable) &#123; imageView.setImageDrawable(drawable); &#125; @Override public void onCompleted() &#123; &#125; @Override public void onError(Throwable e) &#123; Toast.makeText(activity, \"Error!\", Toast.LENGTH_SHORT).show(); &#125;&#125;); 正如上面两个例子这样，创建出 Observable 和 Subscriber，再用 subscribe() 将它们串起来，一次 RxJava 的基本使用就完成了，非常简单！ 然而。 小结在 RxJava 的默认规则中，事件的发出和消费都是在同一个线程的。也就是说，如果只用上面的方法，实现出来的只是一个同步的观察者模式。观察者模式本身的目的就是『后台处理，前台回调』的异步机制，因此异步对于 RxJava 是至关重要的。而要实现异步，则需要用到 RxJava 的另一个核心的概念 Scheduler，后续将给出详细介绍。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RxJava异步框架系列","slug":"RxJava异步框架系列","permalink":"https://ostenant.coding.me/categories/RxJava异步框架系列/"}],"tags":[{"name":"Android","slug":"Android","permalink":"https://ostenant.coding.me/tags/Android/"},{"name":"RxJava","slug":"RxJava","permalink":"https://ostenant.coding.me/tags/RxJava/"},{"name":"异步","slug":"异步","permalink":"https://ostenant.coding.me/tags/异步/"}]},{"title":"分布式唯一ID的几种生成方案","slug":"分布式唯一ID的几种生成方案","date":"2018-05-13T23:46:00.000Z","updated":"2018-06-18T01:53:36.474Z","comments":true,"path":"2018/05/14/分布式唯一ID的几种生成方案/","link":"","permalink":"https://ostenant.coding.me/2018/05/14/分布式唯一ID的几种生成方案/","excerpt":"前言在互联网的业务系统中，涉及到各种各样的ID，如在支付系统中就会有支付ID、退款ID等。那一般生成ID都有哪些解决方案呢？特别是在复杂的分布式系统业务场景中，我们应该采用哪种适合自己的解决方案是十分重要的。下面我们一一来列举一下，不一定全部适合，这些解决方案仅供你参考，或许对你有用。","text":"前言在互联网的业务系统中，涉及到各种各样的ID，如在支付系统中就会有支付ID、退款ID等。那一般生成ID都有哪些解决方案呢？特别是在复杂的分布式系统业务场景中，我们应该采用哪种适合自己的解决方案是十分重要的。下面我们一一来列举一下，不一定全部适合，这些解决方案仅供你参考，或许对你有用。 正文分布式ID的特性 唯一性：确保生成的ID是全网唯一的。 有序递增性：确保生成的ID是对于某个用户或者业务是按一定的数字有序递增的。 高可用性：确保任何时候都能正确的生成ID。 带时间：ID里面包含时间，一眼扫过去就知道哪天的交易。 分布式ID的生成方案1. UUID算法的核心思想是结合机器的网卡、当地时间、一个随记数来生成UUID。 优点：本地生成，生成简单，性能好，没有高可用风险 缺点：长度过长，存储冗余，且无序不可读，查询效率低 2. 数据库自增ID使用数据库的id自增策略，如 MySQL 的 auto_increment。并且可以使用两台数据库分别设置不同步长，生成不重复ID的策略来实现高可用。 优点：数据库生成的ID绝对有序，高可用实现方式简单 缺点：需要独立部署数据库实例，成本高，有性能瓶颈 3. 批量生成ID一次按需批量生成多个ID，每次生成都需要访问数据库，将数据库修改为最大的ID值，并在内存中记录当前值及最大值。 优点：避免了每次生成ID都要访问数据库并带来压力，提高性能 缺点：属于本地生成策略，存在单点故障，服务重启造成ID不连续 4. Redis生成IDRedis的所有命令操作都是单线程的，本身提供像 incr 和 increby 这样的自增原子命令，所以能保证生成的 ID 肯定是唯一有序的。 优点：不依赖于数据库，灵活方便，且性能优于数据库；数字ID天然排序，对分页或者需要排序的结果很有帮助。 缺点：如果系统中没有Redis，还需要引入新的组件，增加系统复杂度；需要编码和配置的工作量比较大。 考虑到单节点的性能瓶颈，可以使用 Redis 集群来获取更高的吞吐量。假如一个集群中有5台 Redis。可以初始化每台 Redis 的值分别是1, 2, 3, 4, 5，然后步长都是 5。各个 Redis 生成的 ID 为： 12345A：1, 6, 11, 16, 21B：2, 7, 12, 17, 22C：3, 8, 13, 18, 23D：4, 9, 14, 19, 24E：5, 10, 15, 20, 25 随便负载到哪个机确定好，未来很难做修改。步长和初始值一定需要事先确定。使用 Redis 集群也可以方式单点故障的问题。 另外，比较适合使用 Redis 来生成每天从0开始的流水号。比如订单号 = 日期 + 当日自增长号。可以每天在 Redis 中生成一个 Key ，使用 INCR 进行累加。 5. Twitter的snowflake算法Twitter 利用 zookeeper 实现了一个全局ID生成的服务 Snowflake：https://github.com/twitter/snowflake 如上图的所示，Twitter 的 Snowflake 算法由下面几部分组成： 1位符号位： 由于 long 类型在 java 中带符号的，最高位为符号位，正数为 0，负数为 1，且实际系统中所使用的ID一般都是正数，所以最高位为 0。 41位时间戳（毫秒级）： 需要注意的是此处的 41 位时间戳并非存储当前时间的时间戳，而是存储时间戳的差值（当前时间戳 - 起始时间戳），这里的起始时间戳一般是ID生成器开始使用的时间戳，由程序来指定，所以41位毫秒时间戳最多可以使用 (1 &lt;&lt; 41) / (1000x60x60x24x365) = 69年。 10位数据机器位： 包括5位数据标识位和5位机器标识位，这10位决定了分布式系统中最多可以部署 1 &lt;&lt; 10 = 1024 s个节点。超过这个数量，生成的ID就有可能会冲突。 12位毫秒内的序列： 这 12 位计数支持每个节点每毫秒（同一台机器，同一时刻）最多生成 1 &lt;&lt; 12 = 4096个ID 加起来刚好64位，为一个Long型。 优点：高性能，低延迟，按时间有序，一般不会造成ID碰撞 缺点：需要独立的开发和部署，依赖于机器的时钟 简单实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public class IdWorker &#123; /** * 起始时间戳 2017-04-01 */ private final long epoch = 1491004800000L; /** * 机器ID所占的位数 */ private final long workerIdBits = 5L; /** * 数据标识ID所占的位数 */ private final long dataCenterIdBits = 5L; /** * 支持的最大机器ID,结果是31 */ private final long maxWorkerId = ~(-1L &lt;&lt; workerIdBits); /** * 支持的最大数据标识ID,结果是31 */ private final long maxDataCenterId = ~(-1 &lt;&lt; dataCenterIdBits); /** * 毫秒内序列在id中所占的位数 */ private final long sequenceBits = 12L; /** * 机器ID向左移12位 */ private final long workerIdShift = sequenceBits; /** * 数据标识ID向左移17(12+5)位 */ private final long dataCenterIdShift = sequenceBits + workerIdBits; /** * 时间戳向左移22(12+5+5)位 */ private final long timestampShift = sequenceBits + workerIdBits + dataCenterIdBits; /** * 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */ private final long sequenceMask = ~(-1L &lt;&lt; sequenceBits); /** * 数据标识ID（0～31） */ private long dataCenterId; /** * 机器ID（0～31） */ private long workerId; /** * 毫秒内序列（0～4095） */ private long sequence; /** * 上次生成ID的时间戳 */ private long lastTimestamp = -1L; public IdWorker(long dataCenterId, long workerId) &#123; if (dataCenterId &gt; maxDataCenterId || dataCenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"dataCenterId can't be greater than %d or less than 0\", maxDataCenterId)); &#125; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(\"worker Id can't be greater than %d or less than 0\", maxWorkerId)); &#125; this.dataCenterId = dataCenterId; this.workerId = workerId; &#125; /** * 获得下一个ID (该方法是线程安全的) * @return snowflakeId */ public synchronized long nextId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳,说明系统时钟回退过,这个时候应当抛出异常 if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException(String.format(\"Clock moved backwards. Refusing to generate id for %d milliseconds\", lastTimestamp - timestamp)); &#125; //如果是同一时间生成的，则进行毫秒内序列 if (timestamp == lastTimestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; //毫秒内序列溢出 if (sequence == 0) &#123; //阻塞到下一个毫秒,获得新的时间戳 timestamp = nextMillis(lastTimestamp); &#125; &#125; else &#123;//时间戳改变，毫秒内序列重置 sequence = 0L; &#125; lastTimestamp = timestamp; //移位并通过按位或运算拼到一起组成64位的ID return ((timestamp - epoch) &lt;&lt; timestampShift) | (dataCenterId &lt;&lt; dataCenterIdShift) | (workerId &lt;&lt; workerIdShift) | sequence; &#125; /** * 返回以毫秒为单位的当前时间 * @return 当前时间(毫秒) */ protected long timeGen() &#123; return System.currentTimeMillis(); &#125; /** * 阻塞到下一个毫秒，直到获得新的时间戳 * @param lastTimestamp 上次生成ID的时间截 * @return 当前时间戳 */ protected long nextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = lastTimestamp; &#125; return timestamp; &#125; &#125; 6. 百度UidGeneratorUidGenerator是百度开源的分布式ID生成器，基于于snowflake算法的实现，看起来感觉还行。不过，国内开源的项目维护性真是担忧。 具体可以参考官网说明：https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md 7. 美团LeafLeaf 是美团开源的分布式ID生成器，能保证全局唯一性、趋势递增、单调递增、信息安全，里面也提到了几种分布式方案的对比，但也需要依赖关系数据库、Zookeeper等中间件。 具体可以参考官网说明：https://tech.meituan.com/MT_Leaf.html 小结这篇文章和大家分享了全局id生成服务的几种常用方案，同时对比了各自的优缺点和适用场景。在实际工作中，大家可以结合自身业务和系统架构体系进行合理选型。 欢迎扫码关注公众号：零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"Unique ID","slug":"Unique-ID","permalink":"https://ostenant.coding.me/tags/Unique-ID/"}]},{"title":"蚂蚁金服SOFA-Boot整合SOFA-RPC(下篇)","slug":"蚂蚁金服SOFA-Boot整合SOFA-RPC(下篇)","date":"2018-05-12T12:12:00.000Z","updated":"2018-06-18T02:00:01.633Z","comments":true,"path":"2018/05/12/蚂蚁金服SOFA-Boot整合SOFA-RPC(下篇)/","link":"","permalink":"https://ostenant.coding.me/2018/05/12/蚂蚁金服SOFA-Boot整合SOFA-RPC(下篇)/","excerpt":"前言上文介绍了SOFA-RPC 的几种调用方式，包括单向调用、同步调用、Future调用、回调，引入了泛化调用和过滤器。本文将对 SOFA-RPC 的高级功能，包括参数配置、自定义线程池、预热权重和自动故障剔除等。","text":"前言上文介绍了SOFA-RPC 的几种调用方式，包括单向调用、同步调用、Future调用、回调，引入了泛化调用和过滤器。本文将对 SOFA-RPC 的高级功能，包括参数配置、自定义线程池、预热权重和自动故障剔除等。 正文1. 参数配置SOFABoot RPC Starter 提供了方便的参数设置方式。这些参数目前可以分为两个部分。一部分是如端口，注册中心地址等配置，这类配置在 application.properties 中。另一部分是如超时时间等配置，这类配置在 XML 中。 XML 配置 调用超时时间 如下是设置超时时间的方式，单位为 ms ，如果调用超过了这个时间则会抛出异常。服务端和客户端都可以设置，以客户端的超时时间设置优先。默认客户端为 3000 ，目前对 bolt，rest，dubbo 生效。 123&lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs timeout=\"5000\"/&gt;&lt;/sofa:binding.bolt&gt; 获取地址等待时间 如下是设置获取地址等待时间，单位为ms。在启动时如果服务引用方等待超过了这个时间则不会再等待地址，会继续启动。客户端设置，默认为-1，表示会一直等待到地址为止。目前对 bolt，rest 生效。 123&lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs address-wait-time=\"30000\"/&gt;&lt;/sofa:binding.bolt&gt; 建立连接超时时间 如下是设置建立连接超时时间，单位为 ms 。在建立连接时如果耗时超过了这个时间则会抛出异常。客户端设，默认为 5000。目前对 bolt，rest 生效。 123&lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs connect.timeout=\"30000\"&lt;/sofa:binding.bolt&gt; 权重 如下是设置权重。客户端在发起调用时，如果采用的算法是随机调用，则会根据该权重来进行随机。服务端设置，默认为 100。目前对 bolt 生效。 123&lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs weight=\"200\"/&gt;&lt;/sofa:binding.bolt&gt; lazy 连接 默认情况下客户端在注册中心推送地址到客户端时，就立即建立好连接，这个过程通常是在第一次调用之前进行的。如果设置服务引用的属性 lazy 为 true，客户端在第一次调用时才和所要调用的远程地址建立连接。默认为 false。 如下设置 lazy 连接方式，将 lazy 属性设为 true。目前支持 bolt 和 dubbo 协议。 12345&lt;sofa:reference id=\"lazyServiceReferenceBolt\" interface=\"com.ostenant.sofa.rpc.example.lazy.LazyService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs lazy=\"true\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; check 属性 默认情况下客户端在启动时，服务引用不要求存在可用的地址和连接。如果设置服务引用的属性 check 为 true，客户端在启动时，服务引用会检查是否存在对应的地址和连接，如果不存在会抛出异常。默认为 false。 如下设置 check 连接方式，将 check 属性设为 true。目前支持 bolt 和 dubbo 协议。 12345&lt;sofa:reference id=\"checkServiceReferenceBolt\" interface=\"com.ostenant.sofa.rpc.example.check.CheckService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs check=\"true\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 重试次数 重试次数，即在第一次调用失败后重试的最大次数，如果重试成功则不再继续重试。默认为 0。如下设置调用次数，利用 retries 属性指定重试次数。目前支持 bolt 和 dubbo 协议。 12345&lt;sofa:reference id=\"retriesServiceReferenceBolt\" interface=\"com.ostenant.sofa.rpc.example.retries.RetriesService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs retries=\"2\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 负载均衡 如下选择负载均衡的方式，利用 loadBalancer 属性指定调用时候使用的负载均衡策略，默认为 random。 目前支持 random，localPref，roundRobin，consistentHash，weightRoundRobin 五种负载均衡策略，具体可见 SOFARPC 负载均衡相关介绍。目前支持bolt协议。 12345&lt;sofa:reference id=\"loadBalancerServiceReference\" interface=\"com.ostenant.sofa.rpc.example.loadBalancer.LoadBalancerService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs loadBalancer=\"random\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 方法级别配置 如下，sofa:method 元素是方法级别的配置。方法级别的配置优先级比服务级别的更高。name 属性指定了方法的名字。支持调用超时时间，调用方式，回调类的设置。方法级别的配置与服务级别的配置所生效的协议一样。 123&lt;sofa:binding.bolt&gt; &lt;sofa:method name=\"sayMethod\" timeout=\"3000\" type=\"sync\" callback-ref=\"xxx\"/&gt;&lt;/sofa:binding.bolt&gt; Properties 配置 属性 描述 默认值 spring.application.name 应用名 logging.path 日志路径 logging.level.com.alipay.sofa.rpc.boot sofa-rpc-boot-start的日志级别(starter自身的日志) info logging.level.com.alipay.sofa.rpc sofa-rpc的日志级别(sofa-rpc核心日志基本在这里) info com.alipay.sofa.rpc.bolt.port bolt 端口 22000 com.alipay.sofa.rpc.bolt.io.thread.count bolt 的 io 线程数 com.alipay.sofa.rpc.bolt.executor.thread.count bolt 的业务线程最大值 200 com.alipay.sofa.rpc.bolt.accepts.count bolt 能够支持的最大长连接数 100000 com.alipay.sofa.rpc.rest.hostname rest 的 hostname com.alipay.sofa.rpc.rest.port rest 端口 8341 com.alipay.sofa.rpc.rest.io.thread.count rest 的 io 线程数 cpu 核数 * 2 com.alipay.sofa.rpc.rest.executor.thread.count rest 的业务线程数 200 com.alipay.sofa.rpc.rest.max.request.size rest 的最大 byte 请求长度 1024 1024 10 com.alipay.sofa.rpc.rest.telnet rest 是否支持 telnet true com.alipay.sofa.rpc.rest.daemon rest 是否支持 daemon true com.alipay.sofa.rpc.dubbo.port dubbo 的端口 20880 com.alipay.sofa.rpc.dubbo.io.thread.count dubbo 的 io 线程数 cpu 核数 + 1 com.alipay.sofa.rpc.dubbo.executor.thread.count dubbo 的业务线程数 100 com.alipay.sofa.rpc.dubbo.accepts.count dubbo能够支持的最大长连接数 0，表示不限制 2. 自定义线程池SOFA-RPC 支持自定义业务线程池。可以为指定服务设置一个独立的业务线程池，和 SOFA-RPC 自身的业务线程池是隔离的，多个服务可以共用一个独立的线程池。目前支持 bolt 协议。 在 SOFA-Boot 环境中可以为一个服务设置一个自定义线程池，配置如下： 声明自定义线程池 如下声明一个自定义线程池，class 必须为 com.alipay.sofa.rpc.server.UserThreadPool，这是 SOFA-RPC 提供的类，init-method=&quot;init&quot; 也必须声明以进行初始化。 123456&lt;bean id=\"customerThreadPool\" class=\"com.alipay.sofa.rpc.server.UserThreadPool\" init-method=\"init\"&gt; &lt;property name=\"corePoolSize\" value=\"10\"/&gt; &lt;property name=\"maximumPoolSize\" value=\"10\"/&gt; &lt;property name=\"queueSize\" value=\"5\"/&gt; &lt;property name=\"threadPoolName\" value=\"customerThreadPool_name\"/&gt;&lt;/bean&gt; 为服务设置自定义线程池 如下通过 sofa:global-attrs 元素的 thread-pool-ref 属性为该服务设置自定义线程池。customerThreadPool 是上面自定义线程池的 bean id。 123456&lt;bean id=\"threadPoolServiceImpl\" class=\"com.ostenant.sofa.rpc.example.threadpool.ThreadPoolServiceImpl\"/&gt;&lt;sofa:service ref=\"threadPoolServiceImpl\" interface=\"com.alipay.sofa.rpc.samples.threadpool.ThreadPoolService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs thread-pool-ref=\"customerThreadPool\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:service&gt; 3. 预热权重SOFA-RPC 提供了预热权重功能让客户端机器能够根据服务端的相应权重进行流量的分发。目前支持 bolt 协议。 SOFA-Boot 中提供了一系列参数属性，对指定服务进行预热配置。客户端机器能够自动解析这些参数，并按权重进行流量分发。 warm-up-time: 服务的预热时间 warm-up-weight: 服务设置预热期间权重 weight: 服务设置预热完后的权重 12345&lt;sofa:reference id=\"sampleRestFacadeReferenceBolt\" interface=\"com.alipay.sofa.endpoint.facade.SampleFacade\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs warm-up-time=\"10000\" warm-up-weight=\"10\" weight=\"100\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 上述配置中，该服务的预热期为10s，在预热期内权重为10，预热期结束后的正常权重为100。 如果该服务一共发布到A，B两个机器上。\bA机器正处于预热期内，使用上述配置；B已经完成预热，正常权重为200。那么客户端在调用的时候，此时流量分发的比重为10：200；A机器预热结束后，流量分发比重为100：200。 4. 自动故障剔除自动故障剔除会自动监控 RPC 调用的情况，对故障节点进行权重降级，并在节点恢复健康时进行权重恢复。目前支持 bolt 协议。 在 SOFA-Boot 中，只需要将自动故障剔除的参数配置到 application.properties 即可。只配置自己关心的参数，其余参数会取默认值。需要注意的是，rpc.aft.regulation.effective 是该功能的全局开关，如果关闭则该功能不会运行，其他参数也都不生效。 自动故障剔除的配置参数意义 属性 描述 默认值 com.alipay.sofa.rpc.aft.time.window 时间窗口大小：对统计信息计算的周期。 10s com.alipay.sofa.rpc.aft.least.window.count 时间窗口内最少调用数：只有在时间窗口内达到了该最低值的数据才会被加入到计算和调控中。 10次 com.alipay.sofa.rpc.aft.least.window.exception.rate.multiple 时间窗口内异常率与服务平均异常率的降级比值：在对统计信息进行计算的时候，会计算出该服务所有有效调用ip的平均异常率，如果某个ip的异常率大于等于了这个最低比值，则会被降级。 6倍 com.alipay.sofa.rpc.aft.weight.degrade.rate 降级比率：地址在进行权重降级时的降级比率。 1/20 com.alipay.sofa.rpc.aft.weight.recover.rate 恢复比率：地址在进行权重恢复时的恢复比率。 2倍 com.alipay.sofa.rpc.aft.degrade.effective 降级开关：如果应用打开了这个开关，则会对符合降级的地址进行降级，否则只会进行日志打印。 false(关闭) com.alipay.sofa.rpc.aft.degrade.least.weight 降级最小权重：地址权重被降级后的值如果小于这个最小权重，则会以该最小权重作为降级后的值。 0 com.alipay.sofa.rpc.aft.degrade.max.ip.count 降级的最大ip数：同一个服务被降级的ip数不能超过该值。 2 com.alipay.sofa.rpc.aft.regulation.effective 全局开关：如果应用打开了这个开关，则会开启整个单点故障自动剔除摘除功能，否则完全不进入该功能的逻辑。 false(关闭) 配置示例 123456789com.alipay.sofa.rpc.aft.time.window=20com.alipay.sofa.rpc.aft.least.window.count=30com.alipay.sofa.rpc.aft.least.window.exception.rate.multiple=6com.alipay.sofa.rpc.aft.weight.degrade.rate=0.5com.alipay.sofa.rpc.aft.weight.recover.rate=1.2com.alipay.sofa.rpc.aft.degrade.effective=turecom.alipay.sofa.rpc.aft.degrade.least.weight=1com.alipay.sofa.rpc.aft.degrade.max.ip.count=2com.alipay.sofa.rpc.aft.regulation.effective=true 上述配置中，默认打开了自动故障剔除功能和降级开关。当节点出现故障时会被进行权重降级，在恢复时会被进行权重恢复。 每隔 20s 进行一次节点健康状态的度量，20s 内调用次数超过 30 次的节点才被作为计算数据。 如果单个节点的异常率超过了所有节点的平均异常率的 6 倍，则对该节点进行权重降级，降级的比率为 0.5。权重最小降级到 1。如果单个节点的异常率低于了平均异常率的 6 倍，则对该节点进行权重恢复，恢复的比率为1.2。单个服务最多降级 2 个 IP。 小结本文介绍了 SOFA-RPC 的\b高级功能，包括参数配置，自定义线程池，服务预热和自动降级与权重恢复等用法。对于 SOFA-RPC \b提供的基本功能，以及整合 SOFA-Boot 的配置和用法就介绍完了。对此有了初步的认识后，有利于后续深入实现原理和\b剖析源码。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"SOFA-RPC","slug":"SOFA-RPC","permalink":"https://ostenant.coding.me/tags/SOFA-RPC/"},{"name":"SOFA-Boot","slug":"SOFA-Boot","permalink":"https://ostenant.coding.me/tags/SOFA-Boot/"}]},{"title":"蚂蚁金服SOFA-Boot整合SOFA-RPC(中篇)","slug":"蚂蚁金服SOFA-Boot整合SOFA-RPC(中篇)","date":"2018-05-09T07:08:00.000Z","updated":"2018-06-18T02:00:18.984Z","comments":true,"path":"2018/05/09/蚂蚁金服SOFA-Boot整合SOFA-RPC(中篇)/","link":"","permalink":"https://ostenant.coding.me/2018/05/09/蚂蚁金服SOFA-Boot整合SOFA-RPC(中篇)/","excerpt":"前言上篇文章简单地介绍了 SOFA-Boot 的功能特性，对 Readiness 健康检查的配置举例说明。重点介绍了如何在 SOFA-Boot 中引入 SOFA-RPC 中间件，给出了基于 bolt、rest 和 dubbo 等不同协议通道的服务发布与消费的全流程。","text":"前言上篇文章简单地介绍了 SOFA-Boot 的功能特性，对 Readiness 健康检查的配置举例说明。重点介绍了如何在 SOFA-Boot 中引入 SOFA-RPC 中间件，给出了基于 bolt、rest 和 dubbo 等不同协议通道的服务发布与消费的全流程。 本文将进一步介绍 SOFA-RPC 中间件提供的丰富而强大的功能，包括单向调用、同步调用、Future调用、回调，泛化调用，过滤器配置等。 正文1. 调用方式SOFA-RPC \b提供单向调用、同步调用、异步调用和回调四种调用机制。\b为了区分\b四者的不同\b之处，这里给出 SOFA 官方提供的原理图。 下面\b给出详细\b阐述和配置说明： 1.1. 单向方式当前线程发起调用后，不关心调用结果，不做超时控制，只要请求已经发出，就完成本次调用。目前支持 bolt 协议。 配置说明使用单向方式需要在服务引用的时候通过 sofa:global-attrs 元素的 type 属性声明调用方式为 oneway ，这样使用该服务引用发起调用时就是使用的单向方式了。 12345&lt;sofa:reference id=\"helloOneWayServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloOneWayService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs type=\"oneway\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 适用场景单向调用不保证成功，而且发起方无法知道调用结果。因此通常用于可以重试，或者定时通知类的场景，调用过程是有可能因为网络问题，机器故障等原因，导致请求失败。业务场景需要能接受这样的异常场景，才可以使用。 1.2. 同步方式当前线程发起调用后，需要在指定的超时时间内，等到响应结果，才能完成本次调用。如果超时时间内没有得到结果，那么会抛出超时异常。 配置说明服务接口与实现类\b SOFA-RPC 缺省采用的就是同步调用，可以省略 sofa:global-attrs 配置项。 \b服务端发布配置 1234&lt;bean id=\"helloSyncServiceImpl\" class=\"com.ostenant.sofa.rpc.example.invoke.HelloSyncServiceImpl\"/&gt;&lt;sofa:service ref=\"helloSyncServiceImpl\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloSyncService\"&gt; &lt;sofa:binding.bolt/&gt;&lt;/sofa:service&gt; 客户端引用配置\b 123&lt;sofa:reference id=\"helloSyncServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloSyncService\"&gt; &lt;sofa:binding.bolt/&gt;&lt;/sofa:reference&gt; 服务端启动入口 12SpringApplication springApplication = new SpringApplication(SyncServerApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端启动入口 12SpringApplication springApplication = new SpringApplication(SyncClientApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端调用 12HelloSyncService helloSyncServiceReference = (HelloSyncService) applicationContext.getBean(\"helloSyncServiceReference\");System.out.println(helloSyncServiceReference.saySync(\"sync\")); 适用场景同步调用是最常用的方式。注意要根据对端的处理能力，合理设置超时时间。 1.3. Future方式Future 方式下，客户端发起调用后不会等待服务端的结果，继续执行后面的业务逻辑。服务端返回的结果会被 SOFA-RPC 缓存，当客户端需要结果的时候，需要主动获取。目前支持 bolt 协议。 配置说明服务接口和实现类 HelloFutureService.java 123public interface HelloFutureService &#123; String sayFuture(String future);&#125; HelloFutureServiceImpl.java 123456public class HelloFutureServiceImpl implements HelloFutureService &#123; @Override public String sayFuture(String future) &#123; return future; &#125;&#125; 服务端发布配置 1234&lt;bean id=\"helloFutureServiceImpl\" class=\"com.ostenant.sofa.rpc.example.invoke.HelloFutureServiceImpl\"/&gt;&lt;sofa:service ref=\"helloFutureServiceImpl\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloFutureService\"&gt; &lt;sofa:binding.bolt/&gt;&lt;/sofa:service&gt; 客户端引用配置 使用 Future 方式需要在服务引用的时候通过 sofa:global-attrs 元素的 type 属性声明调用方式为 future。 12345&lt;sofa:reference id=\"helloFutureServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloFutureService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs type=\"future\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 这样使用该服务引用发起调用时就是使用的 Future 方式了。 服务端启动入口 12SpringApplication springApplication = new SpringApplication(FutureServerApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端启动入口 12SpringApplication springApplication = new SpringApplication(FutureClientApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端获取返回结果有两种方式： 其一，通过 SofaResponseFuture 直接获取结果。第一个参数是获取结果的超时时间，第二个参数表示是否清除线程上下文中的结果。 12345678910HelloFutureService helloFutureServiceReference = (HelloFutureService) applicationContext .getBean(\"helloFutureServiceReference\");helloFutureServiceReference.sayFuture(\"future\");try &#123; String result = (String)SofaResponseFuture.getResponse(1000, true); System.out.println(\"Future result: \" + result)&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; 其二，获取原生 Future。该种方式会获取 JDK 原生的 Future ，参数表示是否清除线程上下文中的结果。获取结果的方式就是 JDK Future 的获取方式。 1234567891011HelloFutureService helloFutureServiceReference = (HelloFutureService) applicationContext .getBean(\"helloFutureServiceReference\");helloFutureServiceReference.sayFuture(\"future\");try &#123; Future future = SofaResponseFuture.getFuture(true); String result = (String)future.get(1000, TimeUnit.MILLISECONDS); System.out.println(\"Future result: \" + result)&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; 适用场景Future 方式适用于非阻塞\b编程模式。对于客户端程序处理后，不需要\b立即获取返回结果，可以先完成后续程序代码执行，在后续业务中，主动从当前线程上下文获取调用返回结果。减少了网络 IO\b 等待造成的代码运行阻塞和延迟。 1.4. 回调方式当前线程发起调用，则本次调用马上结束，可以马上执行下一次调用。发起调用时需要注册一个回调，该回调需要分配一个异步线程池。待响应返回后，会在回调的异步线程池，来执行回调逻辑。 \b配置说明服务接口和实现类 HelloCallbackService.java 123public interface HelloCallbackService &#123; String sayCallback(String callback);&#125; HelloCallbackServiceImpl.java 123456public class HelloCallbackServiceImpl implements HelloCallbackService &#123; @Override public String sayCallback(String string) &#123; return string; &#125;&#125; 业务回调类 客户端回调类需要实现 com.alipay.sofa.rpc.core.invoke.SofaResponseCallback 接口。 CallbackImpl.java 1234567891011121314public class CallbackImpl implements SofaResponseCallback &#123; @Override public void onAppResponse(Object appResponse, String methodName, RequestBase request) &#123; System.out.println(\"callback client process:\" + appResponse); &#125; @Override public void onAppException(Throwable throwable, String methodName, RequestBase request) &#123; &#125; @Override public void onSofaException(SofaRpcException sofaException, String methodName, RequestBase request) &#123; &#125;&#125; SofaResponseCallback 接口提供了 3 个方法： onAppResponse: \b程序正常运行，则进入该回调方法。 onAppException: 服务端程序抛出异常，则进入\b该回调方法。 onSofaException: 框架内部出现错误，则进入该回调方法。 服务端发布配置 1234&lt;bean id=\"helloCallbackServiceImpl\" class=\"helloFutureServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloCallbackServiceImpl\"/&gt;&lt;sofa:service ref=\"helloCallbackServiceImpl\" interface=\"helloFutureServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloCallbackService\"&gt; &lt;sofa:binding.bolt/&gt;&lt;/sofa:service&gt; 客户端引用配置 在服务引用的时候通过 sofa:global-attrs 元素的 type 属性声明调用方式为 callback ，再通过 callback-ref 声明回调的实现类。 1234567&lt;bean id=\"callbackImpl\" class=\"com.ostenant.sofa.rpc.example.invoke.CallbackImpl\"/&gt;&lt;sofa:reference id=\"helloCallbackServiceReference\" interface=\"com.ostenant.sofa.rpc.example.invoke.HelloCallbackService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs type=\"callback\" callback-ref=\"callbackImpl\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 这样使用该服务引用发起调用时，就是使用的回调方式了。在结果返回时，由 SOFA-RPC 自动调用该回调类的相应方法。 服务端启动入口 12SpringApplication springApplication = new SpringApplication(CallbackServerApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端启动入口 12SpringApplication springApplication = new SpringApplication(CallbackClientApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端发起调用 123456789HelloCallbackService helloCallbackServiceReference = (HelloCallbackService) applicationContext .getBean(\"helloCallbackServiceReference\");helloCallbackServiceReference.sayCallback(\"callback\");try &#123; Thread.sleep(3000);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125; sayCallback() 的返回值不应该直接获取。在客户端注册的回调类中，返回值会以参数的形式传入正确的方法，\b以回调的形式\b完成后续逻辑处理。 适用场景Callback 方式适用于异步非阻塞\b编程模式。客户端\u001d程序所在线程发起调用后，\b继续执行后续操作，\b不需要主动去获取返回值。服务端程序处理完成，将返回值传回一个\b异步线程池，由子线程通过\b回调函数进行\b返回值处理。\b很大情况的减少了网络 IO 阻塞，解决了单线程的瓶颈，\b实现了异步编程。 2. 泛化调用泛化调用方式能够在客户端不依赖服务端的接口情况下发起调用，目前支持 bolt 协议。由于不知道服务端的接口，因此需要通过字符串的方式将服务端的接口，调用的方法，参数及结果类进行描述。 配置说明泛化参数类\b SampleGenericParamModel.java 123456789public class SampleGenericParamModel &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 泛化返回类 SampleGenericResultModel.java 12345678910111213141516public class SampleGenericResultModel &#123; private String name; private String value; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getValue() &#123; return value; &#125; public void setValue(String value) &#123; this.value = value; &#125;&#125; 服务接口和实现类 SampleGenericService.java 123public interface SampleGenericService &#123; SampleGenericResultModel sayGeneric(SampleGenericParamModel sampleGenericParamModel);&#125; SampleGenericParamModel：作为 sayGeneric() 的\b\b输入参数类型，有一个 name 成员变量，作为真正的方法入参。 SampleGenericResultModel：作为 sayGeneric() 的返回结果类型，\b声明了 name 和 value 两个成员变量，作为真实的返回值。 SampleGenericServiceImpl.java 12345678910public class SampleGenericServiceImpl implements SampleGenericService &#123; @Override public SampleGenericResultModel sayGeneric(SampleGenericParamModel sampleGenericParamModel) &#123; String name = sampleGenericParamModel.getName(); SampleGenericResultModel resultModel = new SampleGenericResultModel(); resultModel.setName(name); resultModel.setValue(\"sample generic value\"); return resultModel; &#125;&#125; 服务端发布配置 1234&lt;bean id=\"sampleGenericServiceImpl\" class=\"com.ostenant.sofa.rpc.example.generic.SampleGenericServiceImpl\"/&gt;&lt;sofa:service ref=\"sampleGenericServiceImpl\" interface=\"com.ostenant.sofa.rpc.example.generic.SampleGenericService\"&gt; &lt;sofa:binding.bolt/&gt;&lt;/sofa:service&gt; 客户端引用配置 12345&lt;sofa:reference id=\"sampleGenericServiceReference\" interface=\"com.alipay.sofa.rpc.api.GenericService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs generic-interface=\"com.ostenant.sofa.rpc.example.generic.SampleGenericService\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 在泛化调用过程中，客户端配置有两点需要注意： sofa:reference 指向的服务接口\b需要声明为 SOFA-RPC 提供的泛化接口 com.alipay.sofa.rpc.api.GenericService。 sofa:global-attrs 需要声明属性 generic-interface，value 为\b真实的服务接口名称。 服务端启动入口 12SpringApplication springApplication = new SpringApplication(SampleGenericServerApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端启动入口 12SpringApplication springApplication = new SpringApplication(SampleGenericClientApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端发起调用 获取服务的泛化引用 12GenericService sampleGenericServiceReference = (GenericService) applicationContext .getBean(\"sampleGenericServiceReference\"); 准备方法参数 由于客户端没有调用服务的参数类，因此通过 com.alipay.hessian.generic.model.GenericObjectGenericObject 进行描述。 1234// 准备方法参数GenericObject generic\bParam = new GenericObject( \"com.ostenant.sofa.rpc.example.generic.SampleGenericParamModel\");generic\bParam.putField(\"name\", \"Harrison\"); GenericObject 持有一个 Map&lt;String, Object&gt; 类型的变量，你能够通过 GenericObject 提供的 putField() 方法，将参数类的属性和值放到这个 Map 中，以此来描述参数类。 发起泛化调用 通过 GenericService 的 $genericInvoke(arg1, agr2, arg3) 方法可以发起服务的泛化调用，各个参数含义如下： 参数 含义 参数可选 arg1 目标方法名称 \b必填 arg2 参数类型的数组，要求\b严格遵循先后次序 必填 arg3 参数值的数组，要求与参数类型数组保持一致 必填 arg4 返回值的Class类型 可选 方式一： 123456789101112GenericObject genericResult = (GenericObject) sampleGenericServiceReference.$genericInvoke( // 目标方法名称 \"sayGeneric\", // 参数类型名称 new String[] &#123; \"com.ostenant.sofa.rpc.example.generic.SampleGenericParamModel\" &#125;, // \b参数\b的值 new Object[] &#123; generic\bParam &#125;);// 验证返回结果System.out.println(\"Type: \" + genericResult.getType());System.out.println(\"Name: \" + genericResult.getField(\"name\"));System.out.println(\"Value: \" + genericResult.getField(\"value\")); 方式二： 1234567891011121314SampleGenericResultModel sampleGenericResult = sampleGenericServiceReference.$genericInvoke( // 目标方法名称 \"sayGeneric\", // 参数类型名称 new String[] &#123; \"com.ostenant.sofa.rpc.example.generic.SampleGenericParamModel\" &#125;, // 参数\b的值 new Object[] &#123; genericParam &#125;, // 返回值的Class类型 SampleGenericResultModel.class);// 验证返回结果System.out.println(\"Type: \" + sampleGenericResult.getClass().getName());System.out.println(\"Name: \" + sampleGenericResult.getName());System.out.println(\"Value: \" + sampleGenericResult.getValue()); 查看控制台输出 两种方式输出如下： 123Type: com.ostenant.sofa.rpc.example.generic.SampleGenericResultModelName: HarrisonValue: sample generic value 3. 过滤器配置SOFA-RPC 通过过滤器 Filter 来实现对请求和响应的拦截处理。用户可以自定义 Filter 实现拦截扩展，目前支持 bolt 协议。开发人员通过继承 com.alipay.sofa.rpc.filter.Filter 实现过滤器的自定义。 配置说明服务接口与实现类\b FilterService.java 123public interface FilterService &#123; String sayFilter(String filter);&#125; FilterServiceImpl.java 123456public class FilterServiceImpl implements FilterService &#123; @Override public String sayFilter(String filter) &#123; return filters; &#125;&#125; 服务端过滤器 在 Filter 实现类中，invoke() 方法实现具体的拦截逻辑，通过 FilterInvoker.invoke(SofaRequest) 触发服务的调用，在该方法前后可以实现具体的拦截处理。\b 1234567891011public class SampleServerFilter extends Filter &#123; @Override public SofaResponse invoke(FilterInvoker invoker, SofaRequest request) throws SofaRpcException &#123; System.out.println(\"SampleFilter before server process\"); try &#123; return invoker.invoke(request); &#125; finally &#123; System.out.println(\"SampleFilter after server process\"); &#125; &#125;&#125; 服务端发布配置 服务端需要配置服务实现类、过滤器，\b然后在 sofa:service 的 sofa:global-attrs 标签配置 filter 属性，实现两者的绑定。 1234567&lt;bean id=\"sampleFilter\" class=\"com.ostenant.sofa.rpc.example.filter.SampleServerFilter\"/&gt;&lt;bean id=\"filterService\" class=\"com.ostenant.sofa.rpc.example.filter.FilterServiceImpl\"/&gt;&lt;sofa:service ref=\"filterService\" interface=\"com.ostenant.sofa.rpc.example.filter.FilterService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs filter=\"sampleFilter\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:service&gt; 客户端过滤器 1234567891011public class SampleClientFilter extends Filter &#123; @Override public SofaResponse invoke(FilterInvoker invoker, SofaRequest request) throws SofaRpcException &#123; System.out.println(\"SampleFilter before client invoke\"); try &#123; return invoker.invoke(request); &#125; finally &#123; System.out.println(\"SampleFilter after client invoke\"); &#125; &#125;&#125; 客户端引用配置 同样的，客户端过滤器需要在 sofa:reference 的 sofa:global-attrs 标签中配置 filter 属性，实现客户端引用\b类的调用拦截。 123456&lt;bean id=\"sampleFilter\" class=\"com.alipay.sofa.rpc.samples.filter.SampleClientFilter\"/&gt;&lt;sofa:reference id=\"filterServiceReference\" interface=\"\bcom.ostenant.sofa.rpc.example.filter.FilterService\"&gt; &lt;sofa:binding.bolt&gt; &lt;sofa:global-attrs filter=\"sampleFilter\"/&gt; &lt;/sofa:binding.bolt&gt;&lt;/sofa:reference&gt; 服务端启动类 12SpringApplication springApplication = new SpringApplication(FilterServerApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端启动类 12SpringApplication springApplication = new SpringApplication(FilterClientApplication.class);ApplicationContext applicationContext = springApplication.run(args); 客户端调用 12345678910FilterService filterServiceReference = (FilterService) applicationContext.getBean(\"filterServiceReference\");try &#123; // sleep 5s, 便于观察过滤器效果 Thread.sleep(5000);&#125; catch (InterruptedException e) &#123; e.printStackTrace();&#125;String result = filterServiceReference.sayFilter(\"filter\");System.out.println(\"Invoke result: \" + result); 查看拦截\b输出\b 服务端打印输出 12SampleFilter before server processSampleFilter after server process 客户端打印输出 123SampleFilter before client invokeSampleFilter after client invokeInvoke result: filter \b过滤器配置生效，总结过滤器拦截先后次序如下： 客户端发起调用 -&gt; 客户端前置拦截\b -&gt; 服务端前置拦截 服务端方法执行 服务端后置拦截 -&gt; 客户端后置拦截 -&gt; 客户端接收返回值 小结本文介绍了 SOFA-RPC 的集中调用方式，包括单向调用、同步调用、Future调用、回调，引入了 SOFA-RPC 独有的泛化调用机制，同时对过滤器的配置进行了\b简单介绍。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"SOFA-RPC","slug":"SOFA-RPC","permalink":"https://ostenant.coding.me/tags/SOFA-RPC/"},{"name":"SOFA-Boot","slug":"SOFA-Boot","permalink":"https://ostenant.coding.me/tags/SOFA-Boot/"}]},{"title":"蚂蚁金服SOFA-Boot整合SOFA-RPC(上篇)","slug":"蚂蚁金服SOFA-Boot整合SOFA-RPC(上篇)","date":"2018-05-08T13:23:00.000Z","updated":"2018-06-18T01:59:49.466Z","comments":true,"path":"2018/05/08/蚂蚁金服SOFA-Boot整合SOFA-RPC(上篇)/","link":"","permalink":"https://ostenant.coding.me/2018/05/08/蚂蚁金服SOFA-Boot整合SOFA-RPC(上篇)/","excerpt":"前言上文介绍了 SOFARPC 的简单使用。在生产环境中，通常会将 SOFARPC 整合到 SpringBoot 中。蚂蚁金服提供了 SOFABoot 框架，SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等等能力。","text":"前言上文介绍了 SOFARPC 的简单使用。在生产环境中，通常会将 SOFARPC 整合到 SpringBoot 中。蚂蚁金服提供了 SOFABoot 框架，SOFABoot 是蚂蚁金服开源的基于 Spring Boot 的研发框架，它在 Spring Boot 的基础上，提供了诸如 Readiness Check，类隔离，日志空间隔离等等能力。 在增强了 Spring Boot 的同时，SOFABoot 提供了让用户可以在 Spring Boot 中非常方便地使用 SOFA 中间件的能力。当前 SOFABoot 的 2.3.1 版本是基于 Spring Boot 1.4.2.RELEASE 来构建的。 正文1. 功能描述SOFABoot 在 Spring Boot 的基础上，提供了以下能力： 1.1. 扩展 Spring Boot 的健康检查在 Spring Boot 健康检查能力的基础上，提供了 Readiness Check 的能力，保证应用实例安全上线。 1.2. 日志空间隔离能力中间件框架自动发现应用的日志实现依赖并独立打印日志，避免中间件和应用日志实现绑定，通过 sofa-common-tools 实现。 1.3. 提供类隔离的能力基于 SOFAArk 框架提供类隔离能力，方便使用者解决各种类冲突问题。 1.4. 中间件的集成管理统一管控、提供中间件统一易用的编程接口、每一个 SOFA 中间件都是独立可插拔的组件。 1.5. 完全兼容 Spring BootSOFABoot 基于 Spring Boot 的基础上进行构建，并且完全兼容 Spring Boot。 2. 快速开始2.1. 环境准备要使用 SOFABoot，需要先准备好基础环境，SOFABoot 依赖以下环境： JDK7 或 JDK8 需要采用 Apache Maven 3.2.5 或者以上的版本来编译 2.2. 创建工程SOFABoot 是直接构建在 Spring Boot 之上，因此可以使用 Spring Boot 的工程生成工具来生成。添加一个 Web 的依赖，以便最后在浏览器中查看效果。 2.3. 引入 SOFABoot在创建好一个 Spring Boot 的工程之后，接下来就需要引入 SOFABoot 的依赖。首先，需要将上文中生成的 Spring Boot 工程的 zip 包解压后，修改 maven 项目的配置文件 pom.xml。 替换 spring-boot-starter-parent 为相应版本的 sofaboot-dependencies，例如： 123456&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt;&lt;/parent&gt; 替换为： 12345&lt;parent&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;sofaboot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.3.1&lt;/version&gt;&lt;/parent&gt; 2.4. \bSOFABoot \b健康检查引入相关依赖添加 SOFABoot 健康检查扩展能力的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;healthcheck-sofa-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 最后，在工程的 application.properties 文件下添加一个 SOFABoot 必须要使用的参数。 spring.application.name：用于标示当前应用的名称 logging path：用于指定日志的输出目录 1234# Application Namespring.application.name=SOFABoot Example# logging pathlogging.path=./logs 运行 main() 方法，项目启动以后，控制台的日志输出如下： 123452018-05-09 09:56:48.305 INFO 15097 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat started on port(s): 8080 (http)2018-05-09 09:56:48.309 INFO 15097 --- [ main] c.o.s.r.e.SofaBootExampleApplication : Started SofaBootExampleApplication in 2.551 seconds (JVM running for 3.046)2018-05-09 09:57:46.005 INFO 15097 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring FrameworkServlet 'dispatcherServlet'2018-05-09 09:57:46.005 INFO 15097 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization started2018-05-09 09:57:46.021 INFO 15097 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : FrameworkServlet 'dispatcherServlet': initialization completed in 16 ms 查看健康状态 \b在浏览器中输入 http://localhost:8080/sofaboot/versions 来查看当前 SOFABoot 中使用 Maven 插件生成的版本信息汇总，结果类似如下： 1234567891011[ &#123; \"GroupId\": \"com.alipay.sofa\", \"Doc-Url\": \"https://github.com/alipay/sofa-boot\", \"ArtifactId\": \"infra-sofa-boot-starter\", \"Bulit-Time\": \"2018-04-18T22:19:09+0800\", \"Commit-Time\": \"2018-04-18T22:07:52+0800\", \"Commit-Id\": \"466f0e039b250ff7b201dc693eec7fa07eb21ad7\", \"Version\": \"2.3.1\" &#125;] 在浏览器中输入 http://localhost:8080/health/readiness 查看应用 Readiness Check 的状况，类似如下： 123456789101112131415&#123; \"status\": \"UP\", \"sofaBootComponentHealthCheckInfo\": &#123; \"status\": \"UP\" &#125;, \"springContextHealthCheckInfo\": &#123; \"status\": \"UP\" &#125;, \"DiskSpaceHealthIndicator\": &#123; \"status\": \"UP\", \"total\": 250790436864, \"free\": 208612020224, \"threshold\": 10485760 &#125;&#125; status: &quot;UP&quot; 表示应用 Readiness Check 的就绪状态是健康的。 在浏览器中输入 http://localhost:8080/health 来查看应用的运行时健康状态（可能会随着时间发生变化,Spring Boot原生自带功能）。 123456789101112131415161718&#123; \"status\": \"UP\", \"sofaBootComponentHealthCheckInfo\": &#123; \"status\": \"UP\", \"Middleware\": &#123; &#125; &#125;, \"springContextHealthCheckInfo\": &#123; \"status\": \"UP\" &#125;, \"diskSpace\": &#123; \"status\": \"UP\", \"total\": 250790436864, \"free\": 208612528128, \"threshold\": 10485760 &#125;&#125; 查看日志在上面的 application.properties 里面，我们配置的日志打印目录是 ./logs 即当前应用的根目录（我们可以根据自己的实践需要配置），在当前工程的根目录下可以看到类似如下结构的日志文件： 12345678./logs├── health-check│ ├── sofaboot-common-default.log│ └── sofaboot-common-error.log├── infra│ ├── common-default.log│ └── common-error.log└── spring.log 如果应用启动失败或者健康检查返回失败，可以通过相应的日志文件找到错误的原因，有些需要关注 common-error.log 日志。 2.5. SOFA-RPC 环境准备引入相关依赖SOFABoot 使用一系列后缀为 -sofa-boot-starter 来标示一个中间件服务，如果想要使用某个中间件，直接添加对应的依赖即可。进一步引入 SOFA-RPC 的 starter \b依赖： 1234&lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;rpc-sofa-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 选择 Zookeeper 作为服务注册列表，在 pom.xml 文件中引入相关依赖： 12345678910111213141516171819&lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;version&gt;0.10&lt;/version&gt;&lt;/dependency&gt; 注意将 zkclient 重复的依赖排除在外，以免引起冲突。 配置\b zookeeper 集群在 application.properties 中进一步配置 zookeeper 的地址信息。 12# zookeeper address listcom.alipay.sofa.rpc.registry.address=zookeeper://127.0.0.1:2181,127.0.0.1:2182,127.0.0.1:2183?file=/home/admin/registry 为了方便起见，本地使用 docker 环境对 zookeeper 集群进行\u0001容器编排。多个 zookeeper 节点通过逗号分隔，file 参数指定当 zookeeper 不可用时，可以利用本地缓存文件进行服务发现。 编写 docker-compose.yml 文件如下： 1234567891011121314151617181920212223242526272829version: '2'services: zoo1: image: zookeeper:latest restart: always hostname: zoo1 ports: - 2181:2181 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888 zoo2: image: zookeeper:latest restart: always hostname: zoo2 ports: - 2182:2181 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zoo3:2888:3888 zoo3: image: zookeeper:latest restart: always hostname: zoo3 ports: - 2183:2181 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=0.0.0.0:2888:3888 进入 docker-compose.yml 所在文件目录， \b运行 docker-compose up -d 启动3台 zookeeper 容器\b。启动完成后，运行 docker-compose ps 查看进程状态如下： 123456$ docker-compose ps Name Command State Ports ------------------------------------------------------------------------------------------------------zookeeper_zoo1_1 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2181-&gt;2181/tcp, 2888/tcp, 3888/tcpzookeeper_zoo2_1 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2182-&gt;2181/tcp, 2888/tcp, 3888/tcpzookeeper_zoo3_1 /docker-entrypoint.sh zkSe ... Up 0.0.0.0:2183-&gt;2181/tcp, 2888/tcp, 3888/tcp \b\bzookeeper 容器集群启动完成，如果想要查看集群 leader，可以运行 docker exec -it [container-id] /bin/bash 进入容器运行 zk\bServer.sh status 逐一查看。这里加以不累述！ XSD管理在要使用的 XML 配置文件中将头部 xsd 文件的声明设置为如下，这样就能够使用 SOFABoot 定义的 XML 元素进行开发。 12345678&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:sofa=\"http://sofastack.io/schema/sofaboot\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://sofastack.io/schema/sofaboot http://sofastack.io/schema/sofaboot.xsd\" default-autowire=\"byName\"&gt; 2.6. \bSOFA-\bBoot 整合 SOFA-RPC编写服务接口和实现类HelloSyncService.java 123public interface HelloSyncService &#123; String saySync(String string);&#125; HelloSyncServiceImpl.java 123456public class HelloSyncServiceImpl implements HelloSyncService &#123; @Override public String saySync(String sync) &#123; return sync; &#125;&#125; 编写服务提供方配置文件simple-server-example.xml 12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:sofa=\"http://sofastack.io/schema/sofaboot\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://sofastack.io/schema/sofaboot http://sofastack.io/schema/sofaboot.xsd\" default-autowire=\"byName\"&gt; &lt;bean id=\"helloSyncServiceImpl\" class=\"com.ostenant.sofa.rpc.example.simple.HelloSyncServiceImpl\"/&gt; &lt;!-- 以多种通信协议发布服务 --&gt; &lt;sofa:service ref=\"helloSyncServiceImpl\" interface=\"com.ostenant.sofa.rpc.example.simple.HelloSyncService\"&gt; &lt;sofa:binding.bolt/&gt; &lt;sofa:binding.rest/&gt; &lt;sofa:binding.dubbo/&gt; &lt;/sofa:service&gt;&lt;/beans&gt; 通过 sofa:service 元素将该服务发布，其中 ref 属性表示发布的服务实例，interface 属性表示该服务的接口。 sofa:binding.bolt: 服务通过 bolt 协协议通道发布，底层基于 Netty 实现。 sofa:binding.rest: 服务通过 \bhttp 协议发布。 sofa:binding.dubbo: 服务基于 dubbo 的协议通道发布。 编写服务提供方启动程序\bSimpleServerApplication.java 123456789@ImportResource(&#123; \"classpath:simple-server-example.xml\" &#125;)@SpringBootApplicationpublic class \bSimpleServerApplication &#123; public static void main(String[] args) &#123; SpringApplication springApplication = new SpringApplication(\bSimpleServerApplication.class); ApplicationContext applicationContext = springApplication.run(args); &#125;&#125; 编写服务消费方配置文件simple-client-example.xml 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:sofa=\"http://sofastack.io/schema/sofaboot\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://sofastack.io/schema/sofaboot http://sofastack.io/schema/sofaboot.xsd\" default-autowire=\"byName\"&gt; &lt;!-- bolt引用 --&gt; &lt;sofa:reference id=\"boltHelloSyncServiceReference\" interface=\"com.ostenant.sofa.rpc.example.simple.HelloSyncService\"&gt; &lt;sofa:binding.bolt/&gt; &lt;/sofa:reference&gt; &lt;!-- rest引用 --&gt; &lt;sofa:reference id=\"restHelloSyncServiceReference\" interface=\"com.ostenant.sofa.rpc.example.simple.HelloSyncService\"&gt; &lt;sofa:binding.rest/&gt; &lt;/sofa:reference&gt; &lt;!-- dubbo引用 --&gt; &lt;sofa:reference id=\"dubboHelloSyncServiceReference\" interface=\"com.ostenant.sofa.rpc.example.simple.HelloSyncService\"&gt; &lt;sofa:binding.dubbo/&gt; &lt;/sofa:reference&gt;&lt;/beans&gt; 编写服务提供方启动程序SimpleClientApplication.java 123456789101112131415161718@ImportResource(&#123; \"classpath:simple-client-example.xml\" &#125;)@SpringBootApplicationpublic class SimpleClientApplication &#123; public static void main(String[] args) &#123; System.setProperty(\"server.port\", \"8081\"); SpringApplication springApplication = new SpringApplication(SimpleClientApplication.class); ApplicationContext applicationContext = springApplication.run(args); HelloSyncService boltHelloSyncService = (HelloSyncService) applicationContext.getBean(\"boltHelloSyncServiceReference\"); HelloSyncService restHelloSyncService = (HelloSyncService) applicationContext.getBean(\"restHelloSyncServiceReference\"); HelloSyncService dubboHelloSyncService = (HelloSyncService) applicationContext.getBean(\"dubboHelloSyncServiceReference\"); System.out.println(\"Bolt result:\" + boltHelloSyncService.saySync(\"bolt\")); System.out.println(\"Rest result:\" + restHelloSyncService.saySync(\"rest\")); System.out.println(\"Dubbo result:\" + dubboHelloSyncService.saySync(\"dubbo\")); &#125;&#125; 分别启动服务端和客户端客户端控制台输出日志如下： 123Bolt result: boltRest result: restDubbo result: dubbo \b对于同一个服务，在服务发布方\b配置时，可在以 sofa:service 中通过 sofa:binding.xxx 提供多种协议通道配置；在服务消费方配置时，可以在 sofa:reference 中通过 sofa:binding.xxx 提供\b对不同通道服务的引用。 小结\b本文引入了 SOFA-Boot 框架，对 SOFA-Boot 的将康检查功能和\b\b日志管理的使用进行了简单说明，然后在 SOFA-Boot 环境中引入了 SOFA-RPC 框架，并提供了一个\b完整的服务发布和注册的示例程序。 关于 SOFA-\bRPC 更丰富、强大的功能\b介绍，\b下篇敬请期待！ 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"SOFA-RPC","slug":"SOFA-RPC","permalink":"https://ostenant.coding.me/tags/SOFA-RPC/"},{"name":"SOFA-Boot","slug":"SOFA-Boot","permalink":"https://ostenant.coding.me/tags/SOFA-Boot/"}]},{"title":"蚂蚁金服RPC框架SOFA-RPC - 初体验","slug":"蚂蚁金服RPC框架SOFA-RPC - 初体验","date":"2018-04-29T09:59:00.000Z","updated":"2018-06-18T01:59:36.490Z","comments":true,"path":"2018/04/29/蚂蚁金服RPC框架SOFA-RPC - 初体验/","link":"","permalink":"https://ostenant.coding.me/2018/04/29/蚂蚁金服RPC框架SOFA-RPC - 初体验/","excerpt":"前言SOFARPC 最早源于阿里内部的 HSF，是近期蚂蚁金服开源的一个高可扩展性、高性能、生产级的 Java RPC 框架。SOFA-RPC 在蚂蚁金服已经历了十多年的发展，致力于简化应用之间的 RPC 调用。为应用提供方便透明、稳定高效的点对点远程服务调用方案。","text":"前言SOFARPC 最早源于阿里内部的 HSF，是近期蚂蚁金服开源的一个高可扩展性、高性能、生产级的 Java RPC 框架。SOFA-RPC 在蚂蚁金服已经历了十多年的发展，致力于简化应用之间的 RPC 调用。为应用提供方便透明、稳定高效的点对点远程服务调用方案。 为了用户和开发者方便的进行功能扩展，SOFA-RPC 提供了丰富的模型抽象和可扩展接口，包括过滤器、路由、负载均衡等。同时围绕 SOFA-RPC 框架及其周边组件提供丰富的微服务治理方案。 正文1. 功能特性 透明化、高性能的远程服务调用 支持多种服务路由及负载均衡策略 支持多种注册中心的集成 支持 bolt、rest、dubbo 等多种通信协议 支持同步、单向、回调、泛化等多种调用方式 支持集群容错、服务预热、自动故障隔离 强大的扩展功能，可以按需扩展各个功能组件 2. 实现原理 a. 服务发布 当一个 SOFARPC 的应用启动的时候，如果发现当前应用需要发布 RPC 服务的话，那么 SOFARPC 会将这些服务注册到服务注册中心上。如图中 Service 指向 Registry。 b. 服务订阅 当引用这个服务的 SOFARPC 应用启动时，会从服务注册中心订阅到相应服务的元数据信息。服务注册中心收到订阅请求后，会将发布方的元数据列表实时推送给服务引用方。如图中 Registry 指向 Reference。 c. 服务调用 当服务引用方拿到地址以后，就可以从中选取地址发起调用了。如图中 Reference 指向 Service。 3. 快速开始3.1. 引入sofa-rpc依赖1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alipay.sofa&lt;/groupId&gt; &lt;artifactId&gt;sofa-rpc-all&lt;/artifactId&gt; &lt;version&gt;5.3.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 3.2. 编写服务接口和服务实现类HelloService.java 123public interface HelloService &#123; String sayHello(String string);&#125; HelloServiceImpl.java 1234567public class HelloServiceImpl implements HelloService &#123; @Override public String sayHello(String string) &#123; System.out.println(\"Server receive: \" + string); return \"hello \" + string + \" ！\"; &#125;&#125; 3.3. 编写服务提供者启动类QuickStartServer.java 123456789101112131415public class QuickStartServer &#123; public static void main(String[] args) &#123; ServerConfig serverConfig = new ServerConfig() .setProtocol(\"bolt\") // 设置一个协议，默认bolt .setPort(9696) // 设置一个端口，默认12200 .setDaemon(false); // 非守护线程 ProviderConfig&lt;HelloService&gt; providerConfig = new ProviderConfig&lt;HelloService&gt;() .setInterfaceId(HelloService.class.getName()) // 指定接口 .setRef(new HelloServiceImpl()) // 指定实现 .setServer(serverConfig); // 指定服务端 providerConfig.export(); // 发布服务 &#125;&#125; 运行服务端提供方，日志输出如下： 12345Sofa-Middleware-Log SLF4J Warn : No log util is usable, Default app logger will be used.SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.Sofa-Middleware-Log SLF4J Warn : No log util is usable, Default app logger will be used. 3.4. 编写服务消费者启动类QuickStartClient.java 12345678910111213141516171819public class QuickStartClient &#123; public static void main(String[] args) &#123; ConsumerConfig&lt;HelloService&gt; consumerConfig = new ConsumerConfig&lt;HelloService&gt;() .setInterfaceId(HelloService.class.getName()) // 指定接口 .setProtocol(\"bolt\") // 指定协议 .setDirectUrl(\"bolt://127.0.0.1:9696\"); // 指定直连地址 HelloService helloService = consumerConfig.refer(); while (true) &#123; System.out.println(helloService.sayHello(\"world\")); try &#123; Thread.sleep(200); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 运行服务端消费方，调用服务提供方： 服务提供方日志输出如下： 1234Server receive: worldServer receive: worldServer receive: worldServer receive: world 服务消费方日志输出如下： 123456789SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".SLF4J: Defaulting to no-operation (NOP) logger implementationSLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.Sofa-Middleware-Log SLF4J Warn : No log util is usable, Default app logger will be used.Sofa-Middleware-Log SLF4J Warn : No log util is usable, Default app logger will be used.hello world ！hello world ！hello world ！hello world ！ 小结这是一个快速入门的例子！ 可以发现，在使用上，SOFA-RPC 与淘宝的 Dubbo，微博的 Motan 并无太大的区别。Dubbo 作为整套服务治理而存在，而 SOFA-RPC 只是一款轻量级的 RPC 框架，基于 HSF 框架改造，提供更加完善、强大的、多样化 RPC 编程 API。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"SOFA-RPC","slug":"SOFA-RPC","permalink":"https://ostenant.coding.me/tags/SOFA-RPC/"}]},{"title":"分布式理论(四) - 3PC协议","slug":"分布式理论(四) - 3PC协议","date":"2018-04-28T13:26:00.000Z","updated":"2018-06-18T01:55:05.895Z","comments":true,"path":"2018/04/28/分布式理论(四) - 3PC协议/","link":"","permalink":"https://ostenant.coding.me/2018/04/28/分布式理论(四) - 3PC协议/","excerpt":"前言由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷。所以，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。","text":"前言由于二阶段提交存在着诸如同步阻塞、单点问题、脑裂等缺陷。所以，研究者们在二阶段提交的基础上做了改进，提出了三阶段提交。 与两阶段提交不同的是，三阶段提交有两个改动点。 引入超时机制 - 同时在协调者和参与者中都引入超时机制。 在第一阶段和第二阶段中插入一个准备阶段，保证了在最后提交阶段之前各参与节点的状态是一致的。 正文1. 三阶段提交的定义三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。 所谓的三个阶段分别是：询问，然后再锁资源，最后真正提交。 第一阶段：CanCommit 第二阶段：PreCommit 第三阶段：Do Commit 2. 三阶段提交的过程2.1. 阶段一：CanCommit3PC的CanCommit阶段其实和2PC的准备阶段很像。协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。 a. 事务询问 协调者向参与者发送CanCommit请求。询问是否可以执行事务提交操作。然后开始等待参与者的响应。 b. 响应反馈 参与者接到CanCommit请求之后，正常情况下，如果其自身认为可以顺利执行事务，则返回Yes响应，并进入预备状态；否则反馈No。 2.2. 阶段二：PreCommit协调者在得到所有参与者的响应之后，会根据结果执行2种操作：执行事务预提交，或者中断事务。 2.2.1. 执行事务预提交a. 发送预提交请求 协调者向所有参与者节点发出 preCommit 的请求，并进入 prepared 状态。 b. 事务预提交 参与者受到 preCommit 请求后，会执行事务操作，对应 2PC 准备阶段中的 “执行事务”，也会 Undo 和 Redo 信息记录到事务日志中。 c. 各参与者响应反馈 如果参与者成功执行了事务，就反馈 ACK 响应，同时等待指令：提交（commit） 或终止（abort）。 2.2.2. 中断事务a. 发送中断请求 协调者向所有参与者节点发出 abort 请求 。 b. 中断事务 参与者如果收到 abort 请求或者超时了，都会中断事务。 2.3. 阶段三：Do Commit该阶段进行真正的事务提交，也可以分为以下两种情况。 2.3.1. 执行提交a. 发送提交请求 协调者接收到各参与者发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有参与者发送 doCommit 请求。 b. 事务提交 参与者接收到 doCommit 请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。 c. 响应反馈 事务提交完之后，向协调者发送 ACK 响应。 d. 完成事务 协调者接收到所有参与者的 ACK 响应之后，完成事务。 2.3.2. 中断事务协调者没有接收到参与者发送的 ACK 响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。 a. 发送中断请求 协调者向所有参与者发送 abort 请求。 b. 事务回滚 参与者接收到 abort 请求之后，利用其在阶段二记录的 undo 信息来执行事务的回滚操作，并在完成回滚之后释放所有的事务资源。 c. 反馈结果 参与者完成事务回滚之后，向协调者发送 ACK 消息。 d. 中断事务 协调者接收到参与者反馈的 ACK 消息之后，完成事务的中断。 3. 小结3.1. 三阶段提交的优点相对于二阶段提交，三阶段提交主要解决的单点故障问题，并减少了阻塞的时间。 因为一旦参与者无法及时收到来自协调者的信息之后，他会默认执行 commit。而不会一直持有事务资源并处于阻塞状态。 3.2. 三阶段提交的缺点三阶段提交也会导致数据一致性问题。由于网络原因，协调者发送的 abort 响应没有及时被参与者接收到，那么参与者在等待超时之后执行了 commit 操作。 这样就和其他接到 abort 命令并执行回滚的参与者之间存在数据不一致的情况。 欢迎关注技术公众号：零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://ostenant.coding.me/tags/分布式/"},{"name":"3PC","slug":"3PC","permalink":"https://ostenant.coding.me/tags/3PC/"}]},{"title":"分布式理论(三) - 2PC协议","slug":"分布式理论(三) - 2PC协议","date":"2018-04-25T14:22:00.000Z","updated":"2018-06-18T01:54:07.176Z","comments":true,"path":"2018/04/25/分布式理论(三) - 2PC协议/","link":"","permalink":"https://ostenant.coding.me/2018/04/25/分布式理论(三) - 2PC协议/","excerpt":"前言由于BASE理论需要在一致性和可用性方面做出权衡，因此涌现了很多关于一致性的算法和协议。其中比较著名的有二阶提交协议（2 Phase Commitment Protocol），三阶提交协议（3 Phase Commitment Protocol）和Paxos算法。","text":"前言由于BASE理论需要在一致性和可用性方面做出权衡，因此涌现了很多关于一致性的算法和协议。其中比较著名的有二阶提交协议（2 Phase Commitment Protocol），三阶提交协议（3 Phase Commitment Protocol）和Paxos算法。 本文要介绍的2PC协议，分为两个阶段提交一个事务。并通过协调者和各个参与者的配合，实现分布式一致性。 两个阶段事务提交协议，由协调者和参与者共同完成。 角色 XA概念 作用 协调者 事务管理器 协调各个参与者，对分布式事务进行提交或回滚 参与者 资源管理器 分布式集群中的节点 正文1. 分布式事务分布式事务是指会涉及到操作多个数据库的事务，其实就是将对同一库事务的概念扩大到了对多个库的事务。目的是为了保证分布式系统中的数据一致性。 分布式事务处理的关键是： 需要记录事务在任何节点所做的所有动作； 事务进行的所有操作要么全部提交，要么全部回滚。 2. XA规范2.1. XA规范的组成XA规范是由 X/Open组织（即现在的 Open Group ）定义的分布式事务处理模型。 X/Open DTP 模型（ 1994 ）包括： 应用程序（ AP ） 事务管理器（ TM ）：交易中间件等 资源管理器（ RM ）：关系型数据库等 通信资源管理器（ CRM ）：消息中间件等 2.2. XA规范的定义XA规范定义了交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。而XA接口函数由数据库厂商提供。 二阶提交协议和三阶提交协议就是基于XA规范提出的其中，二阶段提交就是实现XA分布式事务的关键。 2.3. XA规范编程规范 配置TM，给TM注册RM作为数据源。其中，一个TM可以注册多个RM。 AP向TM发起一个全局事务。这时，TM会发送一个XID（全局事务ID）通知各个RM。 AP从TM获取资源管理器的代理（例如：使用JTA接口，从TM管理的上下文中，获取出这个TM所管理的RM的JDBC连接或JMS连接）。 AP通过从TM中获取的连接，间接操作RM进行业务操作。TM在每次AP操作时把XID传递给RM，RM正是通过这个XID关联来操作和事务的关系的。 AP结束全局事务时，TM会通知RM全局事务结束。开始二段提交，也就是prepare - commit的过程。 XA规范的流程，大致如图所示： 3. 二阶段提交（2PC）3.1. 二阶段提交的定义二阶段提交的算法思路可以概括为：每个参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报，决定各参与者是否要提交操作还是中止操作。 所谓的两个阶段分别是： 第一阶段：准备阶段（投票阶段） 第二阶段：提交阶段（执行阶段） 3.1.1. 准备阶段准备阶段分为三个步骤： a. 事务询问 协调者向所有的参与者询问，是否准备好了执行事务，并开始等待各参与者的响应。 b. 执行事务 各参与者节点执行事务操作。如果本地事务成功，将Undo和Redo信息记入事务日志中，但不提交；否则，直接返回失败，退出执行。 c. 各参与者向协调者反馈事务询问的响应 如果参与者成功执行了事务操作，那么就反馈给协调者 Yes响应，表示事务可以执行提交；如果参与者没有成功执行事务，就返回No给协调者，表示事务不可以执行提交。 3.1.2. 提交阶段在提交阶段中，会根据准备阶段的投票结果执行2种操作：执行事务提交，中断事务。 提交事务过程如下： a. 发送提交请求 协调者向所有参与者发出commit请求。 b. 事务提交 参与者收到commit请求后，会正式执行事务提交操作，并在完成提交之后，释放整个事务执行期间占用的事务资源。 c. 反馈事务提交结果 参与者在完成事务提交之后，向协调者发送Ack信息。 d. 事务提交确认 协调者接收到所有参与者反馈的Ack信息后，完成事务。 中断事务过程如下： a. 发送回滚请求 协调者向所有参与者发出Rollback请求。 b. 事务回滚 参与者接收到Rollback请求后，会利用其在提交阶段种记录的Undo信息，来执行事务回滚操作。在完成回滚之后，释放在整个事务执行期间占用的资源。 c. 反馈事务回滚结果 参与者在完成事务回滚之后，想协调者发送Ack信息。 d. 事务中断确认 协调者接收到所有参与者反馈的Ack信息后，完成事务中断。 3.1. 二阶段提交的优缺点 优点：原理简单，实现方便。 缺点：同步阻塞，单点问题，数据不一致，容错性不好。 同步阻塞在二阶段提交的过程中，所有的节点都在等待其他节点的响应，无法进行其他操作。这种同步阻塞极大的限制了分布式系统的性能。 单点问题协调者在整个二阶段提交过程中很重要，如果协调者在提交阶段出现问题，那么整个流程将无法运转。更重要的是，其他参与者将会处于一直锁定事务资源的状态中，而无法继续完成事务操作。 数据不一致假设当协调者向所有的参与者发送commit请求之后，发生了局部网络异常，或者是协调者在尚未发送完所有 commit请求之前自身发生了崩溃，导致最终只有部分参与者收到了commit请求。这将导致严重的数据不一致问题。 容错性不好如果在二阶段提交的提交询问阶段中，参与者出现故障，导致协调者始终无法获取到所有参与者的确认信息，这时协调者只能依靠其自身的超时机制，判断是否需要中断事务。显然，这种策略过于保守。换句话说，二阶段提交协议没有设计较为完善的容错机制，任意一个节点是失败都会导致整个事务的失败。 小结对于2PC协议存在的同步阻塞、单点问题，将在下一篇文章的3PC协议中引入解决方案。 欢迎关注技术公众号：零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://ostenant.coding.me/tags/分布式/"},{"name":"2PC","slug":"2PC","permalink":"https://ostenant.coding.me/tags/2PC/"}]},{"title":"分布式理论(二) - BASE理论","slug":"分布式理论(二) - BASE理论","date":"2018-04-24T12:41:00.000Z","updated":"2018-06-18T01:54:20.232Z","comments":true,"path":"2018/04/24/分布式理论(二) - BASE理论/","link":"","permalink":"https://ostenant.coding.me/2018/04/24/分布式理论(二) - BASE理论/","excerpt":"前言BASE理论是由eBay架构师提出的。BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网分布式系统实践的总结，是基于CAP定律逐步演化而来。其核心思想是即使无法做到强一致性，但每个应用都可以根据自身业务特点，才用适当的方式来使系统打到最终一致性。","text":"前言BASE理论是由eBay架构师提出的。BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网分布式系统实践的总结，是基于CAP定律逐步演化而来。其核心思想是即使无法做到强一致性，但每个应用都可以根据自身业务特点，才用适当的方式来使系统打到最终一致性。 正文1. CAP的3选2伪命题实际上，不是为了P（分区容错性），必须在C（一致性）和A（可用性）之间任选其一。分区的情况很少出现，CAP在大多时间能够同时满足C和A。 对于分区存在或者探知其影响的情况下，需要提供一种预备策略做出处理： 探知分区的发生； 进入显示的分区模式，限制某些操作； 启动恢复过程，恢复数据一致性，补偿分区发生期间的错误。 2. BASE理论简介BASE理论是Basically Available(基本可用)，Soft State（软状态）和Eventually Consistent（最终一致性）三个短语的缩写。 其核心思想是： 既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 3. BASE理论的内容 基本可用（Basically Available） 软状态（Soft State） 最终一致性（Eventually Consistent） 下面展开讨论： 3.1. 基本可用什么是基本可用呢？假设系统，出现了不可预知的故障，但还是能用，相比较正常的系统而言： 响应时间上的损失：正常情况下的搜索引擎0.5秒即返回给用户结果，而基本可用的搜索引擎可以在2秒作用返回结果。 功能上的损失：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单。但是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 3.2. 软状态什么是软状态呢？相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种“硬状态”。 软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用性，即允许系统在多个不同节点的数据副本存在数据延时。 3.3. 最终一致性上面说软状态，然后不可能一直是软状态，必须有个时间期限。在期限过后，应当保证所有副本保持数据一致性，从而达到数据的最终一致性。这个时间期限取决于网络延时、系统负载、数据复制方案设计等等因素。 而在实际工程实践中，最终一致性分为5种： 3.3.1. 因果一致性（Causal consistency）因果一致性指的是：如果节点A在更新完某个数据后通知了节点B，那么节点B之后对该数据的访问和修改都是基于A更新后的值。于此同时，和节点A无因果关系的节点C的数据访问则没有这样的限制。 3.3.2. 读己之所写（Read your writes）读己之所写指的是：节点A更新一个数据后，它自身总是能访问到自身更新过的最新值，而不会看到旧值。其实也算一种因果一致性。 3.3.3. 会话一致性（Session consistency）会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现 “读己之所写” 的一致性，也就是说，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。 3.3.4. 单调读一致性（Monotonic read consistency）单调读一致性指的是：如果一个节点从系统中读取出一个数据项的某个值后，那么系统对于该节点后续的任何数据访问都不应该返回更旧的值。 3.3.5. 单调写一致性（Monotonic write consistency）单调写一致性指的是：一个系统要能够保证来自同一个节点的写操作被顺序的执行。 在实际的实践中，这5种系统往往会结合使用，以构建一个具有最终一致性的分布式系统。 实际上，不只是分布式系统使用最终一致性，关系型数据库在某个功能上，也是使用最终一致性的。比如备份，数据库的复制过程是需要时间的，这个复制过程中，业务读取到的值就是旧的。当然，最终还是达成了数据一致性。这也算是一个最终一致性的经典案例。 小结总体来说BASE理论面向的是大型高可用、可扩展的分布式系统。与传统ACID特性相反，不同于ACID的强一致性模型，BASE提出通过牺牲强一致性来获得可用性，并允许数据段时间内的不一致，但是最终达到一致状态。同时，在实际分布式场景中，不同业务对数据的一致性要求不一样。因此在设计中，ACID和BASE理论往往又会结合使用。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://ostenant.coding.me/tags/分布式/"},{"name":"BASE","slug":"BASE","permalink":"https://ostenant.coding.me/tags/BASE/"}]},{"title":"分布式理论(一) - CAP定理","slug":"分布式理论(一) - CAP定理","date":"2018-04-23T12:33:00.000Z","updated":"2018-06-18T01:53:51.322Z","comments":true,"path":"2018/04/23/分布式理论(一) - CAP定理/","link":"","permalink":"https://ostenant.coding.me/2018/04/23/分布式理论(一) - CAP定理/","excerpt":"前言CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性）这三个基本需求，最多只能同时满足其中的2个。","text":"前言CAP原则又称CAP定理，指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性）这三个基本需求，最多只能同时满足其中的2个。 正文1. CAP原则简介 选项 描述 Consistency（一致性） 指数据在多个副本之间能够保持一致的特性（严格的一致性） Availability（可用性） 指系统提供的服务必须一直处于可用的状态，每次请求都能获取到非错的响应（不保证获取的数据为最新数据） Partition tolerance（分区容错性） 分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务，除非整个网络环境都发生了故障 什么是分区？ 在分布式系统中，不同的节点分布在不同的子网络中，由于一些特殊的原因，这些子节点之间出现了网络不通的状态，但他们的内部子网络是正常的。从而导致了整个系统的环境被切分成了若干个孤立的区域，这就是分区。 2. CAP原则论证如图所示，是我们证明CAP的基本场景，网络中有两个节点N1和N2，可以简单的理解N1和N2分别是两台计算机，他们之间网络可以连通，N1中有一个应用程序A，和一个数据库V，N2也有一个应用程序B和一个数据库V。现在，A和B是分布式系统的两个部分，V是分布式系统的数据存储的两个子数据库。 在满足一致性的时候，N1和N2中的数据是一样的，V0=V0。 在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。 在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。 如图所示，这是分布式系统正常运转的流程，用户向N1机器请求数据更新，程序A更新数据库V0为V1。分布式系统将数据进行同步操作M，将V1同步的N2中V0，使得N2中的数据V0也更新为V1，N2中的数据再响应N2的请求。 根据CAP原则定义，系统的一致性、可用性和分区容错性细分如下： 一致性：N1和N2的数据库V之间的数据是否完全一样。 可用性：N1和N2的对外部的请求能否做出正常的响应。 分区容错性：N1和N2之间的网络是否互通。 这是正常运作的场景，也是理想的场景。作为一个分布式系统，它和单机系统的最大区别，就在于网络。现在假设一种极端情况，N1和N2之间的网络断开了，我们要支持这种网络异常。相当于要满足分区容错性，能不能同时满足一致性和可用性呢？还是说要对他们进行取舍？ 假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1。由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0。这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？ 这里有两种选择： 第一：牺牲数据一致性，保证可用性。响应旧的数据V0给用户。 第二：牺牲可用性，保证数据一致性。阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。 这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。 3. CAP原则权衡通过CAP理论，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？ 3.1. CA without P如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但其实分区不是你想不想的问题，而是始终会存在，因此CA的系统更多的是允许分区后各子系统依然保持CA。 3.2. CP without A如果不要求A（可用），相当于每个请求都需要在Server之间强一致，而P（分区）会导致同步时间无限延长，如此CP也是可以保证的。很多传统的数据库分布式事务都属于这种模式。 3.3. AP wihtout C要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的NoSQL都属于此类。 小结对于多数大型互联网应用的场景，主机众多、部署分散。而且现在的集群规模越来越大，所以节点故障、网络故障是常态。这种应用一般要保证服务可用性达到N个9，即保证P和A，只有舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。 对于涉及到钱财这样不能有一丝让步的场景，C必须保证。网络发生故障宁可停止服务，这是保证CA，舍弃P。貌似这几年国内银行业发生了不下10起事故，但影响面不大，报到也不多，广大群众知道的少。还有一种是保证CP，舍弃A，例如网络故障时只读不写。 孰优孰劣，没有定论，只能根据场景定夺，适合的才是最好的。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"分布式系列","slug":"分布式系列","permalink":"https://ostenant.coding.me/categories/分布式系列/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://ostenant.coding.me/tags/分布式/"},{"name":"CAP","slug":"CAP","permalink":"https://ostenant.coding.me/tags/CAP/"}]},{"title":"基于Docker + Consul + Nginx + Consul-template的服务负载均衡实现","slug":"基于Docker + Consul + Nginx + Consul-template的服务负载均衡实现","date":"2018-02-08T03:03:00.000Z","updated":"2018-07-19T10:01:44.413Z","comments":true,"path":"2018/02/08/基于Docker + Consul + Nginx + Consul-template的服务负载均衡实现/","link":"","permalink":"https://ostenant.coding.me/2018/02/08/基于Docker + Consul + Nginx + Consul-template的服务负载均衡实现/","excerpt":"前言上一篇文章使用 Consul 和 Registrator 在 docker 的容器环境中搭建了服务注册和发现集群。在服务发现和注册的基础上，本文将引入 Nginx反向代理服务器和 Consul-template 组件，实现动态的服务负载均衡。","text":"前言上一篇文章使用 Consul 和 Registrator 在 docker 的容器环境中搭建了服务注册和发现集群。在服务发现和注册的基础上，本文将引入 Nginx反向代理服务器和 Consul-template 组件，实现动态的服务负载均衡。 正文1. 工具介绍1.1. Nginx一个高性能的 HTTP 和反向代理服务器，用于前端访问流量到后台应用服务器负载均衡和请求转发。 1.2. Consul-templateConsul-template 是 HashiCorp 基于 Consul 所提供的可扩展的工具，通过监听 Consul 中的数据变化，动态地修改一些配置文件中地模板。常用于在 Nginx、HAProxy 上动态配置健康状态下的客户端反向代理信息。 2. 实现原理 通过 Nginx 自身实现负载均衡和请求转发； 通过 Consul-template 的 config 功能实时监控 Consul 集群节点的服务和数据的变化； 实时的用 Consul 节点的信息替换 Nginx 配置文件的模板，并重新加载配置文件； Consul-template 和 nginx 必须安装在同一台机器上，因为 Consul-template 需要动态修改 nginx 的配置文件 nginx.conf，然后执行 nginx -s reload 命令进行路由更新，达到动态负载均衡的目的。 2.1. 传统负载均衡传统的负载均衡，就是 Client 支姐访问 Nginx，然后被转发到后端某一台 Web Server。如果后端有添加/删除 Web Server，运维需要手动改下 nginx.conf ，然后重新载入配置，就可以动态的调整负载均衡。 2.2. 自动负载均衡再看看基于服务自动发现和注册的负载均衡，负载均衡的方式没有变，只是多了一些外围组件，当然这些组件对 Client 是不可见的，client 依然只能看到 Nginx 入口，访问方式也没变化。 Nginx 的动态负载均衡实现流程如下： 以相同的 Consul 标签对 Web Server 进行服务标记和分类，新增或者删除 Web Server 服务器节点； Registrator 监控到 Web Server 的状态更新，自动在 Consul服务注册中心将它注册或者注销； Consul-template 订阅了 Consul 服务注册中心的服务消息，接收到 Consul 的消息推送，即 Web Server 服务节点状态发生改变。 Consul-template 自动去修改和替换 Nginx 服务器下的 nginx配置文件中的模板，并重新加载服务达到自动负载均衡的目的。 3. 环境准备3.1. 系统环境 软件 版本 操作系统 Ubuntu：16.04 x86_64，内核：4.8.0-58-generic docker Docker version 1.12.6, build 78d1802 docker-compose docker-compose version 1.8.0 3.2. 节点规划 主机IP 组件 192.168.1.181 Consul Server, Registrator, Nginx, Consul-template 192.168.1.186 Consul Server, Registrator, Nginx, Consul-template 192.168.1.182 Consul Client, Registrator, Client WebApp1, Server WebApp1, Server WebApp2 192.168.1.183 Consul Client, Registrator, Client WebApp2, Server WebApp3, Server WebApp4 192.168.1.185 Consul Client, Registrator, Client WebApp3, Server WebApp5, Server WebApp6 Client WebApp：提供基于Thrift的RPC客户端和基于Http协议的RESTful客户端，用于访问 Server 程序。 Server WebApp：提供基于Thrift的RPC服务端和基于Http协议的RESTful服务端，供 Client 程序调用。 这里的3台主机 - 192.168.1.182、192.168.1.183 和 192.168.1.185，每台主机部署两个 Client WebApp 容器和一个 Client Server 容器，用于模拟服务层的负载均衡。 3.3. 镜像构建 Consul：consul:latest Registrator：gliderlabs/registrator:latest Nginx和Consul-template：liberalman/nginx-consul-template:latest Client WebApp：test-client:latest Server WebApp：test-server:latest 这里先说说 test-client 和 test-server 的镜像构建： 克隆项目到本地项目环境： https://github.com/ostenant/spring-cloud-starter-thrift 切换到子模块 spring-cloud-starter-thrift-examples 下的 test 目录，执行命令 mvn clean package 进行程序打包。 分别将 test-client 和 test-server 项目根目录下的 Dockerfile 文件和target目录下的 target/*.jar程序拷贝到 192.168.1.182 、192.168.1.183 和 192.168.1.185 目录下。 进入客户端 Dockerfile 所在目录，对客户端程序 test-client 进行镜像构建，命令如下：docker build . -t test-client:latest 进入服务端 Dockerfile 所在目录，对服务端程序 test-server 进行镜像构建，命令如下：docker build . -t test-server:latest 构建完成后查看本地镜像库： 3.4. 部署模型五台主机，其中 192.168.1.181 和 192.168.1.186 两台主机的主要作用如下： 作为负载均衡转发器 (这里只是演示，可以通过 KeepAlived 实现 Nginx 的HA)，将前端访问流量经过负载算法一次转发到后台 Client WebApp 。 以 Server模式启动 Consul节点，其中一台作为整个服务发现与注册集群的 leader， 用于同步和持久化其余三台 Client 模式的 Consul 节点的数据和状态信息。 其余三台主机 - 192.168.1.182、192.168.1.183 和 192.168.1.185，充当的角色如下： 每台分别以 Client 模式部署 Consul 节点，用于注册和发现本机 docker 容器暴露的服务，同时和 Consul Server 的 leader 节点进行服务状态同步。 分别启动一个 Client WebApp 容器实例和两个 Server WebApp 容器实例，将 Client WebApp 的请求根据服务层的负载算法二次转发到 Server WebApp 中的任意一台上完成具体的业务处理。 这里有两次服务转发操作： 接入层的转发：两台 Nginx 服务器将客户流量，经由一次转发至三个 Client WebApp 服务实例中任意一个做处理。 服务层的转发：三个 Client WebApp服务实例其中之一，根据从服务注册中心拉取的健康的服务缓存列表，将请求二次转发至六个 Server WebApp服务实例其中之一做处理。 3.5. 开始搭建3.5.1. Consul Server主机(a). 分别编写 docker-compose.yml，注意 Registrator 需要配置各自的 IP地址。 主机：192.168.1.181 docker-compose.yml 123456789101112131415161718192021222324252627282930version: '2'services: load_balancer: image: liberalman/nginx-consul-template:latest hostname: lb links: - consul_server_master:consul ports: - \"80:80\" consul_server_master: image: consul:latest hostname: consul_server_master ports: - \"8300:8300\" - \"8301:8301\" - \"8302:8302\" - \"8400:8400\" - \"8500:8500\" - \"8600:8600\" command: consul agent -server -bootstrap-expect 1 -advertise 192.168.1.181 -node consul_server_master -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest hostname: registrator links: - consul_server_master:consul volumes: - \"/var/run/docker.sock:/tmp/docker.sock\" command: -ip 192.168.1.181 consul://192.168.1.181:8500 主机：192.168.1.186 docker-compose.yml 123456789101112131415161718192021222324252627282930version: '2'services: load_balancer: image: liberalman/nginx-consul-template:latest hostname: lb links: - consul_server_slave:consul ports: - \"80:80\" consul_server_slave: image: consul:latest hostname: consul_server_slave ports: - \"8300:8300\" - \"8301:8301\" - \"8302:8302\" - \"8400:8400\" - \"8500:8500\" - \"8600:8600\" command: consul agent -server -join=192.168.1.181 -advertise 192.168.1.186 -node consul_server_slave -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest hostname: registrator links: - consul_server_slave:consul volumes: - \"/var/run/docker.sock:/tmp/docker.sock\" command: -ip 192.168.1.186 consul://192.168.1.186:8500 (b). 在两台主机上分别通过 docker-compose 启动多容器应用，命令如下： 1docker-compose up -d 这是在主机 192.168.1.181 上运行启动命令时的输出，可以看到 docker-compose 启动时会先去检查目标镜像文件是否拉取到本地，然后依次创建并启动 docker-compose.yml 文件配置的容器实例。 (c). 查看正常启动的容器进程，观察Consul、Registrator 和 Nginx/Consul-template的容器都正常启动。 (d). 利用 docker-compose，以相同的方式在主机 192.168.1.186 上启动所配置的容器服务实例，查看启动状态如下： (e). 访问 http://IP:8500 查看 Consul Server 的节点信息和服务注册列表。 节点信息： 服务状态列表： 两台 Consul Server 主机上的容器服务实例均正常启动！ 3.5.2. Consul Client主机一般情况下，我们把 Consul 作为服务注册与发现中心，会使用它提供的服务定义 (Service Definition) 和健康检查定义 (Health Check Definition) 功能，相关配置说明参考如下： 服务定义 环境变量Key 环境变量Value 说明 SERVICE_ID web-001 可以为GUID或者可读性更强变量，保证不重复 SERVICE_NAME web 如果ID没有设置，Consul会将name作为id，则有可能注册失败 SERVICE_TAGS nodejs,web 服务的标签，用逗号分隔，开发者可以根据标签来查询一些信息 SERVICE_IP 内网IP 要使用Consul，可访问的IP SERVICE_PORT 50001 应用的IP, 如果应用监听了多个端口，理应被视为多个应用 SERVICE_IGNORE Boolean 是否忽略本Container，可以为一些不需要注册的Container添加此属性 服健康检查定义配置原则为: SERVICE_XXX_*。如果你的应用监听的是 5000 端口，则改为 SERVICE_5000_CHECK_HTTP，其它环境变量配置同理。 环境变量Key 环境变量Value 说明 — 以下为HTTP模式 — — SERVICE_80_CHECK_HTTP /path_to_health_check 你的健康状态检查的路径如 /status SERVICE_80_CHECK_INTERVAL 15s 15秒检查一次 SERVICE_80_CHECK_TIMEOUT 2s 状态检查超时时间 — 以下为HTTPS模式 — — SERVICE_443_CHECK_HTTPS /path_to_health_check 你的健康状态检查的路径如 /status SERVICE_443_CHECK_INTERVAL 15s 15秒检查一次 SERVICE_443_CHECK_TIMEOUT 2s 状态检查超时时间 — 以下为TCP模式 — — SERVICE_443_CHECK_TCP /path_to_health_check 你的健康状态检查的路径如 /status SERVICE_443_CHECK_INTERVAL 15s 15秒检查一次 SERVICE_443_CHECK_TIMEOUT 2s 状态检查超时时间 — 使用脚本检查 — — SERVICE_CHECK_SCRIPT curl –silent –fail example.com 如官方例子中的check_redis.py — 其他 — — SERVICE_CHECK_INITIAL_STATUS passing Consul默认注册后的服务为failed 配置说明(a). 分别编写 docker-compose.yml，同样注意 Registrator 需要配置各自的 IP 地址。test-server 和 test-client 的服务实例在配置时需要指定相关的环境变量。 主机：192.168.1.182 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465version: '2'services: consul_client_01: image: consul:latest ports: - \"8300:8300\" - \"8301:8301\" - \"8301:8301/udp\" - \"8302:8302\" - \"8302:8302/udp\" - \"8400:8400\" - \"8500:8500\" - \"8600:8600\" command: consul agent -retry-join 192.168.1.181 -advertise 192.168.1.182 -node consul_client_01 -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest volumes: - \"/var/run/docker.sock:/tmp/docker.sock\" command: -ip 192.168.1.182 consul://192.168.1.182:8500 test_server_1: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-01 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-01 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"16000:8080\" - \"30000:25000\" test_server_2: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-02 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-02 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"18000:8080\" - \"32000:25000\" test_client_1: image: test-client:latest environment: - SERVICE_8080_NAME=my-web-server - SERVICE_8080_TAGS=test-client-http-service-01 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/features ports: - \"80:8080\" 主机：192.168.1.183 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465version: '2'services: consul_client_02: image: consul:latest ports: - \"8300:8300\" - \"8301:8301\" - \"8301:8301/udp\" - \"8302:8302\" - \"8302:8302/udp\" - \"8400:8400\" - \"8500:8500\" - \"8600:8600\" command: consul agent -retry-join 192.168.1.181 -advertise 192.168.1.183 -node consul_client_02 -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest volumes: - \"/var/run/docker.sock:/tmp/docker.sock\" command: -ip 192.168.1.183 consul://192.168.1.183:8500 test_server_1: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-03 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-03 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"16000:8080\" - \"30000:25000\" test_server_2: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-04 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-04 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"18000:8080\" - \"32000:25000\" test_client_1: image: test-client:latest environment: - SERVICE_8080_NAME=my-web-server - SERVICE_8080_TAGS=test-client-http-service-02 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/features ports: - \"80:8080\" 主机：192.168.1.185 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465version: '2'services: consul_client_03: image: consul:latest ports: - \"8300:8300\" - \"8301:8301\" - \"8301:8301/udp\" - \"8302:8302\" - \"8302:8302/udp\" - \"8400:8400\" - \"8500:8500\" - \"8600:8600\" command: consul agent -retry-join 192.168.1.181 -advertise 192.168.1.185 -node consul_client_03 -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest volumes: - \"/var/run/docker.sock:/tmp/docker.sock\" command: -ip 192.168.1.185 consul://192.168.1.185:8500 test_server_1: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-05 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-05 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"16000:8080\" - \"30000:25000\" test_server_2: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-06 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-06 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - \"18000:8080\" - \"32000:25000\" test_client_1: image: test-client:latest environment: - SERVICE_8080_NAME=my-web-server - SERVICE_8080_TAGS=test-client-http-service-03 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/features ports: - \"80:8080\" 注意：我们使用的第三方镜像 liberalman/nginx-consul-template，Nginx 会把名称为 my-web-server的服务容器作为后台转发的目标服务器，因此，在 test-client 的配置项中，需要指定 SERVICE_XXX_NAME 为 my-web-server。当然你也可以自己制作镜像指定模板。 (b). 在三台主机上使用 docker-compose 启动多容器应用： 1docker-compose up -d 以主机 192.168.1.182 为例 (其余两台类似)，控制台日志显示，创建并启动 docker-compose.yml 文件配置的5个容器实例。 (c). 查看正常启动的容器进程，观察到 Consul、一台test-client 和 两台test-server的容器都正常启动。 (d). 在 b 操作中的控制台输出可以看到：docker-compose 并非按照 docker-compose.yml 文件中服务配置的先后顺序启动。 registrator 容器的启动依赖于 consul 容器，而此时 consul 还并未启动，就出现了 registrator 优先启动而异常退出的现象。解决方法是再运行一次 docker-compose up -d 命令。 (e). 再次查看容器进程，此时 Registrator 容器就已经正常启动了。 (f). 以相同的方式在其余两台主机上重复以上操作，再次访问 http://IP:8500 查看 Consul Server 的节点信息和服务注册列表。 Consul 集群节点信息，包括两台 Consul Server 节点和一台 Consul Client 节点，节点右侧可以看到所有的服务注册列表和相关的健康检查结果： nginx 服务状态列表，服务名称 nginx-consul-template，提供 http 服务，共有2个服务实例： test-client 服务状态列表，服务名称为 my-web-server，提供 http 服务，共有3个服务实例： test-server 服务状态列表，服务名称为 test-server-http-service 和 test-server-thrift-service，分别对应6个 http 服务实例和 6个 thrift 服务实例： 三台 Consul Client 主机上的容器服务实例均正常启动，服务注册和发现运行正常！ 4. 结果验证4.1. Nginx负载均衡4.1.1. 访问NginxNginx 默认访问端口号为80，任选一台 Nginx 访问，比如： http://192.168.1.181/swagger-ui.html。 请求转发至 Test Client 的 Swagger页面，表明 nginx配置文件 nginx.conf 被 Consul-template 成功修改。 4.1.2. 进入Nginx容器运行 docker ps 查看 nginx-consul-template 的容器 ID，比如这里是：4f2731a7e0cb。进入 nginx-consul-template 容器。 1docker-enter 4f2731a7e0cb 查看容器内部的进程列表： 特别留意以下一行进程命令，这里完成了三步重要的操作： 1consul-template -consul-addr=consul:8500 -template /etc/consul-templates/nginx.conf.ctmpl:/etc/nginx/conf.d/app.conf:nginx -s reload Consul-template 利用 Consul 上的服务信息对 Nginx 的配置文件模板 /etc/consul-templates/nginx.conf.ctmpl 进行重新解析和渲染。 渲染生成的 nginx 配置文件为 /etc/nginx/conf.d/app.conf。 进一步运行 nginx -s reload 重新加载 app.conf，更新路由转发列表。 查看 app.conf 的配置项，发现三个 test-client 节点的 IP:port 都加入了路由转发列表中。 退出并关闭主机 192.168.1.182 上的 test-client 容器。 再次查看 app.conf，可以发现路由节点 192.168.1.182:80 已经从 Nginx 的路由转发列表上剔除掉了。 同样的，重新启动 test-client 恢复容器，又可以发现 Nginx 的路由转发列表 再次自动将其添加! 4.2. 服务负载均衡4.2.1. 接口测试test-client 通过 http 通信方式请求任意一台 test-server，返回响应结果 (请求处理时间 ms )。 test-client 通过 thrift 通信方式请求任意一台 test-server，返回响应结果 (请求处理时间 ms )。 4.2.3. 日志分析服务的负载均衡并不是很好观察，这里直接截取了一段 test-client 的服务缓存列表动态定时刷新时打印的日志： 123456789101112131415161718192021222018-02-09 13:15:55.157 INFO 1 --- [erListUpdater-1] t.c.l.ThriftConsulServerListLoadBalancer : Refreshed thrift serverList: [test-server-thrift-service: [ ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-01], host='192.168.1.182', port=30000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-02], host='192.168.1.182', port=32000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-03], host='192.168.1.183', port=30000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-04], host='192.168.1.183', port=32000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-05], host='192.168.1.185', port=30000, address='192.168.1.185', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-06], host='192.168.1.185', port=32000, address='192.168.1.185', isHealth=true&#125;],test-server-http-service: [ ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-http-service', tags=[test-server-http-service-01], host='192.168.1.182', port=16000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-http-service', tags=[test-server-http-service-02], host='192.168.1.182', port=18000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-http-service', tags=[test-server-http-service-03], host='192.168.1.183', port=16000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-http-service', tags=[test-server-http-service-04], host='192.168.1.183', port=18000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-http-service', tags=[test-server-http-service-05], host='192.168.1.185', port=16000, address='192.168.1.185', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-http-service', tags=[test-server-http-service-06], host='192.168.1.185', port=18000, address='192.168.1.185', isHealth=true&#125;],my-web-server: [ ThriftServerNode&#123;node='consul_client_01', serviceId='my-web-server', tags=[test-client-http-service-01], host='192.168.1.182', port=80, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='my-web-server', tags=[test-client-http-service-02], host='192.168.1.183', port=80, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='my-web-server', tags=[test-client-http-service-03], host='192.168.1.185', port=80, address='192.168.1.185', isHealth=true&#125;]] 服务实例 test-server-http-service 所有健康的服务实例： 服务IP地址 服务端口 服务标签 192.168.1.182 16000 test-server-http-service-01 192.168.1.182 18000 test-server-http-service-02 192.168.1.183 16000 test-server-http-service-03 192.168.1.183 18000 test-server-http-service-04 192.168.1.185 16000 test-server-http-service-05 192.168.1.185 18000 test-server-http-service-06 test-server-thrift-service 所有健康的服务实例： 服务IP地址 服务端口 服务标签 192.168.1.182 30000 test-server-thrift-service-01 192.168.1.182 32000 test-server-thrift-service-02 192.168.1.183 30000 test-server-thrift-service-03 192.168.1.183 32000 test-server-thrift-service-04 192.168.1.185 30000 test-server-thrift-service-05 192.168.1.185 32000 test-server-thrift-service-06 my-web-server 所有健康的服务实例： 服务IP地址 服务端口 服务标签 192.168.1.182 80 test-client-http-service-01 192.168.1.183 80 test-client-http-service-02 192.168.1.185 80 test-client-http-service-03 spring-cloud-starter-thrift 采用的轮询的转发策略，也就是说 my-web-server 会按次序循环往来地将 http 或者 rpc 请求分发到各自的 6 个服务实例完成处理。 总结本文提供了一套基于微服务服务注册与发现体系和容器的高可用 (HA) 解决方案，引入了接入层和服务层的自动负载均衡的实现，详细给出了实践方案和技术手段！ 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"微服务系列","slug":"微服务系列","permalink":"https://ostenant.coding.me/categories/微服务系列/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://ostenant.coding.me/tags/Docker/"},{"name":"Nginx","slug":"Nginx","permalink":"https://ostenant.coding.me/tags/Nginx/"},{"name":"Consul","slug":"Consul","permalink":"https://ostenant.coding.me/tags/Consul/"},{"name":"Consul-template","slug":"Consul-template","permalink":"https://ostenant.coding.me/tags/Consul-template/"}]},{"title":"基于Docker + Consul + Registrator的服务注册与发现集群搭建","slug":"基于Docker + Consul + Registrator的服务注册与发现集群搭建","date":"2018-02-05T03:22:00.000Z","updated":"2018-06-18T01:56:17.566Z","comments":true,"path":"2018/02/05/基于Docker + Consul + Registrator的服务注册与发现集群搭建/","link":"","permalink":"https://ostenant.coding.me/2018/02/05/基于Docker + Consul + Registrator的服务注册与发现集群搭建/","excerpt":"前言近年微服务架构在互联网应用领域中愈来愈火，引入微服务主要解决了单体应用多个模块的紧耦合、无法扩展和运维困难等问题。微服务架构就是按照功能粒度将业务模块进行垂直拆分，对单体应用本身进行服务化和组件化，每个组件单独部署为小应用（从DB到UI）。微服务与微服务之间通过Service API进行交互，同时为了支持水平扩展、性能提升和服务可用性，单个服务允许同时部署一个或者多个服务实例。在运行时，每个实例通常是一个云虚拟机或者Docker容器。","text":"前言近年微服务架构在互联网应用领域中愈来愈火，引入微服务主要解决了单体应用多个模块的紧耦合、无法扩展和运维困难等问题。微服务架构就是按照功能粒度将业务模块进行垂直拆分，对单体应用本身进行服务化和组件化，每个组件单独部署为小应用（从DB到UI）。微服务与微服务之间通过Service API进行交互，同时为了支持水平扩展、性能提升和服务可用性，单个服务允许同时部署一个或者多个服务实例。在运行时，每个实例通常是一个云虚拟机或者Docker容器。 微服务系统内部多个服务的实例之间如何通信？如何感知到彼此的存在和销毁？生产者服务如何知道消费者服务的地址？如何实现服务与注册中心的解耦？这就需要一个第三方的服务注册中心，提供对生产者服务节点的注册管理和消费者服务节点的发现管理。 正文1. 服务发现与注册1.1. 具体流程 服务注册中心：作为整个架构中的核心，要支持分布式、持久化存储，注册信息变动实时通知消费者。 服务提供者：服务以 docker 容器化方式部署(实现服务端口的动态生成)，可以通过 docker-compose 的方式来管理。通过 Registrator 检测到 docker 进程信息以完成服务的自动注册。 服务消费者：要使用服务提供者提供的服务，和服务提供者往往是动态相互转位置的。 一个较为完整的服务注册与发现流程如下： 注册服务：服务提供者到注册中心注册； 订阅服务：服务消费者到注册中心订阅服务信息，对其进行监听； 缓存服务列表：本地缓存服务列表，减少与注册中心的网络通信； 调用服务：先查找本地缓存，找不到再去注册中心拉取服务地址，然后发送服务请求； 变更通知：服务节点变动时 (新增、删除等)，注册中心将通知监听节点，更新服务信息。 1.2. 相关组件一个服务发现系统主要由三部分组成： 注册器(registrator)：根据服务运行状态，注册/注销服务。主要要解决的问题是，何时发起注册/注销动作。 注册表(registry)：存储服务信息。常见的解决方案有zookeeper、etcd、cousul等。 发现机制(discovery)：从注册表读取服务信息，给用户封装访问接口。 1.3. 第三方实现对于第三方的服务注册与发现的实现，现有的工具主要有以下三种： zookeeper：一个高性能、分布式应用程序协调服务，用于名称服务、分布式锁定、共享资源同步和分布式配置管理。 Etcd：一个采用HTTP协议的健/值对存储系统，主要用于共享配置和服务发现，提供的功能相对Zookeeper和Consul相对简单。 Consul：一个分布式高可用的服务发现和配置共享的软件，支持服务发现与注册、多数据中心、健康检查和分布式键/值存储。 简单对比： 与Zookeeper和etcd不一样，Consul内嵌实现了服务发现系统，不需要构建自己的系统或使用第三方系统，客户只需要注册服务，并通过DNS或HTTP接口执行服务发现。 2. Consul和Registrator2.1. Consul简介Consul是什么 Consul 是一种分布式的、高可用、支持水平扩展的的服务注册与发现工具。它大致包括以下特性： 服务发现： Consul 通过 DNS 或者 HTTP 接口使服务注册和服务发现变的很容易。一些外部服务，例如 saas 提供的也可以一样注册； 健康检查：健康检测使 consul 可以快速的告警在集群中的操作。和服务发现的集成，可以防止服务转发到故障的服务上面； 键/值存储：一个用来存储动态配置的系统。提供简单的 HTTP 接口，可以在任何地方操作； 多数据中心：支持多数据中心以避免单点故障，内外网的服务采用不同的端口进行监听。而其部署则需要考虑网络延迟, 分片等情况等。zookeeper和etcd均不提供多数据中心功能的支持； 一致性算法：采用 Raft 一致性协议算法，比Paxos算法好用。 使用 GOSSIP 协议管理成员和广播消息, 并且支持 ACL 访问控制； 服务管理Dashboard：提供一个 Web UI 的服务注册于健康状态监控的管理页面。 Consul的几个概念 下图是Consul官方文档提供的架构设计图： 图中包含两个Consul数据中心，每个数据中心都是一个consul的集群。在数据中心1中，可以看出consul的集群是由N个SERVER，加上M个CLIENT组成的。而不管是SERVER还是CLIENT，都是consul集群的一个节点。所有的服务都可以注册到这些节点上，正是通过这些节点实现服务注册信息的共享。除了这两个，还有一些小细节 一一 简单介绍。 CLIENT CLIENT表示consul的client模式，就是客户端模式。是consul节点的一种模式，这种模式下，所有注册到当前节点的服务会被转发到SERVER节点，本身是不持久化这些信息。 SERVER SERVER表示consul的server模式，表明这个consul是个server节点。这种模式下，功能和CLIENT都一样，唯一不同的是，它会把所有的信息持久化的本地。这样遇到故障，信息是可以被保留的。 SERVER-LEADER 中间那个SERVER下面有LEADER的描述，表明这个SERVER节点是它们的老大。和其它SERVER不一样的一点是，它需要负责同步注册信息给其它的SERVER，同时也要负责各个节点的健康监测。 其它信息 其它信息包括各个节点之间的通信方式，还有一些协议信息、算法。它们是用于保证节点之间的数据同步、实时性要求等等一系列集群问题的解决。这些有兴趣的自己看看官方文档。 2.2. Registrator简介什么是RegistratorRegistrator是一个独立于服务注册表的自动服务注册/注销组件，一般以Docker container的方式进行部署。Registrator会自动侦测它所在的宿主机上的所有Docker容器状态（启用/销毁），并根据容器状态到对应的服务注册列表注册/注销服务。 事实上，Registrator通过读取同一台宿主机的其他容器Container的环境变量进行服务注册、健康检查定义等操作。 Registrator支持可插拔式的服务注册表配置，目前支持包括Consul, etcd和SkyDNS 2三种注册工具。 2.3. Docker安装Consul集群2.3.1. 集群节点规划我本地的使用的是Ubuntu16.04的虚拟机： 容器名称 容器IP地址 映射端口号 宿主机IP地址 服务运行模式 node1 172.17.0.2 8500 -&gt; 8500 192.168.127.128 Server Master node2 172.17.0.3 9500 -&gt; 8500 192.168.127.128 Server node3 172.17.0.4 10500 -&gt; 8500 192.168.127.128 Server node4 172.17.0.5 11500 -&gt; 8500 192.168.127.128 Client 2.3.2. Consul集群安装Consul的配置参数信息说明： 参数列表 参数的含义和使用场景说明 advertise 通知展现地址用来改变我们给集群中的其他节点展现的地址，一般情况下-bind地址就是展现地址 bootstrap 用来控制一个server是否在bootstrap模式，在一个datacenter中只能有一个server处于bootstrap模式，当一个server处于bootstrap模式时，可以自己选举为raft leader bootstrap-expect 在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导整个集群，该标记不能和bootstrap共用 bind 该地址用来在集群内部的通讯IP地址，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0 client consul绑定在哪个client地址上，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1 config-file 明确的指定要加载哪个配置文件 config-dir 配置文件目录，里面所有以.json结尾的文件都会被加载 data-dir 提供一个目录用来存放agent的状态，所有的agent允许都需要该目录，该目录必须是稳定的，系统重启后都继续存在 dc 该标记控制agent允许的datacenter的名称，默认是dc1 encrypt 指定secret key，使consul在通讯时进行加密，key可以通过consul keygen生成，同一个集群中的节点必须使用相同的key join 加入一个已经启动的agent的ip地址，可以多次指定多个agent的地址。如果consul不能加入任何指定的地址中，则agent会启动失败，默认agent启动时不会加入任何节点 retry-interval 两次join之间的时间间隔，默认是30s retry-max 尝试重复join的次数，默认是0，也就是无限次尝试 log-level consul agent启动后显示的日志信息级别。默认是info，可选：trace、debug、info、warn、err node 节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名 protocol consul使用的协议版本 rejoin 使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中 server 定义agent运行在server模式，每个集群至少有一个server，建议每个集群的server不要超过5个 syslog 开启系统日志功能，只在linux/osx上生效 pid-file 提供一个路径来存放pid文件，可以使用该文件进行SIGINT/SIGHUP(关闭/更新)agent 2.4. Docker安装Consul集群2.4.1. 拉取consul官方镜像1madison@ubuntu:~$ docker pull consul:latest 2.4.2. 启动Server节点运行consul镜像，启动Server Master节点node1： node1:12345678910111213madison@ubuntu:~$ docker run -d --name=node1 --restart=always \\ -e 'CONSUL_LOCAL_CONFIG=&#123;\"skip_leave_on_interrupt\": true&#125;' \\ -p 8300:8300 \\ -p 8301:8301 \\ -p 8301:8301/udp \\ -p 8302:8302/udp \\ -p 8302:8302 \\ -p 8400:8400 \\ -p 8500:8500 \\ -p 8600:8600 \\ -h node1 \\ consul agent -server -bind=172.17.0.2 -bootstrap-expect=3 -node=node1 \\ -data-dir=/tmp/data-dir -client 0.0.0.0 -ui 查看node1的日志，追踪运行情况： 现在集群中还没有选举leader节点，继续启动其余两台Server节点node2和node3： node2:123456789101112131415madison@ubuntu:~$ docker run -d --name=node2 --restart=always \\ -e 'CONSUL_LOCAL_CONFIG=&#123;\"skip_leave_on_interrupt\": true&#125;' \\ -p 9300:8300 \\ -p 9301:8301 \\ -p 9301:8301/udp \\ -p 9302:8302/udp \\ -p 9302:8302 \\ -p 9400:8400 \\ -p 9500:8500 \\ -p 9600:8600 \\ -h node2 \\ consul agent -server -bind=172.17.0.3 \\ -join=192.168.127.128 -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \\ -node=node2 \\ -data-dir=/tmp/data-dir -client 0.0.0.0 -ui 查看node2节点的进程启动日志： node3:123456789101112131415madison@ubuntu:~$ docker run -d --name=node3 --restart=always \\ -e 'CONSUL_LOCAL_CONFIG=&#123;\"skip_leave_on_interrupt\": true&#125;' \\ -p 10300:8300 \\ -p 10301:8301 \\ -p 10301:8301/udp \\ -p 10302:8302/udp \\ -p 10302:8302 \\ -p 10400:8400 \\ -p 10500:8500 \\ -p 10600:8600 \\ -h node2 \\ consul agent -server -bind=172.17.0.4 \\ -join=192.168.127.128 -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \\ -node=node3 \\ -data-dir=/tmp/data-dir -client 0.0.0.0 -ui 查看node3节点的进程启动日志： 当3个Server节点都启动并正常运行时，观察node2和node3的进程日志，可以发现node1被选举为leader节点，也就是这个数据中心的Server Master。 再次查看node1节点的进程启动日志： 观察日志发现，node2和node3都成功join到了node1所在的数据中心dc1。当集群中有3台Consul Server启动时，node1被选举为dc1中的主节点。然后，node1会通过心跳检查的方式，不断地对node2和node3进行健康检查。 2.4.4. 启动Client节点node4: 1234567891011121314madison@ubuntu:~$ docker run -d --name=node4 --restart=always \\ -e 'CONSUL_LOCAL_CONFIG=&#123;\"leave_on_terminate\": true&#125;' \\ -p 11300:8300 \\ -p 11301:8301 \\ -p 11301:8301/udp \\ -p 11302:8302/udp \\ -p 11302:8302 \\ -p 11400:8400 \\ -p 11500:8500 \\ -p 11600:8600 \\ -h node4 \\ consul agent -bind=172.17.0.5 -retry-join=192.168.127.128 \\ -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \\ -node=node4 -client 0.0.0.0 -ui 查看node4节点的进程启动日志: 可以发现：node4是以Client模式启动运行的。启动后完成后，把dc1数据中心中的以Server模式启动的节点node1、node2和node3都添加到本地缓存列表中。当客户端向node4发起服务发现的请求后，node4会通过RPC将请求转发给Server节点中的其中一台做处理。 2.4.5. 查看集群状态1madison@ubuntu:~$ docker exec -t node1 consul members dc1数据中心中的4个节点node1, node2, node3和node4分别成功启动，Status表示他们的状态，都为alive。node1, node2, node3以Server模式启动，而node4以Client模式启动。 2.5. Docker安装Registrator2.5.1. 拉取Registrator的镜像1madison@ubuntu:~$ docker pull gliderlabs/registrator:latest 2.5.2. 启动Registrator节点1234madison@ubuntu:~$ docker run -d --name=registrator \\ -v /var/run/docker.sock:/tmp/docker.sock \\ --net=host \\ gliderlabs/registrator -ip=\"192.168.127.128\" consul://192.168.127.128:8500 –net指定为host表明使用主机模式。 -ip用于指定宿主机的IP地址，用于健康检查的通信地址。 consul://192.168.127.128:8500: 使用Consul作为服务注册表，指定具体的Consul通信地址进行服务注册和注销（注意：8500是Consul对外暴露的HTTP通信端口）。 查看Registrator的容器进程启动日志： Registrator在启动过程完成了以下几步操作： 查看Consul数据中心的leader节点，作为服务注册表； 同步当前宿主机的启用容器，以及所有的服务端口； 分别将各个容器发布的服务地址/端口注册到Consul的服务注册列表。 2.5.3. 查看Consul的注册状态Consul提供了一个Web UI来可视化服务注册列表、通信节点、数据中心和键/值存储等，直接访问宿主机的8500端口。 服务注册列表： NODES节点下挂载着dc1数据中心中的所有的Consul节点，包括Consul Server和Client。 通信节点列表： 启动Registrator以后，宿主机中的所有容器把服务都注册到Consul的SERVICES上，测试完成！ 总结单数据中心的Consul集群的搭建就完成了！！！后续章节我会介绍如何使用Registrator进行服务注册的标签化。然后通过docker部署多实例的Web容器来实现基于HTTP的RESTful Service和基于TCP的RPC Service的服务注册和健康检查定义，并演示如何以标签标识一个服务的多个实例。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"微服务系列","slug":"微服务系列","permalink":"https://ostenant.coding.me/categories/微服务系列/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://ostenant.coding.me/tags/Docker/"},{"name":"Consul","slug":"Consul","permalink":"https://ostenant.coding.me/tags/Consul/"},{"name":"Registrator","slug":"Registrator","permalink":"https://ostenant.coding.me/tags/Registrator/"}]},{"title":"Spring Cloud整合Thrift RPC(二) - 应用案例","slug":"Spring Cloud整合Thrift RPC(二) - 应用案例","date":"2018-01-24T02:21:00.000Z","updated":"2018-06-18T01:51:40.263Z","comments":true,"path":"2018/01/24/Spring Cloud整合Thrift RPC(二) - 应用案例/","link":"","permalink":"https://ostenant.coding.me/2018/01/24/Spring Cloud整合Thrift RPC(二) - 应用案例/","excerpt":"前言上一篇简单的阐述了 spring-cloud-thrift-starter 这个插件的配置和使用，并引入了一个calculator的项目。本文将基于一个银行存款、取款的业务场景，给出一套thrift在生产环境的应用案例。","text":"前言上一篇简单的阐述了 spring-cloud-thrift-starter 这个插件的配置和使用，并引入了一个calculator的项目。本文将基于一个银行存款、取款的业务场景，给出一套thrift在生产环境的应用案例。 首先设计如下几张简单的数据库表：银行(bank)、分支(branch)、银行卡(deposit_card)、客户(customer)、存款历史纪录(deposit_history)、取款历史纪录(withdraw_history)。 正文项目结构如下，依然是由三个模块组成： deposit deposit-client deposit-iface deposit-server Thrift IDL编写关于 thrift更复杂的用法可以参考Apache Thrift基础学习系列，根据数据库表的设计编写 deposit.thrift。 deposit.thrift定义了以下四个部分：命名空间 (namespace)、枚举类型 (enum)、结构类型 (struct)和服务类型 (service)。 (a). 命名空间 (namespace) 12// 指定编译生成的源代码的包路径名称namespace java com.icekredit.rpc.thrift.examples.thrift (b). 枚举类型 (enum) 123456789101112131415161718192021222324// 通过枚举定义银行分支所属区域enum ThriftRegion &#123; NORTH = 1, CENTRAL = 2, SOUTH = 3, EAST = 4, SOUTHWEST = 5, NORTHWEST = 6, NORTHEAST = 7&#125;// 存款完成状态enum ThriftDepositStatus &#123; FINISHED = 1, PROCCEDING = 2, FAILED = 3&#125;// 取款完成状态enum ThriftWithdrawStatus &#123; FINISHED = 1, PROCCEDING = 2, FAILED = 3&#125; (c). 结构类型 (struct) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// 银行struct ThriftBank &#123; 1: required i64 id, 2: required string code, 3: required string name, 4: optional string description, 5: optional map&lt;ThriftRegion, list&lt;ThriftBranch&gt;&gt; branches&#125;// 银行分支struct ThriftBranch &#123; 1: required i64 id, 2: required string code, 3: required string name, 4: required string address, 5: optional i32 staffs, 6: optional ThriftBank bank, 7: optional ThriftRegion region&#125;// 客户struct ThriftCustomer &#123; 1: required string IDNumber, 2: required string name, 3: required string birthday, 4: required i32 sex = 0, 5: required i32 age, 6: optional list&lt;string&gt; address, 7: optional set&lt;ThriftDepositCard&gt; depositCards&#125;// 银行卡struct ThriftDepositCard &#123; 1: required string id, 2: required bool isVip, 3: required string openingTime, 4: required double accountBalance, 5: optional double accountFlow, 6: optional ThriftBranch branch, 7: optional ThriftCustomer customer, 8: optional list&lt;ThriftDeposit&gt; depositHistory, 9: optional list&lt;ThriftWithdraw&gt; WithdrawHistory&#125;// 存款历史纪录struct ThriftDeposit &#123; 1: required string serialNumber, 2: required double transactionAmount, 3: required string submittedTime, 4: optional string finishedTime, 5: optional ThriftDepositStatus status, 6: optional ThriftDepositCard depositCard&#125;// 取款历史纪录struct ThriftWithdraw &#123; 1: required string serialNumber, 2: required double transactionAmount, 3: required string submittedTime, 4: optional string finishedTime, 5: optional ThriftWithdrawStatus status, 6: optional ThriftDepositCard depositCard&#125; (d). 服务类型 (service) 12345678910111213141516171819202122232425262728293031323334// 银行 - 业务服务定义service ThriftBankService &#123; void registerNewBank(ThriftBank bank); list&lt;ThriftBank&gt; queryAllBanks(); ThriftBank getBankById(i64 bankId); map&lt;ThriftRegion, list&lt;ThriftBranch&gt;&gt; queryAllBranchesByRegion(i64 bankId);&#125;// 银行分支 - 业务服务定义service ThriftBranchService &#123; void addNewBranch(i64 bankId, ThriftBranch branch); list&lt;ThriftBranch&gt; queryAllBranches(i64 bankId); ThriftBranch getBranchById(i64 branchId);&#125;// 客户 - 业务服务定义service ThriftCustomerService &#123; ThriftCustomer getCustomerById(string customerId); list&lt;ThriftCustomer&gt; queryAllCustomers(); void addNewUser(ThriftCustomer customer); void modifyUserById(string customerId, ThriftCustomer customer); i32 getTotalDepositCard(string customerId);&#125;// 银行卡 - 业务服务定义service ThriftDepositCardService &#123; set&lt;ThriftDepositCard&gt; queryAllDepositCards(string customerId); void addNewDepositCard(string customerId, ThriftDepositCard depositCard); ThriftDepositStatus depositMoney(string depositCardId, double money); ThriftWithdrawStatus withdrawMoney(string depositCardId, double money); list&lt;ThriftDeposit&gt; queryDepositHistorys(string depositCardId); list&lt;ThriftWithdraw&gt; queryWithdrawHistorys(string depositCardId);&#125; 进入src/main/thrift目录，编译生成所需的枚举类、结构类和业务服务类的源文件。 1thrift -gen java ./deposit.thrift 所有生成的源文件都位于同一个命名空间(包)下面：com.icekredit.rpc.thrift.examples.thrift 中间契约(deposit-iface)将上述源文件拷贝到 deposit-iface 模块中。 通过Mybatis逆向工程插件生成SQLMapper的XML和接口文件以及实体类。 友情提示：Mybatis逆向工程生成的实体类 (entity)，需要和Thrift编译生成器生成的结构类 (struct) 区分开来。而Thrift生成器生成的所有源文件，都一定程度封装了底层的通信方式和相关协议，开发人员是不应该动手脚的。 为了在Thrift中通过Mybatis完成数据持久化，必须在实体类 (entity)包装一层与结构类 (struct)相互转换的方法。在每个实体类中，根据业务添加以下两个方法，以DepositCard为例： toThrift()：将实体类对象转换为结构类对象。 1234567891011121314151617public ThriftDepositCard toThrift() &#123; ThriftDepositCard thriftDepositCard = new ThriftDepositCard(); thriftDepositCard.setId(this.getId()); thriftDepositCard.setAccountBalance(this.getAccountBalance()); thriftDepositCard.setAccountFlow(this.getAccountFlow()); thriftDepositCard.setIsVip(this.getIsVip()); thriftDepositCard.setOpeningTime(this.getOpeningTime()); ThriftBranch thriftBranch = new ThriftBranch(); thriftBranch.setId(this.getBranchId()); thriftDepositCard.setBranch(thriftBranch); ThriftCustomer thriftCustomer = new ThriftCustomer(); thriftCustomer.setIDNumber(this.getCustomerId()); thriftDepositCard.setCustomer(thriftCustomer); return thriftDepositCard;&#125; fromThrift()：静态方法，将结构类对象转换为实体类对象。 12345678910111213141516171819202122public static DepositCard fromThrift(ThriftDepositCard thriftDepositCard) &#123; DepositCard depositCard = new DepositCard(); depositCard.setId(thriftDepositCard.getId()); depositCard.setAccountBalance(thriftDepositCard.getAccountBalance()); depositCard.setAccountFlow(thriftDepositCard.getAccountFlow()); depositCard.setIsVip(thriftDepositCard.isIsVip()); ThriftCustomer thriftCustomer = thriftDepositCard.getCustomer(); if (thriftCustomer != null) &#123; String customerIDNumber = thriftCustomer.getIDNumber(); depositCard.setCustomerId(customerIDNumber); &#125; ThriftBranch thriftBranch = thriftDepositCard.getBranch(); if (thriftBranch != null) &#123; Long branchId = thriftBranch.getId(); depositCard.setBranchId(branchId); &#125; depositCard.setOpeningTime(thriftDepositCard.getOpeningTime()); return depositCard;&#125; 服务端(deposit-server)在服务端模块引入： spring-cloud-starter-thrift-server：thrift服务端的 starter程序。 calculator-iface：中间契约模块，这里作为服务端骨架(Skeleton)程序。 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;parent&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;deposit&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;deposit-server&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;dependencies&gt; &lt;!-- Thrift相关依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-thrift-server&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;deposit-iface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 数据库相关依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Swagger依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在application.yml中配置thrift服务端的运行参数、数据源连接池参数和Mybatis相关属性： application.yml 123456789101112131415161718192021222324252627282930313233343536373839404142server: port: 8080endpoints: actuator: sensitive: false enabled: truemanagement: security: enabled: falsespring: datasource: druid: url: jdbc:mysql://localhost:3306/deposit?useUnicode=true&amp;characterEncoding=utf-8 driver-class-name: com.mysql.jdbc.Driver username: root password: root thrift: server: service-id: deposit-server-rpc service-model: hsHa port: 25000 worker-queue-capacity: 1000 hs-ha: min-worker-threads: 5 max-worker-threads: 20 keep-alived-time: 3mybatis: mapper-locations: classpath:mapper/*.xml type-aliases-package: com.icekredit.rpc.thrift.examples.http.entitieslogging: level: root: INFO com: icekredit: rpc: thrift: examples: mapper: DEBUG 服务端程序启动入口类，设置 Swagger API所在的包路径名称。 Application.java 12345678910111213141516171819202122232425@SpringBootApplication@EnableSwagger2public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Bean public Docket createRestfulApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(\"com.icekredit.rpc.thrift.examples.service.http.controller\")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(\"Deposit Server\") .description(\"Deposit Server\") .version(\"1.0\") .build(); &#125;&#125; 编写服务端的Thrift的实现，以ThriftDepositCardService为例，由实现类ThriftDepositCardServiceImpl实现ThriftDepositCardService.Iface接口的方法： ThriftDepositCardServiceImpl.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106@ThriftService(name = \"thriftDepositCardService\")public class ThriftDepositCardServiceImpl implements ThriftDepositCardService.Iface &#123; private final BranchMapper branchMapper; private final DepositCardMapper depositCardMapper; private final CustomerMapper customerMapper; private final DepositHistoryMapper depositHistoryMapper; private final WithdrawHistoryMapper withdrawHistoryMapper; @Autowired public ThriftDepositCardServiceImpl(BranchMapper branchMapper, DepositCardMapper depositCardMapper, CustomerMapper customerMapper, DepositHistoryMapper depositHistoryMapper, WithdrawHistoryMapper withdrawHistoryMapper) &#123; this.branchMapper = branchMapper; this.depositCardMapper = depositCardMapper; this.customerMapper = customerMapper; this.depositHistoryMapper = depositHistoryMapper; this.withdrawHistoryMapper = withdrawHistoryMapper; &#125; @Override public Set&lt;ThriftDepositCard&gt; queryAllDepositCards(String customerId) throws TException &#123; List&lt;DepositCard&gt; depositCardList = depositCardMapper.queryAllDepositCards(customerId); // 查询客户持有的银行卡 return depositCardList.stream().map(depositCard -&gt; &#123; ThriftDepositCard thriftDepositCard = depositCard.toThrift(); Long branchId = depositCard.getBranchId(); if (Objects.nonNull(branchId) &amp;&amp; branchId &gt; 0L) &#123; Branch branch = branchMapper.findById(branchId); ThriftBranch thriftBranch = branch.toThrift(); ThriftBank thriftBank = new ThriftBank(); thriftBank.setId(branch.getBankId()); thriftBranch.setBank(thriftBank); thriftDepositCard.setBranch(thriftBranch); &#125; Customer customer = customerMapper.findById(customerId); ThriftCustomer thriftCustomer = customer.toThrift(); thriftDepositCard.setCustomer(thriftCustomer); return thriftDepositCard; &#125;).collect(Collectors.toSet()); &#125; @Override @Transactional public void addNewDepositCard(String customerId, ThriftDepositCard depositCard) throws TException &#123; DepositCard newDepositCard = DepositCard.fromThrift(depositCard); // 新增银行卡信息 depositCardMapper.save(newDepositCard); &#125; @Override @Transactional public ThriftDepositStatus depositMoney(String depositCardId, double money) throws TException &#123; SimpleDateFormat sf = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss\"); try &#123; DepositHistory depositHistory = new DepositHistory(); depositHistory.setSubmittedTime(sf.format(new Date())); depositCardMapper.incrementMoney(depositCardId, money); depositHistory.setFinishedTime(sf.format(new Date())); depositHistory.setSerialNumber(UUID.randomUUID().toString().replace(\"-\", \"\")); depositHistory.setTransactionAmount(money); depositHistory.setDepositCardId(depositCardId); depositHistory.setStatus(1); // 新增存款历史记录 depositHistoryMapper.save(depositHistory); return ThriftDepositStatus.FINISHED; &#125; catch (Exception e) &#123; e.printStackTrace(); return ThriftDepositStatus.FAILED; &#125; &#125; @Override @Transactional public ThriftWithdrawStatus withdrawMoney(String depositCardId, double money) throws TException &#123; SimpleDateFormat sf = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss\"); try &#123; WithdrawHistory withdrawHistory = new WithdrawHistory(); withdrawHistory.setSubmittedTime(sf.format(new Date())); depositCardMapper.decrementMoney(depositCardId, money); withdrawHistory.setFinishedTime(sf.format(new Date())); withdrawHistory.setSerialNumber(UUID.randomUUID().toString().replace(\"-\", \"\")); withdrawHistory.setTransactionAmount(money); withdrawHistory.setDepositCardId(depositCardId); withdrawHistory.setStatus(1); // 新增取款历史记录 withdrawHistoryMapper.save(withdrawHistory); return ThriftWithdrawStatus.FINISHED; &#125; catch (Exception e) &#123; e.printStackTrace(); return ThriftWithdrawStatus.FAILED; &#125; &#125; @Override public List&lt;ThriftDeposit&gt; queryDepositHistorys(String depositCardId) throws TException &#123; List&lt;DepositHistory&gt; depositHistory = depositHistoryMapper.queryDepositHistoryList(depositCardId); // 查询存款历史纪录 return depositHistory.stream().map(DepositHistory::toThrift).collect(Collectors.toList()); &#125; @Override public List&lt;ThriftWithdraw&gt; queryWithdrawHistorys(String depositCardId) throws TException &#123; List&lt;WithdrawHistory&gt; withdrawHistory = withdrawHistoryMapper.queryWithdrawHistoryList(depositCardId); // 查询取款历史纪录 return withdrawHistory.stream().map(WithdrawHistory::toThrift).collect(Collectors.toList()); &#125;&#125; Mybatis持久层，还是以DepositCardMapper为例： DepositCardMapper.java 123456789@Repository@Mapperpublic interface DepositCardMapper &#123; int save(DepositCard record); List&lt;DepositCard&gt; queryAllDepositCards(@Param(\"customerId\") String customerId); void decrementMoney(@Param(\"depositCardId\") String depositCardId, @Param(\"money\") Double money); void incrementMoney(@Param(\"depositCardId\") String depositCardId, @Param(\"money\") Double money); Long countRowsByCustomerId(@Param(\"customerId\") String customerId);&#125; DepositCardMapper.xml 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;insert id=\"save\" parameterType=\"com.icekredit.rpc.thrift.examples.http.entities.DepositCard\"&gt; INSERT INTO deposit_card (id, is_vip, opening_time, account_balance, account_flow, branch_id, customer_id) VALUES (#&#123;id,jdbcType=VARCHAR&#125;, #&#123;isVip,jdbcType=BIT&#125;, #&#123;openingTime,jdbcType=VARCHAR&#125;, #&#123;accountBalance,jdbcType=DOUBLE&#125;, #&#123;accountFlow,jdbcType=DOUBLE&#125;, #&#123;branchId,jdbcType=BIGINT&#125;, #&#123;customerId,jdbcType=VARCHAR&#125;)&lt;/insert&gt;&lt;select id=\"queryAllDepositCards\" resultMap=\"BaseResultMap\" parameterType=\"java.lang.String\"&gt; SELECT &lt;include refid=\"Base_Column_List\"/&gt; FROM deposit_card WHERE customer_id = #&#123;customerId&#125;&lt;/select&gt;&lt;select id=\"countRowsByCustomerId\" resultType=\"java.lang.Long\" parameterType=\"java.lang.String\"&gt; SELECT COUNT(id) FROM deposit_card WHERE customer_id = #&#123;customerId&#125;&lt;/select&gt;&lt;update id=\"decrementMoney\"&gt; UPDATE deposit_card &lt;set&gt; &lt;if test=\"money != null\"&gt; account_balance = account_balance - #&#123;money&#125;, &lt;/if&gt; &lt;/set&gt; WHERE id = #&#123;depositCardId&#125;&lt;/update&gt;&lt;update id=\"incrementMoney\"&gt; UPDATE deposit_card &lt;set&gt; &lt;if test=\"money != null\"&gt; account_balance = account_balance + #&#123;money&#125;, &lt;/if&gt; &lt;/set&gt; WHERE id = #&#123;depositCardId&#125;&lt;/update&gt; 客户端(deposit-client)同样，在客户端模块引入： spring-cloud-starter-thrift-client：thrift客户端的 starter程序。 deposit-iface：中间契约模块，这里作为客户端桩(Stub)程序。 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;parent&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;deposit&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;deposit-client&lt;/artifactId&gt;&lt;dependencies&gt; &lt;!-- Thrift相关依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-thrift-client&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;deposit-iface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SpringBoot依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud Consul服务注册与发现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Spring Cloud声明式Restful客户端 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Swagger依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在application.yml中配置thrift的客户端的的运行参数和 Consul 的服务注册与发现的参数： application.yml 12345678910111213141516171819202122232425262728293031323334server: port: 8080endpoints: actuator: sensitive: false enabled: truemanagement: security: enabled: falsespring: cloud: consul: host: 192.168.91.128 port: 8500 discovery: register: false register-health-check: true health-check-interval: 30s retry: max-attempts: 3 max-interval: 2000 thrift: client: package-to-scan: com.icekredit.rpc.thrift.examples.thrift.client service-model: hsHa pool: retry-times: 3 pool-max-total-per-key: 200 pool-min-idle-per-key: 10 pool-max-idle-per-key: 40 pool-max-wait: 10000 connect-timeout: 5000 客户端程序启动入口类，设置 Swagger API所在的包路径名称，同时允许自身作为注册程序注册到注册中心。 123456789101112131415161718192021222324252627@SpringBootApplication@EnableFeignClients@EnableDiscoveryClient@EnableSwagger2public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Bean public Docket createRestfulApi() &#123; return new Docket(DocumentationType.SWAGGER_2) .apiInfo(apiInfo()) .select() .apis(RequestHandlerSelectors.basePackage(\"com.icekredit.rpc.thrift.examples\")) .paths(PathSelectors.any()) .build(); &#125; private ApiInfo apiInfo() &#123; return new ApiInfoBuilder() .title(\"Deposit Client\") .description(\"Deposit Client\") .version(\"1.0\") .build(); &#125;&#125; 在客户端使用@ThriftClient注解标识服务端的thrift服务代理接口，代理服务ID为deposit-server-rpc，代理的目标类是ThriftDepositCardService。 DepositCardThriftClient.java 123@ThriftClient(serviceId = \"deposit-server-rpc\", refer = ThriftDepositCardService.class)public interface DepositCardThriftClient extends ThriftClientAware&lt;ThriftDepositCardService.Client&gt; &#123;&#125; BankThriftClient.java 123@ThriftClient(serviceId = \"deposit-server-rpc\", refer = ThriftBankService.class)public interface BankThriftClient extends ThriftClientAware&lt;ThriftBankService.Client&gt; &#123;&#125; 在客户端控制器中通过ThriftReferer注入需要使用的服务代理接口，通过 thriftClient.client()即可获取Thrift客户端桩对象，然后实现远程服务的调用。 DepositCardRpcController.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@RestController@RequestMapping(\"/rpc/deposit\")public class DepositCardRpcController &#123; @ThriftReferer private DepositCardThriftClient thriftClient; @GetMapping(\"/queryAllDepositCards\") public List&lt;DepositCard&gt; queryAllDepositCards(@RequestParam(\"customerId\") String customerId) throws Exception &#123; return thriftClient.client().queryAllDepositCards(customerId) .stream().map(DepositCard::fromThrift) .collect(Collectors.toList()); &#125; @PostMapping(\"/addNewDepositCard\") public void addNewDepositCard(DepositCard depositCard) throws Exception &#123; thriftClient.client().addNewDepositCard(depositCard.getCustomerId(), depositCard.toThrift()); &#125; @GetMapping(\"/depositMoney\") public ThriftDepositStatus depositMoney(@RequestParam(\"depositCardId\") String depositCardId, @RequestParam(\"money\") double money) throws Exception &#123; return thriftClient.client().depositMoney(depositCardId, money); &#125; @GetMapping(\"/withdrawMoney\") public ThriftWithdrawStatus withdrawMoney(@RequestParam(\"depositCardId\") String depositCardId, @RequestParam(\"money\") double money) throws Exception &#123; return thriftClient.client().withdrawMoney(depositCardId, money); &#125; @GetMapping(\"/queryDepositHistory\") public List&lt;DepositHistory&gt; queryDepositHistory(@RequestParam(\"depositCardId\") String depositCardId) throws Exception &#123; return thriftClient.client().queryDepositHistorys(depositCardId) .stream().map(DepositHistory::fromThrift) .collect(Collectors.toList()); &#125; @GetMapping(\"/queryWithdrawHistory\") public List&lt;WithdrawHistory&gt; queryWithdrawHistory(@RequestParam(\"depositCardId\") String depositCardId) throws Exception &#123; return thriftClient.client().queryWithdrawHistorys(depositCardId) .stream().map(WithdrawHistory::fromThrift) .collect(Collectors.toList()); &#125;&#125; BankRpcController.java 123456789101112131415161718192021222324252627282930313233@RestController@RequestMapping(\"/rpc/bank\")public class BankRpcController &#123; @ThriftReferer private BankThriftClient thriftClient; @PostMapping(\"/addNewBank\") public void addNewBank(Bank bank) throws Exception &#123; thriftClient.client().registerNewBank(bank.toThrift()); &#125; @GetMapping(\"/getBankById\") public Bank getBankById(@RequestParam(\"bankId\") Long bankId) throws Exception &#123; return Bank.fromThrift(thriftClient.client().getBankById(bankId)); &#125; @GetMapping(\"/queryAllBranchesByRegion\") public Map&lt;Region, List&lt;Branch&gt;&gt; queryAllBranchesByRegion(@RequestParam(\"bankId\") Long bankId) throws Exception &#123; Map&lt;ThriftRegion, List&lt;ThriftBranch&gt;&gt; thriftRegionListMap = thriftClient.client() .queryAllBranchesByRegion(bankId); Map&lt;Region, List&lt;Branch&gt;&gt; regionListMap = new HashMap&lt;&gt;(); for (Map.Entry&lt;ThriftRegion, List&lt;ThriftBranch&gt;&gt; entry : thriftRegionListMap.entrySet()) &#123; ThriftRegion thriftRegion = entry.getKey(); Region region = Region.findByValue(thriftRegion.getValue()); List&lt;ThriftBranch&gt; thriftBranches = entry.getValue(); List&lt;Branch&gt; branchList = thriftBranches.stream().map(Branch::fromThrift).collect(Collectors.toList()); regionListMap.put(region, branchList); &#125; return regionListMap; &#125;&#125; 因为服务代理客户端接口使用@ThriftClient标识，通过(服务ID + 客户端桩 + 版本号)唯一标识, 即使同时注入多个服务代理客户端接口，@ThriftReferer也可忽略注解属性的配置。 总结有一点是肯定的，那就是在已有技术框架(比如说：Spring + Mybatis/JPA)内，为了提高服务的性能和吞吐量，而引入诸如Thrift的RPC框架，编程难度和复杂度是会大大提高的。好比一把双刃剑，技术选型时还需要多方面权衡利弊。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"Thrift","slug":"Thrift","permalink":"https://ostenant.coding.me/tags/Thrift/"},{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://ostenant.coding.me/tags/Spring-Cloud/"}]},{"title":"Spring Cloud整合Thrift RPC(一) - 使用指南","slug":"Spring Cloud整合Thrift RPC(一) - 使用指南","date":"2018-01-18T07:07:00.000Z","updated":"2018-06-18T01:51:04.005Z","comments":true,"path":"2018/01/18/Spring Cloud整合Thrift RPC(一) - 使用指南/","link":"","permalink":"https://ostenant.coding.me/2018/01/18/Spring Cloud整合Thrift RPC(一) - 使用指南/","excerpt":"前言前面几篇博客，着重对Apache Thrift的使用和原理做了介绍。在微服架构流行的今天，自然而然就会想到Spring Boot和Spring Cloud作为微服务的基础框架。然而，Spring Cloud从诞生以来，就基于HTTP协议的轻量级Restful API作为服务之间的通信方式。","text":"前言前面几篇博客，着重对Apache Thrift的使用和原理做了介绍。在微服架构流行的今天，自然而然就会想到Spring Boot和Spring Cloud作为微服务的基础框架。然而，Spring Cloud从诞生以来，就基于HTTP协议的轻量级Restful API作为服务之间的通信方式。 在微服务架构设计中，可以分为外部服务和内部服务。两者主要区别是： 外部服务：基于Restful风格的HTTP协议，通过外网向外部提供服务，相对来说简单并且通用。 内部服务：基于RPC消息通信的TCP/IP协议，提供内网服务与服务之间的调用，以达到减少带宽、降低延迟率、提高性能。 一些应用场景，尤其是内部服务需要高频地调用，就需要考虑是否需要改造为RPC实现，来提高吞吐量和系统性能，比如说鉴权服务一类。 正文简述下载 spring-cloud-starter-thrift并导入IDEA开发环境，项目地址：https://github.com/ostenant/spring-cloud-starter-thrift spring-cloud-starter-thrift 提供 Spring Cloud 对可伸缩的跨语言服务调用框架Apache Thrift的封装和集成。 spring-cloud-starter-thrift包括客户端spring-cloud-starter-thrift-client和服务端spring-cloud-starter-thrift-server两个模块。而spring-cloud-starter-thrift-examples 子模块提供了3个示例项目：calculator、deposit和test。 calculator：简单上手项目示例。 deposit：复杂业务场景项目示例。 test：性能测试项目示例。 服务端 支持 Apache Thrift的各种原生线程服务模型，包括单线程阻塞模型(simple)、单线程非阻塞模型(nonBlocking)、线程池阻塞模型(threadPool)、半同步半异步模型(hsHa)和线程选择器模型(threadedSelector)。 支持 Apache Thrift 0.10.0版本后提供的多路复用处理器，提供服务的统一注册管理功能。 支持由服务签名 (服务ID + 客户端Stub接口名称 + 服务版本号) 唯一标识服务Stub的具体实现类，支持服务版本的平滑升级。 支持Server Group形式的启动方式，每个服务实例可以开启多台Thrift Server，通过不同的端口号暴露给客户端。 客户端 支持由服务签名 (服务ID + 客户端Stub接口名称 + 服务版本号) 唯一标识和调用服务端的Stub具体实现类。 支持Apache Thrift的Transport层的连接池管理，减少了客户端与服务端之间连接的频繁创建和销毁。 支持与Spring Cloud Consul的无缝集成，客户端通过心跳检测与服务注册中心Consul保持连接，动态定时的刷新服务列表、监测服务的启用、关闭和健康状态。 支持客户端负载均衡，包括随机、轮询的负载均衡策略，客户端的Thrift程序通过本地的服务缓存列表实现调用的动态转发。 快速上手项目结构： calculator calculator-client calculator-iface calculator-server spring-cloud-starter-thrift 使用的是 0.10.0版本的 thrift。以calculator项目入手，首先，通过 Thrift IDL (接口描述语言) 编写客户端桩Stub和服务端骨架Skeleton，通过.thrift文件定义接口规范。 首先进入 spring-cloud-starter-thrift 根目录，pom.xml 定义如下： pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.8.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;modules&gt; &lt;module&gt;calculator-client&lt;/module&gt; &lt;module&gt;calculator-server&lt;/module&gt; &lt;module&gt;calculator-iface&lt;/module&gt;&lt;/modules&gt;&lt;artifactId&gt;calculator&lt;/artifactId&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Dalston.SR4&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 将项目打包并安装到本地Maven仓库： 1mvn clean install Thrift IDL编写1234567namespace java com.icekredit.rpc.thrift.exampleservice CalculatorService &#123; i32 add(1: i32 arg1, 2: i32 arg2) i32 subtract(1: i32 arg1, 2: i32 arg2) i32 multiply(1: i32 arg1, 2: i32 arg2) i32 division(1: i32 arg1, 2: i32 arg2)&#125; 下载并安装0.10.0的 Thrift IDL编译生成器，下载地址：http://thrift.apache.org/docs/install。通过编译器生成.java的Stub类文件。 1thrift -gen java ./CalculatorService.thrift 编译器生成的CalculatorService.java文件。CalculatorService.java有成千上万行代码。对于开发人员而言，只需要关注以下四个核心接口/类：Iface、AsyncIface、Client和AsyncClient。 Iface：服务端通过实现 HelloWorldService.Iface 接口，向客户端的提供具体的同步业务逻辑。 AsyncIface：服务端通过实现 HelloWorldService.Iface 接口，向客户端的提供具体的异步业务逻辑。 Client：客户端通过 HelloWorldService.Client 的实例对象，以同步的方式访问服务端提供的服务方法。 AsyncClient：客户端通过 HelloWorldService.AsyncClient 的实例对象，以异步的方式访问服务端提供的服务方法。 中间契约(calculator-iface)在中间契约模块引入thrift的maven依赖，拷贝上一步thrift编译生成器生成的 CalculatorService源文件到此模块。 pom.xml 123456789101112131415&lt;parent&gt; &lt;artifactId&gt;calculator&lt;/artifactId&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;calculator-iface&lt;/artifactId&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt; &lt;artifactId&gt;libthrift&lt;/artifactId&gt; &lt;version&gt;0.10.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 服务端(calculator-server)在服务端模块引入： spring-cloud-starter-thrift-server：thrift服务端的 starter程序。 calculator-iface：中间契约模块，这里作为服务端骨架(Skeleton)程序。 pom.xml 1234567891011121314151617181920212223242526272829303132333435363738&lt;parent&gt; &lt;artifactId&gt;calculator&lt;/artifactId&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;calculator-server&lt;/artifactId&gt;&lt;packaging&gt;jar&lt;/packaging&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-thrift-server&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;calculator-iface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在application.yml中配置thrift服务端的运行参数： application.yml 1234567891011121314151617181920212223242526## 服务端Restful服务所在的HTTP端口号server: port: 8080## 用于Consul健康检查endpoints: actuator: sensitive: false enabled: truemanagement: security: enabled: false## Spring Thrift服务端配置spring: thrift: server: service-id: thrift-rpc-calculator ## service-model: hsHa ## 半同步/半异步服务模型 port: 25000 ## 服务端RPC服务所在的TCP端口号 worker-queue-capacity: 1000 ## 半同步/半异步服务模型参数配置 hs-ha: min-worker-threads: 5 ## 最少工作线程数 max-worker-threads: 20 ## 最大工作线程数 keep-alived-time: 3 ## 空闲线程存活时间 实现Thrift IDL生成的骨架(Skeleton)类CalculatorService的内部接口Iface，编写具体的业务逻辑： 这里需要注意几点： 实现 CalculatorService.Iface接口。 实现类标记 @ThriftService注解，包含以下属性： name：通过name标识服务名称，缺省时默认为类名称首字母小写。 version：通过version标识服务版本，缺省值为1.0，也就是说同一个服务名称可以拥有多个版本实现。 RpcCalculatorService.java 123456789101112131415161718192021222324252627282930@ThriftService(name = \"rpcCalculatorService\", version = 2.0)public class RpcCalculatorService implements CalculatorService.Iface &#123; @Override public int add(int arg1, int arg2) &#123; BigDecimal arg1Decimal = new BigDecimal(arg1); BigDecimal arg2Decimal = new BigDecimal(arg2); return arg1Decimal.add(arg2Decimal).intValue(); &#125; @Override public int subtract(int arg1, int arg2) &#123; BigDecimal arg1Decimal = new BigDecimal(arg1); BigDecimal arg2Decimal = new BigDecimal(arg2); return arg1Decimal.subtract(arg2Decimal).intValue(); &#125; @Override public int multiply(int arg1, int arg2) &#123; BigDecimal arg1Decimal = new BigDecimal(arg1); BigDecimal arg2Decimal = new BigDecimal(arg2); return arg1Decimal.multiply(arg2Decimal).intValue(); &#125; @Override public int division(int arg1, int arg2) &#123; BigDecimal arg1Decimal = new BigDecimal(arg1); BigDecimal arg2Decimal = new BigDecimal(arg2); return arg1Decimal.divide(arg2Decimal).intValue(); &#125;&#125; 对服务端程序进行打包： 1mvn clean package -Dmaven.test.skip=true 编写 Dockerfile 文件： 123FROM openjdk:8-jdk-alpineADD target/spring-boot-thrift-server-0.0.1-SNAPSHOT.jar calculator-server.jarENTRYPOINT [\"java\", \"-jar\", \"calculator-server.jar\"] 将Dockerfile 和 target/spring-boot-thrift-server-0.0.1-SNAPSHOT.jar拷贝到服务器上，构建 Thrift Server 的服务镜像： 1docker build . -t icekredit/calculator-server 客户端(calculator-client)在客户端模块引入： spring-cloud-starter-thrift-client：thrift客户端的 starter程序。 calculator-iface：中间契约模块，这里作为客户端桩(Stub)程序。 pom.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;parent&gt; &lt;artifactId&gt;calculator&lt;/artifactId&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/parent&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;artifactId&gt;calculator-client&lt;/artifactId&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-thrift-client&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.icekredit.rpc.thrift.examples&lt;/groupId&gt; &lt;artifactId&gt;calculator-iface&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 在 application.yml中配置 thrift客户端的运行参数，需要与服务端配置保持一致： 1234567891011121314151617181920212223242526272829303132333435363738394041## 客户端Restful服务所在的HTTP端口号server: port: 8080## 用于Consul健康检查endpoints: actuator: sensitive: false enabled: truemanagement: security: enabled: false## Spring Thrift客户端配置(Thrift Client的自动配置取决于Spring Cloud Consul的正确配置)spring: application: name: thrift-calculator-client cloud: consul: host: 192.168.91.128 ## Consul的IP地址 port: 8500 ## Consul的HTTP端口号 discovery: register: false ## 不使用SpringCloud提供的基于服务的程序注册方式 register-health-check: false ## 不使用Spring Cloud进行健康检查 retry: max-attempts: 3 max-interval: 2000 ## Thrift Client配置 thrift: client: package-to-scan: com.icekredit.rpc.thrift.example.rpc ## 标记由有注解@ThriftClient接口的包路径 service-model: hsHa ##服务线程模型（这里必须与服务端保持一致, 默认都是hsHa） ## 客户端连接池配置 pool: retry-times: 3 ## 异常失败，连接超时后的重试次数 ## key由IP + Port组成，唯一标识一个服务实例 pool-max-total-per-key: 200 ## 客户端保持的最大连接数，包含不同的服务和服务实例 pool-min-idle-per-key: 10 ## 每个服务实例最小的空闲连接数 pool-max-idle-per-key: 40 ## 每个服务实例最大的空闲连接数 pool-max-wait: 30000 ## 空闲连接最大存活时间 connect-timeout: 2000 ## 连接超时时间 编写 Thrift Client的客户端代理接口，这里有两点注意事项： 接口需要继承于父接口 ThriftClientAware，且 ThriftClientAware 里的泛型参数填写为 Thrift IDL 生成的 Stub 类 CalculatorService 中的 Client 内部类。 接口需要标识 @ThriftClient 注解， @ThriftClient 包含如下属性： serviceId：此客户端代理接口绑定的 Thrift 服务端的服务注册ID (与服务端保持一致)。 refer：客户端桩 Stub的类型，例如这里是CalculatorService.class。 version：具体业务实现类的版本号(不填写默认为1.0)，需要与服务端保持一致。 CalculatorThriftClient.java 123@ThriftClient(serviceId = \"thrift-rpc-calculator\", refer = CalculatorService.class, version = 2.0)public interface CalculatorThriftClient extends ThriftClientAware&lt;CalculatorService.Client&gt; &#123;&#125; 使用注解 @ThriftReferer，在客户端的 Controller 中注入 CalculatorThriftClient。 使用时，通过 CalculatorThriftClient.thriftClient() 方法，即可调用Thrift Server的服务方法。 RpcCalculatorController.java 1234567891011121314151617181920212223242526@RestController@RequestMapping(\"/rpc\")public class RpcCalculatorController &#123; @ThriftReferer private CalculatorThriftClient calculators; @GetMapping(\"/add\") public int add(@RequestParam(\"arg1\") int arg1, @RequestParam(\"arg2\") int arg2) throws Exception &#123; return calculators.client().add(arg1, arg2); &#125; @GetMapping(\"/subtract\") public int subtract(@RequestParam(\"arg1\") int arg1, @RequestParam(\"arg2\") int arg2) throws Exception &#123; return calculators.client().subtract(arg1, arg2); &#125; @GetMapping(\"/multiply\") public int multiply(@RequestParam(\"arg1\") int arg1, @RequestParam(\"arg2\") int arg2) throws Exception &#123; return calculators.client().multiply(arg1, arg2); &#125; @GetMapping(\"/division\") public int division(@RequestParam(\"arg1\") int arg1, @RequestParam(\"arg2\") int arg2) throws Exception &#123; return calculators.client().division(arg1, arg2); &#125;&#125; 测试方便，在本地开发环境配置Consul的地址，运行客户端程序即可。对于容器环境测试，配置对客户端程序进行打包： 1mvn clean package -Dmaven.test.skip=true 编写 Dockerfile 文件： 123FROM openjdk:8-jdk-alpineADD target/spring-boot-thrift-client-0.0.1-SNAPSHOT.jar calculator-client.jarENTRYPOINT [\"java\", \"-jar\", \"calculator-client.jar\"] 将Dockerfile 和 target/spring-boot-thrift-client-0.0.1-SNAPSHOT.jar拷贝到服务器上，构建 Thrift Client 的服务镜像： 1docker build . -t icekredit/calculator-client 简单测试发布服务端程序为了方便测试，在一台主机上启动三个 Thrift Server 的 docker 容器，以不同的端口区分，分别指定对应的端口号和 Consul 注册信息： Thrift Server实例1(25001端口)： 1234567docker run -d -p 8081:8080 -p 25001:25000 --name calculator-server-01 \\ -e \"SERVICE_25000_NAME=thrift-rpc-calculator\" \\ -e \"SERVICE_25000_CHECK_TCP=/\" \\ -e \"SERVICE_25000_CHECK_INTERVAL=30s\" \\ -e \"SERVICE_25000_CHECK_TIMEOUT=3s\" \\ -e \"SERVICE_25000_TAGS=thrift-rpc-calculator-25001\" \\ icekredit/calculator-server Thrift Server实例2(25002端口)： 1234567docker run -d -p 8081:8080 -p 25002:25000 --name calculator-server-01 \\ -e \"SERVICE_25000_NAME=thrift-rpc-calculator\" \\ -e \"SERVICE_25000_CHECK_TCP=/\" \\ -e \"SERVICE_25000_CHECK_INTERVAL=30s\" \\ -e \"SERVICE_25000_CHECK_TIMEOUT=3s\" \\ -e \"SERVICE_25000_TAGS=thrift-rpc-calculator-25002\" \\ icekredit/calculator-server Thrift Server实例3(25003端口)： 1234567docker run -d -p 8081:8080 -p 25003:25000 --name calculator-server-01 \\ -e \"SERVICE_25000_NAME=thrift-rpc-calculator\" \\ -e \"SERVICE_25000_CHECK_TCP=/\" \\ -e \"SERVICE_25000_CHECK_INTERVAL=30s\" \\ -e \"SERVICE_25000_CHECK_TIMEOUT=3s\" \\ -e \"SERVICE_25000_TAGS=thrift-rpc-calculator-25003\" \\ icekredit/calculator-server 观察各个容器的启动日志，如果包含以下几行输出信息，则表明 Thrift Server 成功启动并正常提供 RPC 服务。 12342017-11-19 22:28:47.779 INFO 12960 --- [ main] c.i.r.t.s.context.ThriftServerContext : Build thrift server from HsHaServerContext2017-11-19 22:28:47.820 INFO 12960 --- [ main] c.i.r.t.s.p.TRegisterProcessorFactory : Processor bean org.ostenant.springboot.learning.examples.CalculatorService$Processor@445bce9a with signature [thrift-rpc-calculator$org.ostenant.springboot.learning.examples.CalculatorService$2.0] is instantiated2017-11-19 22:28:47.822 INFO 12960 --- [ main] c.i.r.t.s.p.TRegisterProcessorFactory : Single processor org.ostenant.springboot.learning.examples.CalculatorService$Processor@445bce9a register onto multiplexed processor with signature [thrift-rpc-calculator$org.ostenant.springboot.learning.examples.CalculatorService$2.0]2017-11-19 22:28:47.822 INFO 12960 --- [ main] c.i.r.t.s.p.TRegisterProcessorFactory : Multiplexed processor totally owns 1 service processors 启动 Consul 和Registrator 容器，Thrift Server 的三个服务实例成功注册到Consul服务列表： 有关 Consul和 Registrator的安装配置以及使用，请参考：Docker+Consul+Registrator(一) 搭建服务发现与注册集群！ 服务端程序成功运行，Thrift RPC服务正常发布！ 启动客户端程序在本地 8080 端口号启动 Thrift 客户端，正常启动后观察启动日志如下： 12345678910112017-11-20 11:00:20.025 INFO 4052 --- [ main] .r.t.c.ThriftClientBeanScannerConfigurer : Base package org.ostenant.springboot.learning.examples.rpc is to be scanned with com.icekredit.rpc.thrift.client.scanner.ThriftClientBeanScanner@374967202017-11-20 11:00:20.029 INFO 4052 --- [ main] c.i.r.t.c.s.ThriftClientBeanScanner : Packages scanned by thriftClientBeanDefinitionScanner is [org.ostenant.springboot.learning.examples.rpc]2017-11-20 11:00:20.029 INFO 4052 --- [ main] c.i.r.t.c.s.ThriftClientBeanScanner : Scanned and found thrift client, bean calculatorThriftClient assigned from org.ostenant.springboot.learning.examples.rpc.CalculatorThriftClient2017-11-20 11:00:20.050 INFO 4052 --- [ main] f.a.AutowiredAnnotationBeanPostProcessor : JSR-330 'javax.inject.Inject' annotation found and supported for autowiring2017-11-20 11:00:20.134 INFO 4052 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.ostenant.springboot.learning.examples.rest.CalculatorFeignClient' of type [org.springframework.cloud.netflix.feign.FeignClientFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-11-20 11:00:20.136 WARN 4052 --- [ main] c.i.r.t.c.s.ThriftClientFactoryBean : Bean class is not found2017-11-20 11:00:20.142 INFO 4052 --- [ main] c.i.r.t.c.s.ThriftClientFactoryBean : Succeed to instantiate an instance of ThriftClientFactoryBean: com.icekredit.rpc.thrift.client.scanner.ThriftClientFactoryBean@7bac686b2017-11-20 11:00:20.142 INFO 4052 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'calculatorThriftClient' of type [com.icekredit.rpc.thrift.client.scanner.ThriftClientFactoryBean] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-11-20 11:00:20.411 INFO 4052 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.netflix.metrics.MetricsInterceptorConfiguration$MetricsRestTemplateConfiguration' of type [org.springframework.cloud.netflix.metrics.MetricsInterceptorConfiguration$MetricsRestTemplateConfiguration$$EnhancerBySpringCGLIB$$a9ef18dc] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-11-20 11:00:20.423 INFO 4052 --- [ main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$93dc7598] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)2017-11-20 11:00:21.592 INFO 4052 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http) 启动过程中，所有的标记有注解 @ThriftClient的接口都生成了代理对象，并通过注解 @ThriftReferer注入到 Controller中。 同时，客户端启动时开启了一个ServerUpdater，定时动态的去Consul服务注册列表抓取健康的服务节点信息，缓存到本地服务列表中。 1232017-11-20 11:02:26.726 INFO 4052 --- [erListUpdater-0] t.c.l.ThriftConsulServerListLoadBalancer : Refreshed thrift serverList: [thrift-rpc-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25001], host='192.168.91.128', port=25001, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25002], host='192.168.91.128', port=25002, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25003], host='192.168.91.128', port=25003, address='192.168.91.128', isHealth=true&#125;], consul-8301: [ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=8301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=9301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=10301, address='192.168.91.128', isHealth=true&#125;], consul-8302: [ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=8302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=9302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=10302, address='192.168.91.128', isHealth=true&#125;], thrift-rest-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8081], host='192.168.91.128', port=8081, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8082], host='192.168.91.128', port=8082, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8083], host='192.168.91.128', port=8083, address='192.168.91.128', isHealth=true&#125;]]2017-11-20 11:02:56.752 INFO 4052 --- [erListUpdater-0] t.c.l.ThriftConsulServerListLoadBalancer : Refreshed thrift serverList: [thrift-rpc-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25001], host='192.168.91.128', port=25001, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25002], host='192.168.91.128', port=25002, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25003], host='192.168.91.128', port=25003, address='192.168.91.128', isHealth=true&#125;], consul-8301: [ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=8301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=9301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=10301, address='192.168.91.128', isHealth=true&#125;], consul-8302: [ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=8302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=9302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=10302, address='192.168.91.128', isHealth=true&#125;], thrift-rest-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8081], host='192.168.91.128', port=8081, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8082], host='192.168.91.128', port=8082, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8083], host='192.168.91.128', port=8083, address='192.168.91.128', isHealth=true&#125;]]2017-11-20 11:03:26.764 INFO 4052 --- [erListUpdater-0] t.c.l.ThriftConsulServerListLoadBalancer : Refreshed thrift serverList: [thrift-rpc-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25001], host='192.168.91.128', port=25001, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25002], host='192.168.91.128', port=25002, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rpc-calculator', tags=[thrift-rpc-calculator-25003], host='192.168.91.128', port=25003, address='192.168.91.128', isHealth=true&#125;], consul-8301: [ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=8301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=9301, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8301', tags=[udp], host='192.168.91.128', port=10301, address='192.168.91.128', isHealth=true&#125;], consul-8302: [ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=8302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=9302, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='consul-8302', tags=[udp], host='192.168.91.128', port=10302, address='192.168.91.128', isHealth=true&#125;], thrift-rest-calculator: [ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8081], host='192.168.91.128', port=8081, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8082], host='192.168.91.128', port=8082, address='192.168.91.128', isHealth=true&#125;, ThriftServerNode&#123;node='node1', serviceId='thrift-rest-calculator', tags=[thrift-rest-calculator-8083], host='192.168.91.128', port=8083, address='192.168.91.128', isHealth=true&#125;]] 访问本地Thrift客户端： 访问地址 参数arg1 参数arg2 页面输出结果 /rpc/add 200 100 300 /rpc/subtract 200 100 100 /rpc/multiply 200 100 20000 /rpc/division 200 100 2 总结本文简单地介绍了如何利用 starter 将 Apache Thrift 整合进入 Spring Cloud 中，关于更复杂的应用场景和starter内部的设计、实现原理，后续会一步步的给出具体的介绍！ 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"Thrift","slug":"Thrift","permalink":"https://ostenant.coding.me/tags/Thrift/"},{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"},{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"https://ostenant.coding.me/tags/Spring-Cloud/"}]},{"title":"阿里云CentOS 7上安装配置Docker","slug":"阿里云CentOS 7上安装配置Docker","date":"2018-01-18T01:44:00.000Z","updated":"2018-06-27T03:06:34.045Z","comments":true,"path":"2018/01/18/阿里云CentOS 7上安装配置Docker/","link":"","permalink":"https://ostenant.coding.me/2018/01/18/阿里云CentOS 7上安装配置Docker/","excerpt":"前言Docker是一个开源工具，它可以让创建和管理Linux容器变得简单。容器就像是轻量级的虚拟机，并且可以以毫秒级的速度来启动或停止。Docker帮助系统管理员和程序员在容器中开发应用程序，并且可以扩展到成千上万的节点。","text":"前言Docker是一个开源工具，它可以让创建和管理Linux容器变得简单。容器就像是轻量级的虚拟机，并且可以以毫秒级的速度来启动或停止。Docker帮助系统管理员和程序员在容器中开发应用程序，并且可以扩展到成千上万的节点。 这是一只鲸鱼，它托着许多集装箱。我们可以把宿主机可当做这只鲸鱼，把相互隔离的容器可看成集装箱，每个集装箱中都包含自己的应用程序。 传送门Docker与传统虚拟区别 传统虚拟化技术的体系架构： Docker技术的体系架构： 容器和虚拟机(VM)的主要区别是： 容器提供了基于进程的隔离，而虚拟机提供了资源(CPU、内存和硬盘)的完全隔离。 虚拟机可能需要一分钟来启动，而容器只需要一秒钟或更短。 虚拟机占用的内存空间可达到几个G，而容器可能只需要几百兆。 容器使用宿主操作系统的内核，而虚拟机使用独立的内核。 Docker平台的基本构成 Docker平台基本上由三部分组成： 客户端：用户使用Docker提供的工具(CLI以及API等)来构建，上传镜像并发布命令来创建和启动容器。 Docker主机：从Docker registry上下载镜像并启动和托管容器。 Docker registry：Docker镜像仓库，用于保存镜像，并提供镜像上传和下载。 Docker容器的状态机 一个容器在某个时刻可能处于以下几种状态之一： created：已经被创建 (使用docker ps -a命令可以列出) 但是还没有被启动，使用docker ps命令还无法列出。running：容器在这正常运行中。paused：容器的进程被暂停了。restarting：容器的进程正在重启过程中。exited：上图中的stopped状态，表示容器之前运行过但是现在处于停止状态 (要区别于created状态，它是指一个新创建的尚未运行过的容器)。可以通过start命令使其重新进入running状态。destroyed：容器从宿主机删除了，再也不存在了。 Docker的安装RedHat/CentOS必须要6.6版本以上，或者7.x才能安装docker，建议在RedHat/CentOS 7上使用docker，因为RedHat/CentOS 7的内核升级到了kernel 3.10，对lxc容器支持更好。 查看Linux内核版本(内核版本必须是3.10或者以上)： 12345678cat /proc/versionuname -alsb_release -a##无法执行命令安装yum install -y redhat-lsb 更新yum安装源： 1yum install docker -y 检查docker版本： 1docker -v 安装完成后，使用下面的命令来启动docker服务，并将其设置为开机启动： 12service docker startchkconfig docker on 下载官方的CentOS的docker镜像： 1docker pull centos 检查CentOS镜像是否被成功拉取到本地宿主机： 12345678# 查看本地镜像列表docker images# 删除镜像docker rmi &lt;image id&gt;# 删除镜像(针对多个相同image id的镜像)docker rmi repository:tag 镜像下载完成后，你应该会看到： 123[root@iZ2ze74fkxrls31tr2ia2fZ ~]# docker images centosREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/centos latest 3fa822599e10 3weeks ago 203.5 MB 如果看到以上输出，说明你可以使用docker.io/centos这个镜像了，或将其称为仓库(Repository)，该镜像有一个名为latest的标签(Tag)，此外还有一个名为3fa822599e10的镜像ID (可能您所看到的镜像 ID 与此处的不一致，那是正常现象，因为这个数字是随机生成的)。此外，我们可以看到该镜像只有203.5MB，非常小巧，而不像虚拟机的镜像文件那样庞大。 重命名TAG为centos： 12# docker tag IMAGE_ID(镜像id) REPOSITORY:TAG(仓库：标签)docker tag 3fa822599e10 docker.io/centos:centos 启动CentOS的容器： 1docker run -i -t -v /root/software/:/mnt/software/ 3fa822599e10 /bin/bash 命令参数说明：docker run &lt;相关参数&gt; &lt;镜像ID&gt; &lt;初始命令&gt; -i：表示以交互模式运行容器 -t：表示容器启动后会进入其命令行 -v：表示需要将本地哪个目录挂载到容器中，格式：-v &lt;宿主机目录&gt;:&lt;容器目录&gt; 更多参数详解： 12345678910111213141516171819202122232425262728293031323334353637383940Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...] -d, --detach=false 指定容器运行于前台还是后台，默认为false -i, --interactive=false 打开STDIN，用于控制台交互 -t, --tty=false 分配tty设备，该可以支持终端登录，默认为false -u, --user=\"\" 指定容器的用户 -a, --attach=[] 登录容器（必须是以docker run -d启动的容器） -w, --workdir=\"\" 指定容器的工作目录 -c, --cpu-shares=0 设置容器CPU权重，在CPU共享场景使用 -e, --env=[] 指定环境变量，容器中可以使用该环境变量 -m, --memory=\"\" 指定容器的内存上限 -P, --publish-all=false 指定容器暴露的端口 -p, --publish=[] 指定容器暴露的端口 -h, --hostname=\"\" 指定容器的主机名 -v, --volume=[] 给容器挂载存储卷，挂载到容器的某个目录 --volumes-from=[] 给容器挂载其他容器上的卷，挂载到容器的某个目录 --cap-add=[] 添加权限，权限清单详见：http://linux.die.net/man/7/capabilities --cap-drop=[] 删除权限，权限清单详见：http://linux.die.net/man/7/capabilities --cidfile=\"\" 运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法 --cpuset=\"\" 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU --device=[] 添加主机设备给容器，相当于设备直通 --dns=[] 指定容器的dns服务器 --dns-search=[] 指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件 --entrypoint=\"\" 覆盖image的入口点 --env-file=[] 指定环境变量文件，文件格式为每行一个环境变量 --expose=[] 指定容器暴露的端口，即修改镜像的暴露端口 --link=[] 指定容器间的关联，使用其他容器的IP、env等信息 --lxc-conf=[] 指定容器的配置文件，只有在指定--exec-driver=lxc时使用 --name=\"\" 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字 --net=\"bridge\" 容器网络设置: bridge 使用docker daemon指定的网桥 host //容器使用主机的网络 container:NAME_or_ID &gt;//使用其他容器的网路，共享IP和PORT等网络资源 none 容器使用自己的网络（类似--net=bridge），但是不进行配置 --privileged=false 指定容器是否为特权容器，特权容器拥有所有的capabilities --restart=\"no\" 指定容器停止后的重启策略: no：容器退出时不重启 on-failure：容器故障退出（返回值非零）时重启 always：容器退出时总是重启 --rm=false 指定容器停止后自动删除容器(不支持以docker run -d启动的容器) --sig-proxy=true 设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理 Docker的常用命令我们可以把Docker的命令大概地分类如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960## 镜像操作： build Build an image from a Dockerfile commit Create a new image from a container's changes images List images load Load an image from a tar archive or STDIN pull Pull an image or a repository from a registry push Push an image or a repository to a registry rmi Remove one or more images search Search the Docker Hub for images tag Tag an image into a repository save Save one or more images to a tar archive history 显示某镜像的历史 inspect 获取镜像的详细信息## 容器及其中应用的生命周期操作： create 创建一个容器 kill Kill one or more running containers inspect Return low-level information on a container, image or task pause Pause all processes within one or more containers ps List containers rm 删除一个或者多个容器 rename Rename a container restart Restart a container run 创建并启动一个容器 start 启动一个处于停止状态的容器 stats 显示容器实时的资源消耗信息 stop 停止一个处于运行状态的容器 top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers wait Block until a container stops, then print its exit code attach Attach to a running container exec Run a command in a running container port List port mappings or a specific mapping for the container logs 获取容器的日志## 容器文件系统操作： cp Copy files/folders between a container and the local filesystem diff Inspect changes on a container's filesystem export Export a container's filesystem as a tar archive import Import the contents from a tarball to create a filesystem image Docker registry 操作： login Log in to a Docker registry. logout Log out from a Docker registry.## Volume操作： volume Manage Docker volumes## 网络操作： network Manage Docker networks## Swarm 相关操作： swarm Manage Docker Swarm service Manage Docker services node Manage Docker Swarm nodes## 系统操作： version Show the Docker version information events 持续返回docker 事件 info 显示Docker 主机系统范围内的信息 1234567891011121314151617181920212223242526# 查看运行中的容器docker ps# 查看所有容器docker ps -a# 退出容器按Ctrl+D 即可退出当前容器【但退出后会停止容器】# 退出不停止容器：组合键：Ctrl+P+Q# 启动容器docker start 容器名或ID# 进入容器docker attach 容器名或ID# 停止容器docker stop 容器名或ID# 暂停容器docker pause 容器名或ID#继续容器docker unpause 容器名或ID# 删除容器docker rm 容器名或ID# 删除全部容器--慎用docker stop $(docker ps -q) &amp; docker rm $(docker ps -aq)#保存容器，生成镜像docker commit 容器ID 镜像名称#从 host 拷贝文件到 container 里面docker cp /home/soft centos:/webapp docker run与start的区别docker run只在第一次运行时使用，将镜像放到容器中，以后再次启动这个容器时，只需要使用命令docker start 即可。 docker run相当于执行了两步操作：将镜像放入容器中(docker create)，然后将容器启动，使之变成运行时容器(docker start)。 而docker start的作用是，重新启动已存在的镜像。也就是说，如果使用这个命令，我们必须事先知道这个容器的ID，或者这个容器的名字，我们可以使用docker ps找到这个容器的信息。 因为容器的ID是随机码，而容器的名字又是看似无意义的命名，我们可以使用命令： 1docker rename jovial_cori centos 给这个容器命名。这样以后，我们再次启动或停止容器时，就可以直接使用这个名字： 1docker [stop] [start] new_name 而要显示出所有容器，包括没有启动的，可以使用命令： 1docker ps -a Docker的配置更改存储目录： 12345#复制docker存储目录rsync -aXS /var/lib/docker/. /home/docker#更改 docker 存储文件目录ln -s /home/docker /var/lib/docker 查看启动容器的具体信息： 1docker inspect &lt;container_id&gt; 要获取所有容器名称及其IP地址只需一个命令： 123docker inspect -f '&#123;&#123;.Name&#125;&#125; - &#123;&#123;.NetworkSettings.IPAddress &#125;&#125;' $(docker ps -aq)docker inspect --format='&#123;&#123;.Name&#125;&#125; - &#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;' $(docker ps -aq) Docker镜像加速器注册一个阿里云帐号： https://dev.aliyun.com/search.html 阿里云会自动为用户分配一个镜像加速器的地址，登录后进入”管理中心” —&gt; ”加速器”，里面有分配给你的镜像加速器的地址以及各个环境的使用说明。 镜像加速器地址示例：https://xxxxx.mirror.aliyuncs.com 如何配置镜像加速器针对Docker客户端版本大于1.10.0的用户，可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器**： 123&#123; \"registry-mirrors\": [\"&lt;your accelerate address&gt;\"]&#125; 重启Docker Daemon： 12sudo systemctl daemon-reloadsudo systemctl restart docker 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Docker学习系列","slug":"Docker学习系列","permalink":"https://ostenant.coding.me/categories/Docker学习系列/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://ostenant.coding.me/tags/Docker/"},{"name":"CentOS","slug":"CentOS","permalink":"https://ostenant.coding.me/tags/CentOS/"}]},{"title":"Apache Thrift系列详解(三) - 序列化机制","slug":"Apache Thrift系列详解(三) - 序列化机制","date":"2018-01-16T07:37:00.000Z","updated":"2018-06-18T01:46:26.767Z","comments":true,"path":"2018/01/16/Apache Thrift系列详解(三) - 序列化机制/","link":"","permalink":"https://ostenant.coding.me/2018/01/16/Apache Thrift系列详解(三) - 序列化机制/","excerpt":"前言Thrift支持二进制，压缩格式，以及json格式数据的序列化和反序列化。开发人员可以更加灵活的选择协议的具体形式。协议是可自由扩展的，新版本的协议，完全兼容老的版本！","text":"前言Thrift支持二进制，压缩格式，以及json格式数据的序列化和反序列化。开发人员可以更加灵活的选择协议的具体形式。协议是可自由扩展的，新版本的协议，完全兼容老的版本！ 正文数据交换格式简介当前流行的数据交换格式可以分为如下几类： (一) 自解析型序列化的数据包含完整的结构， 包含了field名称和value值。比如xml/json/java serizable，大百度的mcpack/compack，都属于此类。即调整不同属性的顺序对序列化/反序列化不造成影响。 (二) 半解析型序列化的数据，丢弃了部分信息， 比如field名称， 但引入了index(常常是id+type的方式)来对应具体属性和值。这方面的代表有google protobuf/thrift也属于此类。 (三) 无解析型传说中大百度的infpack实现，就是借助该种方式来实现，丢弃了很多有效信息，性能/压缩比最好，不过向后兼容需要开发做一定的工作， 详情不知。 交换格式 类型 优点 缺点 Xml 文本 易读 臃肿，不支持二进制数据类型 JSON 文本 易读 丢弃了类型信息，比如”score”:100，对score类型是int/double解析有二义性， 不支持二进制数据类型 Java serizable 二进制 使用简单 臃肿，只限制在JAVA领域 Thrift 二进制 高效 不易读，向后兼容有一定的约定限制 Google Protobuf 二进制 高效 不易读，向后兼容有一定的约定限制 Thrift的数据类型 基本类型： bool: 布尔值 byte: 8位有符号整数 i16: 16位有符号整数 i32: 32位有符号整数 i64: 64位有符号整数 double: 64位浮点数 string: UTF-8编码的字符串 binary: 二进制串 结构体类型： struct: 定义的结构体对象 容器类型： list: 有序元素列表 set: 无序无重复元素集合 map: 有序的key/value集合 异常类型： exception: 异常类型 服务类型： service: 具体对应服务的类 Thrift的序列化协议Thrift可以让用户选择客户端与服务端之间传输通信协议的类别，在传输协议上总体划分为文本(text)和二进制(binary)传输协议。为节约带宽，提高传输效率，一般情况下使用二进制类型的传输协议为多数，有时还会使用基于文本类型的协议，这需要根据项目/产品中的实际需求。常用协议有以下几种： TBinaryProtocol：二进制编码格式进行数据传输 TCompactProtocol：高效率的、密集的二进制编码格式进行数据传输 TJSONProtocol： 使用JSON文本的数据编码协议进行数据传输 TSimpleJSONProtocol：只提供JSON只写的协议，适用于通过脚本语言解析 Thrift的序列化测试(a). 首先编写一个简单的thrift文件pair.thrift： 1234struct Pair &#123; 1: required string key 2: required string value&#125; 这里标识了required的字段，要求在使用时必须正确赋值，否则运行时会抛出TProtocolException异常。缺省和指定为optional时，则运行时不做字段非空校验。 (b). 编译并生成java源代码： 1thrift -gen java pair.thrift (c). 编写序列化和反序列化的测试代码： 序列化测试，将Pair对象写入文件中 1234567private static void writeData() throws IOException， TException &#123; Pair pair = new Pair(); pair.setKey(\"key1\").setValue(\"value1\"); FileOutputStream fos = new FileOutputStream(new File(\"pair.txt\")); pair.write(new TBinaryProtocol(new TIOStreamTransport(fos))); fos.close();&#125; 反序列化测试，从文件中解析生成Pair对象 12345678private static void readData() throws TException， IOException &#123; Pair pair = new Pair(); FileInputStream fis = new FileInputStream(new File(\"pair.txt\")); pair.read(new TBinaryProtocol(new TIOStreamTransport(fis))); System.out.println(\"key =&gt; \" + pair.getKey()); System.out.println(\"value =&gt; \" + pair.getValue()); fis.close();&#125; (d) 观察运行结果，正常输出表明序列化和反序列化过程正常完成。 Thrift协议源码(一) writeData()分析首先查看thrift的序列化机制，即数据写入实现，这里采用二进制协议TBinaryProtocol，切入点为pair.write(TProtocol)： 查看scheme()方法，决定采用元组计划(TupleScheme)还是标准计划(StandardScheme)来实现序列化，默认采用的是标准计划StandardScheme。 标准计划(StandardScheme)下的write()方法： 这里完成了几步操作： (a). 根据Thrift IDL文件中定义了required的字段验证字段是否正确赋值。 123456789public void validate() throws org.apache.thrift.TException &#123; // check for required fields if (key == null) &#123; throw new org.apache.thrift.protocol.TProtocolException(\"Required field 'key' was not present! Struct: \" + toString()); &#125; if (value == null) &#123; throw new org.apache.thrift.protocol.TProtocolException(\"Required field 'value' was not present! Struct: \" + toString()); &#125;&#125; (b). 通过writeStructBegin()记录写入结构的开始标记。 1public void writeStructBegin(TStruct struct) &#123;&#125; (c). 逐一写入Pair对象的各个字段，包括字段字段开始标记、字段的值和字段结束标记。 123456if (struct.key != null) &#123; oprot.writeFieldBegin(KEY_FIELD_DESC); oprot.writeString(struct.key); oprot.writeFieldEnd();&#125;// 省略... (1). 首先是字段开始标记，包括type和field-id。type是字段的数据类型的标识号，field-id是Thrift IDL定义的字段次序，比如说key为1，value为2。 1234public void writeFieldBegin(TField field) throws TException &#123; writeByte(field.type); writeI16(field.id);&#125; Thrift提供了TType，对不同的数据类型(type)提供了唯一标识的typeID。 12345678910111213141516public final class TType &#123; public static final byte STOP = 0; // 数据读写完成 public static final byte VOID = 1; // 空值 public static final byte BOOL = 2; // 布尔值 public static final byte BYTE = 3; // 字节 public static final byte DOUBLE = 4; // 双精度浮点型 public static final byte I16 = 6; // 短整型 public static final byte I32 = 8; // 整型 public static final byte I64 = 10; // 长整型 public static final byte STRING = 11; // 字符串类型 public static final byte STRUCT = 12; // 引用类型 public static final byte MAP = 13; // Map public static final byte SET = 14; // 集合 public static final byte LIST = 15; // 列表 public static final byte ENUM = 16; // 枚举&#125; (2). 然后是写入字段的值，根据字段的数据类型又归纳为以下实现：writeByte()、writeBool()、writeI32()、writeI64()、writeDouble()、writeString()和writeBinary()方法。 TBinaryProtocol通过一个长度为8的byte字节数组缓存写入或读取的临时字节数据。 1private final byte[] inoutTemp = new byte[8]; 常识1：16进制的介绍。以0x开始的数据表示16进制，0xff换成十进制为255。在16进制中，A、B、C、D、E、F这五个字母来分别表示10、11、12、13、14、15。 16进制变十进制：f表示15。第n位的权值为16的n次方，由右到左从0位起：0xff = 1516^1 + 1516^0 = 25516进制变二进制再变十进制：0xff = 1111 1111 = 2^8 - 1 = 255 常识2：位运算符的使用。&gt;&gt;表示代表右移符号，如：int i=15; i&gt;&gt;2的结果是3，移出的部分将被抛弃。而&lt;&lt;表示左移符号，与&gt;&gt;刚好相反。 转为二进制的形式可能更好理解，0000 1111(15)右移2位的结果是0000 0011(3)，0001 1010(18)右移3位的结果是0000 0011(3)。 writeByte()：写入单个字节数据。 1234public void writeByte(byte b) throws TException &#123; inoutTemp[0] = b; trans_.write(inoutTemp， 0， 1);&#125; writeBool()：写入布尔值数据。 123public void writeBool(boolean b) throws TException &#123; writeByte(b ? (byte)1 : (byte)0);&#125; writeI16()：写入短整型short类型数据。 12345public void writeI16(short i16) throws TException &#123; inoutTemp[0] = (byte)(0xff &amp; (i16 &gt;&gt; 8)); inoutTemp[1] = (byte)(0xff &amp; (i16)); trans_.write(inoutTemp， 0， 2);&#125; writeI32()：写入整型int类型数据。 1234567public void writeI32(int i32) throws TException &#123; inoutTemp[0] = (byte)(0xff &amp; (i32 &gt;&gt; 24)); inoutTemp[1] = (byte)(0xff &amp; (i32 &gt;&gt; 16)); inoutTemp[2] = (byte)(0xff &amp; (i32 &gt;&gt; 8)); inoutTemp[3] = (byte)(0xff &amp; (i32)); trans_.write(inoutTemp， 0， 4);&#125; writeI64()：写入长整型long类型数据。 1234567891011public void writeI64(long i64) throws TException &#123; inoutTemp[0] = (byte)(0xff &amp; (i64 &gt;&gt; 56)); inoutTemp[1] = (byte)(0xff &amp; (i64 &gt;&gt; 48)); inoutTemp[2] = (byte)(0xff &amp; (i64 &gt;&gt; 40)); inoutTemp[3] = (byte)(0xff &amp; (i64 &gt;&gt; 32)); inoutTemp[4] = (byte)(0xff &amp; (i64 &gt;&gt; 24)); inoutTemp[5] = (byte)(0xff &amp; (i64 &gt;&gt; 16)); inoutTemp[6] = (byte)(0xff &amp; (i64 &gt;&gt; 8)); inoutTemp[7] = (byte)(0xff &amp; (i64)); trans_.write(inoutTemp， 0， 8);&#125; writeDouble()：写入双浮点型double类型数据。 123public void writeDouble(double dub) throws TException &#123; writeI64(Double.doubleToLongBits(dub));&#125; writeString()：写入字符串类型，这里先写入字符串长度，再写入字符串内容。 123456789public void writeString(String str) throws TException &#123; try &#123; byte[] dat = str.getBytes(\"UTF-8\"); writeI32(dat.length); trans_.write(dat， 0， dat.length); &#125; catch (UnsupportedEncodingException uex) &#123; throw new TException(\"JVM DOES NOT SUPPORT UTF-8\"); &#125;&#125; writeBinary：写入二进制数组类型数据，这里数据输入是NIO中的ByteBuffer类型。 12345public void writeBinary(ByteBuffer bin) throws TException &#123; int length = bin.limit() - bin.position(); writeI32(length); trans_.write(bin.array()， bin.position() + bin.arrayOffset()， length);&#125; (3). 每个字段写入完成后，都需要记录字段结束标记。 1public void writeFieldEnd() &#123;&#125; (d). 当所有的字段都写入以后，需要记录字段停止标记。 123public void writeFieldStop() throws TException &#123; writeByte(TType.STOP);&#125; (e). 当所有数据写入完成后，通过writeStructEnd()记录写入结构的完成标记。 1public void writeStructEnd() &#123;&#125; (二) readData()分析查看thrift的反序列化机制，即数据读取实现，同样采用二进制协议TBinaryProtocol，切入点为pair.read(TProtocol)： 数据读取和数据写入一样，也是采用的标准计划StandardScheme。标准计划(StandardScheme)下的read()方法： 这里完成的几步操作： (a). 通过readStructBegin读取结构的开始标记。 1iprot.readStructBegin(); (b). 循环读取结构中的所有字段数据到Pair对象中，直到读取到org.apache.thrift.protocol.TType.STOP为止。iprot.readFieldBegin()指明开始读取下一个字段的前需要读取字段开始标记。 1234567while (true) &#123; schemeField = iprot.readFieldBegin(); if (schemeField.type == org.apache.thrift.protocol.TType.STOP) &#123; break; &#125; // 字段的读取，省略...&#125; (c). 根据Thrift IDL定义的field-id读取对应的字段，并赋值到Pair对象中，并设置Pair对象相应的字段为已读状态(前提：字段在IDL中被定义为required)。 1234567891011121314151617181920switch (schemeField.id) &#123; case 1: // KEY if (schemeField.type == org.apache.thrift.protocol.TType.STRING) &#123; struct.key = iprot.readString(); struct.setKeyIsSet(true); &#125; else &#123; org.apache.thrift.protocol.TProtocolUtil.skip(iprot， schemeField.type); &#125; break; case 2: // VALUE if (schemeField.type == org.apache.thrift.protocol.TType.STRING) &#123; struct.value = iprot.readString(); struct.setValueIsSet(true); &#125; else &#123; org.apache.thrift.protocol.TProtocolUtil.skip(iprot， schemeField.type); &#125; break; default: org.apache.thrift.protocol.TProtocolUtil.skip(iprot， schemeField.type);&#125; 关于读取字段的值，根据字段的数据类型也分为以下实现：readByte()、readBool()、readI32()、readI64()、readDouble()、readString()和readBinary()方法。 readByte()：读取单个字节数据。 123456789public byte readByte() throws TException &#123; if (trans_.getBytesRemainingInBuffer() &gt;= 1) &#123; byte b = trans_.getBuffer()[trans_.getBufferPosition()]; trans_.consumeBuffer(1); return b; &#125; readAll(inoutTemp， 0， 1); return inoutTemp[0];&#125; readBool()：读取布尔值数据。 123public boolean readBool() throws TException &#123; return (readByte() == 1);&#125; readI16()：读取短整型short类型数据。 123456789101112131415public short readI16() throws TException &#123; byte[] buf = inoutTemp; int off = 0; if (trans_.getBytesRemainingInBuffer() &gt;= 2) &#123; buf = trans_.getBuffer(); off = trans_.getBufferPosition(); trans_.consumeBuffer(2); &#125; else &#123; readAll(inoutTemp， 0， 2); &#125; return (short) (((buf[off] &amp; 0xff) &lt;&lt; 8) | ((buf[off+1] &amp; 0xff)));&#125; readI32()：读取整型int类型数据。 12345678910111213141516public int readI32() throws TException &#123; byte[] buf = inoutTemp; int off = 0; if (trans_.getBytesRemainingInBuffer() &gt;= 4) &#123; buf = trans_.getBuffer(); off = trans_.getBufferPosition(); trans_.consumeBuffer(4); &#125; else &#123; readAll(inoutTemp， 0， 4); &#125; return ((buf[off] &amp; 0xff) &lt;&lt; 24) | ((buf[off+1] &amp; 0xff) &lt;&lt; 16) | ((buf[off+2] &amp; 0xff) &lt;&lt; 8) | ((buf[off+3] &amp; 0xff));&#125; readI64()：读取长整型long类型数据。 123456789101112131415161718192021public long readI64() throws TException &#123; byte[] buf = inoutTemp; int off = 0; if (trans_.getBytesRemainingInBuffer() &gt;= 8) &#123; buf = trans_.getBuffer(); off = trans_.getBufferPosition(); trans_.consumeBuffer(8); &#125; else &#123; readAll(inoutTemp， 0， 8); &#125; return ((long)(buf[off] &amp; 0xff) &lt;&lt; 56) | ((long)(buf[off+1] &amp; 0xff) &lt;&lt; 48) | ((long)(buf[off+2] &amp; 0xff) &lt;&lt; 40) | ((long)(buf[off+3] &amp; 0xff) &lt;&lt; 32) | ((long)(buf[off+4] &amp; 0xff) &lt;&lt; 24) | ((long)(buf[off+5] &amp; 0xff) &lt;&lt; 16) | ((long)(buf[off+6] &amp; 0xff) &lt;&lt; 8) | ((long)(buf[off+7] &amp; 0xff));&#125; readDouble()：读取双精度浮点double类型数据。 123public double readDouble() throws TException &#123; return Double.longBitsToDouble(readI64());&#125; readString()：读取字符串类型的数据，首先读取并校验4字节的字符串长度，然后检查NIO缓冲区中是否有对应长度的字节未消费。如果有，直接从缓冲区中读取；否则，从传输通道中读取数据。 12345678910111213141516public String readString() throws TException &#123; int size = readI32(); checkStringReadLength(size); if (trans_.getBytesRemainingInBuffer() &gt;= size) &#123; try &#123; String s = new String(trans_.getBuffer()， trans_.getBufferPosition()， size， \"UTF-8\"); trans_.consumeBuffer(size); return s; &#125; catch (UnsupportedEncodingException e) &#123; throw new TException(\"JVM DOES NOT SUPPORT UTF-8\"); &#125; &#125; return readStringBody(size);&#125; 如果是从传输通道中读取数据，查看readStringBody()方法： 123456789public String readStringBody(int size) throws TException &#123; try &#123; byte[] buf = new byte[size]; trans_.readAll(buf， 0， size); return new String(buf， \"UTF-8\"); &#125; catch (UnsupportedEncodingException uex) &#123; throw new TException(\"JVM DOES NOT SUPPORT UTF-8\"); &#125;&#125; readBinary()：读取二进制数组类型数据，和字符串读取类似，返回一个ByteBuffer字节缓存对象。 1234567891011121314public ByteBuffer readBinary() throws TException &#123; int size = readI32(); checkStringReadLength(size); if (trans_.getBytesRemainingInBuffer() &gt;= size) &#123; ByteBuffer bb = ByteBuffer.wrap(trans_.getBuffer()， trans_.getBufferPosition()， size); trans_.consumeBuffer(size); return bb; &#125; byte[] buf = new byte[size]; trans_.readAll(buf， 0， size); return ByteBuffer.wrap(buf);&#125; (d). 每个字段数据读取完成后，都需要再读取一个字段结束标记。 1public void readFieldEnd() &#123;&#125; (e). 当所有字段读取完成后，需要通过readStructEnd()再读入一个结构完成标记。 1public void readStructEnd() &#123;&#125; (f). 读取结束后，同样需要校验在Thrift IDL中定义为required的字段是否为空，是否合法。 123456789public void validate() throws org.apache.thrift.TException &#123; // check for required fields if (key == null) &#123; throw new org.apache.thrift.protocol.TProtocolException(\"Required field 'key' was not present! Struct: \" + toString()); &#125; if (value == null) &#123; throw new org.apache.thrift.protocol.TProtocolException(\"Required field 'value' was not present! Struct: \" + toString()); &#125;&#125; 总结其实到这里，对于Thrift的序列化机制和反序列化机制的具体实现和高效性，相信各位已经有了比较深入的认识！ 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"Thrift","slug":"Thrift","permalink":"https://ostenant.coding.me/tags/Thrift/"},{"name":"Apache","slug":"Apache","permalink":"https://ostenant.coding.me/tags/Apache/"},{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"}]},{"title":"Apache Thrift系列详解(二) - 网络服务模型","slug":"Apache Thrift系列详解(二) - 网络服务模型","date":"2018-01-11T09:36:00.000Z","updated":"2018-06-18T01:46:17.217Z","comments":true,"path":"2018/01/11/Apache Thrift系列详解(二) - 网络服务模型/","link":"","permalink":"https://ostenant.coding.me/2018/01/11/Apache Thrift系列详解(二) - 网络服务模型/","excerpt":"前言Thrift提供的网络服务模型：单线程、多线程、事件驱动，从另一个角度划分为：阻塞服务模型、非阻塞服务模型。","text":"前言Thrift提供的网络服务模型：单线程、多线程、事件驱动，从另一个角度划分为：阻塞服务模型、非阻塞服务模型。 阻塞服务模型：TSimpleServer、TThreadPoolServer。 非阻塞服务模型：TNonblockingServer、THsHaServer和TThreadedSelectorServer。 TServer类的层次关系： 正文TServerTServer定义了静态内部类Args，Args继承自抽象类AbstractServerArgs。AbstractServerArgs采用了建造者模式，向TServer提供各种工厂： 工厂属性 工厂类型 作用 ProcessorFactory TProcessorFactory 处理层工厂类，用于具体的TProcessor对象的创建 InputTransportFactory TTransportFactory 传输层输入工厂类，用于具体的TTransport对象的创建 OutputTransportFactory TTransportFactory 传输层输出工厂类，用于具体的TTransport对象的创建 InputProtocolFactory TProtocolFactory 协议层输入工厂类，用于具体的TProtocol对象的创建 OutputProtocolFactory TProtocolFactory 协议层输出工厂类，用于具体的TProtocol对象的创建 下面是TServer的部分核心代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public abstract class TServer &#123; public static class Args extends org.apache.thrift.server.TServer.AbstractServerArgs&lt;org.apache.thrift.server.TServer.Args&gt; &#123; public Args(TServerTransport transport) &#123; super(transport); &#125; &#125; public static abstract class AbstractServerArgs&lt;T extends org.apache.thrift.server.TServer.AbstractServerArgs&lt;T&gt;&gt; &#123; final TServerTransport serverTransport; TProcessorFactory processorFactory; TTransportFactory inputTransportFactory = new TTransportFactory(); TTransportFactory outputTransportFactory = new TTransportFactory(); TProtocolFactory inputProtocolFactory = new TBinaryProtocol.Factory(); TProtocolFactory outputProtocolFactory = new TBinaryProtocol.Factory(); public AbstractServerArgs(TServerTransport transport) &#123; serverTransport = transport; &#125; &#125; protected TProcessorFactory processorFactory_; protected TServerTransport serverTransport_; protected TTransportFactory inputTransportFactory_; protected TTransportFactory outputTransportFactory_; protected TProtocolFactory inputProtocolFactory_; protected TProtocolFactory outputProtocolFactory_; private boolean isServing; protected TServer(org.apache.thrift.server.TServer.AbstractServerArgs args) &#123; processorFactory_ = args.processorFactory; serverTransport_ = args.serverTransport; inputTransportFactory_ = args.inputTransportFactory; outputTransportFactory_ = args.outputTransportFactory; inputProtocolFactory_ = args.inputProtocolFactory; outputProtocolFactory_ = args.outputProtocolFactory; &#125; public abstract void serve(); public void stop() &#123;&#125; public boolean isServing() &#123; return isServing; &#125; protected void setServing(boolean serving) &#123; isServing = serving; &#125;&#125; TServer的三个方法：serve()、stop()和isServing()。serve()用于启动服务，stop()用于关闭服务，isServing()用于检测服务的起停状态。 TServer的不同实现类的启动方式不一样，因此serve()定义为抽象方法。不是所有的服务都需要优雅的退出, 因此stop()方法没有被定义为抽象。 TSimpleServerTSimpleServer的工作模式采用最简单的阻塞IO，实现方法简洁明了，便于理解，但是一次只能接收和处理一个socket连接，效率比较低。它主要用于演示Thrift的工作过程，在实际开发过程中很少用到它。 (一) 工作流程 (二) 使用入门服务端： 12345678910111213ServerSocket serverSocket = new ServerSocket(ServerConfig.SERVER_PORT);TServerSocket serverTransport = new TServerSocket(serverSocket);HelloWorldService.Processor processor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldServiceImpl());TBinaryProtocol.Factory protocolFactory = new TBinaryProtocol.Factory();TSimpleServer.Args tArgs = new TSimpleServer.Args(serverTransport);tArgs.processor(processor);tArgs.protocolFactory(protocolFactory);// 简单的单线程服务模型 一般用于测试TServer tServer = new TSimpleServer(tArgs);System.out.println(\"Running Simple Server\");tServer.serve(); 客户端： 12345678TTransport transport = new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT);TProtocol protocol = new TBinaryProtocol(transport);HelloWorldService.Client client = new HelloWorldService.Client(protocol);transport.open();String result = client.say(\"Leo\");System.out.println(\"Result =: \" + result);transport.close(); (三) 源码分析查看上述流程的源代码，即TSimpleServer.java中的serve()方法如下： serve()方法的操作： 设置TServerSocket的listen()方法启动连接监听。 以阻塞的方式接受客户端地连接请求，每进入一个连接即为其创建一个通道TTransport对象。 为客户端创建处理器对象、输入传输通道对象、输出传输通道对象、输入协议对象和输出协议对象。 通过TServerEventHandler对象处理具体的业务请求。 ThreadPoolServerTThreadPoolServer模式采用阻塞socket方式工作，主线程负责阻塞式监听是否有新socket到来，具体的业务处理交由一个线程池来处理。 (一) 工作流程 (二) 使用入门服务端： 1234567891011121314ServerSocket serverSocket = new ServerSocket(ServerConfig.SERVER_PORT);TServerSocket serverTransport = new TServerSocket(serverSocket);HelloWorldService.Processor&lt;HelloWorldService.Iface&gt; processor = new HelloWorldService.Processor&lt;&gt;(new HelloWorldServiceImpl());TBinaryProtocol.Factory protocolFactory = new TBinaryProtocol.Factory();TThreadPoolServer.Args ttpsArgs = new TThreadPoolServer.Args(serverTransport);ttpsArgs.processor(processor);ttpsArgs.protocolFactory(protocolFactory);// 线程池服务模型 使用标准的阻塞式IO 预先创建一组线程处理请求TServer ttpsServer = new TThreadPoolServer(ttpsArgs);System.out.println(\"Running ThreadPool Server\");ttpsServer.serve(); 客户端： 12345678TTransport transport = new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT);TProtocol protocol = new TBinaryProtocol(transport);HelloWorldService.Client client = new HelloWorldService.Client(protocol);transport.open();String result = client.say(\"ThreadPoolClient\");System.out.println(\"Result =: \" + result);transport.close(); (三) 源码分析ThreadPoolServer解决了TSimpleServer不支持并发和多连接的问题，引入了线程池。实现的模型是One Thread Per Connection。查看上述流程的源代码，先查看线程池的代码片段： TThreadPoolServer.java中的serve()方法如下： serve()方法的操作： 设置TServerSocket的listen()方法启动连接监听。 以阻塞的方式接受客户端的连接请求，每进入一个连接，将通道对象封装成一个WorkerProcess对象(WorkerProcess实现了Runnabel接口)，并提交到线程池。 WorkerProcess的run()方法负责业务处理，为客户端创建了处理器对象、输入传输通道对象、输出传输通道对象、输入协议对象和输出协议对象。 通过TServerEventHandler对象处理具体的业务请求。 WorkerProcess的run()方法： (四) 优缺点TThreadPoolServer模式的优点拆分了监听线程(Accept Thread)和处理客户端连接的工作线程(Worker Thread)，数据读取和业务处理都交给线程池处理。因此在并发量较大时新连接也能够被及时接受。 线程池模式比较适合服务器端能预知最多有多少个客户端并发的情况，这时每个请求都能被业务线程池及时处理，性能也非常高。 TThreadPoolServer模式的缺点线程池模式的处理能力受限于线程池的工作能力，当并发请求数大于线程池中的线程数时，新请求也只能排队等待。 TNonblockingServerTNonblockingServer模式也是单线程工作，但是采用NIO的模式，借助Channel/Selector机制, 采用IO事件模型来处理。 所有的socket都被注册到selector中，在一个线程中通过seletor循环监控所有的socket。 每次selector循环结束时，处理所有的处于就绪状态的socket，对于有数据到来的socket进行数据读取操作，对于有数据发送的socket则进行数据发送操作，对于监听socket则产生一个新业务socket并将其注册到selector上。 注意：TNonblockingServer要求底层的传输通道必须使用TFramedTransport。 (一) 工作流程 (二) 使用入门服务端： 123456789101112TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldServiceImpl());TNonblockingServerSocket tnbSocketTransport = new TNonblockingServerSocket(ServerConfig.SERVER_PORT);TNonblockingServer.Args tnbArgs = new TNonblockingServer.Args(tnbSocketTransport);tnbArgs.processor(tprocessor);tnbArgs.transportFactory(new TFramedTransport.Factory());tnbArgs.protocolFactory(new TCompactProtocol.Factory());// 使用非阻塞式IO服务端和客户端需要指定TFramedTransport数据传输的方式TServer server = new TNonblockingServer(tnbArgs);System.out.println(\"Running Non-blocking Server\");server.serve(); 客户端： 123456789TTransport transport = new TFramedTransport(new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT));// 协议要和服务端一致TProtocol protocol = new TCompactProtocol(transport);HelloWorldService.Client client = new HelloWorldService.Client(protocol);transport.open();String result = client.say(\"NonBlockingClient\");System.out.println(\"Result =: \" + result);transport.close(); (三) 源码分析TNonblockingServer继承于AbstractNonblockingServer，这里我们更关心基于NIO的selector部分的关键代码。 (四) 优缺点TNonblockingServer模式优点相比于TSimpleServer效率提升主要体现在IO多路复用上，TNonblockingServer采用非阻塞IO，对accept/read/write等IO事件进行监控和处理，同时监控多个socket的状态变化。 TNonblockingServer模式缺点TNonblockingServer模式在业务处理上还是采用单线程顺序来完成。在业务处理比较复杂、耗时的时候，例如某些接口函数需要读取数据库执行时间较长，会导致整个服务被阻塞住，此时该模式效率也不高，因为多个调用请求任务依然是顺序一个接一个执行。 THsHaServer鉴于TNonblockingServer的缺点，THsHaServer继承于TNonblockingServer，引入了线程池提高了任务处理的并发能力。THsHaServer是半同步半异步(Half-Sync/Half-Async)的处理模式，Half-Aysnc用于IO事件处理(Accept/Read/Write)，Half-Sync用于业务handler对rpc的同步处理上。 注意：THsHaServer和TNonblockingServer一样，要求底层的传输通道必须使用TFramedTransport。 (一) 工作流程 (二) 使用入门服务端： 1234567891011TNonblockingServerSocket tnbSocketTransport = new TNonblockingServerSocket(ServerConfig.SERVER_PORT);TProcessor tprocessor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldServiceImpl());// 半同步半异步THsHaServer.Args thhsArgs = new THsHaServer.Args(tnbSocketTransport);thhsArgs.processor(tprocessor);thhsArgs.transportFactory(new TFramedTransport.Factory());thhsArgs.protocolFactory(new TBinaryProtocol.Factory());TServer server = new THsHaServer(thhsArgs);System.out.println(\"Running HsHa Server\");server.serve(); 客户端： 123456789TTransport transport = new TFramedTransport(new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT));// 协议要和服务端一致TProtocol protocol = new TBinaryProtocol(transport);HelloWorldService.Client client = new HelloWorldService.Client(protocol);transport.open();String result = client.say(\"HsHaClient\");System.out.println(\"Result =: \" + result);transport.close(); (三) 源码分析THsHaServer继承于TNonblockingServer，新增了线程池并发处理工作任务的功能，查看线程池的相关代码： 任务线程池的创建过程： 下文的TThreadedSelectorServer囊括了THsHaServer的大部分特性，源码分析可参考TThreadedSelectorServer。 (四) 优缺点THsHaServer的优点THsHaServer与TNonblockingServer模式相比，THsHaServer在完成数据读取之后，将业务处理过程交由一个线程池来完成，主线程直接返回进行下一次循环操作，效率大大提升。 THsHaServer的缺点主线程仍然需要完成所有socket的监听接收、数据读取和数据写入操作。当并发请求数较大时，且发送数据量较多时，监听socket上新连接请求不能被及时接受。 TThreadedSelectorServerTThreadedSelectorServer是对THsHaServer的一种扩充，它将selector中的读写IO事件(read/write)从主线程中分离出来。同时引入worker工作线程池，它也是种Half-Sync/Half-Async的服务模型。 TThreadedSelectorServer模式是目前Thrift提供的最高级的线程服务模型，它内部有如果几个部分构成： 一个AcceptThread线程对象，专门用于处理监听socket上的新连接。 若干个SelectorThread对象专门用于处理业务socket的网络I/O读写操作，所有网络数据的读写均是有这些线程来完成。 一个负载均衡器SelectorThreadLoadBalancer对象，主要用于AcceptThread线程接收到一个新socket连接请求时，决定将这个新连接请求分配给哪个SelectorThread线程。 一个ExecutorService类型的工作线程池，在SelectorThread线程中，监听到有业务socket中有调用请求过来，则将请求数据读取之后，交给ExecutorService线程池中的线程完成此次调用的具体执行。主要用于处理每个rpc请求的handler回调处理(这部分是同步的)。 (一) 工作流程 (二) 使用入门服务端： 12345678910111213TNonblockingServerSocket serverSocket = new TNonblockingServerSocket(ServerConfig.SERVER_PORT);TProcessor processor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldServiceImpl());// 多线程半同步半异步TThreadedSelectorServer.Args ttssArgs = new TThreadedSelectorServer.Args(serverSocket);ttssArgs.processor(processor);ttssArgs.protocolFactory(new TBinaryProtocol.Factory());// 使用非阻塞式IO时 服务端和客户端都需要指定数据传输方式为TFramedTransportttssArgs.transportFactory(new TFramedTransport.Factory());// 多线程半同步半异步的服务模型TThreadedSelectorServer server = new TThreadedSelectorServer(ttssArgs);System.out.println(\"Running ThreadedSelector Server\");server.serve(); 客户端： 12345678910111213141516171819202122232425for (int i = 0; i &lt; 10; i++) &#123; new Thread(\"Thread \" + i) &#123; @Override public void run() &#123; // 设置传输通道 对于非阻塞服务 需要使用TFramedTransport(用于将数据分块发送) for (int j = 0; j &lt; 10; j++) &#123; TTransport transport = null; try &#123; transport = new TFramedTransport(new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT)); TProtocol protocol = new TBinaryProtocol(transport); HelloWorldService.Client client = new HelloWorldService.Client(protocol); transport.open(); String result = client.say(\"ThreadedSelector Client\"); System.out.println(\"Result =: \" + result); transport.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 关闭传输通道 transport.close(); &#125; &#125; &#125; &#125;.start();&#125; (三) 核心代码以上工作流程的三个组件AcceptThread、SelectorThread和ExecutorService在源码中的定义如下： TThreadedSelectorServer模式中有一个专门的线程AcceptThread用于处理新连接请求，因此能够及时响应大量并发连接请求；另外它将网络I/O操作分散到多个SelectorThread线程中来完成，因此能够快速对网络I/O进行读写操作，能够很好地应对网络I/O较多的情况。 TThreadedSelectorServer默认参数定义如下： 负责网络IO读写的selector默认线程数(selectorThreads)：2 负责业务处理的默认工作线程数(workerThreads)：5 工作线程池单个线程的任务队列大小(acceptQueueSizePerThread)：4 创建、初始化并启动AcceptThread和SelectorThreads，同时启动selector线程的负载均衡器(selectorThreads)。 AcceptThread源码AcceptThread继承于Thread，可以看出包含三个重要的属性：非阻塞式传输通道(TNonblockingServerTransport)、NIO选择器(acceptSelector)和选择器线程负载均衡器(threadChooser)。 查看AcceptThread的run()方法，可以看出accept线程一旦启动，就会不停地调用select()方法： 查看select()方法，acceptSelector选择器等待IO事件的到来，拿到SelectionKey即检查是不是accept事件。如果是，通过handleAccept()方法接收一个新来的连接；否则，如果是IO读写事件，AcceptThread不作任何处理，交由SelectorThread完成。 在handleAccept()方法中，先通过doAccept()去拿连接通道，然后Selector线程负载均衡器选择一个Selector线程，完成接下来的IO读写事件。 接下来继续查看doAddAccept()方法的实现，毫无悬念，它进一步调用了SelectorThread的addAcceptedConnection()方法，把非阻塞传输通道对象传递给选择器线程做进一步的IO读写操作。 SelectorThreadLoadBalancer源码SelectorThreadLoadBalancer如何创建？ SelectorThreadLoadBalancer是一个基于轮询算法的Selector线程选择器，通过线程迭代器为新进来的连接顺序分配SelectorThread。 SelectorThread源码SelectorThread和AcceptThread一样，是TThreadedSelectorServer的一个成员内部类，每个SelectorThread线程对象内部都有一个阻塞式的队列，用于存放该线程被接收的连接通道。 阻塞队列的大小可由构造函数指定： 上面看到，在AcceptThread的doAddAccept()方法中调用了SelectorThread的addAcceptedConnection()方法。 这个方法做了两件事： 将被此SelectorThread线程接收的连接通道放入阻塞队列中。 通过wakeup()方法唤醒SelectorThread中的NIO选择器selector。 既然SelectorThread也是继承于Thread，查看其run()方法的实现： SelectorThread方法的select()监听IO事件，仅仅用于处理数据读取和数据写入。如果连接有数据可读，读取并以frame的方式缓存；如果需要向连接中写入数据，缓存并发送客户端的数据。且在数据读写处理完成后，需要向NIO的selector清空和注销自身的SelectionKey。 数据写操作完成以后，整个rpc调用过程也就结束了，handleWrite()方法如下： 数据读操作完成以后，Thrift会利用已读数据执行目标方法，handleRead()方法如下： handleRead方法在执行read()方法，将数据读取完成后，会调用requestInvoke()方法调用目标方法完成具体业务处理。requestInvoke()方法将请求数据封装为一个Runnable对象，提交到工作任务线程池(ExecutorService)进行处理。 select()方法完成后，线程继续运行processAcceptedConnections()方法处理下一个连接的IO事件。 这里比较核心的几个操作： 尝试从SelectorThread的阻塞队列acceptedQueue中获取一个连接的传输通道。如果获取成功，调用registerAccepted()方法；否则，进入下一次循环。 registerAccepted()方法将传输通道底层的连接注册到NIO的选择器selector上面，获取到一个SelectionKey。 创建一个FrameBuffer对象，并绑定到获取的SelectionKey上面，用于数据传输时的中间读写缓存。 总结本文对Thrift的各种线程服务模型进行了介绍，包括2种阻塞式服务模型：TSimpleServer、TThreadPoolServer，3种非阻塞式服务模型：TNonblockingServer、THsHaServer和TThreadedSelectorServer。对各种服务模型的具体用法、工作流程、原理和源码实现进行了一定程度的分析。 鉴于篇幅较长，请各位看官请慢慢批阅！ 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"Thrift","slug":"Thrift","permalink":"https://ostenant.coding.me/tags/Thrift/"},{"name":"Apache","slug":"Apache","permalink":"https://ostenant.coding.me/tags/Apache/"},{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"}]},{"title":"Apache Thrift系列详解(一) - 概述与入门","slug":"Apache Thrift系列详解(一) - 概述与入门","date":"2018-01-08T02:14:00.000Z","updated":"2018-06-18T01:46:34.646Z","comments":true,"path":"2018/01/08/Apache Thrift系列详解(一) - 概述与入门/","link":"","permalink":"https://ostenant.coding.me/2018/01/08/Apache Thrift系列详解(一) - 概述与入门/","excerpt":"前言Thrift是一个轻量级、跨语言的远程服务调用框架，最初由Facebook开发，后面进入Apache开源项目。它通过自身的IDL中间语言, 并借助代码生成引擎生成各种主流语言的RPC服务端/客户端模板代码。","text":"前言Thrift是一个轻量级、跨语言的远程服务调用框架，最初由Facebook开发，后面进入Apache开源项目。它通过自身的IDL中间语言, 并借助代码生成引擎生成各种主流语言的RPC服务端/客户端模板代码。 Thrift支持多种不同的编程语言，包括C++、Java、Python、PHP、Ruby等，本系列主要讲述基于Java语言的Thrift的配置方式和具体使用。 正文Thrift的技术栈Thrift对软件栈的定义非常的清晰, 使得各个组件能够松散的耦合, 针对不同的应用场景, 选择不同是方式去搭建服务。 Thrift软件栈分层从下向上分别为：传输层(Transport Layer)、协议层(Protocol Layer)、处理层(Processor Layer)和服务层(Server Layer)。 传输层(Transport Layer)：传输层负责直接从网络中读取和写入数据，它定义了具体的网络传输协议；比如说TCP/IP传输等。 协议层(Protocol Layer)：协议层定义了数据传输格式，负责网络传输数据的序列化和反序列化；比如说JSON、XML、二进制数据等。 处理层(Processor Layer)：处理层是由具体的IDL（接口描述语言）生成的，封装了具体的底层网络传输和序列化方式，并委托给用户实现的Handler进行处理。 服务层(Server Layer)：整合上述组件，提供具体的网络线程/IO服务模型，形成最终的服务。 Thrift的特性(一) 开发速度快通过编写RPC接口Thrift IDL文件，利用编译生成器自动生成服务端骨架(Skeletons)和客户端桩(Stubs)。从而省去开发者自定义和维护接口编解码、消息传输、服务器多线程模型等基础工作。 服务端：只需要按照服务骨架即接口，编写好具体的业务处理程序(Handler)即实现类即可。 客户端：只需要拷贝IDL定义好的客户端桩和服务对象，然后就像调用本地对象的方法一样调用远端服务。 (二) 接口维护简单通过维护Thrift格式的IDL（接口描述语言）文件（注意写好注释），即可作为给Client使用的接口文档使用，也自动生成接口代码，始终保持代码和文档的一致性。且Thrift协议可灵活支持接口的可扩展性。 (三) 学习成本低因为其来自Google Protobuf开发团队，所以其IDL文件风格类似Google Protobuf，且更加易读易懂；特别是RPC服务接口的风格就像写一个面向对象的Class一样简单。 初学者只需参照：http://thrift.apache.org/，一个多小时就可以理解Thrift IDL文件的语法使用。 (四) 多语言/跨语言支持Thrift支持C++、 Java、Python、PHP、Ruby、Erlang、Perl、Haskell、C#、Cocoa、JavaScript、Node.js、Smalltalk等多种语言，即可生成上述语言的服务器端和客户端程序。 对于我们经常使用的Java、PHP、Python、C++支持良好，虽然对iOS环境的Objective-C(Cocoa)支持稍逊，但也完全满足我们的使用要求。 (五) 稳定/广泛使用Thrift在很多开源项目中已经被验证是稳定和高效的，例如Cassandra、Hadoop、HBase等；国外在Facebook中有广泛使用，国内包括百度、美团小米、和饿了么等公司。 Thrift的数据类型Thrift 脚本可定义的数据类型包括以下几种类型： 基本类型： bool: 布尔值 byte: 8位有符号整数 i16: 16位有符号整数 i32: 32位有符号整数 i64: 64位有符号整数 double: 64位浮点数 string: UTF-8编码的字符串 binary: 二进制串 结构体类型： struct: 定义的结构体对象 容器类型： list: 有序元素列表 set: 无序无重复元素集合 map: 有序的key/value集合 异常类型： exception: 异常类型 服务类型： service: 具体对应服务的类 Thrift的协议Thrift可以让用户选择客户端与服务端之间传输通信协议的类别，在传输协议上总体划分为文本(text)和二进制(binary)传输协议。为节约带宽，提高传输效率，一般情况下使用二进制类型的传输协议为多数，有时还会使用基于文本类型的协议，这需要根据项目/产品中的实际需求。常用协议有以下几种： TBinaryProtocol：二进制编码格式进行数据传输 TCompactProtocol：高效率的、密集的二进制编码格式进行数据传输 TJSONProtocol： 使用JSON文本的数据编码协议进行数据传输 TSimpleJSONProtocol：只提供JSON只写的协议，适用于通过脚本语言解析 Thrift的传输层常用的传输层有以下几种： TSocket：使用阻塞式I/O进行传输，是最常见的模式 TNonblockingTransport：使用非阻塞方式，用于构建异步客户端 TFramedTransport：使用非阻塞方式，按块的大小进行传输，类似于Java中的NIO Thrift的服务端类型 TSimpleServer：单线程服务器端，使用标准的阻塞式I/O TThreadPoolServer：多线程服务器端，使用标准的阻塞式I/O TNonblockingServer：单线程服务器端，使用非阻塞式I/O THsHaServer：半同步半异步服务器端，基于非阻塞式IO读写和多线程工作任务处理 TThreadedSelectorServer：多线程选择器服务器端，对THsHaServer在异步IO模型上进行增强 Thrift入门示例(一) 编写Thrift IDL文件a). 下载0.10.0的Thrift IDL编译器，下载地址：http://thrift.apache.org/docs/install。 通过编译生成器生成.java接口的类文件。 b). 下载Windows安装环境的.exe文件，将thrift.exe的路径加入环境变量中。在Idea上安装Thrift编辑插件。 c). 编写hello.thrift的IDL文件： 123service HelloWorldService &#123; string say(1: string username)&#125; d). 使用代码生成工具生成代码，执行以下命令： 1thrift -gen java hello.thrift e). 由于未指定代码生成的目标目录，生成的类文件默认存放在gen-java目录下。这里生成一个HelloWorldService.java类文件，文件大小超过数千行，下面截取一部分核心代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class HelloWorldService &#123; public interface Iface &#123; public String say(String username) throws org.apache.thrift.TException; &#125; public interface AsyncIface &#123; public void say(String username, org.apache.thrift.async.AsyncMethodCallback&lt;String&gt; resultHandler) throws org.apache.thrift.TException; &#125; public static class Client extends org.apache.thrift.TServiceClient implements Iface &#123; public static class Factory implements org.apache.thrift.TServiceClientFactory&lt;Client&gt; &#123; public Factory() &#123; &#125; public Client getClient(org.apache.thrift.protocol.TProtocol prot) &#123; return new Client(prot); &#125; public Client getClient(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot) &#123; return new Client(iprot, oprot); &#125; &#125; public Client(org.apache.thrift.protocol.TProtocol prot) &#123; super(prot, prot); &#125; public Client(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot) &#123; super(iprot, oprot); &#125; public String say(String username) throws org.apache.thrift.TException &#123; send_say(username); return recv_say(); &#125; // 省略..... &#125; public static class AsyncClient extends org.apache.thrift.async.TAsyncClient implements AsyncIface &#123; public static class Factory implements org.apache.thrift.async.TAsyncClientFactory&lt;AsyncClient&gt; &#123; private org.apache.thrift.async.TAsyncClientManager clientManager; private org.apache.thrift.protocol.TProtocolFactory protocolFactory; public Factory(org.apache.thrift.async.TAsyncClientManager clientManager, org.apache.thrift.protocol.TProtocolFactory protocolFactory) &#123; this.clientManager = clientManager; this.protocolFactory = protocolFactory; &#125; public AsyncClient getAsyncClient(org.apache.thrift.transport.TNonblockingTransport transport) &#123; return new AsyncClient(protocolFactory, clientManager, transport); &#125; &#125; public AsyncClient(org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.async.TAsyncClientManager clientManager, org.apache.thrift.transport.TNonblockingTransport transport) &#123; super(protocolFactory, clientManager, transport); &#125; public void say(String username, org.apache.thrift.async.AsyncMethodCallback&lt;String&gt; resultHandler) throws org.apache.thrift.TException &#123; checkReady(); say_call method_call = new say_call(username, resultHandler, this, ___protocolFactory, ___transport); this.___currentMethod = method_call; ___manager.call(method_call); &#125; // 省略..... &#125; // 省略.....&#125; 对于开发人员而言，使用原生的Thrift框架，仅需要关注以下四个核心内部接口/类：Iface, AsyncIface, Client和AsyncClient。 Iface：服务端通过实现HelloWorldService.Iface接口，向客户端的提供具体的同步业务逻辑。 AsyncIface：服务端通过实现HelloWorldService.Iface接口，向客户端的提供具体的异步业务逻辑。 Client：客户端通过HelloWorldService.Client的实例对象，以同步的方式访问服务端提供的服务方法。 AsyncClient：客户端通过HelloWorldService.AsyncClient的实例对象，以异步的方式访问服务端提供的服务方法。 (二) 新建Maven工程a). 新建maven工程，引入thrift的依赖，这里使用的是版本0.10.0。 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.thrift&lt;/groupId&gt; &lt;artifactId&gt;libthrift&lt;/artifactId&gt; &lt;version&gt;0.10.0&lt;/version&gt;&lt;/dependency&gt; b). 将生成类的HelloWorldService.java源文件拷贝进项目源文件目录中，并实现HelloWorldService.Iface的定义的say()方法。 HelloWorldServiceImpl.java 123456public class HelloWorldServiceImpl implements HelloWorldService.Iface &#123; @Override public String say(String username) throws TException &#123; return \"Hello \" + username; &#125;&#125; c). 服务器端程序编写： SimpleServer.java 123456789101112131415161718public class SimpleServer &#123; public static void main(String[] args) throws Exception &#123; ServerSocket serverSocket = new ServerSocket(ServerConfig.SERVER_PORT); TServerSocket serverTransport = new TServerSocket(serverSocket); HelloWorldService.Processor processor = new HelloWorldService.Processor&lt;HelloWorldService.Iface&gt;(new HelloWorldServiceImpl()); TBinaryProtocol.Factory protocolFactory = new TBinaryProtocol.Factory(); TSimpleServer.Args tArgs = new TSimpleServer.Args(serverTransport); tArgs.processor(processor); tArgs.protocolFactory(protocolFactory); // 简单的单线程服务模型 一般用于测试 TServer tServer = new TSimpleServer(tArgs); System.out.println(\"Running Simple Server\"); tServer.serve(); &#125;&#125; d). 客户端程序编写： SimpleClient.java 1234567891011121314151617181920public class SimpleClient &#123; public static void main(String[] args) &#123; TTransport transport = null; try &#123; transport = new TSocket(ServerConfig.SERVER_IP, ServerConfig.SERVER_PORT, ServerConfig.TIMEOUT); TProtocol protocol = new TBinaryProtocol(transport); HelloWorldService.Client client = new HelloWorldService.Client(protocol); transport.open(); String result = client.say(\"Leo\"); System.out.println(\"Result =: \" + result); &#125; catch (TException e) &#123; e.printStackTrace(); &#125; finally &#123; if (null != transport) &#123; transport.close(); &#125; &#125; &#125;&#125; e). 运行服务端程序，服务端在指定端口监听客户端的连接请求，控制台输出启动日志： f). 运行客户端程序，客户端通过网络请求HelloWorldService的say()方法的具体实现，控制台输出返回结果： 这里使用的一个基于单线程同步的简单服务模型，一般仅用于入门学习和测试！ 总结本文对Thrift的概念做了相关介绍，体验了一番thrift程序如何编写！ 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"RPC通信框架系列","slug":"RPC通信框架系列","permalink":"https://ostenant.coding.me/categories/RPC通信框架系列/"}],"tags":[{"name":"Thrift","slug":"Thrift","permalink":"https://ostenant.coding.me/tags/Thrift/"},{"name":"Apache","slug":"Apache","permalink":"https://ostenant.coding.me/tags/Apache/"},{"name":"RPC","slug":"RPC","permalink":"https://ostenant.coding.me/tags/RPC/"}]},{"title":"深入浅出OAuth 2.0授权机制","slug":"深入浅出OAuth 2.0授权机制","date":"2018-01-04T13:10:00.000Z","updated":"2018-06-18T01:59:06.018Z","comments":true,"path":"2018/01/04/深入浅出OAuth 2.0授权机制/","link":"","permalink":"https://ostenant.coding.me/2018/01/04/深入浅出OAuth 2.0授权机制/","excerpt":"前言举个简单的例子。新浪微博是你的家，有时候你会想让一些人(第三方应用)去你的家里帮你办点事情，或者取点东西。你可以直接复制一把钥匙(用户名和密码)给他们，但这里存在几个问题：","text":"前言举个简单的例子。新浪微博是你的家，有时候你会想让一些人(第三方应用)去你的家里帮你办点事情，或者取点东西。你可以直接复制一把钥匙(用户名和密码)给他们，但这里存在几个问题： 别人拿了钥匙后可以去你家里的所有房间。 别人拿到你的钥匙后也许会不小心丢到，甚至故意送到它人手里。这样你都不知到谁有你家钥匙。 过一段时间你也许会想要回自己的钥匙，但别人不还怎么办？ 总结起来就是两个问题：其一，拿到钥匙的人权限太大，可以进入任一房间；其二，拿到钥匙的人可能对钥匙进行复制和更改。 OAuth是高级钥匙，可以理解为指纹识别，它主要解决了以上的缺陷： 你可以配置不同权限的钥匙。有些只能进大厅(读取你的微博流)。有些钥匙可以进储藏柜(读取你的相片)。 钥匙上带着指纹验证程序(指纹 = appkey)，只有收到钥匙的人自己能使用钥匙。 钥匙有一定的时效性，同时你也可以远程废除钥匙。 正文OAuth是一个关于授权(authorization)的开放网络标准，在全世界得到广泛应用，目前的版本是2.0版。本文对OAuth 2.0的设计思路和运行流程，做一个简明通俗的解释。 应用场景为了理解OAuth的适用场景，举一个通俗易懂的例子。有一个”云冲印”的网站，可以将用户储存在Google的照片，冲印出来。用户为了使用该服务，必须让”云冲印”读取自己储存在Google上的照片。 问题是只有得到用户的授权，Google才会同意”云冲印”读取这些照片。那么，”云冲印”怎样获得用户的授权呢？传统方法是，用户将自己的Google用户名和密码，告诉”云冲印”，后者就可以读取用户的照片了。这样的做法有以下几个严重的缺点。 1. &quot;云冲印&quot;为了后续的服务，会保存用户的密码，这样很不安全。 2. Google不得不部署密码登录，而我们知道，单纯的密码登录并不安全。 3. &quot;云冲印&quot;拥有了获取用户储存在Google所有资料的权利，用户没法限制&quot;云冲印&quot;获得授权的范围和有效期。 4. 用户只有修改密码，才能收回赋予&quot;云冲印&quot;的权力。但是这样做，会使得其他所有获得用户授权的第三方应用程序全部失效。 5. 只要有一个第三方应用程序被破解，就会导致用户密码泄漏，以及所有被密码保护的数据泄漏。 OAuth就是为了解决上面这些问题而诞生的。 专业术语在详细讲解OAuth 2.0之前，需要了解几个专用名词。它们对读懂后面的讲解，尤其是几张图，至关重要。 专业术语 中文含义 具体解释说明 Third-party application 第三方应用程序 本文中又称”客户端”(client)，即上一节例子中的”云冲印” Resource Owner 资源所有者 本文中又称”用户”(user)。 HTTP service HTTP服务提供商 本文中简称”服务提供商”，即上一节例子中的Google。 User Agent 用户代理 本文中就是指浏览器。 Authorization server 认证服务器 即服务提供商专门用来处理认证的服务器。 Resource server 资源服务器 即服务提供商存放用户生成的资源的服务器。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。 OAuth的思路OAuth在”客户端“与”服务提供商“之间，设置了一个授权层(authorization layer)。”客户端“不能直接登录”服务提供商“，只能登录授权层，以此将用户与客户端区分开来。”客户端“登录授权层所用的令牌(token)，与用户的密码不同。用户可以在登录的时候，指定授权层令牌的权限范围和有效期。“客户端”登录授权层以后，”服务提供商”根据令牌的权限范围和有效期，向”客户端“开放用户储存的资料。 具体流程 (A). 用户打开客户端以后，客户端要求用户给予授权。 (B). 用户同意给予客户端授权。 (C). 客户端拿到上一步获取到的授权，向认证服务器申请令牌。 (D). 认证服务器对客户端进行认证以后，确认无误，统一发放令牌。 (E). 客户端使用令牌，向资源服务器申请获取用户的资源。 (F). 资源服务器确认令牌无误，同意向客户端开放资源。 不难看出来，上面六个步骤之中，步骤(B)是关键，即用户怎样才能给于客户端授权。有了这个授权以后，客户端就可以获取令牌，进而凭令牌获取资源。 几种授权模式客户端必须得到了用户的授权。(authorization grant)，才能获取令牌(access token)。OAuth 2.0定义了四种授权方式。 授权码模式(authorization code) 简化模式(implicit) 密码模式(resource owner password credentials) 客户端模式(client credentials) 下面一一讲解客户端获取授权的四种模式。 (一). 授权码模式授权码模式(authorization code)是功能最完整、流程最严密的授权模式。它的特点就是通过客户端的后台服务器，与”服务提供商“的认证服务器进行互动。 它的步骤如下： (A). 用户访问客户端，后者将前者导向认证服务器。 (B). 用户选择是否给予客户端授权。 (C). 假设用户给予授权，认证服务器将用户导向客户端事先指定的&quot;重定向URI&quot;(redirection URI)，同时附上一个授权码。 (D). 客户端收到授权码，附上早先的&quot;重定向URI&quot;，向认证服务器申请令牌。这一步是在客户端的后台的服务器上完成的，对用户不可见。 (E). 认证服务器核对了授权码和重定向URI，确认无误后，向客户端发送访问令牌(access token)和更新令牌(refresh token)。 对于每个步骤具体所需要参数如下： A步骤中，客户端申请认证的URI，包含以下参数： 参数 具体含义 是否必填 response_type 授权类型 必选项，此处的值固定为”code” client_id 客户端的ID 必选项 redirect_uri 重定向URI 可选项 scope 申请的权限范围 可选项 state 客户端的当前状态，认证服务器会原封不动地返回这个值 可选项，可以指定任意值 下面是一个例子：123GET /authorize?response_type=code&amp;client_id=s6BhdRkqt3&amp;state=xyz &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1Host: server.example.com C步骤中，服务器回应客户端的URI，包含以下参数： 参数 具体含义 是否必填 code 授权码。该码的有效期应该很短，通常设为10分钟，客户端只能使用该码一次，否则会被授权服务器拒绝。该码与客户端ID和重定向URI，是一一对应关系 必选项 state 如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数。 可选项 下面是一个例子： 12HTTP/1.1 302 FoundLocation: https://client.example.com/cb?code=SplxlOBeZQQYbYS6WxSbIA&amp;state=xyz D步骤中，客户端向认证服务器申请令牌的HTTP请求，包含以下参数： 参数 具体含义 是否必填 grant_type 授权模式 必选项，此处的值固定为”authorization_code” code 上一步获得的授权码 必选项 redirect_uri 重定向URI 必选项，且必须与A步骤中的该参数值保持一致 client_id 客户端ID 必选项 下面是一个例子： 1234567POST /token HTTP/1.1Host: server.example.comAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JWContent-Type: application/x-www-form-urlencodedgrant_type=authorization_code&amp;code=SplxlOBeZQQYbYS6WxSbIA&amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb E步骤中，认证服务器发送的HTTP回复，包含以下参数： 参数 具体含义 是否必填 access_token 访问令牌 必选项 token_type 牌类型，该值大小写不敏感 必选项，可以是bearer类型或mac类型 expires_in 过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间 可选项 refresh_token 更新令牌，用来获取下一次的访问令牌 可选项 scope 申请的权限范围 可选项 下面是一个例子： 123456789101112HTTP/1.1 200 OKContent-Type: application/json;charset=UTF-8Cache-Control: no-storePragma: no-cache&#123; \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\", \"token_type\":\"bearer\", \"expires_in\":3600, \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\", \"example_parameter\":\"example_value\"&#125; 从上面代码可以看到，相关参数使用JSON格式发送(Content-Type: application/json)。此外，HTTP头信息中明确指定不得缓存。 (二). 简化模式简化模式(implicit grant type)不通过第三方应用程序的服务器，直接在浏览器中向认证服务器申请令牌，跳过了”授权码“这个步骤，因此得名。所有步骤在浏览器中完成，令牌对访问者是可见的，且客户端不需要认证。 它的步骤如下： (A). 客户端将用户导向认证服务器。 (B). 用户决定是否给于客户端授权。 (C). 假设用户给予授权，认证服务器将用户导向客户端指定的&quot;重定向URI&quot;，并在URI的Hash部分包含了访问令牌。 (D). 浏览器向资源服务器发出请求，其中不包括上一步收到的Hash值。 (E). 资源服务器返回一个网页，其中包含的代码可以获取Hash值中的令牌。 (F). 浏览器执行上一步获得的脚本，提取出令牌。 (G). 浏览器将令牌发给客户端。 下面是上面这些步骤所需要的参数： A步骤中，客户端发出的HTTP请求，包含以下参数： 参数 具体含义 是否必填 response_type 授权类型 必选项，此处的值固定为”token” client_id 客户端的ID 必选项 redirect_uri 重定向URI 可选项 scope 申请的权限范围 可选项 state 客户端的当前状态，认证服务器会原封不动地返回这个值 可选项，可以指定任意值 下面是一个例子： 123GET /authorize?response_type=token&amp;client_id=s6BhdRkqt3&amp;state=xyz &amp;redirect_uri=https%3A%2F%2Fclient%2Eexample%2Ecom%2Fcb HTTP/1.1Host: server.example.com C步骤中，认证服务器回应客户端的URI，包含以下参数： 参数 具体含义 是否必填 access_token 访问令牌 必选项 token_type 牌类型，该值大小写不敏感 必选项 expires_in 过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间 可选项 scope 权限范围 如果与客户端申请的范围一致，此项可省略 state 如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数 可选项 下面是一个例子： 123HTTP/1.1 302 FoundLocation: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA &amp;state=xyz&amp;token_type=example&amp;expires_in=3600 下面是一个例子： 123HTTP/1.1 302 FoundLocation: http://example.com/cb#access_token=2YotnFZFEjr1zCsicMWpAA &amp;state=xyz&amp;token_type=bearer&amp;expires_in=3600 在上面的例子中，认证服务器用HTTP头信息的Location栏，指定浏览器重定向的网址。注意，在这个网址的Hash部分包含了令牌。根据上面的D步骤，下一步浏览器会访问Location指定的网址，但是Hash部分不会发送。接下来的E步骤，服务提供商的资源服务器发送过来的脚本代码，会提取出Hash中的令牌。 (三). 密码模式密码模式(Resource Owner Password Credentials Grant)中，用户向客户端提供自己的用户名和密码。客户端使用这些信息，向”服务商提供商“索要授权。 在这种模式中，用户必须把自己的密码给客户端，但是客户端不得储存密码。这通常用在用户对客户端高度信任的情况下，比如客户端是操作系统的一部分，或者由一个著名公司出品。而认证服务器只有在其他授权模式无法执行的情况下，才能考虑使用这种模式。 它的步骤如下： (A). 用户向客户端提供用户名和密码。 (B). 客户端将用户名和密码发给认证服务器，向后者请求令牌。 (C). 认证服务器确认无误后，向客户端提供访问令牌。 B步骤中，客户端发出的HTTP请求，包含以下参数： 参数 具体含义 是否必填 grant_type 授权类型 必选项，此处的值固定为”password” username 用户名 必选项 password 用户的密码 必选项 scope 申请的权限范围 可选项 下面是一个例子： 123456POST /token HTTP/1.1Host: server.example.comAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JWContent-Type: application/x-www-form-urlencodedgrant_type=password&amp;username=johndoe&amp;password=A3ddj3w C步骤中，认证服务器向客户端发送访问令牌： 参数 具体含义 是否必填 access_token 访问令牌 必选项 token_type 牌类型，该值大小写不敏感 必选项 expires_in 过期时间，单位为秒。如果省略该参数，必须其他方式设置过期时间 可选项 scope 权限范围 如果与客户端申请的范围一致，此项可省略 example_parameter 如果客户端的请求中包含这个参数，认证服务器的回应也必须一模一样包含这个参数 可选项 下面是一个例子： 123456789101112HTTP/1.1 200 OKContent-Type: application/json;charset=UTF-8Cache-Control: no-storePragma: no-cache&#123; \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\", \"token_type\":\"example\", \"expires_in\":3600, \"refresh_token\":\"tGzv3JOkF0XG5Qx2TlKWIA\", \"example_parameter\":\"example_value\"&#125; (四). 客户端模式客户端模式(Client Credentials Grant)指客户端以自己的名义，而不是以用户的名义，向”服务提供商“进行认证。严格地说，客户端模式并不属于OAuth框架所要解决的问题。 在这种模式中，用户直接向客户端注册，客户端以自己的名义要求”服务提供商“提供服务，其实不存在授权问题。 它的步骤如下： (A). 客户端向认证服务器进行身份认证，并要求一个访问令牌。 (B). 认证服务器确认无误后，向客户端提供访问令牌。 A步骤中，客户端发出的HTTP请求，包含以下参数： 参数 具体含义 是否必填 grant_type 授权类型 必选项，此处的值固定为”clientcredentials” scope 权限范围 可选项。 123456POST /token HTTP/1.1Host: server.example.comAuthorization: Basic czZCaGRSa3F0MzpnWDFmQmF0M2JWContent-Type: application/x-www-form-urlencodedgrant_type=client_credentials 认证服务器必须以某种方式，验证客户端身份。 B步骤中，认证服务器向客户端发送访问令牌，下面是一个例子： 1234567891011HTTP/1.1 200 OKContent-Type: application/json;charset=UTF-8Cache-Control: no-storePragma: no-cache&#123; \"access_token\":\"2YotnFZFEjr1zCsicMWpAA\", \"token_type\":\"example\", \"expires_in\":3600, \"example_parameter\":\"example_value\"&#125; 总结本文介绍了OAuth 2.0的一些基本概念，以及四种授权模式：授权码模式、简单模式、密码模式和客户端模式。o 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"认证与授权系列","slug":"认证与授权系列","permalink":"https://ostenant.coding.me/categories/认证与授权系列/"}],"tags":[{"name":"OAuth 2.0","slug":"OAuth-2-0","permalink":"https://ostenant.coding.me/tags/OAuth-2-0/"}]},{"title":"Java NIO系列(四) - Selector","slug":"Java NIO系列(四) - Selector","date":"2017-12-31T04:16:00.000Z","updated":"2018-06-18T01:47:59.042Z","comments":true,"path":"2017/12/31/Java NIO系列(四) - Selector/","link":"","permalink":"https://ostenant.coding.me/2017/12/31/Java NIO系列(四) - Selector/","excerpt":"前言Selector 是 Java NIO 中的一个组件，用于检查一个或多个通道 Channel 的状态是否处于可读、可写状态。如此可以实现单线程管理多个通道，也就是可以管理多个网络连接。","text":"前言Selector 是 Java NIO 中的一个组件，用于检查一个或多个通道 Channel 的状态是否处于可读、可写状态。如此可以实现单线程管理多个通道，也就是可以管理多个网络连接。 为什么使用Selector?用单线程处理多个 Channel 的好处是我需要更少的线程来处理 Channel 。实际上，你甚至可以用一个线程来处理所有的Channel。从操作系统的角度来看，切换线程的开销是比较昂贵的，并且每个线程都需要占用系统资源，因此暂用线程越少越好。 简而言之，通过 Selector 我们可以实现单线程操作多个 Channel。下面是单线程使用一个 Selector 处理 3 个 Channel 的示例图： 正文Selector的组件Java NIO Selector中有三个重要的组成：Selector、SelectableChannel 和 SelectionKey。 (一) 选择器(Selector)Selector选择器类管理着一个被注册的通道集合的信息和它们的就绪状态。选择器所在线程不停地更新通道的就绪状态，对通道注册的连接、数据读写事件等事件进行响应。 (二) 可选择通道(SelectableChannel)SelectableChannel 是一个抽象类，提供了通道的可选择性所需要的公共方法的实现，它是所有支持就绪检查的通道类的父类。 因为 FileChannel 类没有继承 SelectableChannel，因此不是可选通道。而所有 Socket 通道都是可选择的，包括从管道 (Pipe) 对象的中获得的通道。SelectableChannel 可以被注册到 Selector 对象上，并且注册时可以指定感兴趣的事件操作，比如：数据读取、数据写入操作。一个通道可以被注册到多个选择器上，但对每个选择器而言只能被注册一次。 (三) 选择键(SelectionKey)选择键封装了特定的通道与特定的选择器的注册关系。选择键对象由被 SelectableChannel.register() 返回并提供一个表示这种注册关系的标记。选择键包含了两个比特集(以整数的形式进行编码)，指示了该注册关系所关心的通道操作，以及通道已经准备好的操作。 Selector的使用(一) 创建Selector对象Selector 对象是通过调用静态工厂方法 open() 来实例化的，如下： 1Selector Selector = Selector.open(); (二) 将SelectableChannel注册到Selector为了将 Channel 和 Selector 配合使用，必须将 Channel 注册到 Selector 上。通过 SelectableChannel.register() 方法来实现，如下： 123channel.configureBlocking(false);// 对读操作感兴趣，向Selector注册读事件SelectionKey key = channel.register(selector, Selectionkey.OP_READ); 与 Selector 一起使用时，Channel 必须处于非阻塞模式下。这意味着不能将 FileChannel 与 Selector 一起使用，因为 FileChannel 不能切换到非阻塞模式，而套接字通道都可以。 注意 register() 方法的第二个参数。这是一个兴趣 (interest) 集合，意思是在通过 Selector 监听 Channel 时对什么事件感兴趣。可以监听四种不同类型的事件： 连接操作(Connect)：监听 SocketChannel 到来的连接事件。 接受操作(Accept)：对应常量 SelectionKey.OP_ACCEPT，专注于监听 ServerSocketChannel 接受 SocketChannel 的事件。 读操作(Read)：对应常量 SelectionKey.OP_READ，监听数据完全到达，通道可读的事件。 写操作(Write)：对应常量 SelectionKey.OP_READ，监听数据准备完成，通道可写的事件。 注意：并非所有的操作在所有的可选择通道上都能被支持。比如 ServerSocketChannel 支持 Accept操作，而 SocketChannel 中不支持。我们可以通过通道上的 validOps() 方法来获取特定通道下所有支持的操作集合。 以上四种事件用 SelectionKey 的四个常量来表示： 1234public static final int OP_READ = 1 &lt;&lt; 0; // 1public static final int OP_WRITE = 1 &lt;&lt; 2; // 4public static final int OP_CONNECT = 1 &lt;&lt; 3; // 8public static final int OP_ACCEPT = 1 &lt;&lt; 4; // 16 如果一个通道同时对多种操作感兴趣，可以用 “位或” 操作符将常量连接起来，如下： 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; (三) 为SelectionKey绑定附加对象可以将一个对象或者更多信息附着到 SelectionKey 上，这样就能方便的识别某个给定的通道。例如，可以附加与通道一起使用的 Buffer，或是包含聚集数据的某个对象。使用方法如下： 12selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); 还可以在用 register() 方法向 Selector 注册 Channel 的时候附加对象，例如： 1SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 如果要取消该对象，则可以通过该种方式: 1selectionKey.attach(null); (四) 通过Selector选择通道一旦向 Selector 注册了一或多个通道，就可以调用几个重载的 select() 方法。这些方法返回你所感兴趣的事件 (如连接、接受、读或写) 已经准备就绪的那些通道。换句话说，如果你对“读就绪”的通道感兴趣，select() 方法会返回读事件已经就绪的那些通道的 SelectionKey。 下面是 select() 方法的几个重载： int select()：阻塞到至少有一个通道在此选择器注册的事件上就绪了。 int select(long timeout)：select(long timeout) 和 select() 一样，除了最长会阻塞timeout毫秒(参数)。 int selectNow()：不会阻塞，不管什么通道就绪都立刻返回。如果没有通道变成可选择的，则此方法直接返回 0。 也可以通过遍历 SelectionKey 上的已选择键集合来访问就绪的通道，如下： 123456789101112131415Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator();while(keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if(key.isAcceptable()) &#123; // 一个连接被ServerSocketChannel接受 &#125; else if (key.isConnectable()) &#123; // 与远程服务器建立了连接 &#125; else if (key.isReadable()) &#123; // 一个channel做好了读准备 &#125; else if (key.isWritable()) &#123; // 一个channel做好了写准备 &#125; keyIterator.remove();&#125; 注意：每次迭代完成时 Selector 自己不会将已经处理完成的 SelectionKey实例移除，在迭代的末尾需要调用 keyIterator.remove() 方法手动移除。 SelectionKey.channel() 方法返回的通道需要强转为你要处理的类型，如：ServerSocketChannel 或 SocketChannel 等。 Selector完整实例服务端代码1234567891011121314151617181920212223242526272829303132333435ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();serverSocketChannel.configureBlocking(false);serverSocketChannel.socket().bind(new InetSocketAddress(port));Selector selector = Selector.open();serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);while (true) &#123; int number = selector.select(); if (number == 0) continue; Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) &#123; SelectionKey selectionKey = iterator.next(); if (selectionKey.isAcceptable()) &#123; // 获取客户端通道 SocketChannel socketChannel = (SocketChannel) selectionKey.channel(); socketChannel.configureBlocking(false); // 将客户端通道注册到选择器上 socketChannel.register(selector, SelectionKey.OP_READ, ByteBuffer.allocate(bufferSize)); &#125; if (selectionKey.isReadable()) &#123; handleRead(selectionKey); &#125; if (selectionKey.isWritable()) &#123; handleWrite(selectionKey); &#125; if (selectionKey.isConnectable()) &#123; System.out.println(\"Isonnectable := true\"); &#125; iterator.remove(); &#125;&#125; 服务端操作过程 创建 ServerSocketChannel 实例，设置为非阻塞模式，并绑定指定的服务端口； 创建 Selector 实例； 将 serverSocketChannel 注册到 selector 上面，并指定事件 OP_ACCEPT，最底层的 socket 通过 channel 和 selector 建立关联； 如果没有准备好 (Accept) 的socket，select方法会被阻塞一段时间并返回 0； 如果底层有 socket 已经准备好，selector 的 select() 方法会返回 socket 的个数，而且 selectedKeys 方法会返回 socket 对应的事件(connect、accept、read 和 write)； 根据事件类型，进行不同的处理逻辑。 总结这里简单的介绍了 Java NIO 中选择器的用法，有关 Selector 底层的实现原理需要进一步查看源码。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java编程进阶系列","slug":"Java编程进阶系列","permalink":"https://ostenant.coding.me/categories/Java编程进阶系列/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://ostenant.coding.me/tags/NIO/"}]},{"title":"Java NIO系列(三) - Channel","slug":"Java NIO系列(三) - Channel","date":"2017-12-27T07:22:00.000Z","updated":"2018-06-18T01:45:23.961Z","comments":true,"path":"2017/12/27/Java NIO系列(三) - Channel/","link":"","permalink":"https://ostenant.coding.me/2017/12/27/Java NIO系列(三) - Channel/","excerpt":"前言上文讲到Java NIO一些基本概念。在标准的IO中，都是基于字节流/字符流进行数据操作的，而在NIO中则是是基于Channel和Buffer进行操作，其中的Channel的虽然模拟了流的概念，实则大不相同。 本文将详细阐述NIO中的通道Channel的概念和具体的用法。","text":"前言上文讲到Java NIO一些基本概念。在标准的IO中，都是基于字节流/字符流进行数据操作的，而在NIO中则是是基于Channel和Buffer进行操作，其中的Channel的虽然模拟了流的概念，实则大不相同。 本文将详细阐述NIO中的通道Channel的概念和具体的用法。 Channel和Stream的区别 区别 Stream Channel 是否支持异步 不支持 支持 是否支持双向数据传输 不支持，只能单向 支持，既可以从通道读取数据，也可以向通道写入数据 是否结合Buffer使用 不 必须结合Buffer使用 性能 较低 较高 Channel用于在字节缓冲区和位于通道另一侧的服务（通常是文件或者套接字）之间以便有效的进行数据传输。借助通道，可以用最小的总开销来访问操作系统本身的I/O服务。 需要注意的是Channel必须结合Buffer使用，应用程序不能直接向通道中读/写数据，也就是缓冲区充当着应用程序和通道数据流动的转换的角色。 正文Channel的源码查看Channel的源码。所有的接口都实现于Channel接口，从接口上来看，所有的通道都有这两种操作：检查通道的开启状态和关闭通道。 12345public interface Channel extends Closeable &#123; public boolean isOpen(); public void close() throws IOException;&#125; Channel的分类广义上来说通道可以被分为两类：文件I/O和网络I/O，也就是文件通道和套接字通道。如果分的更细致一点则是： FileChannel：从文件读写数据； SocketChannel：通过TCP读写网络数据； ServerSocketChannel：可以监听新进来的TCP连接，并对每个链接创建对应的SocketChannel； DatagramChannel：通过UDP读写网络中的数据。 Channel的特性单向or双向通道既可以是单向的也可以是双向的。只实现ReadableByteChannel接口中的read()方法或者只实现WriteableByteChannel接口中的write()方法的通道皆为单向通道，同时实现ReadableByteChannel和WriteableByteChannel为双向通道，比如ByteChannel。 12public interface ByteChannel extends ReadableByteChannel, WritableByteChannel &#123;&#125; 对于Socket通道来说，它们一直是双向的，而对于FileChannel来说，它同样实现了ByteChannel，但是通过FileInputStream的getChannel()获取的FileChannel只具有文件的只读权限。 注意：调用FileChannel的write()方法会抛出了NonWriteChannelException异常。 阻塞or非阻塞通道的工作模式有两种：阻塞或非阻塞。在非阻塞模式下，调用的线程不会休眠，请求的操作会立刻返回结果；在阻塞模式下，调用的线程会产生休眠。 除FileChannel不能运行在非阻塞模式下，其余的通道都可阻塞运行也可以以非阻塞的方式运行。 另外从SelectableChannel引申出的类可以和支持有条件选择的Selector结合使用，进而充分利用多路复用的I/O(Multiplexed I/O)来提高性能。 SelectableChannel的源码中有以下几个抽象方法，可以看出支持配置两种工作模式：1234567891011121314public abstract class SelectableChannel extends AbstractInterruptibleChannel implements Channel &#123; /** * 配置是否为Channel阻塞模式 */ public abstract SelectableChannel configureBlocking(boolean block) throws IOException; /** * 判断是否为Channel阻塞模式 */ public abstract boolean isBlocking(); /** * 获取阻塞的锁对象 */ public abstract Object blockingLock();&#125; 对于Socket通道类来说，通常与Selector共同使用以提高性能。需要注意的是通道不能被同时使用，一个打开的通道代表着与一个特定I/O服务进行连接并封装了该连接的状态，通道一旦关闭，该连接便会断开。 通道的close()比较特殊，无论在通道时在阻塞模式下还是非阻塞模式下，由于close()方法的调用而导致底层I/O的关闭都可能会造成线程的暂时阻塞。在一个已关闭的通道上调用close()并没有任何意义，只会立即返回。 Channel的实战 对于Socket通道来说存在直接创建新Socket通道的方法，而对于文件通道来说，升级之后的FileInputStream、FileOutputStream和RandomAccessFile提供了getChannel()方法来获取通道。 FileChannelJava NIO中的FileChannel是一个连接到文件的通道，可以通过文件通道读写文件。文件通道总是阻塞式的，因此FileChannel无法设置为非阻塞模式。 文件读写(一). 文件写操作： 123456789101112131415161718192021public static void testWriteOnFileChannel() &#123; try &#123; RandomAccessFile randomAccess = new RandomAccessFile(\"D://test.txt\", \"rw\"); FileChannel fileChannel = randomAccess.getChannel(); byte[] bytes = new String(\"Java Non-blocking IO\").getBytes(); ByteBuffer byteBuffer = ByteBuffer.wrap(bytes); // 将缓冲区中的字节写入文件通道中 fileChannel.write(byteBuffer); // 强制将通道中未写入磁盘的数据立刻写入到磁盘 fileChannel.force(true); // 清空缓冲区，释放内存 byteBuffer.clear(); fileChannel.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; (二). 文件读操作： 12345678910111213141516171819202122232425public static void testReadOnFileChannel() &#123; try &#123; FileInputStream inputStream = new FileInputStream(new File(\"D://test.txt\")); FileChannel fileChannel = inputStream.getChannel(); ByteBuffer byteBuffer = ByteBuffer.allocate(10); // 不断地写入缓冲区，写一次读一次 while (fileChannel.read(byteBuffer) != -1) &#123; // 缓冲区从写模式切换为读模式 byteBuffer.flip(); // 开始读取 while (byteBuffer.hasRemaining()) &#123; // 一个字节一个字节地读取，并向后移动position地位置 System.out.print((char) byteBuffer.get()); &#125; // 缓冲区不会被自动覆盖，需要主动调用该方法(实际上还是覆盖) byteBuffer.clear(); &#125; fileChannel.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 文件读写测试：123456789public static void main(String[] args) &#123; System.out.println(\"Start to write\"); // 通过FileChannel写入数据 testWriteOnFileChannel(); System.out.println(\"Start to read\"); // 通过FileChannel读取数据 testReadOnFileChannel();&#125; 测试结果： transferFrom和transferTo(一). transferFrom()的使用 FileChannel的transferFrom()方法可以将数据从源通道传输到FileChannel中。下面是一个简单的例子： 12345678910111213141516public static void testTransferFrom()&#123; try &#123; RandomAccessFile fromFile = new RandomAccessFile(\"D://file1.txt\", \"rw\"); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile(\"D://file2.txt\", \"rw\"); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); toChannel.transferFrom(fromChannel, position, count); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; (二). transferTo()的使用 transferTo()方法将数据从FileChannel传输到目标channel中。下面是一个简单的例子： 123456789101112131415public static void testTransferTo() &#123; try &#123; RandomAccessFile fromFile = new RandomAccessFile(\"D://file1.txt\", \"rw\"); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile(\"D://file3.txt\", \"rw\"); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); fromChannel.transferTo(position, count, toChannel); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; ServerSocketChannelJava NIO中的ServerSocketChannel是一个可以监听新进来的TCP连接的通道。它类似ServerSocket，要注意的是和DatagramChannel和SocketChannel不同，ServerSocketChannel本身不具备传输数据的能力，而只是负责监听传入的连接和创建新的SocketChannel。 ServerSocketChannel的用法(一). 创建ServerSocketChannel 通过ServerSocketChannel.open()方法来创建一个新的ServerSocketChannel对象，该对象关联了一个未绑定ServerSocket的通道。通过调用该对象上的socket()方法可以获取与之关联的ServerSocket。 1ServerSocketChannel socketChannel = ServerSocketChannel.open(); (二). 为ServerSocketChannel绑定监听端口号 在JDK 1.7之前，ServerSocketChannel没有bind()方法，因此需要通过他关联的的socket对象的socket()来绑定。 12// JDK1.7之前serverSocketChannel.socket().bind(new InetSocketAddress(25000)); 从JDK1.7及以后，可以直接通过ServerSocketChannel的bind()方法来绑定端口号。 12// JDK1.7之后serverSocketChannel.bind(new InetSocketAddress(25000)); (三). 设置ServerSocketChannel的工作模式 ServerSocketChannel底层默认采用阻塞的工作模式，它提供了一个configureBlocking()方法，允许配置ServerSocketChannel以非阻塞方式运行。 12// 设置为非阻塞模式serverSocketChannel.configureBlocking(false); 进一步查看configureBlocking源码如下： 12345678910111213public final SelectableChannel configureBlocking(boolean block) throws IOException &#123; synchronized (regLock) &#123; if (!isOpen()) throw new ClosedChannelException(); if (blocking == block) return this; if (block &amp;&amp; haveValidKeys()) throw new IllegalBlockingModeException(); implConfigureBlocking(block); blocking = block; &#125; return this;&#125; Javadoc解释configureBlocking()方法用于调整底层通道的工作模式，即阻塞和非阻塞，默认是阻塞工作模式。 如果block设置为true，直接返回当前的阻塞式的通道；如果block设置为false，configureBlocking()方法会调用implConfigureBlocking()方法。这里implConfigureBlocking()是由ServerSocketChannelImpl实现，最终调用了IOUtil中的native方法configureBlocking()。 (四). 监听新进来的连接 通过ServerSocketChannel.accept()方法监听新进来的连接，这里需要根据configureBlocking()的配置区分两种工作模式的使用： 在阻塞模式下，当accept()方法返回的时候，它返回一个包含新连接的SocketChannel，否则accept()方法会一直阻塞到有新连接到达。 在非阻塞模式下，在没有新连接的情况下，accept()会立即返回null，该模式下通常不会仅仅监听一个连接，因此需在while循环中调用accept()方法. 阻塞模式： 123456while(true) &#123; SocketChannel socketChannel = serverSocketChannel.accept(); // 新连接没到达之前，后面的程序无法继续执行 InetSocketAddress remoteAddress = (InetSocketAddress) socketChannel.getRemoteAddress(); // 其他操作&#125; 非阻塞模式： 12345678while(true) &#123; SocketChannel socketChannel = serverSocketChannel.accept(); // 新连接没到达之前，后面程序一直循环，直到检测到socketChannel不为null时进入真正的执行逻辑 if(socketChannel != null) &#123; InetSocketAddress remoteAddress = (InetSocketAddress) socketChannel.getRemoteAddress(); // 其他操作 &#125;&#125; (五). 关闭ServerSocketChannel 通过调用ServerSocketChannel.close()方法来关闭ServerSocketChannel。 1serverSocketChannel.close(); ServerSocketChannel的完整示例(一). 阻塞模式 代码示例： 12345678910111213141516171819202122public static void blockingTest() throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.bind(new InetSocketAddress(25000)); System.out.println(\"ServerSocketChannel listening on 25000...\"); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); while(true) &#123; SocketChannel socketChannel = serverSocketChannel.accept(); InetSocketAddress remoteAddress = (InetSocketAddress) socketChannel.getRemoteAddress(); System.out.println(\"Remote address: \" + remoteAddress.getHostString()); while (socketChannel.read(byteBuffer) != -1) &#123; byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; System.out.print((char) byteBuffer.get()); &#125; byteBuffer.clear(); &#125; &#125;&#125; 运行结果： (二). 非阻塞模式 代码示例： 123456789101112131415161718192021222324public static void nonBlockingTest() throws IOException &#123; ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.bind(new InetSocketAddress(25001)); System.out.println(\"ServerSocketChannel listening on 25001...\"); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); while (true) &#123; SocketChannel socketChannel = serverSocketChannel.accept(); System.out.println(\"SocketChannel： \" + socketChannel); if (socketChannel != null) &#123; InetSocketAddress remoteAddress = (InetSocketAddress) socketChannel.getRemoteAddress(); System.out.println(\"Remote address: \" + remoteAddress.getHostString()); while (socketChannel.read(byteBuffer) != -1) &#123; byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; System.out.print((char) byteBuffer.get()); &#125; byteBuffer.clear(); &#125; &#125; &#125;&#125; 运行结果： SocketChannelJava NIO中的SocketChannel是一个连接到TCP网络套接字的通道，它是Socket类的对等类。 通常SocketChannel在客户端向服务器发起连接请求，每个SocketChannel对象创建时都关联一个对等的Socket对象。同样SocketChannel也可以运行在非阻塞模式下。 SocketChannel的用法SocketChannel创建的方式有两种： 客户端主动创建：客户端打开一个SocketChannel并连接到某台服务器上； 服务端被动创建：一个新连接到达ServerSocketChannel时，服务端会创建一个SocketChannel。 (一). 创建SocketChannel 通过SocketChannel的静态方法open()创建SocketChannel对象。此时通道虽然打开，但并未建立连接。此时如果进行I/O操作会抛出NotYetConnectedException异常。 1SocketChannel socketChannel = SocketChannel.open(); (二). 连接指定服务器 通过SocketChannel对象的connect()连接指定地址。该通道一旦连接，将保持连接状态直到被关闭。可通过isConnected()来确定某个SocketChannel当前是否已连接。 阻塞模式： 如果在客户端的SocketChannel阻塞模式下，即服务器端的ServerSocketChannel也为阻塞模式： 123socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 25000));// connect()方法调用以后，socketChannel底层的连接创建完成后，才会执行后面的打印语句System.out.println(\"连接创建完成...\"); 非阻塞模式： 两点需要注意：其一，SocketChannel需要通过configureBlocking()设置为非阻塞模式；其二，非阻塞模式下，connect()方法调用后会异步返回，为了确定连接是否建立，需要调用finishConnect()的方法。 123456789socketChannel.configureBlocking(false);socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 25001));// connect()方法调用以后，异步返回，需要手动调用finishConnect确保连接创建while(!socketChannel.finishConnect())&#123; // 检测到还未创建成功则睡眠10ms TimeUnit.MILLISECONDS.sleep(10);&#125;System.out.println(\"连接创建完成...\"); (三). 从SocketChannel读数据 利用SocketChannel对象的read()方法将数据从SocketChannel读取到Buffer。 12345678910ByteBuffer byteBuffer = ByteBuffer.allocate(1024);// 非阻塞模式下，read()方法在尚未读取到任何数据时可能就返回了，所以需要关注它的int返回值。while (socketChannel.read(byteBuffer) != -1) &#123; byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; System.out.println((char) byteBuffer.get()); &#125; byteBuffer.clear();&#125; (四). 向SocketChannel写数据 利用SocketChannel对象的write()将Buffer的数据写入SocketChannel。 12345678910111213ByteBuffer byteBuffer = ByteBuffer.allocate(1024);byteBuffer.put(\"Client Blocking SocketChannel\".getBytes());// byteBuffer.put(\"Client Non-Blocking SocketChannel\".getBytes());byteBuffer.flip();// 非阻塞模式下，write()方法在尚未写出任何内容时可能就返回了。所以需要在循环中调用write()while (byteBuffer.hasRemaining()) &#123; socketChannel.write(byteBuffer);&#125;// 保持睡眠，观察控制台输出TimeUnit.SECONDS.sleep(20000);socketChannel.close(); (五). 关闭SocketChannel 利用SocketChannel对象的close()方法关闭SocketChannel。 1socketChannel.close(); SocketChannel的完整示例(一). 阻塞模式 代码示例： 123456789101112131415public static void blockingWrite() throws Exception &#123; SocketChannel socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 25000)); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); byteBuffer.put(\"Client Blocking SocketChannel\".getBytes()); byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; socketChannel.write(byteBuffer); &#125; TimeUnit.SECONDS.sleep(20000); socketChannel.close();&#125; 服务端打印结果： (一). 非阻塞模式 代码示例： 12345678910111213141516171819public static void nonBlockingWrite() throws Exception &#123; SocketChannel socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); socketChannel.connect(new InetSocketAddress(\"127.0.0.1\", 25001)); while(!socketChannel.finishConnect())&#123; TimeUnit.MILLISECONDS.sleep(10); &#125; ByteBuffer byteBuffer = ByteBuffer.allocate(1024); byteBuffer.put(\"Client Non-Blocking SocketChannel\".getBytes()); byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; socketChannel.write(byteBuffer); &#125; TimeUnit.SECONDS.sleep(20000); socketChannel.close();&#125; 服务端打印结果： DatagramChannelJava NIO中的DatagramChannel是一个能收发UDP包的通道，其底层实现为DatagramSocket + Selector。DatagramChannel可以调用socket()方法获取对等DatagramSocket对象。DatagramChannel对象既可以充当服务端（监听者），也可以充当客户端（发送者）。如果需要新创建的通道负责监听，那么该通道必须绑定一个端口（或端口组）： DatagramChannel的完整示例数据报发送方： 123456public static void main(String[] args) throws Exception &#123; DatagramChannel datagramChannel = DatagramChannel.open(); ByteBuffer byteBuffer = ByteBuffer.wrap(\"DatagramChannel Sender\".getBytes()); int byteSent = datagramChannel.send(byteBuffer, new InetSocketAddress(\"127.0.0.1\", 50020)); System.out.println(\"Byte sent is: \" + byteSent);&#125; 数据报接收方： 123456789101112public static void main(String[] args) throws Exception &#123; DatagramChannel datagramChannel = DatagramChannel.open(); datagramChannel.socket().bind(new InetSocketAddress(50020)); ByteBuffer byteBuffer = ByteBuffer.allocate(1024); datagramChannel.receive(byteBuffer); byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; System.out.print((char) byteBuffer.get()); &#125;&#125; 先运行DatagramChannelReceiveTest，再运行DatagramChannelSendTest，观察控制台输出： 数据报发送方： 数据报接收方： 工具类ChannelsNIO通道提供了一个便捷的通道类Channels，其中定义了几种静态的工厂方法以简化通道和流转换。其中常用的方法如下： 方法 返回 描述 newChannel(InputStream in) ReadableByteChannel 返回一个将从给定的输入流读取数据的通道。 newChannel(OutputStream out) WritableByteChannel 返回一个将向给定的输出流写入数据的通道。 newInputStream(ReadableByteChannel ch) InputStream 返回一个将从给定的通道读取字节的流。 newOutputStream(WritableByteChannel ch) OutputStream 返回一个将向给定的通道写入字节的流。 newReader(ReadableByteChannel ch, CharsetDecoder dec, int minBufferCap) Reader 返回一个reader，它将从给定的通道读取字节并依据提供的字符集名称对读取到的字节进行解码。 newReader(ReadableByteChannel ch, String csName) Reader 返回一个reader，它将从给定的通道读取字节并依据提供的字符集名称将读取到的字节解码成字符。 newWriter(WritableByteChannel ch, CharsetEncoder dec, int minBufferCap) Writer 返回一个writer，它将使用提供的字符集名称对字符编码并写到给定的通道中。 newWriter(WritableByteChannel ch, String csName) Writer 返回一个writer，它将依据提供的字符集名称对字符编码并写到给定的通道中。 总结本文针对NIO中的通道的做了详细的介绍，对于文件通道FileChannel，网络通道SocketChannel、ServerSocketChannel和DatagramChannel进行了实战演示。 篇幅较长，可见NIO提供的原生的通道API在使用上并不是太容易。 欢迎扫码关注我的个人技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java编程进阶系列","slug":"Java编程进阶系列","permalink":"https://ostenant.coding.me/categories/Java编程进阶系列/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://ostenant.coding.me/tags/NIO/"}]},{"title":"Java NIO系列(二) - Buffer","slug":"Java NIO系列(二) - Buffer","date":"2017-12-26T13:41:00.000Z","updated":"2018-06-18T01:47:39.151Z","comments":true,"path":"2017/12/26/Java NIO系列(二) - Buffer/","link":"","permalink":"https://ostenant.coding.me/2017/12/26/Java NIO系列(二) - Buffer/","excerpt":"前言在Java NIO中，缓冲区用来临时存储数据，可以理解为是I/O操作中数据暂存的中转站。缓冲区直接为通道(Channel)服务，数据是从通道读入缓冲区，从缓冲区写入到通道中的。 缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问这块内存。","text":"前言在Java NIO中，缓冲区用来临时存储数据，可以理解为是I/O操作中数据暂存的中转站。缓冲区直接为通道(Channel)服务，数据是从通道读入缓冲区，从缓冲区写入到通道中的。 缓冲区本质上是一块可以写入数据，然后可以从中读取数据的内存。这块内存被包装成NIO Buffer对象，并提供了一组方法，用来方便的访问这块内存。 正文Buffer的类型Java NIO提供以下几种Buffer类型： ByteBuffer MappedByteBuffer ShortBuffer LongBuffer FloatBuffer CharBuffer IntBuffer DoubleBuffer 这些Buffer类型代表了Java中7种基本数据类型。换句话说，就是可以通过byte、char、short、int、long、float或double类型来操作缓冲区中的数据。 Buffer的基本用法使用Buffer读写数据一般遵循以下四个步骤： 写入数据到Buffer中； 调用Buffer的flip()方法； 从Buffer中读取数据； 调用clear()方法或者compact()方法。 当向Buffer写入数据时，Buffer会记录下写了多少数据。一旦要读取数据，需要通过flip()方法将Buffer从写模式切换到读模式。在读模式下，可以读取之前写入到Buffer的所有数据。 一旦读完了所有的数据，就需要清空缓冲区，让它可以再次被写入。两种方式能清空缓冲区：调用clear()或compact()方法。 clear()方法：清空整个缓冲区，包括已读和未读的数据。 compact()方法：只会清空已读的数据，未读的数据都被移到缓冲区的起始处，新写入的数据将放到缓冲区未读数据的后面。 下面给出一个ByteBuffer的简单使用示例，其他缓冲区API的使用类似： 123456789101112131415161718192021222324public static void testReadFromBuffer() &#123; try &#123; RandomAccessFile file = new RandomAccessFile(\"D://test.txt\", \"rw\"); FileChannel fileChannel = file.getChannel(); //创建容量为10byte的buffer ByteBuffer byteBuffer = ByteBuffer.allocate(10); // 不断地写入缓冲区，写一次读一次 while (fileChannel.read(byteBuffer) != -1) &#123; // 设置buffer切换模式为读模式 byteBuffer.flip(); while (byteBuffer.hasRemaining()) &#123; // 每次读取1byte，也就是一个字节 System.out.print((char) byteBuffer.get()); &#125; // 清空整个缓存区，准备下次写入 byteBuffer.clear(); &#125; fileChannel.close(); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; Buffer的重要属性为了理解Buffer的工作原理，需要熟悉它的4个核心属性： 属性 含义 具体描述 capacity 容量 缓冲区可以容纳的最大数据量，在缓冲区创建时被设定并且不能改变 limit 上界 缓冲区中当前已使用的数据量 position 位置 缓冲区下一个要被读或写的元素的索引 mark 标记 调用mark()来设置mark=position，再调用reset()可以让position恢复到标记的位置即position=mark 其中，position和limit的含义取决于Buffer处在读模式还是写模式。不管Buffer处在什么模式，capacity的含义总是一样的。 capacity作为一个内存块，Buffer有一个固定的大小值，也叫capacity。你最多只能写入capacity个的byte、char、int、long等类型数据。一旦Buffer满了，需要将其清空（通过读数据或者清除数据）才能继续往里写数据。 position 写入数据时： 当你写数据到Buffer中时，position表示下一个可写入的数据的位置。position的初始位置为0，当一个byte、char、int、long等数据写到Buffer后，position会向前移动到下一个可插入数据的Buffer单元。position最大可为capacity – 1。 读取数据时： 当从Buffer读取数据时，position表示下一个可读取的数据的位置。当将Buffer从写模式切换到读模式，position会被重置为0。当从Buffer的position处读取数据时，position向前移动到下一个可读的位置。 limit 写入数据时： 在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。写模式下，limit等于Buffer的capacity，也就是内存块的最大容量。 写入数据时： 当切换Buffer到读模式时，limit会被设置成写模式下的position值，limit表示你最多能读到多少数据。limit被设置成已写数据的数量，这个值在写模式下就是position。 Buffer的方法Buffer的分配要想获得一个Buffer对象首先要进行分配，每一个Buffer类都有一个allocate()方法。下面是一个分配10字节capacity的ByteBuffer的例子： 1ByteBuffer buf = ByteBuffer.allocate(10); 这是分配一个可存储1024个字符的CharBuffer： 1CharBuffer buf = CharBuffer.allocate(1024); 向Buffer中写入数据写数据到Buffer有两种方式： 从Channel将数据写入Buffer。 1int bytesRead = channel.read(buffer); 通过Buffer的put()方法写到Buffer中。 1buffer.put(1); put()在ByteBuffer中为抽象方法，在ByteBuffer有很多的重载，由其子类HeapByteBuffer和DirectByteBuffer实现。 写模式切换为读模式flip()方法将Buffer从写模式切换到读模式。调用flip()方法会将position设回0，并将limit设置成之前position的值。 1buffer.flip(); 查看flip()方法的源码确认： 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; 从Buffer从读取数据从Buffer中读取数据也有两种方式： 从Buffer读取数据到Channel中。 1int bytesWritten = channel.write(buf); 通过Buffer的get()方法从Buffer中读取数据。 1byte b = buffer.get(); get()方法和put()一样有很多的重载，允许以不同的方式从Buffer中读取数据。例如：从指定position读取，或者从Buffer中读取数据到字节数组。 clear()和compact()方法一旦读完Buffer中的数据，需要让Buffer准备好再次被写入。前面也说了，可以通过clear()或compact()方法来完成。 clear()方法如果调用的是clear()方法，position将被设回0，limit被设置成capacity的值。 1buffer.clear(); 查看clear()方法的源码确认： 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; 换句话说，Buffer被清空了。Buffer中的数据并未清除，只是这些标记告诉我们可以从哪里开始往Buffer里写数据。 compact()方法如果调用的是compact()方法，所有的未读数据都将被拷贝到Buffer的起始位置，position会设置为最后一个未读元素的后面。limit()方法和clear()方法一样，会被设置为capacity的大小。 查看compact()方法的实现，此方法在ByteBuffer中为抽象方法，查看其子类HeapByteBuffer的实现： 1234567891011public ByteBuffer compact() &#123; // 将未读的数据往前移动 System.arraycopy(hb, ix(position()), hb, ix(0), remaining()); // 设置postion为最后一个未读数据后面的位置 position(remaining()); // 设置limit为最大的容量 limit(capacity()); // 清除标记位 discardMark(); return this;&#125; 现在Buffer准备好写数据了，但是不会覆盖未读的数据。 mark()与reset()方法通过调用mark()方法，可以标记Buffer中的一个特定position。之后可以通过调用reset()方法恢复到这个position。例如： mark()方法1buffer.mark(); 查看mark()方法的源码，mark变量被设置为position的值： 1234public final Buffer mark() &#123; mark = position; return this;&#125; reset()方法1buffer.reset(); 查看mark()方法的源码，position变量被设置为之前的mark的值： 1234567public final Buffer reset() &#123; int m = mark; if (m &lt; 0) throw new InvalidMarkException(); position = m; return this;&#125; equals()与compareTo()方法可以使用equals()和compareTo()方法比较两个Buffer。 equals()方法当同时满足下列条件时，表示两个Buffer相等： 有相同的类型(byte、char、int和long类型等)。 Buffer中剩余的byte、char等元素的个数相等。 Buffer中所有剩余的byte、char等都相同。 equals()方法比较的实际是Buffer中的剩余元素是否相等。它只是比较Buffer的一部分，不是每一个在它里面的元素都比较。 compareTo()方法compareTo()方法比较两个Buffer的剩余元素(byte、char等)。当满足下列条件时，则认为一个Buffer小于另一个Buffer。 第一个不相等的元素小于另一个Buffer中对应的元素。 所有元素都相等，但第一个Buffer比另一个先耗尽(第一个Buffer的元素个数比另一个少)。 总结这里只是对Buffer进行了入门的介绍，具体深入学习还需要查看各种缓冲区以及相关的具体实现。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java编程进阶系列","slug":"Java编程进阶系列","permalink":"https://ostenant.coding.me/categories/Java编程进阶系列/"}],"tags":[{"name":"NIO","slug":"NIO","permalink":"https://ostenant.coding.me/tags/NIO/"}]},{"title":"一天一个设计模式(五) - 适配器模式(Adapter)","slug":"一天一个设计模式(五) - 适配器模式(Adapter)","date":"2017-12-25T12:46:00.000Z","updated":"2018-06-18T01:53:02.731Z","comments":true,"path":"2017/12/25/一天一个设计模式(五) - 适配器模式(Adapter)/","link":"","permalink":"https://ostenant.coding.me/2017/12/25/一天一个设计模式(五) - 适配器模式(Adapter)/","excerpt":"前言适配器模式把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。","text":"前言适配器模式把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口不匹配而无法在一起工作的两个类能够在一起工作。 适配器模式的用途最经典的就是电器的例子，笔记本电脑的插头一般都是三相的，即除了阳极、阴极之外，还有一个地极。而有些地方的电源插座却只有两极，没有地极。电源插座与笔记本电脑的电源插头不匹配使得笔记本电脑无法使用。这时候一个三相到两相的转换器（适配器）就能解决此问题，而这正像是本模式所做的事情。 适配器模式的形式适配器模式有类的适配器模式和对象的适配器模式两种不同的形式。 正文类的适配器模式类的适配器模式，简单来说，就是适配的类的API转换成为目标接口的API。 从上图可以看出，Adaptee类并没有sampleOperation2()方法，而客户端则期待这个方法。 为了使客户端能够使用Adaptee类，提供一个中间环节，即类Adapter，把Adaptee类的API同Target接口的API衔接起来。Adapter与Adaptee是继承关系，这决定了这个适配器模式是类的适配器模式。 相关角色 目标(Target)角色：这就是所期待得到的接口。注意：由于这里讨论的是类适配器模式，因此目标不可以是类。 源(Adaptee)角色：现在需要适配的到目标角色的类。 适配器(Adapter)角色：适配器是目标角色和源角色之间的桥梁。适配器把源角色的类转换成目标接口的实现。 示例代码Target.java 1234567891011public interface Target &#123; /** * 这是源类Adaptee中也有的方法 */ public void sampleOperation1(); /** * 这是源类Adaptee中没有的方法 */ public void sampleOperation2();&#125; 上面给出的是目标角色的接口代码，这个角色是以一个接口的形式实现的。可以看出，这个接口声明了两个方法：sampleOperation1()和sampleOperation2()，而源角色Adaptee是一个具体类，它有一个sampleOperation1()方法，但是没有sampleOperation2()方法。 Adaptee.java 12345public class Adaptee &#123; public void sampleOperation1() &#123; System.out.println(\"Operation 1st\"); &#125;&#125; 适配器角色Adapter拓展了Adaptee，同时又实现了目标角色Target接口。由于Adaptee没有提供sampleOperation2()方法，而目标接口有要求这个方法，因此适配器角色Adapter实现了这个方法。 Adapter.java 123456public class Adapter extends Adaptee implements Target &#123; @Override public void sampleOperation2() &#123; System.out.println(\"Operation 2nd\"); &#125;&#125; 对象的适配器模式与类的适配器模式一样，对象的适配器模式把被适配类的API转换成为目标类的API。 与类的适配器模式不同的是，对象的适配器模式不是使用继承关系链接到Adaptee类，而是使用委派关系连接到Adaptee类。 从上图可以看出，Adaptee类并没有sampleOperation2()方法，而客户端则期待这个方法。 为使客户端能够使用Adaptee类，需要提供一个包装Wrapper类Adapter。这个包装类包括了一个Adaptee的实例，从而此包装类能够把Adaptee的API与Target类的API衔接起来。Adapter类与Adaptee类是委派关系，这决定了适配器模式是对象的。 相关角色 目标(Target)角色：这就是所期待得到的接口。注意：由于这里讨论的是类适配器模式，因此目标不可以是类。 源(Adaptee)角色：现在需要适配的到目标角色的类。 适配器(Adapter)角色：适配器是目标角色和源角色之间的桥梁。适配器把源角色的类包装到目标接口的实现中。 示例代码Target.java 1234567891011public interface Target &#123; /** * 这是源类Adaptee中也有的方法 */ public void sampleOperation1(); /** * 这是源类Adaptee中没有的方法 */ public void sampleOperation2();&#125; 上面给出的是目标角色的接口代码，这个角色是以一个接口的形式实现的。可以看出，这个接口声明了两个方法：sampleOperation1()和sampleOperation2()，而源角色Adaptee是一个具体类，它有一个sampleOperation1()方法，但是没有sampleOperation2()方法。 Adaptee.java 12345public class Adaptee &#123; public void sampleOperation1() &#123; System.out.println(\"Operation 1st\"); &#125;&#125; 在对象的适配器模式中，适配器角色中持有一个对源角色的引用，并在需要适配的方法中使用源角色的方法实现。 Adapter.java 1234567891011121314151617181920212223public class Adapter &#123; private Adaptee adaptee; public Adapter (Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; /** * 源类Adaptee有方法sampleOperation1 * 因此适配器可以直接进行委派 */ public void sampleOperation1() &#123; this.adaptee.sampleOperation1(); &#125; /** * 源类Adaptee没有方法sampleOperation2 * 因此适配器需要自己实现此方法 */ public void sampleOperation2() &#123; System.out.println(\"Operation 2nd\"); &#125;&#125; 两种适配器模式的对比类的适配器模式 使用对象继承的方式，是静态的定义方式。 由于适配器直接继承了Adaptee，使得适配器不能和Adaptee的子类一起工作。因为继承是静态的关系，而适配器继承了Adaptee后，就不可能再去处理Adaptee的子类了。 适配器可以重定义Adaptee的部分行为，相当于子类覆盖父类的部分实现方法。 不需要额外的引用过来间接得到Adaptee。 对象的适配器模式 使用对象组合的方式，是动态的组合方式。 一个适配器可以把多种不同的适配源适配到同一个目标类上。换言之，同一个适配器可以把源类和它的子类都适配到目标接口。因为对象适配器采用的是对象组合的关系，只要对象类型正确，是不是子类都无所谓。 要重定义Adaptee的行为比较困难，这种情况下，需要定义Adaptee的子类来实现重定义，然后让适配器组合子类。这样，虽然增加了一定的复杂性，也提供了一定的灵活性。 需要额外的引用来间接得到Adaptee。 建议尽量使用对象适配器的实现方式，多用合成/聚合，少用继承。当然，具体问题还是需要具体分析，根据需要来选用实现方式，最适合的才是最好的。 总结适配器模式的优点 更好的复用性 系统需要使用现有的类，因此类的接口不符合系统的需要。那么通过适配器模式就可以让这些功能得到更好的复用。 更好的拓展性 在实现适配器功能的时候，可以调用自己开发的功能，从而自然的拓展系统的功能。 适配器模式的缺点过多的使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是A接口，其实内部都被适配成了B接口的实现。一个系统如果太多的出现这种情况，无异于异常灾难。 因此如果不是很有必要，可以不是用适配器，而是直接对系统进行重构。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA设计模式系列","slug":"JAVA设计模式系列","permalink":"https://ostenant.coding.me/categories/JAVA设计模式系列/"}],"tags":[{"name":"Adapter","slug":"Adapter","permalink":"https://ostenant.coding.me/tags/Adapter/"}]},{"title":"一天一个设计模式(四) - 原型模式(Prototype)","slug":"一天一个设计模式(四) - 原型模式(Prototype)","date":"2017-12-21T08:22:00.000Z","updated":"2018-06-18T01:53:19.195Z","comments":true,"path":"2017/12/21/一天一个设计模式(四) - 原型模式(Prototype)/","link":"","permalink":"https://ostenant.coding.me/2017/12/21/一天一个设计模式(四) - 原型模式(Prototype)/","excerpt":"前言原型模式属于对象的创建模式。通过给出一个原型对象来指明所有创建的对象的类型，然后用这个原型对象提供的复制办法创建出更多同类型的对象。","text":"前言原型模式属于对象的创建模式。通过给出一个原型对象来指明所有创建的对象的类型，然后用这个原型对象提供的复制办法创建出更多同类型的对象。 原型模式的结构原型模式要求对象实现一个可以克隆自身的接口(类型)。这样一来，通过原型实例创建新的对象，就不需要关心这个实例本身的类型，只需要实现克隆自身的方法，也而无需再去通过new来创建。 原型类型的表现形式 简单形式 登记形式 正文简单形式 相关角色 客户(Client)角色：客户类提出创建对象的请求； 抽象原型(Prototype)角色：这是一个抽象角色，通常由一个Java接口或者Java抽象类实现。此角色定义了的具体原型类所需的实现的方法。 具体原型(Concrete Prototype)角色：此角色需要实现抽象原型角色要求的克隆相关的接口。 示例代码Prototype.java 123456789101112131415161718192021222324/** * 抽象原型角色 */public abstract class Prototype &#123; private String id; public Prototype(String id) &#123; this.id = id; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; /** * 克隆自身的方法 * @return 一个从自身克隆出来的对象。 */ public abstract Prototype clone();&#125; ConcretePrototype1.java 12345678910public class ConcretePrototype1 extends Prototype &#123; public ConcretePrototype1(String id) &#123; super(id); &#125; public Prototype clone() &#123; Prototype prototype = new ConcretePrototype1(this.getId()); return prototype; &#125;&#125; ConcretePrototype2.java 12345678910public class ConcretePrototype2 extends Prototype &#123; public ConcretePrototype2(String id) &#123; super(id); &#125; public Prototype clone() &#123; Prototype prototype = new ConcretePrototype2(this.getId()); return prototype; &#125;&#125; 运行结果 登记形式 相关角色 客户(Client)角色：客户类提出创建对象的请求； 抽象原型(Prototype)角色：这是一个抽象角色，通常由一个Java接口或者Java抽象类实现。此角色定义了的具体原型类所需的实现的方法。 具体原型(Concrete Prototype)角色：此角色需要实现抽象原型角色要求的克隆相关的接口。 原型管理器(Prototype Manager)角色：提供各种原型对象的创建和管理。 示例代码除了原型管理器Prototype Manager以外，登记模式和简单模式并无其他差异。 Prototype.javaW12345public interface Prototype &#123; public Prototype clone(); public String getName(); public void setName(String name);&#125; ConcretePrototype1.java1234567891011121314151617181920212223242526public class ConcretePrototype1 implements Prototype &#123; private String name; @Override public String getName() &#123; return this.name; &#125; @Override public void setName(String name) &#123; this.name = name; &#125; @Override public Prototype clone() &#123; Prototype prototype = new ConcretePrototype1(); prototype.setName(this.name); return prototype; &#125; @Override public String toString() &#123; return \"ConcretePrototype1 [name=\" + name + \"]\"; &#125;&#125; ConcretePrototype2.java12345678910111213141516171819202122232425public class ConcretePrototype2 implements Prototype &#123; private String name; @Override public String getName() &#123; return this.name; &#125; @Override public void setName(String name) &#123; this.name = name; &#125; @Override public Prototype clone() &#123; Prototype prototype = new ConcretePrototype2(); prototype.setName(this.name); return prototype; &#125; @Override public String toString() &#123; return \"ConcretePrototype2 [name=\" + name + \"]\"; &#125;&#125; PrototypeManager.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class PrototypeManager &#123; /** * 用来记录原型的编号同原型实例的对象关系 */ private static Map&lt;String, Prototype&gt; map = new HashMap&lt;&gt;(); /** * 私有化构造方法，避免从外部创建实例 */ private PrototypeManager() &#123; &#125; /** * 向原型管理器里面添加或者修改原型实例 * * @param prototypeId 原型编号 * @param prototype 原型实例 */ public static void setProtoType(String prototypeId, Prototype prototype) &#123; map.put(prototypeId, prototype); &#125; /** * 根据原型编号从原型管理器里面移除原型实例 * * @param prototypeId 原型编号 */ public static void removePrototype(String prototypeId) &#123; map.remove(prototypeId); &#125; /** * 根据原型编号获取原型实例 * * @param prototypeId 原型编号 * @return 原型实例对象 * @throws Exception 如果根据原型编号无法获取对应实例，则提示异常“您希望获取的原型还没有注册或已被销毁” */ public static Prototype getPrototype(String prototypeId) throws Exception &#123; Prototype prototype = map.get(prototypeId); if (prototype == null) &#123; throw new Exception(\"您希望获取的原型还没有注册或已被销毁\"); &#125; return prototype; &#125;&#125; Client.java12345678910111213141516171819202122232425262728293031323334public class Client &#123; public static void main(String[] args) &#123; try &#123; // 创建第一个实例 Prototype p1 = new ConcretePrototype1(); // 注册第一个实例 PrototypeManager.setProtoType(\"p1\", p1); // 克隆第一个实例的原型 Prototype p3 = PrototypeManager.getPrototype(\"p1\").clone(); p3.setName(\"张三\"); System.out.println(\"第一个实例的副本：\" + p3); // 创建第二个实例 Prototype p2 = new ConcretePrototype2(); // 注册第二个实例 PrototypeManager.setProtoType(\"p2\", p2); // 克隆第二个实例的原型 Prototype p4 = PrototypeManager.getPrototype(\"p2\").clone(); p4.setName(\"李四\"); System.out.println(\"第二个实例的副本：\" + p4); // 注销第一个实例 PrototypeManager.removePrototype(\"p1\"); // 再次克隆第一个实例的原型 Prototype p5 = PrototypeManager.getPrototype(\"p1\").clone(); p5.setName(\"王五\"); System.out.println(\"第一个实例的副本：\" + p5); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 运行结果 两者之间的比较简单形式和登记形式的原型模式各有其长处和短处。 如果要创建的原型对象数据较少而且比较固定的话，可以采用第一种形式。在这种情况下，原型对象的引用可以由客户端自己保存。 如果要创建的原型对象数据不固定的话，可以采用第二种形式。在这种情况下，客户端不保存对原型对象的引用，这个任务被交给原型管理器角色。在克隆一个对象之前，客户端可以查看管理员对象是否已经有一个满足要求的原型对象。如果有，可以从原型管理器角色中取得这个对象引用；如果没有，客户端就需要自行复制此原型对象。 总结原型模式的优点原型模式允许在运行时动态改变具体的实现类型。原型模式可以在运行期间，有客户来注册符合原型接口的实现类型，也可以动态的改变具体的实现类型，看起来接口没有任何变化，但是其实运行的已经是另外一个类实体了。因为克隆一个原型对象就类似于实例化一个类。 原型模式的缺点原型模式最主要的缺点是每一个类都必须要配备一个克隆方法。配备克隆方法需要对类的功能进行通盘考虑，这对于全新的类来说并不是很难，但是对于已有的类来说并不容易。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA设计模式系列","slug":"JAVA设计模式系列","permalink":"https://ostenant.coding.me/categories/JAVA设计模式系列/"}],"tags":[{"name":"Prototype","slug":"Prototype","permalink":"https://ostenant.coding.me/tags/Prototype/"}]},{"title":"一天一个设计模式(三) - 建造者模式(Builder)","slug":"一天一个设计模式(三) - Builder建造者模式","date":"2017-12-19T09:20:00.000Z","updated":"2018-06-18T01:52:24.170Z","comments":true,"path":"2017/12/19/一天一个设计模式(三) - Builder建造者模式/","link":"","permalink":"https://ostenant.coding.me/2017/12/19/一天一个设计模式(三) - Builder建造者模式/","excerpt":"前言建造模式是对象的创建模式。建造模式可以将一个产品的内部表象(internal representation)与产品的生产过程分割开来，从而可以使一个建造过程生成具有不同的内部表象的产品对象。","text":"前言建造模式是对象的创建模式。建造模式可以将一个产品的内部表象(internal representation)与产品的生产过程分割开来，从而可以使一个建造过程生成具有不同的内部表象的产品对象。 (一). 产品的内部表象一个产品常有不同的组成成分作为产品的零件，这些零件有可能是对象，也有可能不是对象，他们通常又称为产品的内部表象(internal representation)。 (二). 对象性质的建造有些情况下，一个对象会有些重要的性质，在它们没有正确赋值之前，对象不能作为一个完整的产品使用。比如：一个电子邮件有发件人地址、收件人地址、主题、内容、附件等部分，而在最基本的发件人地址得到赋值之前，这个电子邮件是不可以发送的。 有些情况下，一个对象的有些性质必须按照某个顺序赋值才有意义。在某个性质没有赋值之前，另一个性质则无法赋值。 这些情况使得性质本身的建造设计到复杂的业务逻辑。设置后，此对象相当于一个有待建造的产品，而对象的这些性质相当于产品的零件，建造产品的过程是建造零件的过程。 由于建造零件的过程很复杂，因此，这些零件的建造过程往往被外部化到另一个成为建造者的对象中，建造者对象返还给客户端的是一个全部零件都建造完毕的产品对象。 建造模式利用一个导演者对象和具体建造者对象一个个的建造出所有的零件，从而建造出完整的产品对象。建造者模式将产品的结构和产品的零件的建造过程对客户端隐藏起来，把对建造过程进行指挥的责任和具体建造者零件的责任分割开来，达到责任划分和封装的目的。 正文建造模式的结构 在这个示意的系统里，最终产品Product只有两个零件，即part1和part2。相应的构造方法也有两个，即buildPart1()和buildPart2()。 同时可以看出本模式涉及到四个角色，它们分别为： 抽象建造者(Builder)：给出一个抽象接口，以规范产品对象的各个组成成分的建造。模式中真正创建产品对象的是具体建造者ConcreteBuilder角色。 具体建造者类必须实现这个接口要求的两种方法： 一种是产品具体零件建造方法：buildPart1()和buildPart2()； 另一种是返回构造完成的产品的方法retrieveResult()。 一般来说，产品所包含的零件数目与建造方法的数目相符。换言之，有多少零件需要建造，就会有多少相应的建造方法。 具体建造者(ContreteBuilder)：担任这个角色的是抽象建造者在具体业务场景的下的建造实现。这个角色要完成的任务包括： 实现抽象建造者Builder所声明的接口，给出一步步完成创建产品实例的操作。 在建造过程完成后，提供产品的实例。 导演者(Director)：担任这个角色的类调用具体建造者角色以创建产品对象。应当指出的是，导演者角色并没有产品类的具体知识，真正拥有产品类的具体知识的是具体建造者角色。 产品(Product)：产品便是建造中的复杂对象，一般来说，一个系统中会有多于一个的产品类，而且这些产品类并不一定有共同的接口，而完全可以是不相关联的。 建造模式的示例代码Product.java12345678910111213141516171819202122232425public class Product &#123; /** * 产品零件 */ private String part1; private String part2; public String getPart1() &#123; return part1; &#125; public void setPart1(String part1) &#123; this.part1 = part1; &#125; public String getPart2() &#123; return part2; &#125; public void setPart2(String part2) &#123; this.part2 = part2; &#125; @Override public String toString() &#123; return \"Product [part1=\" + part1 + \", part2=\" + part2 + \"]\"; &#125;&#125; Builder.java 1234567891011/** * 抽象建造者角色 * * 提供零件建造方法及返回结果方法 */public interface Builder &#123; void buildPart1(); void buildPart2(); Product retrieveResult();&#125; ConcreteBuilder.java 123456789101112131415161718192021222324252627282930313233/** * 具体建造者角色 */public class ConcreteBuilder implements Builder &#123; private Product product = new Product(); /** * 建造零件1 */ @Override public void buildPart1() &#123; product.setPart1(\"零件分类1，编号：10000\"); &#125; /** * 建造零件2 */ @Override public void buildPart2() &#123; product.setPart2(\"零件分类2，编号：20000\"); &#125; /** * 返回建造后成功的产品 * @return */ @Override public Product retrieveResult() &#123; return product; &#125;&#125; Director.java 123456789101112131415161718192021222324252627/** * 导演者角色 */public class Director &#123; /** * 创建建造者对象 */ private Builder builder; /** * 构造函数，给定建造者对象 * @param builder 建造者对象 */ public Director(Builder builder) &#123; this.builder = builder; &#125; /** * 产品构造方法，在该方法内，调用产品零件建造方法。 */ public Product construct()&#123; builder.buildPart1(); builder.buildPart2(); // 返回builder建造完成的产品对象 return builder.construct(); &#125;&#125; Client.java 1234567891011public class Client &#123; public static void main(String[] args) &#123; //创建具体建造者对象 Builder builder = new ConcreteBuilder(); //创造导演者角色，给定建造者对象 Director director = new Director(builder); //调用导演者角色，创建产品零件。并返回产品建造结果。 Product product = director.construct(); System.out.println(product); &#125;&#125; 上述代码完成的具体步骤： 客户端创建具体建造者对象； 将具体建造者对象交给导演者； 导演者操作建造者对象建造产品零件； 当产品创建完成后，导演者将产品返回给客户端。 建造者模式构建复杂对象考虑这样一个实际业务应用，要创建一个保险合同的对象，里面很多属性的值都有约束，要求创建出来的对象是满足这些约束规则的。 约束规则如下： 保险合同通常情况下可以和个人签订，也可以和某个公司签订个，但是一份保险合同不能同时和个人和公司签订。这个对象里有很多类似于这样的约束，采用建造者模式来构建复杂的对象，通常会对建造者模式进行一定的简化，因为目标明确，就是创建某个复杂对象，因此做适当的简化会使得程序更简介。 具体实现思路如下： 由于是用Builder建造者模式来创建某个对象，因此就没有必要再定义一个Builder接口，直接提供一个具体的建造类就可以了。 对于创建一个复杂的对象，可能会有很多种不同的选择和步骤，干脆去掉导演者Director，把导演者的功能和Client客户端的功能合并起来，也就是说Client客户端的功能就相当于导演者，它来指导建造者去构建需要的复杂对象。 于是，建造者(Builder)可以抽象到目标产品(Product)的内部，这样最大的好处对外屏蔽掉具体的建造实现，是示例代码如下： InstranceContract.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125/** * 保险合同编号 */public class InstranceContract &#123; /** * 保险合同编号 */ private String contractId; /** * 受保人名称，此处因为有限制条件：要么同个人签订，要么同公司签订 * 也就是说，受保人名称属性同受保公司名称属性不能同时有值。 */ private String personName; /** * 受保公司名称 */ private String companyName; /** * 开始时间 */ private long beginDate; /** * 结束时间，需要大于开始时间 */ private long endDate; /** * 其他数据 */ private String otherData; private InstranceContract(ConcreteBuilder builder)&#123; this.contractId = builder.contractId; this.personName = builder.personName; this.companyName = builder.companyName; this.beginDate = builder.beginDate; this.endDate = builder.endDate; this.otherData = builder.otherData; &#125; /** * 保险合同的一些操作 */ public void someOperation()&#123; System.out.println(\"当前正在操作的保险合同编号为【\"+this.contractId+\"】\"); System.out.println(this); &#125; @Override public String toString() &#123; return \"InstranceContract [contractId=\" + contractId + \", personName=\" + personName + \", companyName=\"+ companyName + \", beginDate=\" + beginDate + \", endDate=\" + endDate + \", otherData=\" + otherData + \"]\"; &#125; public static class ConcreteBuilder &#123; private String contractId; private String personName; private String companyName; private long beginDate; private long endDate; private String otherData; /** * 构造方法 * @param contractId 保险合同编号 * @param beginDate 生效时间 * @param endDate 失效时间 */ public ConcreteBuilder(String contractId, long beginDate, long endDate) &#123; this.contractId = contractId; this.beginDate = beginDate; this.endDate = endDate; &#125; public ConcreteBuilder setPersonName(String personName) &#123; this.personName = personName; return this; &#125; public ConcreteBuilder setCompanyName(String companyName) &#123; this.companyName = companyName; return this; &#125; public ConcreteBuilder setOtherData(String otherData) &#123; this.otherData = otherData; return this; &#125; public InstranceContract build() &#123; if (contractId == null || contractId.trim().length() == 0) &#123; throw new IllegalArgumentException(\"合同编号不能为空\"); &#125; boolean signPerson = (personName != null &amp;&amp; personName.trim().length() &gt; 0); boolean signCompany = (companyName != null &amp;&amp; companyName.trim().length() &gt; 0); if (signPerson &amp;&amp; signCompany) &#123; throw new IllegalArgumentException(\"一份保险合同不能同时与个人和公司签订\"); &#125; if (!signPerson &amp;&amp; !signCompany) &#123; throw new IllegalArgumentException(\"一份保险合同不能没有签订对象\"); &#125; if (beginDate &lt;= 0) &#123; throw new IllegalArgumentException(\"一份保险合同必须有生效的日期\"); &#125; if (endDate &lt;= 0) &#123; throw new IllegalArgumentException(\"一份保险合同必须有失效的日期\"); &#125; if (endDate &lt;= beginDate) &#123; throw new IllegalArgumentException(\"一份保险合同的失效日期必须要大于生效的日期\"); &#125; return new InstranceContract(this); &#125; &#125;&#125; 客户端(Client)、导演者(Director)合并到一个类上面，如下： 123456789101112public class Client &#123; public static void main(String[] args) &#123; InstranceContract.ConcreteBuilder builder = new InstranceContract.ConcreteBuilder(\"8888\", 1233L, 2253L); // 导演者进行组装 InstranceContract contract = builder.setPersonName(\"赵四\").setOtherData(\"测试数据\").build(); contract.someOperation(); &#125;&#125; 总结建造者模式主要适用于如下的业务场景： 内部结构复杂： 需要生成的产品对象有复杂的内部结构，每一个内部组件本身也可以是复杂对象，也可以仅仅是一个简单的组成部分。 属性顺序和依赖： 需要生成的产品对象的属性相互依赖。建造模式可以强制实行一种分步骤顺序进行的建造过程。因此，如果产品对象的一个属性必须在另外一个属性赋值之后才可以被赋值，那么，使用建造者模式是一个很好的设计思想。 属性获取过程复杂： 在对象创建过程中会使用到系统中的一些其他对象，这些对象在产品对象的创建过程中不易得到。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA设计模式系列","slug":"JAVA设计模式系列","permalink":"https://ostenant.coding.me/categories/JAVA设计模式系列/"}],"tags":[{"name":"Builder","slug":"Builder","permalink":"https://ostenant.coding.me/tags/Builder/"}]},{"title":"Java NIO系列(一) - 概述","slug":"Java NIO系列(一) - 概述","date":"2017-12-19T03:23:00.000Z","updated":"2018-06-18T01:45:30.648Z","comments":true,"path":"2017/12/19/Java NIO系列(一) - 概述/","link":"","permalink":"https://ostenant.coding.me/2017/12/19/Java NIO系列(一) - 概述/","excerpt":"前言Java NIO全称java non-blocking IO，是指jdk1.4及以上版本里提供的新api(New IO)，为所有的原始类型(boolean类型除外)提供缓存支持的数据容器，使用它可以提供非阻塞式的高伸缩性网络。","text":"前言Java NIO全称java non-blocking IO，是指jdk1.4及以上版本里提供的新api(New IO)，为所有的原始类型(boolean类型除外)提供缓存支持的数据容器，使用它可以提供非阻塞式的高伸缩性网络。 Java NIO提供了与标准IO不同的IO工作方式，Channel、Buffer和Selector构成了核心的API。其它组件，如Pipe和FileLock，只不过是与三个核心组件共同使用的工具类。 通道和缓冲区 (Channel and Buffer)： 标准的IO基于字节流和字符流进行单向的数据读写操作。而NIO是基于通道(Channel)和缓冲区(Buffer)进行操作，数据总是从通道中读取到缓冲区中，或者从缓冲区中写入到通道中。 异步IO (Asynchronous IO)： Java NIO可以让你异步的使用IO，例如：当线程从通道读取数据到缓冲区时，线程还是可以进行其他事情；当数据被线程写入到缓冲区时，线程可以继续处理它。从缓冲区写入通道也类似。 选择器 (Selector)： Java NIO引入了选择器的概念，选择器用于监听多个通道的事件（比如：连接打开，数据读取和数据写入）。因此，单个的线程可以监听多个数据通道。 下面就来详细介绍Java NIO的相关知识。 正文1. Java NIO概述Java NIO由以下几个核心部分组成： Channel Buffer Selector 1.1. Channel和Buffer基本上，所有的IO 在NIO中都从一个Channel`开始： 通道Channel有点像流(Stream)，两者可以做个简单对比： 流是单向的，一个流对象要么是输出流、要么是输入流。 通道是全双工的，一个通道通常搭配缓存一起使用。数据可以从Channel读到Buffer中，也可以从Buffer写到Channel中。 这里有个图示： Channel和Buffer`有好几种类型。 JAVA NIO中的一些主要Channel的实现，主要涵盖了文件IO和UDP、TCP的网络IO： FileChannel：从文件中读写数据 ServerSocketChannel：能通过UDP读写网络中的数据 SocketChannel：能通过TCP读写网络中的数据 DatagramChannel：可以监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。 JAVA NIO中关键的Buffer实现，涵盖了除boolean的其余7种基本数据类型(byte、short、int、long、float、double 和 char)： ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 1.2. SelectorSelector允许单线程处理多个Channel的连接事件和数据读写。如果你的应用打开了多个连接（通道），但每个连接的流量都很低，使用Selector就会很方便，例如：一个聊天服务器。 这是在一个单线程中使用一个Selector处理3个Channel的图示： 要使用Selector，得向Selector注册Channel，然后调用它的select()方法。这个方法会一直阻塞到某个注册的通道有事件就绪。一旦这个方法返回，线程就可以处理这些事件。 事件类型主要包括：新连接进来、数据接收、数据发送等。 2. Java NIO对比IO上面提到了NIO主要的组件和特性，在实际的IO操作中，应该如何在标准IO和NIO进行选择，这里就需要具体对比两者的差异，并引入一些概念。 IO NIO 底层读写实现 面向流读写 面向缓冲区读写 是否有选择器 无 基于选择器的事件分离 IO是否阻塞 阻塞式IO 非阻塞式IO 2.1. 底层读写实现Java NIO和IO之间第一个最大的区别是，IO是面向流的，NIO是面向缓冲区的。 面向流 Java IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。 面向缓冲区 Java NIO的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。 2.2. 是否有选择器Java NIO的选择器允许一个单独的线程来监视多个输入通道。 IO的读写速度和CPU的处理速度相差了一个数量级，导致IO事件延长了CPU的空闲等待时间，导致性能上的瓶颈。为了尽量的缩短CPU的等待时间，在单个IO操作进行时CPU可以抽出身来去做别的事情(其他IO)，NIO引入单线程处理多IO事件的概念，从而充分利用CPU分配的资源。 Java NIO允许已注册的多个通道使用一个选择器，然后使用一个单独的线程来选择通道。这种选择机制，使得一个单线程很容易地管理多个通道。 2.3. IO是否阻塞所谓阻塞，就是线程在进行IO操作时，不能抽出身来去干其他事情，必须等待数据读写完成。 Java IO的各种流是阻塞的。 当一个线程调用read()或write()时，该线程被阻塞，直到有一些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情。 Java NIO的非阻塞的。 当监听某个通道的读操作事件时，线程向该通道发送请求读取数据，之后这个线程就可以去干别的事情。 当监听某个通道的写操作事件时，线程向请求向该通道写入数据，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道(channel)。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA编程进阶系列","slug":"JAVA编程进阶系列","permalink":"https://ostenant.coding.me/categories/JAVA编程进阶系列/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"},{"name":"NIO","slug":"NIO","permalink":"https://ostenant.coding.me/tags/NIO/"}]},{"title":"Java基础篇 - 强引用、弱引用、软引用和虚引用","slug":"Java基础篇 - 强引用、弱引用、软引用和虚引用","date":"2017-12-18T07:38:00.000Z","updated":"2018-06-18T01:48:16.250Z","comments":true,"path":"2017/12/18/Java基础篇 - 强引用、弱引用、软引用和虚引用/","link":"","permalink":"https://ostenant.coding.me/2017/12/18/Java基础篇 - 强引用、弱引用、软引用和虚引用/","excerpt":"前言Java执行GC判断对象是否存活有两种方式其中一种是引用计数。","text":"前言Java执行GC判断对象是否存活有两种方式其中一种是引用计数。 引用计数：Java堆中每一个对象都有一个引用计数属性，引用每新增1次计数加1，引用每释放1次计数减1。 在JDK 1.2以前的版本中，若一个对象不被任何变量引用，那么程序就无法再使用这个对象。也就是说，只有对象处于(reachable)可达状态，程序才能使用它。 从JDK 1.2版本开始，对象的引用被划分为4种级别，从而使程序能更加灵活地控制对象的生命周期。这4种级别由高到低依次为：强引用、软引用、弱引用和虚引用。 正文(一) 强引用(StrongReference)强引用是使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。如下： 1Object strongReference = new Object(); 当内存空间不足时，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。如果强引用对象不使用时，需要弱化从而使GC能够回收，如下： 1strongReference = null; 显式地设置strongReference对象为null，或让其超出对象的生命周期范围，则gc认为该对象不存在引用，这时就可以回收这个对象。具体什么时候收集这要取决于GC算法。 1234public void test() &#123; Object strongReference = new Object(); // 省略其他操作&#125; 在一个方法的内部有一个强引用，这个引用保存在Java栈中，而真正的引用内容(Object)保存在Java堆中。当这个方法运行完成后，就会退出方法栈，则引用对象的引用数为0，这个对象会被回收。 但是如果这个strongReference是全局变量时，就需要在不用这个对象时赋值为null，因为强引用不会被垃圾回收。 ArrayList的Clear方法： 在ArrayList类中定义了一个elementData数组，在调用clear方法清空数组时，每个数组元素被赋值为null。不同于elementData=null，强引用仍然存在，避免在后续调用add()等方法添加元素时进行内存的重新分配。使用如clear()方法内存数组中存放的引用类型进行内存释放特别适用，这样就可以及时释放内存。 (二) 软引用(SoftReference)如果一个对象只具有软引用，则内存空间充足时，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。 软引用可用来实现内存敏感的高速缓存。 12345// 强引用String strongReference = new String(\"abc\");// 软引用String str = new String(\"abc\");SoftReference&lt;String&gt; softReference = new SoftReference&lt;String&gt;(str); 软引用可以和一个引用队列(ReferenceQueue)联合使用。如果软引用所引用对象被垃圾回收，JAVA虚拟机就会把这个软引用加入到与之关联的引用队列中。 123456789101112ReferenceQueue&lt;String&gt; referenceQueue = new ReferenceQueue&lt;&gt;();String str = new String(\"abc\");SoftReference&lt;String&gt; softReference = new SoftReference&lt;&gt;(str, referenceQueue);str = null;// Notify GCSystem.gc();System.out.println(softReference.get()); // abcReference&lt;? extends String&gt; reference = referenceQueue.poll();System.out.println(reference); //null 注意：软引用对象是在jvm内存不够的时候才会被回收，我们调用System.gc()方法只是起通知作用，JVM什么时候扫描回收对象是JVM自己的状态决定的。就算扫描到软引用对象也不一定会回收它，只有内存不够的时候才会回收。 当内存不足时，JVM首先将软引用中的对象引用置为null，然后通知垃圾回收器进行回收： 123456if(JVM内存不足) &#123; // 将软引用中的对象引用置为null str = null; // 通知垃圾回收器进行回收 System.gc();&#125; 也就是说，垃圾收集线程会在虚拟机抛出OutOfMemoryError之前回收软引用对象，而且虚拟机会尽可能优先回收长时间闲置不用的软引用对象。对那些刚构建的或刚使用过的“较新的”软对象会被虚拟机尽可能保留，这就是引入引用队列ReferenceQueue的原因。 应用场景： 浏览器的后退按钮。按后退时，这个后退时显示的网页内容是重新进行请求还是从缓存中取出呢？这就要看具体的实现策略了。 如果一个网页在浏览结束时就进行内容的回收，则按后退查看前面浏览过的页面时，需要重新构建； 如果将浏览过的网页存储到内存中会造成内存的大量浪费，甚至会造成内存溢出。 这时候就可以使用软引用，很好的解决了实际的问题： 1234567891011121314151617// 获取浏览器对象进行浏览Browser browser = new Browser();// 从后台程序加载浏览页面BrowserPage page = browser.getPage();// 将浏览完毕的页面置为软引用SoftReference softReference = new SoftReference(page);// 回退或者再次浏览此页面时if(softReference.get() != null) &#123; // 内存充足，还没有被回收器回收，直接获取缓存 page = softReference.get();&#125; else &#123; // 内存不足，软引用的对象已经回收 page = browser.getPage(); // 重新构建软引用 softReference = new SoftReference(page);&#125; (三) 弱引用(WeakReference)弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。 123String str = new String(\"abc\");WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str);str = null; JVM首先将软引用中的对象引用置为null，然后通知垃圾回收器进行回收： 12str = null;System.gc(); 注意：如果一个对象是偶尔(很少)的使用，并且希望在使用时随时就能获取到，但又不想影响此对象的垃圾收集，那么你应该用Weak Reference来记住此对象。 下面的代码会让一个弱引用再次变为一个强引用： 1234String str = new String(\"abc\");WeakReference&lt;String&gt; weakReference = new WeakReference&lt;&gt;(str);// 弱引用转强引用String strongReference = weakReference.get(); 同样，弱引用可以和一个引用队列(ReferenceQueue)联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 简单测试： GCTarget.java 12345678910111213141516public class GCTarget &#123; // 对象的ID public String id; // 占用内存空间 byte[] buffer = new byte[1024]; public GCTarget(String id) &#123; this.id = id; &#125; protected void finalize() throws Throwable &#123; // 执行垃圾回收时打印显示对象ID System.out.println(\"Finalizing GCTarget, id is : \" + id); &#125;&#125; GCTargetWeakReference.java 1234567891011121314public class GCTargetWeakReference extends WeakReference&lt;GCTarget&gt; &#123; // 弱引用的ID public String id; public GCTargetWeakReference(GCTarget gcTarget, ReferenceQueue&lt;? super GCTarget&gt; queue) &#123; super(gcTarget, queue); this.id = gcTarget.id; &#125; protected void finalize() &#123; System.out.println(\"Finalizing GCTargetWeakReference \" + id); &#125;&#125; WeakReferenceTest.java 1234567891011121314151617181920212223242526272829303132333435363738public class WeakReferenceTest &#123; // 弱引用队列 private final static ReferenceQueue&lt;GCTarget&gt; REFERENCE_QUEUE = new ReferenceQueue&lt;&gt;(); public static void main(String[] args) &#123; LinkedList&lt;GCTargetWeakReference&gt; gcTargetList = new LinkedList&lt;&gt;(); // 创建弱引用的对象，依次加入链表中 for (int i = 0; i &lt; 5; i++) &#123; GCTarget gcTarget = new GCTarget(String.valueOf(i)); GCTargetWeakReference weakReference = new GCTargetWeakReference(gcTarget, REFERENCE_QUEUE); gcTargetList.add(weakReference); System.out.println(\"Just created GCTargetWeakReference obj: \" + gcTargetList.getLast()); &#125; // 通知GC进行垃圾回收 System.gc(); try &#123; // 休息几分钟，等待上面的垃圾回收线程运行完成 Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 检查关联的引用队列是否为空 Reference&lt;? extends GCTarget&gt; reference; while((reference = REFERENCE_QUEUE.poll()) != null) &#123; if(reference instanceof GCTargetWeakReference) &#123; System.out.println(\"In queue, id is: \" + ((GCTargetWeakReference) (reference)).id); &#125; &#125; &#125;&#125; 运行WeakReferenceTest.java，运行结果如下： 可见WeakReference对象的生命周期基本由垃圾回收器决定，一旦垃圾回收线程发现了弱引用对象，在下一次GC过程中就会对其进行回收。 (四) 虚引用(PhantomReference)虚引用顾名思义，就是形同虚设。与其他几种引用都不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。 应用场景： 虚引用主要用来跟踪对象被垃圾回收器回收的活动。虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列(ReferenceQueue)联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 1234String str = new String(\"abc\");ReferenceQueue queue = new ReferenceQueue();// 创建虚引用，要求必须与一个引用队列关联PhantomReference pr = new PhantomReference(str, queue); 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要进行垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 总结 Java中4种引用的级别和强度由高到低依次为：强引用 -&gt; 软引用 -&gt; 弱引用 -&gt; 虚引用 当垃圾回收器回收时，某些对象会被回收，某些不会被回收。垃圾回收器会从根对象Object来标记存活的对象，然后将某些不可达的对象和一些引用的对象进行回收。 通过表格来说明一下，如下： 引用类型 被垃圾回收时间 用途 生存时间 强引用 从来不会 对象的一般状态 JVM停止运行时终止 软引用 当内存不足时 对象缓存 内存不足时终止 弱引用 正常垃圾回收时 对象缓存 垃圾回收后终止 虚引用 正常垃圾回收时 跟踪对象的垃圾回收 垃圾回收后终止 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"Java编程基础系列","slug":"Java编程基础系列","permalink":"https://ostenant.coding.me/categories/Java编程基础系列/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"},{"name":"Reference","slug":"Reference","permalink":"https://ostenant.coding.me/tags/Reference/"}]},{"title":"Java 8系列(二) - JDK1.8函数式接口详解","slug":"Java 8系列(二) - JDK1.8函数式接口详解","date":"2017-07-05T02:24:00.000Z","updated":"2018-06-18T01:45:39.275Z","comments":true,"path":"2017/07/05/Java 8系列(二) - JDK1.8函数式接口详解/","link":"","permalink":"https://ostenant.coding.me/2017/07/05/Java 8系列(二) - JDK1.8函数式接口详解/","excerpt":"简述函数式接口的概念函数式接口本质上还是一个接口，但是它是一种特殊的SAM类型的接口（Single Abstract Method）。","text":"简述函数式接口的概念函数式接口本质上还是一个接口，但是它是一种特殊的SAM类型的接口（Single Abstract Method）。 函数式接口的使用 一个函数式接口只能声明一个抽象方法； JDK1.8中的默认方法(default)和静态方法(static)都不算抽象方法 函数式接口默认继承了Java.lang.Object，覆盖了Object类中的所有方法，equals(Object)、hashCode()、clone()、toString()等方法都不算为抽象方法； 如果接口被标注了@FunctionalInterface，这个类就必须符合函数式接口的规范。即使一个接口没有标注@FunctionalInterface，如果这个接口满足函数式接口规则，依旧被当作函数式接口。 JDK中以前所有的函数式接口都已经使用@FunctionalInterface定义，可以通过查看JDK1.8源码来确认，以下附JDK 8之前已有的函数式接口： java.lang.Runnable java.util.concurrent.Callable java.security.PrivilegedAction java.util.Comparator java.io.FileFilter java.nio.file.PathMatcher java.lang.reflect.InvocationHandler java.beans.PropertyChangeListener java.awt.event.ActionListener javax.swing.event.ChangeListener 函数式接口的意义函数式接口使得Lambda表达式能够作为方法调用的参数。一旦我们调用某方法，可以传入lambda表达式作为参数，那么这个方法的参数类型，必定是一个函数式的接口，这个类型必定会使用@FunctionalInterface进行修饰。 正文Java8里关于函数式接口的包是java.util.function，里面全部是函数式接口。主要包含几大类：Function、Predicate、Supplier和Consumer，如图所示： JDK1.8内置的几个函数式接口 接口名称 抽象方法 方法含义 Function R apply(T) 就是函数映射的意思，一个输入，一个相应的输出。 Predicate boolean test(T) 表示判断。输入一个对象，返回布尔值。 Consumer void accept(T) 消费一个操作。输入一个对象，处理（消费）完后不返回值。 Supplier T get() 直接返回一个对象。 其他的接口无非是基于以上几个接口给出的扩展，下面依次对这几个接口展开讨论： Function接口Function接口接收一个参数，并返回单一的结果。默认方法可以将多个函数串在一起（compose, andThen）。首先查看Function接口的源码： 123456789101112131415161718@FunctionalInterfacepublic interface Function&lt;T, R&gt; &#123; R apply(T t); default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) &#123; Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v)); &#125; default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t)); &#125; static &lt;T&gt; Function&lt;T, T&gt; identity() &#123; return t -&gt; t; &#125;&#125; Function接口使用@FunctionalInterface标识，表明此接口为函数式接口，有且只能有一个抽象方法； Function泛型规定了T、R分别对应Lambda表达式的输入参数类型和输出参数类型； Function定义了compose、andThen两个默认方法和静态方法identity。 apply()1R apply(T t); 把Function&lt;T, R&gt;对象运用于输入的参数t中，即执行传入的满足Function定义（一个输入、一个输出）的Lambda表达式的方法体，返回R类型输出结果r。 compose()1234default &lt;V&gt; Function&lt;V, R&gt; compose(Function&lt;? super V, ? extends T&gt; before) &#123; Objects.requireNonNull(before); return (V v) -&gt; apply(before.apply(v));&#125; 构建一个Lambda表达式，输入类型为V，输出类型为R； 先传入before对象的apply方法 – before.apply(v) – 其中before对象的类型为Function&lt;V, T&gt;，其输入为类型V，输出为类型T； 再传入当前对象的apply方法 – apply(before.apply(v)) – 其中当前对象的类型为Function&lt;T, R&gt;，其输入类型为T，输出类型为R。 最终构造出输入类型为V，输出类型为R的函数接口(中间转换结果类型为T)：Function&lt;V, R&gt; – 对应的Lambda表达式为：(V v) -&gt; apply(before.apply(v))。 andThen()1234default &lt;V&gt; Function&lt;T, V&gt; andThen(Function&lt;? super R, ? extends V&gt; after) &#123; Objects.requireNonNull(after); return (T t) -&gt; after.apply(apply(t));&#125; 构建一个Lambda表达式，输入类型为T，输出类型为V； 先传入当前对象对象的apply方法 – apply(t) – 其中当前对象的类型为Function&lt;T, R&gt;，其输入为类型T，输出为类型R； 再传入after对象的apply方法 – after.apply(apply(t)) – 其中after对象的类型为Function&lt;R, V&gt;，其输入类型为R，输出类型为V。 最终构造出输入类型为T，输出类型为V的函数接口(中间转换结果类型为R)：Function&lt;T, V&gt; – 对应的Lambda表达式为：(T t) -&gt; after.apply(apply(t))。 identity()123static &lt;T&gt; Function&lt;T, T&gt; identity() &#123; return t -&gt; t;&#125; 返回一个输入类型和输出类型都为T的Function对象。 案例12345678910111213@Testpublic void test() throws Exception &#123; // 创建一个Function对象 Function&lt;String, Integer&gt; function = x -&gt; Integer.parseInt(x) * 10; // 1. apply()方法 System.out.println(function.apply(\"10\")); // 2. compose()方法 System.out.println(function.compose((String y) -&gt; y.substring(1)).apply(\"a10\")); // 3. andThen()方法 System.out.println(function.andThen((Integer x) -&gt; \"[\" + x + \"]\").apply(\"10\")); // 4. identity()静态方法。identity()本来就是一个函数式接口 System.out.println(Function.identity().apply(10));&#125; 输出结果： 100100[100]10 Predicate接口Predicate接口接收一个参数，并返回boolean类型的返回值。默认方法可以将多个函数串在一起（and, or, negate）。首先查看Predicate接口接口的源码： 123456789101112131415161718192021222324@FunctionalInterfacepublic interface Predicate&lt;T&gt; &#123; boolean test(T t); default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); &#125; default Predicate&lt;T&gt; negate() &#123; return (t) -&gt; !test(t); &#125; default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t); &#125; static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) &#123; return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object); &#125;&#125; Predicate接口使用@FunctionalInterface标识，表明此接口为函数式接口，有且只能有一个抽象方法； Predicate泛型规定了T对应Lambda表达式的输入参数类型； Predicate定义了and、or、negate三个默认方法和静态方法isEqual。 test()1boolean test(T t); and()1234default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t);&#125; or()1234default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) &#123; Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t);&#125; negate()123default Predicate&lt;T&gt; negate() &#123; return (t) -&gt; !test(t);&#125; isEqual()12345static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) &#123; return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object);&#125; 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JDK1.8编程系列","slug":"JDK1-8编程系列","permalink":"https://ostenant.coding.me/categories/JDK1-8编程系列/"}],"tags":[{"name":"JDK1.8","slug":"JDK1-8","permalink":"https://ostenant.coding.me/tags/JDK1-8/"}]},{"title":"Java 8系列(一) - JDK1.8对字符串的连接处理","slug":"Java 8系列(一) - JDK1.8对字符串连接处理","date":"2017-07-04T08:35:00.000Z","updated":"2018-06-18T01:45:45.869Z","comments":true,"path":"2017/07/04/Java 8系列(一) - JDK1.8对字符串连接处理/","link":"","permalink":"https://ostenant.coding.me/2017/07/04/Java 8系列(一) - JDK1.8对字符串连接处理/","excerpt":"简述在JDK1.8之前，我们通常使用StringBuffer、StringBuilder等可变字符串进行字符串的截取、拼接、替换、组装等功能。","text":"简述在JDK1.8之前，我们通常使用StringBuffer、StringBuilder等可变字符串进行字符串的截取、拼接、替换、组装等功能。 例如，我们需要将List&lt;String&gt;中的所有字符串组装为str1,str2,str3,…strn的形式。在JDK1.8之前我们通常会作如下处理： 1234567891011121314151617181920private final static List&lt;String&gt; LIST = Arrays.asList(\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\");private final static String DELIMITER = \", \";public static void main(String[] args) &#123; String result = concatList(LIST, DELIMITER); System.out.println(result);&#125;public static String concatList(List&lt;String&gt; list, String delimiter) &#123; StringBuilder result = new StringBuilder(); for (String i : list) &#123; result.append(i).append(DELIMITER); &#125; if (result.length() &gt; 0) &#123; // 删除最后一个分隔符 result.delete(result.length() - delimiter.length(), result.length()); &#125; return result.toString();&#125; 使用StringBuilder的运行结果如下： a, b, c, d, e, f, g 下面我们看看如何用JDK1.8提供的字符串处理API完成以上操作。 正文StringJoiner(delimiter)JDK1.8新增了一个用于字符串连接的新类，专门用于这种需要分隔符的场合 – StringJoiner。StringJoiner在构造时可以指定一个分隔符（delimiter），然后每连接一个元素它便会加上一个delimiter。 concatList方法如下：1234567public static String concatList(List&lt;String&gt; list, String delimiter) &#123; StringJoiner result = new StringJoiner(DELIMITER); for (String i : list) &#123; result.add(i); &#125; return result.toString();&#125; 同样，使用StringJoiner的运行结果如下： a, b, c, d, e, f, g String.join(delimiter, elements)StringJoiner使得代码更加的简洁了。当然,还可以更简洁。JDK1.8为String类添加了一个新的静态方法 – String.join。 concatList方法如下：123public static String concatList(List&lt;String&gt; list, String delimiter) &#123; return String.join(delimiter, list);&#125; 同样，使用String.join()的运行结果如下： a, b, c, d, e, f, g 查看String.join()的源码，可以发现join()静态方法也是通过StringJoiner来实现的：12345678910public static String join(CharSequence delimiter, CharSequence... elements) &#123; Objects.requireNonNull(delimiter); Objects.requireNonNull(elements); // Number of elements not likely worth Arrays.stream overhead. StringJoiner joiner = new StringJoiner(delimiter); for (CharSequence cs: elements) &#123; joiner.add(cs); &#125; return joiner.toString();&#125; StringJoiner(delimiter, prefix, suffix)String.join方法的不足是它不能指定前缀和后缀 – 比如我们想要直接将List&lt;String&gt;格式化为 { str1,str2,str3,…strn } 就不行。而StringJoiner提供了StringJoiner(delimiter, prefix, suffix)的构造方法完美地解决了这个问题。 1234567public static String concatList(List&lt;String&gt; list, String delimiter, String prefix, String suffix) &#123; StringJoiner result = new StringJoiner(DELIMITER, PREFIX, SUFFIX); for (String i : list) &#123; result.add(i); &#125; return result.toString();&#125; 运行结果如下： { a, b, c, d, e, f, g } Collectors.joining(delimiter, prefix, suffix)使用StringJoiner已经完全可以实现带前后缀的字符串组装。更优雅同时也更加推荐的方式是使用Collectors.joining()方法。123public static String concatList(List&lt;String&gt; list, String delimiter, String prefix, String suffix) &#123; return list.stream().collect(Collectors.joining(delimiter, prefix, suffix));&#125; 同样，运行结果如下： { a, b, c, d, e, f, g } 总结查看StringJoiner的源码，我们可以知道StringJoiner的底层实现就是StringBuilder– Java8将使用分隔符连接多个字符串这一功能进行封装，提供很多易用且简介的API，确实在很大程度上方便了我们编码。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JDK1.8编程系列","slug":"JDK1-8编程系列","permalink":"https://ostenant.coding.me/categories/JDK1-8编程系列/"}],"tags":[{"name":"JDK1.8","slug":"JDK1-8","permalink":"https://ostenant.coding.me/tags/JDK1-8/"}]},{"title":"一天一个设计模式(二) -单例模式(Singleton)","slug":"一天一个设计模式(二) - 单例模式(Singleton)","date":"2017-06-03T07:37:00.000Z","updated":"2018-06-18T01:52:49.667Z","comments":true,"path":"2017/06/03/一天一个设计模式(二) - 单例模式(Singleton)/","link":"","permalink":"https://ostenant.coding.me/2017/06/03/一天一个设计模式(二) - 单例模式(Singleton)/","excerpt":"前言单例模式 (Singleton) 是一种创建型模式，指某个类采用Singleton模式，则在这个类被创建后，只可能产生一个实例供外部访问，并且提供一个全局的访问点。","text":"前言单例模式 (Singleton) 是一种创建型模式，指某个类采用Singleton模式，则在这个类被创建后，只可能产生一个实例供外部访问，并且提供一个全局的访问点。 正文(一). 优缺点Java中单例模式 (Singleton) 是一种广泛使用的设计模式。单例模式的主要作用是保证在Java程序中，某个类只有一个实例存在。一些管理器和控制器常被设计成单例模式。 1. 优点 提供了对唯一实例的受控访问。 由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象单例模式无疑可以提高系统的性能。 可以根据实际情况需要，在单例模式的基础上扩展做出双例模式，多例模式。 2. 缺点 单例类的职责过重，里面的代码可能会过于复杂，在一定程度上违背了“单一职责原则”。 如果实例化的对象长时间不被利用，会被系统认为是垃圾而被回收，这将导致对象状态的丢失。 (二). 具体实现简单点说，就是一个应用程序中，某个类的实例对象只有一个，你没有办法去new，因为构造器是被private修饰的，一般通过getInstance()的方法来获取它们的实例。getInstance()的返回值是一个同一个对象的引用，并不是一个新的实例。单例模式 实现起来也很容易，以下给出六种实现方式： 1. 饿汉式特点：线程安全，无法实现实例懒加载策略。123456789public class Singleton1 &#123; private final static Singleton1 singleton1 = new Singleton1(); private Singleton1() &#123; &#125; public static Singleton1 getInstance() &#123; return singleton1; &#125;&#125; 2. 懒汉式特点：线程不安全，实现了实例懒加载策略。1234567891011public class Singleton2 &#123; private final static Singleton2 singleton2; private Singleton2() &#123; &#125; public static Singleton2 getInstance() &#123; if (singleton2 == null) singleton2 = new Singleton2(); return singleton2; &#125;&#125; 3. 全局锁式特点：线程安全，且实现了懒加载策略，但是线程同步时效率不高。1234567891011public class Singleton3 &#123; private final static Singleton3 singleton3; private Singleton3() &#123; &#125; public synchronized static Singleton3 getInstance() &#123; if (singleton3 == null) singleton3 = new Singleton3(); return singleton3; &#125;&#125; 4. 静态代码块式特点：线程安全，类主动加载时才初始化实例，实现了懒加载策略，且线程安全。123456789101112public class Singleton4 &#123; private final static Singleton4 singleton4; private Singleton4() &#123; &#125; static &#123; singleton4 = new Singleton4(); &#125; public static Singleton4 getInstance() &#123; return singleton4; &#125;&#125; 5. 双重校验锁式特点：线程安全，且实现了懒加载策略，同时保证了线程同步时的效率。但是volatile强制当前线程每次读操作进行时，保证所有其他的线程的写操作已完成。volatile使得JVM内部的编译器舍弃了编译时优化，对于性能有一定的影响。 12345678910111213141516public class Singleton5 &#123; private static volatile Singleton5 singleton5; private Singleton5() &#123; &#125; public static Singleton5 getInstance() &#123; if (singleton5 == null) &#123; synchronized (Singleton5.class) &#123; if (singleton5 == null) &#123; singleton5 = new Singleton5(); &#125; &#125; &#125; return singleton5; &#125;&#125; 6. 静态内部类式【推荐】特点：线程安全，不存在线程同步问题，且单例对象在程序第一次 getInstance() 时主动加载 SingletonHolder 和其 静态成员 INSTANCE，因而实现了懒加载策略。123456789101112public class Singleton6 &#123; private Singleton6() &#123; &#125; private static class SingletonHolder &#123; private static final Singleton6 INSTANCE = new Singleton6(); &#125; public static Singleton6 getInstance() &#123; return Singleton6.SingletonHolder.INSTANCE; &#125;&#125; 7. 枚举方式【作者推荐】特点：线程安全，不存在线程同步问题，且单例对象在枚举类型 INSTANCE 第一次引用时通过枚举的 构造函数 初始化，因而实现了懒加载策略。1234567891011121314151617181920212223242526public class Singleton7 &#123; private Singleton7() &#123; &#125; enum SingletonEnum &#123; INSTANCE; private final Singleton7 singleton7; private SingletonEnum() &#123; singleton7 = new Singleton7(); &#125; &#125; public static Singleton7 getInstance() &#123; return SingletonEnum.INSTANCE.singleton7; &#125; public static void main(String[] args) &#123; IntStream.rangeClosed(0, 100).forEach(i -&gt; new Thread() &#123; public void run() &#123; out.println(Singleton7.getInstance()); &#125;; &#125;.start()); &#125;&#125; 这种方式是Effective Java作者 Josh Bloch 提倡的方式，它不仅能避免多线程同步问题，而且还能防止反序列化重新创建新的对象，可谓是很坚强的壁垒啊。不过，由于JDK 1.5中才加入enum特性，用这种方式写不免让人感觉生疏。 测试代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@FixMethodOrderpublic class SingletonTester &#123; protected final static int FROM = 0; protected final static int TO = 1000; protected static HashSet&lt;Object&gt; GLOBAL_SET = new HashSet&lt;&gt;(); static &#123; Runtime.getRuntime().addShutdownHook(new Thread() &#123; @Override public void run() &#123; out.println(); // count GLOBAL_SET.forEach((value) -&gt; &#123; out.println(\"Global [\" + value + \"]\"); &#125;); &#125; &#125;); &#125; // testSingleton1 @Test public void testSingleton1() throws Exception &#123; final HashSet&lt;Object&gt; localSet = new HashSet&lt;&gt;(); final CountDownLatch latch = new CountDownLatch(TO); IntStream.range(FROM, TO).forEach(i -&gt; new Thread() &#123; public void run() &#123; Singleton1 singleton = Singleton1.getInstance(); count(singleton); &#125; protected void count(Singleton1 singleton) &#123; localSet.add(singleton); out.println(\"Size of HashSet1 is: [\" + localSet.size() + \"]\"); // 计数减1，释放线程 latch.countDown(); &#125;; &#125;.start()); // 等待子线程执行结束 latch.await(); synchronized (localSet) &#123; // count localSet.forEach((value) -&gt; &#123; out.println(\"[\" + value + \"]\"); out.println(); &#125;); GLOBAL_SET.addAll(localSet); &#125; &#125; // testSingleton2 // testSingleton3 // testSingleton4 // testSingleton5 // testSingleton6 // testSingleton7&#125; 测试结果截图如下，测试用例反映7种单例模式的方案都可以正常执行： 这里只演示其中一种单例方式，运行截图如下： 上图显示，通过 getInstance() 得到的实例全局唯一。对于其余六中方式，根据测试用例测试得到的结果一致，大家可以自行测试。 总结本文总结了七种Java中实现单例模式的方法，其中使用双重校验锁、静态内部类 和 枚举类 的方式可以解决大部分问题。其中，极为推荐 静态内部类 和 枚举类 这两种实现方式。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA设计模式系列","slug":"JAVA设计模式系列","permalink":"https://ostenant.coding.me/categories/JAVA设计模式系列/"}],"tags":[{"name":"Singleton","slug":"Singleton","permalink":"https://ostenant.coding.me/tags/Singleton/"}]},{"title":"一天一个设计模式(一) - 总体概述","slug":"一天一个设计模式(一) - 总体概述","date":"2017-06-02T05:22:00.000Z","updated":"2018-06-18T01:52:08.499Z","comments":true,"path":"2017/06/02/一天一个设计模式(一) - 总体概述/","link":"","permalink":"https://ostenant.coding.me/2017/06/02/一天一个设计模式(一) - 总体概述/","excerpt":"前言最近在对设计模式进行了一系列总结，本文将给大家关于设计模式的一个整体的介绍。","text":"前言最近在对设计模式进行了一系列总结，本文将给大家关于设计模式的一个整体的介绍。 正文1. 定义设计模式是某类特定问题的代码设计解决方案，是一套代码设计的经验总结。 2. 作用 提高代码复用率，降低开发成本和周期 提高代码可维护性、可拓展性 使代码更加优雅，可读性更强 让代码更容易被他人理解 3. 设计原则在设计模式进行设计时需要遵循以下的面向对象设计原则： 单一职责原则 (SRP)：就一个类而言，应该仅有一个引起它变化的原因。 开闭原则 (ASD)：类、模块、函数等等应该是可以拓展的，但是不可修改。 里氏替换原则 (LSP)：所有引用基类（父类）的地方必须能透明地使用其子类的对象。 依赖倒置原则 (DIP)：高层模块不应该依赖低层模块，两个都应该依赖于抽象。抽象不应该依赖于细节，细节应该依赖于抽象。 迪米特原则 (LOD)：一个软件实体应当尽可能少地与其他实体发生相互作用。 接口隔离原则 (ISP)：一个类对另一个类的依赖应该建立在最小的接口上。 4. 设计模式分类常用的23种设计模式总体来说分为三大类：创建型模式、结构型模式 和 行为型模式。 创建型模式 (共五种)：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式 (共七种)：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式 (共十一种)：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 三大类设计模式及其分类，如下图所示： 总结本文对设计模式的定义进行了大致总体的介绍，接下来我会对几种常用的设计模式进行详细的分析。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA设计模式系列","slug":"JAVA设计模式系列","permalink":"https://ostenant.coding.me/categories/JAVA设计模式系列/"}],"tags":[]},{"title":"JVM系列(五) - JVM类加载机制详解","slug":"JVM系列(五) - JVM类加载机制详解","date":"2017-05-10T03:17:00.000Z","updated":"2018-08-02T09:34:00.579Z","comments":true,"path":"2017/05/10/JVM系列(五) - JVM类加载机制详解/","link":"","permalink":"https://ostenant.coding.me/2017/05/10/JVM系列(五) - JVM类加载机制详解/","excerpt":"前言本文将由浅及深，介绍Java类加载的过程和原理，进一步对类加载器的进行源码分析，完成一个自定义的类加载器。","text":"前言本文将由浅及深，介绍Java类加载的过程和原理，进一步对类加载器的进行源码分析，完成一个自定义的类加载器。 正文(一). 类加载器是什么类加载器简言之，就是用于把.class文件中的字节码信息转化为具体的java.lang.Class对象的过程的工具。 具体过程： 在实际类加载过程中，JVM会将所有的.class字节码文件中的二进制数据读入内存中，导入运行时数据区的方法区中。 当一个类首次被主动加载或被动加载时，类加载器会对此类执行类加载的流程 – 加载、连接（验证、准备、解析）、初始化。 如果类加载成功，堆内存中会产生一个新的Class对象，Class对象封装了类在方法区内的数据结构。 Class对象的创建过程描述： (二). 类加载的过程类加载的过程分为三个步骤(五个阶段) ：加载 -&gt; 连接（验证、准备、解析）-&gt; 初始化。 加载、验证、准备和初始化这四个阶段发生的顺序是确定的，而解析阶段可以在初始化阶段之后发生，也称为动态绑定或晚期绑定。 类加载的过程描述： 1. 加载加载：查找并加载类的二进制数据的过程。 加载的过程描述： 通过类的全限定名定位.class文件，并获取其二进制字节流。 把字节流所代表的静态存储结构转换为方法区的运行时数据结构。 在Java堆中生成一个此类的java.lang.Class对象，作为方法区中这些数据的访问入口。 2. 连接连接：包括验证、准备、解析三步。 a). 验证验证：确保被加载的类的正确性。验证是连接阶段的第一步，用于确保Class字节流中的信息是否符合虚拟机的要求。 具体验证形式： 文件格式验证：验证字节流是否符合Class文件格式的规范；例如：是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证：对字节码描述的信息进行语义分析（注意：对比javac编译阶段的语义分析），以保证其描述的信息符合Java语言规范的要求；例如：这个类是否有父类，除了java.lang.Object之外。 字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证：确保解析动作能正确执行。 b). 准备准备：为类的静态变量分配内存，并将其初始化为默认值。准备过程通常分配一个结构用来存储类信息，这个结构中包含了类中定义的成员变量，方法和接口信息等。 具体行为： 这时候进行内存分配的仅包括类变量(static)，而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。 这里所设置的初始值通常情况下是数据类型默认的零值（如0、0L、null、false等），而不是被在Java代码中被显式赋值。 c). 解析解析：把类中对常量池内的符号引用转换为直接引用。 解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符等7类符号引用进行。 3. 初始化初始化：对类静态变量赋予正确的初始值 (注意和连接时的解析过程区分开)。 初始化的目标 实现对声明类静态变量时指定的初始值的初始化； 实现对使用静态代码块设置的初始值的初始化。 初始化的步骤 如果此类没被加载、连接，则先加载、连接此类； 如果此类的直接父类还未被初始化，则先初始化其直接父类； 如果类中有初始化语句，则按照顺序依次执行初始化语句。 初始化的时机 创建类的实例(new关键字)； java.lang.reflect包中的方法(如：Class.forName(“xxx”))； 对类的静态变量进行访问或赋值； 访问调用类的静态方法； 初始化一个类的子类，父类本身也会被初始化； 作为程序的启动入口，包含main方法(如：SpringBoot入口类)。 (三). 类的主动引用和被动引用主动引用主动引用：在类加载阶段，只执行加载、连接操作，不执行初始化操作。 主动引用的几种形式 创建类的实例(new关键字)； java.lang.reflect包中的方法(如：Class.forName(“xxx”))； 对类的静态变量进行访问或赋值； 访问调用类的静态方法； 初始化一个类的子类，父类本身也会被初始化； 作为程序的启动入口，包含main方法(如：SpringBoot入口类)。 主动引用1 - main方法在初始类中代码示例：123456789public class OptimisticReference0 &#123; static &#123; System.out.println(OptimisticReference0.class.getSimpleName() + \" is referred!\"); &#125; public static void main(String[] args) &#123; System.out.println(); &#125;&#125; 运行结果： OptimisticReference0 is referred! 主动引用2 – 创建子类会触发父类的初始化代码示例：1234567891011121314151617public class OptimisticReference1 &#123; public static class Parent &#123; static &#123; System.out.println(Parent.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static class Child extends Parent &#123; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static void main(String[] args) &#123; new Child(); &#125;&#125; 运行结果： Parent is referred!Child is referred! 主动引用3 – 访问一个类静态变量代码示例：12345678910111213public class OptimisticReference2 &#123; public static class Child &#123; protected static String name; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); name = \"Child\"; &#125; &#125; public static void main(String[] args) &#123; System.out.println(Child.name); &#125;&#125; 运行结果： Child is referred!Child 主动引用4 – 对类的静态变量进行赋值代码示例：123456789101112public class OptimisticReference3 &#123; public static class Child &#123; protected static String name; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static void main(String[] args) &#123; Child.name = \"Child\"; &#125;&#125; 运行结果： Child is referred! 主动引用5 – 使用java.lang.reflect包提供的反射机制代码示例： 12345public class OptimisticReference4 &#123; public static void main(String[] args) throws ClassNotFoundException &#123; Class.forName(\"org.ostenant.jdk8.learning.examples.reference.optimistic.Child\"); &#125;&#125; 运行结果： Child is referred! 被动引用被动引用： 在类加载阶段，会执行加载、连接和初始化操作。 被动引用的几种形式： 通过子类引用父类的的静态字段，不会导致子类初始化； 定义类的数组引用而不赋值，不会触发此类的初始化； 访问类定义的常量，不会触发此类的初始化。 被动引用1 – 子类引用父类的的静态字段，不会导致子类初始化代码示例：123456789101112131415161718public class NegativeReference0 &#123; public static class Parent &#123; public static String name = \"Parent\"; static &#123; System.out.println(Parent.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static class Child extends Parent &#123; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static void main(String[] args) &#123; System.out.println(Child.name); &#125;&#125; 运行结果： Parent is referred!Parent 被动引用2 – 定义类的数组引用而不赋值，不会触发此类的初始化代码示例：1234567891011public class NegativeReference1 &#123; public static class Child &#123; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static void main(String[] args) &#123; Child[] childs = new Child[10]; &#125;&#125; 运行结果： 无输出 被动引用3 – 访问类定义的常量，不会触发此类的初始化示例代码：123456789101112public class NegativeReference2 &#123; public static class Child &#123; public static final String name = \"Child\"; static &#123; System.out.println(Child.class.getSimpleName() + \" is referred!\"); &#125; &#125; public static void main(String[] args) &#123; System.out.println(Child.name); &#125;&#125; 运行结果： Child (四). 三种类加载器类加载器：类加载器负责加载程序中的类型（类和接口），并赋予唯一的名字予以标识。 类加载器的组织结构 类加载器的关系 Bootstrap Classloader 是在Java虚拟机启动后初始化的。 Bootstrap Classloader 负责加载 ExtClassLoader，并且将 ExtClassLoader的父加载器设置为 Bootstrap Classloader Bootstrap Classloader 加载完 ExtClassLoader 后，就会加载 AppClassLoader，并且将 AppClassLoader 的父加载器指定为 ExtClassLoader。 类加载器的作用 Class Loader 实现方式 具体实现类 负责加载的目标 Bootstrap Loader C++ 由C++实现 %JAVA_HOME%/jre/lib/rt.jar以及-Xbootclasspath参数指定的路径以及中的类库 Extension ClassLoader Java sun.misc.Launcher$ExtClassLoader %JAVA_HOME%/jre/lib/ext路径下以及java.ext.dirs系统变量指定的路径中类库 Application ClassLoader Java sun.misc.Launcher$AppClassLoader Classpath以及-classpath、-cp指定目录所指定的位置的类或者是jar文档，它也是Java程序默认的类加载器 类加载器的特点 层级结构：Java里的类装载器被组织成了有父子关系的层级结构。Bootstrap类装载器是所有装载器的父亲。 代理模式： 基于层级结构，类的代理可以在装载器之间进行代理。当装载器装载一个类时，首先会检查它在父装载器中是否进行了装载。如果上层装载器已经装载了这个类，这个类会被直接使用。反之，类装载器会请求装载这个类 可见性限制：一个子装载器可以查找父装载器中的类，但是一个父装载器不能查找子装载器里的类。 不允许卸载：类装载器可以装载一个类但是不可以卸载它，不过可以删除当前的类装载器，然后创建一个新的类装载器装载。 类加载器的隔离问题每个类装载器都有一个自己的命名空间用来保存已装载的类。当一个类装载器装载一个类时，它会通过保存在命名空间里的类全局限定名(Fully Qualified Class Name) 进行搜索来检测这个类是否已经被加载了。 JVM 及 Dalvik 对类唯一的识别是 ClassLoader id + PackageName + ClassName，所以一个运行程序中是有可能存在两个包名和类名完全一致的类的。并且如果这两个类不是由一个 ClassLoader 加载，是无法将一个类的实例强转为另外一个类的，这就是 ClassLoader 隔离性。 为了解决类加载器的隔离问题，JVM引入了双亲委托机制。 (五). 双亲委托机制核心思想：其一，自底向上检查类是否已加载；其二，自顶向下尝试加载类。 具体加载过程 当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败（例如在%JAVA_HOME%/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载； 如果ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 源码分析ClassLoader.class loadClass()：通过指定类的全限定名称，由类加载器检测、装载、创建并返回该类的java.lang.Class对象。 ClassLoader通过loadClass()方法实现了双亲委托机制，用于类的动态加载。 loadClass()本身是一个递归向上调用的过程。 自底向上检查类是否已加载 先通过findLoadedClass()方法从最底端类加载器开始检查类是否已经加载。 如果已经加载，则根据resolve参数决定是否要执行连接过程，并返回Class对象。 如果没有加载，则通过parent.loadClass()委托其父类加载器执行相同的检查操作(默认不做连接处理)。 直到顶级类加载器，即parent为空时，由findBootstrapClassOrNull()方法尝试到Bootstrap ClassLoader中检查目标类。 自顶向下尝试加载类 如果仍然没有找到目标类，则从Bootstrap ClassLoader开始，通过findClass()方法尝试到对应的类目录下去加载目标类。 如果加载成功，则根据resolve参数决定是否要执行连接过程，并返回Class对象。 如果加载失败，则由其子类加载器尝试加载，直到最底端类加载器也加载失败，最终抛出ClassNotFoundException。 findLoadedClass() 查找当前类加载器的缓存中是否已经加载目标类。findLoadedClass()实际调用了底层的native方法findLoadedClass0()。 findBootstrapClassOrNull() 查找最顶端Bootstrap类加载器的是否已经加载目标类。同样，findBootstrapClassOrNull()实际调用了底层的native方法findBootstrapClass()。 findClass() ClassLoader是java.lang包下的抽象类，也是所有类加载器(除了Bootstrap)的基类，findClass()是ClassLoader对子类提供的加载目标类的抽象方法。 注意：Bootstrap ClassLoader并不属于JVM的层次，它不遵守ClassLoader的加载规则，Bootstrap classLoader并没有子类。 defineClass() defineClass()是ClassLoader向子类提供的方法，它可以将.class文件的二进制数据转换为合法的java.lang.Class对象。 (六). 类的动态加载类的几种加载方式 通过命令行启动时由JVM初始化加载； 通过Class.forName()方法动态加载； 通过ClassLoader.loadClass()方法动态加载。 Class.forName()和ClassLoader.loadClass() Class.forName()：把类的.class文件加载到JVM中，对类进行解释的同时执行类中的static静态代码块； ClassLoader.loadClass()：只是把.class文件加载到JVM中，不会执行static代码块中的内容，只有在newInstance才会去执行。 (七). 对象的初始化对象的初始化顺序静态变量/静态代码块 -&gt; 普通代码块 -&gt; 构造函数 父类静态变量和静态代码块（先声明的先执行）； 子类静态变量和静态代码块（先声明的先执行）； 父类普通成员变量和普通代码块（先声明的先执行）； 父类的构造函数； 子类普通成员变量和普通代码块（先声明的先执行）； 子类的构造函数。 对象的初始化示例Parent.java Children.java Tester.java 测试结果： 测试结果表明：JVM在创建对象时，遵守以上对象的初始化顺序。 (八). 自定义类加载器编写自己的类加载器在源码分析阶段，我们已经解读了如何实现自定义类加载器，现在我们开始怼自己的类加载器。 Step 1：定义待加载的目标类Parent.java和Children.java。 Parent.java1234567891011121314151617181920212223242526272829package org.ostenant.jdk8.learning.examples.classloader.custom;public class Parent &#123; protected static String CLASS_NAME; protected static String CLASS_LOADER_NAME; protected String instanceID; // 1.先执行静态变量和静态代码块（只在类加载期间执行一次） static &#123; CLASS_NAME = Parent.class.getName(); CLASS_LOADER_NAME = Parent.class.getClassLoader().toString(); System.out.println(\"Step a: \" + CLASS_NAME + \" is loaded by \" + CLASS_LOADER_NAME); &#125; // 2.然后执行变量和普通代码块（每次创建实例都会执行） &#123; instanceID = this.toString(); System.out.println(\"Step c: Parent instance is created: \" + CLASS_LOADER_NAME + \" -&gt; \" + instanceID); &#125; // 3.然后执行构造方法 public Parent() &#123; System.out.println(\"Step d: Parent instance：\" + instanceID + \", constructor is invoked\"); &#125; public void say() &#123; System.out.println(\"My first class loader...\"); &#125;&#125; Children.java12345678910111213141516171819202122package org.ostenant.jdk8.learning.examples.classloader.custom;public class Children extends Parent &#123; static &#123; CLASS_NAME = Children.class.getName(); CLASS_LOADER_NAME = Children.class.getClassLoader().toString(); System.out.println(\"Step b: \" + CLASS_NAME + \" is loaded by \" + CLASS_LOADER_NAME); &#125; &#123; instanceID = this.toString(); System.out.println(\"Step e: Children instance is created: \" + CLASS_LOADER_NAME + \" -&gt; \" + instanceID); &#125; public Children() &#123; System.out.println(\"Step f: Children instance：\" + instanceID + \", constructor is invoked\"); &#125; public void say() &#123; System.out.println(\"My first class loader...\"); &#125;&#125; Step 2：实现自定义类加载器CustomClassLoader CustomClassLoader.java123456789101112131415161718192021222324252627282930313233343536373839public class CustomClassLoader extends ClassLoader &#123; private String classPath; public CustomClassLoader(String classPath) &#123; this.classPath = classPath; &#125; @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; Class&lt;?&gt; c = findLoadedClass(name); // 可省略 if (c == null) &#123; byte[] data = loadClassData(name); if (data == null) &#123; throw new ClassNotFoundException(); &#125; return defineClass(name, data, 0, data.length); &#125; return null; &#125; protected byte[] loadClassData(String name) &#123; try &#123; // package -&gt; file folder name = name.replace(\".\", \"//\"); FileInputStream fis = new FileInputStream(new File(classPath + \"//\" + name + \".class\")); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int len = -1; byte[] b = new byte[2048]; while ((len = fis.read(b)) != -1) &#123; baos.write(b, 0, len); &#125; fis.close(); return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; Step 3：测试类加载器的加载过程 CustomerClassLoaderTester.java 测试程序启动时，逐一拷贝并加载待加载的目标类源文件。 12345678910111213141516private static final String CHILDREN_SOURCE_CODE_NAME = SOURCE_CODE_LOCATION + \"Children.java\";private static final String PARENT_SOURCE_CODE_NAME = SOURCE_CODE_LOCATION + \"Parent.java\";private static final List&lt;String&gt; SOURCE_CODE = Arrays.asList(CHILDREN_SOURCE_CODE_NAME, PARENT_SOURCE_CODE_NAME);static &#123; SOURCE_CODE.stream().map(path -&gt; new File(path)) // 路径转文件对象 .filter(f -&gt; !f.isDirectory()) // 文件遍历 .forEach(f -&gt; &#123; // 拷贝后源代码 File targetFile = copySourceFile(f); // 编译源代码 compileSourceFile(targetFile); &#125;);&#125; 拷贝单一源文件到自定义类加载器的类加载目录。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected static File copySourceFile(File f) &#123; BufferedReader reader = null; BufferedWriter writer = null; try &#123; reader = new BufferedReader(new FileReader(f)); // package ...; String firstLine = reader.readLine(); StringTokenizer tokenizer = new StringTokenizer(firstLine, \" \"); String packageName = \"\"; while (tokenizer.hasMoreElements()) &#123; String e = tokenizer.nextToken(); if (e.contains(\"package\")) &#123; continue; &#125; else &#123; packageName = e.trim().substring(0, e.trim().length() - 1); &#125; &#125; // package -&gt; path String packagePath = packageName.replace(\".\", \"//\"); // java file path String targetFileLocation = TARGET_CODE_LOCALTION + \"//\" + packagePath + \"//\"; String sourceFilePath = f.getPath(); String fileName = sourceFilePath.substring(sourceFilePath.lastIndexOf(\"\\\\\") + 1); File targetFile = new File(targetFileLocation, fileName); File targetFileLocationDir = new File(targetFileLocation); if (!targetFileLocationDir.exists()) &#123; targetFileLocationDir.mkdirs(); &#125; // writer writer = new BufferedWriter(new FileWriter(targetFile)); // 写入第一行 writer.write(firstLine); writer.newLine(); writer.newLine(); String input = \"\"; while ((input = reader.readLine()) != null) &#123; writer.write(input); writer.newLine(); &#125; return targetFile; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; reader.close(); writer.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return null;&#125; 对拷贝后的.java源文件执行手动编译，在同级目录下生成.class文件。 123456789101112131415protected static void compileSourceFile(File f) &#123; try &#123; JavaCompiler javaCompiler = ToolProvider.getSystemJavaCompiler(); StandardJavaFileManager standardFileManager = javaCompiler.getStandardFileManager(null, null, null); Iterable&lt;? extends JavaFileObject&gt; javaFileObjects = standardFileManager.getJavaFileObjects(f); // 执行编译任务 CompilationTask task = javaCompiler.getTask(null, standardFileManager, null, null, null, javaFileObjects); task.call(); standardFileManager.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 通过自定义类加载器加载Children的java.lang.Class&lt;?&gt;对象，然后用反射机制创建Children的实例对象。 123456789101112131415161718@Testpublic void test() throws Exception &#123; // 创建自定义类加载器 CustomClassLoader classLoader = new CustomClassLoader(TARGET_CODE_LOCALTION); // E://myclassloader//classpath // 动态加载class文件到内存中（无连接） Class&lt;?&gt; c = classLoader.loadClass(\"org.ostenant.jdk8.learning.examples.classloader.custom.Children\"); // 通过反射拿到所有的方法 Method[] declaredMethods = c.getDeclaredMethods(); for (Method method : declaredMethods) &#123; if (\"say\".equals(method.getName())) &#123; // 通过反射拿到children对象 Object children = c.newInstance(); // 调用children的say()方法 method.invoke(children); break; &#125; &#125;&#125; 测试编写的类加载器(一). 测试场景一 保留static代码块，把目标类Children.java和Parent.java拷贝到类加载的目录，然后进行手动编译。 保留测试项目目录中的目标类Children.java和Parent.java。 测试结果输出： 测试结果分析： 我们成功创建了Children对象，并通过反射调用了它的say()方法。然而查看控制台日志，可以发现类加载使用的仍然是AppClassLoader，CustomClassLoader并没有生效。 查看CustomClassLoader的类加载目录： 类目录下有我们拷贝并编译的Parent和Chidren文件。 分析原因： 由于项目空间中的Parent.java和Children.java，在拷贝后并没有移除。导致AppClassLoader优先在其Classpath下面找到并成功加载了目标类。 (二). 测试场景二 注释掉static代码块（类目录下有已编译的目标类.class文件）。 移除测试项目目录中的目标类Children.java和Parent.java。 测试结果输出：测试结果分析： 我们成功通过自定义类加载器加载了目标类。创建了Children对象，并通过反射调用了它的say()方法。 至此，我们自己的一个简单的类加载器就完成了！ 参考书籍周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA虚拟机系列","slug":"JAVA虚拟机系列","permalink":"https://ostenant.coding.me/categories/JAVA虚拟机系列/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"},{"name":"JDK","slug":"JDK","permalink":"https://ostenant.coding.me/tags/JDK/"}]},{"title":"JVM系列(四) - JVM GC回收算法","slug":"JVM系列(四) - JVM GC回收算法","date":"2017-05-02T10:09:00.000Z","updated":"2018-08-02T09:36:50.476Z","comments":true,"path":"2017/05/02/JVM系列(四) - JVM GC回收算法/","link":"","permalink":"https://ostenant.coding.me/2017/05/02/JVM系列(四) - JVM GC回收算法/","excerpt":"前言前面介绍了Java内存运行时区域，其中程序计数器、虚拟机栈、本地方法栈 三个区域随线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，因此这几个区域的内存分配和回收都具备确定性。在这几个区域内不需要过多考虑回收的问题，因为方法结束或线程结束时，内存自然就跟随着回收了。","text":"前言前面介绍了Java内存运行时区域，其中程序计数器、虚拟机栈、本地方法栈 三个区域随线程而生，随线程而灭；栈中的栈帧随着方法的进入和退出而有条不紊地执行着出栈和入栈操作。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，因此这几个区域的内存分配和回收都具备确定性。在这几个区域内不需要过多考虑回收的问题，因为方法结束或线程结束时，内存自然就跟随着回收了。 Java堆 和 方法区 则不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样。我们只有在程序处于运行期间时才能知道会创建哪些对象，这部分内存的分配和回收都是动态的，垃圾收集器 所关注的是这部分内存。 正文(一). 对象生死判定如何判断Java中一个对象应该 “存活” 还是 “死去”，这是 垃圾回收器要做的第一件事。 1. 引用计数算法Java 堆 中每个具体对象（不是引用）都有一个引用计数器。当一个对象被创建并初始化赋值后，该变量计数设置为1。每当有一个地方引用它时，计数器值就加1。当引用失效时，即一个对象的某个引用超过了生命周期（出作用域后）或者被设置为一个新值时，计数器值就减1。任何引用计数为0的对象可以被当作垃圾收集。当一个对象被垃圾收集时，它引用的任何对象计数减 1。 优点： 引用计数收集器执行简单，判定效率高，交织在程序运行中。对程序不被长时间打断的实时环境比较有利。 缺点： 难以检测出对象之间的循环引用。同时，引用计数器增加了程序执行的开销。所以Java语言并没有选择这种算法进行垃圾回收。 2. 可达性分析算法可达性分析算法也叫根搜索算法，通过一系列的称为 GC Roots 的对象作为起点，然后向下搜索。搜索所走过的路径称为引用链 （Reference Chain）， 当一个对象到 GC Roots 没有任何引用链相连时, 即该对象不可达，也就说明此对象是 不可用的。 如下图所示: Object5、Object6、Object7 虽然互有关联, 但它们到GC Roots是不可达的, 因此也会被判定为可回收的对象。 GC根对象 在Java中, 可作为GC Roots的对象包括以下四种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 本地方法栈 中 JNI （Native方法）引用的变量 方法区 中类静态属性引用的变量 方法区 中常量引用的变量 JVM 中用到的所有现代 GC 算法在回收前都会先找出所有仍存活的对象。可达性分析算法 是从离散数学中的图论引入的，程序把所有的引用关系看作一张图。下图展示的 JVM 中的内存布局可以用来很好地阐释这一概念： (二). 对象引用分类1. 强引用(Strong Reference)在代码中普遍存在的，类似Object obj = new Object()这类引用，只要强引用还在，垃圾收集器永远不会回收掉被引用的对象。 2. 软引用(Sofe Reference)有用但并非必需 的对象，可用SoftReference类来实现软引用。在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。 3. 弱引用(Weak Reference)非必需 的对象，但它的强度比软引用更弱，被弱引用关联的对象只能生存到下一次垃圾收集发生之前，JDK提供了WeakReference类来实现弱引用。无论当前内存是否足够，用软引用相关联的对象都会被回收掉。 4. 虚引用(Phantom Reference)虚引用也称为幽灵引用或幻影引用，是最弱的一种引用关系，JDK提供了PhantomReference类来实现虚引用。为一个对象设置虚引用的唯一目的是：能在这个对象在垃圾回收器回收时收到一个系统通知。 (三). finalize()二次标记一个对象是否应该在垃圾回收器在GC时回收，至少要经历两次标记过程。 第一次标记过程通过 可达性分析算法 分析对象是否与GC Roots可达。经过第一次标记，并且被筛选为不可达的对象会进行第二次标记。 第二次标记过程判断不可达对象是否有必要执行finalize方法。执行条件是当前对象的finalize方法被重写，并且还未被系统调用过。如果允许执行那么这个对象将会被放到一个叫F-Query的队列中，等待被执行。 注意：由于finalize由一个优先级比较低的Finalizer线程运行，所以该对象的的finalize方法不一定被执行，即使被执行了，也不保证finalize方法一定会执行完。如果对象第二次小规模标记，即finalize方法中拯救自己，只需要重新和引用链上的任一对象建立关联即可。 (四). 垃圾回收算法本节具体介绍一下各种垃圾回收算法的思想： 1. 标记-清除算法标记-清除算法对根集合进行扫描，对存活的对象进行标记。标记完成后，再对整个空间内未被标记的对象扫描，进行回收。 1.1. 标记阶段标记阶段，通过根节点，标记所有从根节点开始的可达对象，未标记过的对象就是未被引用的垃圾对象。 1.2. 清除阶段清除阶段，清除所有未被标记的对象。 优点：实现简单，不需要进行对象进行移动。 缺点：标记、清除过程效率低，产生大量不连续的内存碎片，提高了垃圾回收的频率。 2. 复制算法这种收集算法解决了标记清除算法存在的效率问题。它将内存区域划分成相同的两个 内存块。每次仅使用一半的空间，JVM生成的新对象放在一半空间中。当一半空间用完时进行GC，把可到达对象复制到另一半空间，然后把使用过的内存空间一次清理掉。 优点：按顺序分配内存即可，实现简单、运行高效，不用考虑内存碎片。 缺点：可用的内存大小缩小为原来的一半，对象存活率高时会频繁进行复制。 3. 标记-整理算法标记-整理算法 采用和 标记-清除算法 一样的方式进行对象的标记，但后续不直接对可回收对象进行清理，而是将所有的 存活对象 往一端 空闲空间 移动，然后清理掉端边界以外的内存空间。 优点：解决了标记-清理算法存在的内存碎片问题。 缺点：仍需要进行局部对象移动，一定程度上降低了效率。 4. 分代收集算法当前商业虚拟机都采用分代收集的垃圾收集算法。分代收集算法，顾名思义是根据对象的存活周期将内存划分为几块。一般包括年轻代、老年代 和 永久代，如图所示： 新生代（Young generation）绝大多数最新被创建的对象会被分配到这里，由于大部分对象在创建后会很快变得不可达，所以很多对象被创建在新生代，然后消失。对象从这个区域消失的过程我们称之为 minor GC。 新生代 中存在一个Eden区和两个Survivor区。新对象会首先分配在Eden中（如果新对象过大，会直接分配在老年代中）。在GC中，Eden中的对象会被移动到Survivor中，直至对象满足一定的年纪（定义为熬过GC的次数），会被移动到老年代。 可以设置新生代和老年代的相对大小。这种方式的优点是新生代大小会随着整个堆大小动态扩展。参数 -XX:NewRatio 设置老年代与新生代的比例。例如 -XX:NewRatio=8 指定 老年代/新生代 为8/1. 老年代 占堆大小的 7/8 ，新生代 占堆大小的 1/8（默认即是 1/8）。 例如： 1-XX:NewSize=64m -XX:MaxNewSize=1024m -XX:NewRatio=8 老年代（Old generation）对象没有变得不可达，并且从新生代中存活下来，会被拷贝到这里。其所占用的空间要比新生代多。也正由于其相对较大的空间，发生在老年代上的GC要比新生代要少得多。对象从老年代中消失的过程，可以称之为major GC（或者full GC）。 永久代（permanent generation）像一些 类的层级信息，方法数据 和 方法信息（如 字节码，栈 和 变量大小），运行时常量池（JDK7之后移出 永久代），已确定的 符号引用 和 虚方法表 等等。它们几乎都是 静态的 并且 很少 被 卸载和回收，在 JDK8 之前的 HotSpot 虚拟机中，类的这些 永久的 数据存放在一个叫做 永久代 的区域。 永久代 是一段 连续的内存空间，我们在JVM启动之前可以通过设置 -XX:MaxPermSize 的值来控制永久代的大小。但是JDK8之后取消了 永久代，这些 元数据 被移到了一个与堆 不相连 的称为 元空间 (Metaspace) 的 本地内存区域。 小结JDK8堆内存一般是划分为 年轻代 和 老年代，不同年代 根据自身特性采用不同的垃圾收集算法。 对于 新生代，每次GC时都有大量的对象死亡，只有 少量 对象存活。考虑到复制成本低，适合采用复制算法。因此有了From Survivor和To Survivor区域。 对于老年代，因为对象存活率高，没有额外的内存空间对它进行担保。因而适合采用标记-清理算法和标记-整理算法进行回收。 参考周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 欢迎关注技术公众号：零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA虚拟机系列","slug":"JAVA虚拟机系列","permalink":"https://ostenant.coding.me/categories/JAVA虚拟机系列/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://ostenant.coding.me/tags/JVM/"}]},{"title":"JVM系列(三) - JVM对象探秘","slug":"JVM系列(三) - JVM对象探秘","date":"2017-04-28T03:22:00.000Z","updated":"2018-06-18T01:49:38.018Z","comments":true,"path":"2017/04/28/JVM系列(三) - JVM对象探秘/","link":"","permalink":"https://ostenant.coding.me/2017/04/28/JVM系列(三) - JVM对象探秘/","excerpt":"前言对于 JVM 运行时区域有了一定了解以后，本文将更进一步介绍虚拟机内存中的数据的细节信息。以JVM虚拟机(Hotspot)的内存区域Java堆为例，探讨Java堆是如何创建对象、如何布局对象以及如何访问对象的。","text":"前言对于 JVM 运行时区域有了一定了解以后，本文将更进一步介绍虚拟机内存中的数据的细节信息。以JVM虚拟机(Hotspot)的内存区域Java堆为例，探讨Java堆是如何创建对象、如何布局对象以及如何访问对象的。 正文 (一). 对象的创建说到对象的创建，首先让我们看看 Java 中提供的几种对象创建方式： Header 解释 使用new关键字 调用了构造函数 使用Class的newInstance方法 调用了构造函数 使用Constructor类的newInstance方法 调用了构造函数 使用clone方法 没有调用构造函数 使用反序列化 没有调用构造函数 下面举例说明五种方式的具体操作方式： Employee.java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public class Employee implements Cloneable, Serializable &#123; private static final long serialVersionUID = 1L; private String name; public Employee() &#123;&#125; public Employee(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public int hashCode() &#123; final int prime = 31; int result = 1; result = prime * result + ((name == null) ? 0 : name.hashCode()); return result; &#125; @Override public boolean equals(Object obj) &#123; if (this == obj) return true; if (obj == null) return false; if (getClass() != obj.getClass()) return false; Employee other = (Employee) obj; if (name == null) &#123; if (other.name != null) return false; &#125; else if (!name.equals(other.name)) return false; return true; &#125; @Override public String toString() &#123; return \"Employee [name=\" + name + \"]\"; &#125; @Override public Object clone() &#123; Object obj = null; try &#123; obj = super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return obj; &#125;&#125; 1. new关键字这是最常见也是最简单的创建对象的方式了。通过这种方式，我们可以调用任意的构造函数(无参的和带参数的)。 1Employee emp1 = new Employee(); 1Employee emp1 = new Employee(name); 2. Class类的newInstance方法我们也可以使用Class类的newInstance方法创建对象。这个newInstance方法调用无参的构造函数创建对象。 方式一： 1Employee emp2 = (Employee) Class.forName(\"org.ostenant.jvm.instance.Employee\").newInstance(); 方式二： 1Employee emp2 = Employee.class.newInstance(); 3. Constructor类的newInstance方法和Class类的newInstance方法很像， java.lang.reflect.Constructor类里也有一个newInstance方法可以创建对象。我们可以通过这个newInstance方法调用有参数的和私有的构造函数。其中，Constructor可以从对应的Class类中获得。 12Constructor&lt;Employee&gt; constructor = Employee.class.getConstructor();Employee emp3 = constructor.newInstance(); 这两种newInstance方法就是大家所说的反射。事实上Class的newInstance方法内部调用Constructor的newInstance方法。 4. Clone方法无论何时我们调用一个对象的clone方法，JVM都会创建一个新的对象，将前面对象的内容全部拷贝进去。用clone方法创建对象并不会调用任何构造函数。 为了使用clone方法，我们需要先实现Cloneable接口并实现其定义的clone方法。 1Employee emp4 = (Employee) emp3.clone(); 5. 反序列化当我们序列化和反序列化一个对象，JVM会给我们创建一个单独的对象。在反序列化时，JVM创建对象并不会调用任何构造函数。 为了反序列化一个对象，我们需要让我们的类实现Serializable接口。 12345678ByteArrayOutputStream out = new ByteArrayOutputStream();ObjectOutputStream oos = new ObjectOutputStream(out);oos.writeObject(emp4);ByteArrayInputStream in = new ByteArrayInputStream(oos.toByteArray());ObjectInputStream ois =new ObjectInputStream(in);Employee emp5 = (Employee) in.readObject(); 本文以new关键字为例，讲述JVM堆中对象实例的创建过程如下： 当虚拟机遇到一条new指令时，首先会检查这个指令的参数能否在常量池中定位一个符号引用。然后检查这个符号引用的类字节码对象是否加载、解析和初始化。如果没有，将执行对应的类加载过程。 类加载 完成以后，虚拟机将会为新生对象分配内存区域，对象所需内存空间大小在类加载完成后就已确定。 内存分配 完成以后，虚拟机将分配到的内存空间都初始化为零值。 虚拟机对对象进行一系列的设置，如所属类的元信息、对象的哈希码、对象GC分带年龄 、线程持有的锁 、偏向线程ID 等信息。这些信息存储在对象头 (Object Header)。 上述工作完成以后，从虚拟机的角度来说，一个新的对象已经产生了。然而，从Java程序的角度来说，对象创建才刚开始。 (二). 对象的布局HotSpot虚拟机中，对象在内存中存储的布局可以分为三块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头在HotSpot虚拟机中，对象头有两部分信息组成：运行时数据 和 类型指针。 1. 运行时数据用于存储对象自身运行时的数据，如哈希码（hashCode）、GC分带年龄、线程持有的锁、偏向线程ID 等信息。 这部分数据的长度在32位和64位的虚拟机（暂不考虑开启压缩指针的场景）中分别为32个和64个Bit，官方称它为 “Mark Word”。 在32位的HotSpot虚拟机中对象未被锁定的状态下，Mark Word的32个Bit空间中的25Bit用于存储对象哈希码（HashCode），4Bit用于存储对象分代年龄，2Bits用于存储锁标志位，1Bit固定为0。 在其他状态（轻量级锁定、重量级锁定、GC标记、可偏向）下对象的存储内容如下表所示： 存储内容 标志位 状态 对象哈希码、对象分代年龄 01 未锁定 指向锁记录的指针 00 轻量级锁定 指向重量级锁的指针 10 膨胀（重量级锁定） 空，不需要记录信息 11 GC标记 偏向线程ID、偏向时间戳、对象分代年龄 01 可偏向 2. 类型指针指向实例对象的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。 如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数据。 实例数据实例数据 部分是对象真正存储的有效信息，无论是从父类继承下来的还是该类自身的，都需要记录下来，而这部分的存储顺序受虚拟机的分配策略和定义的顺序的影响。 默认分配策略： long/double -&gt; int/float -&gt; short/char -&gt; byte/boolean -&gt; reference 如果设置了-XX:FieldsAllocationStyle=0（默认是1），那么引用类型数据就会优先分配存储空间： reference -&gt; long/double -&gt; int/float -&gt; short/char -&gt; byte/boolean 结论： 分配策略总是按照字节大小由大到小的顺序排列，相同字节大小的放在一起。 对齐填充HotSpot虚拟机要求每个对象的起始地址必须是8字节的整数倍，也就是对象的大小必须是8字节的整数倍。而对象头部分正好是8字节的倍数（32位为1倍，64位为2倍），因此，当对象实例数据部分没有对齐的时候，就需要通过对齐填充来补全。 (三). 对象的访问定位Java程序需要通过 JVM 栈上的引用访问堆中的具体对象。对象的访问方式取决于 JVM 虚拟机的实现。目前主流的访问方式有 句柄 和 直接指针 两种方式。 指针： 指向对象，代表一个对象在内存中的起始地址。句柄： 可以理解为指向指针的指针，维护着对象的指针。句柄不直接指向对象，而是指向对象的指针（句柄不发生变化，指向固定内存地址），再由对象的指针指向对象的真实内存地址。 1. 句柄Java堆中划分出一块内存来作为句柄池，引用中存储对象的句柄地址，而句柄中包含了对象实例数据与对象类型数据各自的具体地址信息，具体构造如下图所示： 优势：引用中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而引用本身不需要修改。 2. 直接指针如果使用直接指针访问，引用 中存储的直接就是对象地址，那么Java堆对象内部的布局中就必须考虑如何放置访问类型数据的相关信息。 优势：速度更快，节省了一次指针定位的时间开销。由于对象的访问在Java中非常频繁，因此这类开销积少成多后也是非常可观的执行成本。 参考周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA虚拟机系列","slug":"JAVA虚拟机系列","permalink":"https://ostenant.coding.me/categories/JAVA虚拟机系列/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://ostenant.coding.me/tags/JVM/"}]},{"title":"JVM系列(二) - JVM内存区域详解","slug":"JVM系列(二) - JVM内存区域和内存溢出异常详解","date":"2017-04-25T09:57:00.000Z","updated":"2018-08-02T09:35:51.664Z","comments":true,"path":"2017/04/25/JVM系列(二) - JVM内存区域和内存溢出异常详解/","link":"","permalink":"https://ostenant.coding.me/2017/04/25/JVM系列(二) - JVM内存区域和内存溢出异常详解/","excerpt":"前言JVM内存区域包括PC计数器、Java虚拟机栈、本地方法栈、堆、方法区、运行时常量池和直接内存。 本文主要介绍各个内存区域的作用和特性，同时分别阐述各个区域发生内存溢出的可能性和异常类型。","text":"前言JVM内存区域包括PC计数器、Java虚拟机栈、本地方法栈、堆、方法区、运行时常量池和直接内存。 本文主要介绍各个内存区域的作用和特性，同时分别阐述各个区域发生内存溢出的可能性和异常类型。 正文 (一). JVM内存区域Java虚拟机执行Java程序的过程中，会把所管理的内存划分为若干不同的数据区域。这些内存区域各有各的用途，以及创建和销毁时间。有的区域随着虚拟机进程的启动而存在，有的区域伴随着用户线程的启动和结束而创建和销毁。 JVM内存区域也称为Java运行时数据区域。其中包括：程序计数器、虚拟机栈、本地方法栈、堆、静态方法区、静态常量池等。 注意：程序计数器、虚拟机栈、本地方法栈属于每个线程私有的；堆和方法区属于线程共享访问的。 1.1. PC计数器程序计数器（Program Counter Register）是一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码行号指示器。 当前线程所执行的字节码行号指示器。 每个线程都有一个自己的PC计数器。 线程私有的，生命周期与线程相同，随JVM启动而生，JVM关闭而死。 线程执行Java方法时，记录其正在执行的虚拟机字节码指令地址。 线程执行Native方法时，计数器记录为空(Undefined)。 唯一在Java虚拟机规范中没有规定任何OutOfMemoryError情况区域。 1.2. Java虚拟机栈线程私有内存空间，它的生命周期和线程相同。线程执行期间，每个方法执行时都会创建一个栈帧(Stack Frame) ，用于存储 局部变量表、操作数栈 、动态链接 、方法出口 等信息。 局部变量表 操作数栈 动态链接 方法出口 每一个方法从调用直到执行完成的过程，就对应着一个栈帧在虚拟机栈中的入栈和出栈的全过程。 下面依次解释栈帧里的四种组成元素的具体结构和功能： 1). 局部变量表局部变量表是一组变量值的存储空间，用于存储方法参数和局部变量。 在 Class 文件的方法表的 Code 属性的 max_locals 指定了该方法所需局部变量表的最大容量。 局部变量表在编译期间分配内存空间，可以存放编译期的各种变量类型： 基本数据类型 ：boolean, byte, char, short, int, float, long, double等8种； 对象引用类型 ：reference，指向对象起始地址的引用指针； 返回地址类型 ：returnAddress，返回地址的类型。 变量槽(Variable Slot)： 变量槽是局部变量表的最小单位，规定大小为32位。对于64位的long和double变量而言，虚拟机会为其分配两个连续的Slot空间。 2). 操作数栈操作数栈（Operand Stack）也常称为操作栈，是一个后入先出栈。在 Class 文件的 Code 属性的 max_stacks 指定了执行过程中最大的栈深度。Java虚拟机的解释执行引擎被称为基于栈的执行引擎 ，其中所指的栈就是指－操作数栈。 和局部变量表一样，操作数栈也是一个以32字长为单位的数组。 虚拟机在操作数栈中可存储的数据类型：int、long、float、double、reference和returnType等类型 (对于byte、short以及char类型的值在压入到操作数栈之前，也会被转换为int)。 和局部变量表不同的是，它不是通过索引来访问，而是通过标准的栈操作 — 压栈和出栈来访问。比如，如果某个指令把一个值压入到操作数栈中，稍后另一个指令就可以弹出这个值来使用。 虚拟机把操作数栈作为它的工作区——大多数指令都要从这里弹出数据，执行运算，然后把结果压回操作数栈。 123456beginiload_0 // push the int in local variable 0 onto the stackiload_1 // push the int in local variable 1 onto the stackiadd // pop two ints, add them, push resultistore_2 // pop int, store into local variable 2end 在这个字节码序列里，前两个指令 iload_0 和 iload_1 将存储在局部变量表中索引为0和1的整数压入操作数栈中，其后iadd指令从操作数栈中弹出那两个整数相加，再将结果压入操作数栈。第四条指令istore_2则从操作数栈中弹出结果，并把它存储到局部变量表索引为2的位置。 下图详细表述了这个过程中局部变量表和操作数栈的状态变化(图中没有使用的局部变量表和操作数栈区域以空白表示)。 3). 动态链接每个栈帧都包含一个指向运行时常量池中所属的方法引用，持有这个引用是为了支持方法调用过程中的动态链接。 Class文件的常量池中存在有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用为参数。这些符号引用： 静态解析：一部分会在类加载阶段或第一次使用的时候转化为直接引用（如final、static域等），称为静态解析， 动态解析：另一部分将在每一次的运行期间转化为直接引用，称为动态链接。 4). 方法返回地址当一个方法开始执行以后，只有两种方法可以退出当前方法： 正常返回：当执行遇到返回指令，会将返回值传递给上层的方法调用者，这种退出的方式称为正常完成出口(Normal Method Invocation Completion)，一般来说，调用者的PC计数器可以作为返回地址。 异常返回：当执行遇到异常，并且当前方法体内没有得到处理，就会导致方法退出，此时是没有返回值的，称为异常完成出口(Abrupt Method Invocation Completion)，返回地址要通过异常处理器表来确定。 当一个方法返回时，可能依次进行以下3个操作： 恢复上层方法的局部变量表和操作数栈。 把返回值压入调用者栈帧的操作数栈。 将PC计数器的值指向下一条方法指令位置。 小结： 注意：在Java虚拟机规范中，对这个区域规定了两种异常。其一：如果当前线程请求的栈深度大于虚拟机栈所允许的深度，将会抛出 StackOverflowError 异常（在虚拟机栈不允许动态扩展的情况下）；其二：如果扩展时无法申请到足够的内存空间，就会抛出 OutOfMemoryError 异常。 1.3. 本地方法栈本地方法栈和Java虚拟机栈发挥的作用非常相似，主要区别是Java虚拟机栈执行的是Java方法服务，而本地方法栈执行Native方法服务(通常用C编写)。 有些虚拟机发行版本(譬如Sun HotSpot虚拟机)直接将本地方法栈和Java虚拟机栈合二为一。与虚拟机栈一样，本地方法栈也会抛出StackOverflowError和OutOfMemoryError异常。 1.4. 堆Java堆是被所有线程共享的最大的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。 在Java中，堆被划分成两个不同的区域：新生代 (Young Generation) 、老年代 (Old Generation) 。新生代 (Young) 又被划分为三个区域：一个Eden区和两个Survivor区 - From Survivor区和To Survivor区。 简要归纳：新的对象分配是首先放在年轻代 (Young Generation) 的Eden区，Survivor区作为Eden区和Old区的缓冲，在Survivor区的对象经历若干次收集仍然存活的，就会被转移到老年代Old中。 这样划分的目的是为了使JVM能够更好的管理堆内存中的对象，包括内存的分配以及回收。 1.5. 方法区方法区和Java堆一样，为多个线程共享，它用于存储类信息、常量、静态常量和即时编译后的代码等数据。 1.6. 运行时常量池运行时常量池是方法区的一部分，Class文件中除了有类的版本、字段、方法和接口等描述信息外，还有一类信息是常量池，用于存储编译期间生成的各种字面量和符号引用。 1.7. 直接内存直接内存不属于虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。Java NIO允许Java程序直接访问直接内存，通常直接内存的速度会优于Java堆内存。因此，对于读写频繁、性能要求高的场景，可以考虑使用直接内存。 (二). 常见内存溢出异常除了程序计数器外，Java虚拟机的其他运行时区域都有可能发生OutOfMemoryError的异常，下面分别给出验证： 2.1. Java堆溢出Java堆能够存储对象实例。通过不断地创建对象，并保证GC Roots到对象有可达路径来避免垃圾回收机制清除这些对象。当对象数量到达最大堆的容量限制时就会产生OutOfMemoryError异常。 设置JVM启动参数：-Xms20M设置堆的最小内存为20M，-Xmx20M设置堆的最大内存和最小内存一样，这样可以防止Java堆在内存不足时自动扩容。-XX:+HeapDumpOnOutOfMemoryError参数可以让虚拟机在出现内存溢出异常时Dump出内存堆运行时快照。 HeapOOM.java 1234567891011121314/** * VM Args: -Xms20M -Xmx20M -XX:+HeapDumpOnOutOfMemoryError */public class HeapOOM &#123; public static class OOMObject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMObject&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new OOMObject()); &#125; &#125;&#125; 测试运行结果： 打开Java VisualVM导出Heap内存运行时的dump文件。 HeapOOM对象不停地被创建，堆内存使用达到99%。垃圾回收器不断地尝试回收但都以失败告终。 分析：遇到这种情况，通常要考虑内存泄露和内存溢出两种可能性。 如果是内存泄露： 进一步使用Java VisualVM工具进行分析，查看泄露对象是通过怎样的路径与GC Roots关联而导致垃圾回收器无法回收的。 如果是内存溢出： 通过Java VisualVM工具分析，不存在泄露对象，也就是说堆内存中的对象必须得存活着。就要考虑如下措施： 从代码上检查是否存在某些对象生命周期过长、持续状态时间过长的情况，尝试减少程序运行期的内存。 检查虚拟机的堆参数(-Xmx与-Xms)，对比机器的物理内存看是否还可以调大。 2.2. 虚拟机和本地方法栈溢出关于虚拟机栈和本地方法栈，分析内存异常类型可能存在以下两种： 如果现场请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常。 如果虚拟机在扩展栈时无法申请到足够的内存空间，可能会抛出OutOfMemoryError异常。 可以划分为两类问题，当栈空间无法分配时，到底时栈内存太小，还是已使用的栈内存过大。 StackOverflowError异常测试方案一： 使用-Xss参数减少栈内存的容量，异常发生时打印栈的深度。 定义大量的本地局部变量，以达到增大栈帧中的本地变量表的长度。 设置JVM启动参数：-Xss128k设置栈内存的大小为128k。 JavaVMStackSOF.java 123456789101112131415161718192021/** * VM Args: -Xss128k */public class JavaVMStackSOF &#123; private int stackLength = 1; private void stackLeak() &#123; stackLength++; stackLeak(); &#125; public static void main(String[] args) &#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try &#123; oom.stackLeak(); &#125; catch (Throwable e) &#123; System.out.println(\"Stack length: \" + oom.stackLength); throw e; &#125; &#125;&#125; 测试结果： 分析：在单个线程下，无论是栈帧太大还是虚拟机栈容量太小，当无法分配内存的时候，虚拟机抛出的都是StackOverflowError异常。 测试方案二： 不停地创建线程并保持线程运行状态。 JavaVMStackOOM.java 12345678910111213141516171819202122232425/** * VM Args: -Xss2M */public class JavaVMStackOOM &#123; private void running() &#123; while (true) &#123; &#125; &#125; public void stackLeakByThread() &#123; while (true) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; running(); &#125; &#125;).start(); &#125; &#125; public static void main(String[] args) &#123; JavaVMStackOOM oom = new JavaVMStackOOM(); oom.stackLeakByThread(); &#125;&#125; 测试结果：1Exception in thread \"main\" java.lang.OutOfMemoryError: unable to create new native thread 上述测试代码运行时存在较大的风险，可能会导致操作系统假死，这里就不亲自测试了，引用作者的测试结果。 2.3. 方法区和运行时常量池溢出(一). 运行时常量池内存溢出测试运行时常量和字面量都存放于运行时常量池中，常量池又是方法区的一部分，因此两个区域的测试是一样的。这里采用String.intern()进行测试： String.intern()是一个native方法，它的作用是：如果字符串常量池中存在一个String对象的字符串，那么直接返回常量池中的这个String对象；否则，将此String对象包含的字符串放入常量池中，并且返回这个String对象的引用。 设置JVM启动参数：通过-XX:PermSize=10M和-XX:MaxPermSize=10M限制方法区的大小为10M，从而间接的限制其中常量池的容量。 RuntimeConstantPoolOOM.java 123456789101112131415/** * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M */public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; // 使用List保持着常量池的引用，避免Full GC回收常量池 List&lt;String&gt; list = new ArrayList&lt;&gt;(); // 10MB的PermSize在Integer范围内足够产生OOM了 int i = 0; while (true) &#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125; 测试结果分析： JDK1.6版本运行结果：12Exception in thread \"main\" java.lang.OutOfMemoryError: PermGen space at java.lang.String.intern(Native Method) JDK1.6版本运行结果显示常量池会溢出并抛出永久带的OutOfMemoryError异常。而JDK1.7及以上的版本则不会得到相同的结果，它会一直循环下去。 (二). 方法区内存溢出测试方法区存放Class相关的信息，比如类名、访问修饰符、常量池、字段描述、方法描述等。对于方法区的内存溢出的测试，基本思路是在运行时产生大量类字节码区填充方法区。 这里引入Spring框架的CGLib动态代理的字节码技术，通过循环不断生成新的代理类，达到方法区内存溢出的效果。 JavaMethodAreaOOM.java 1234567891011121314151617181920212223242526/** * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M */public class JavaMethodAreaOOM &#123; public static void main(String[] args) &#123; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; return proxy.invokeSuper(obj, args); &#125; &#125;); enhancer.create(); &#125; &#125; private static class OOMObject &#123; public OOMObject() &#123; &#125; &#125;&#125; JDK1.6版本运行结果：1234Exception in thread \"main\" java.lang.OutOfMemoryError: PermGen space at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClassCond(ClassLoader.java:632) at java.lang.ClassLoader.defineClass(ClassLoader.java:616) 测试结果分析： JDK1.6版本运行结果显示常量池会溢出并抛出永久带的OutOfMemoryError异常。而JDK1.7及以上的版本则不会得到相同的结果，它会一直循环下去。 2.4. 直接内存溢出本机直接内存的容量可通过-XX:MaxDirectMemorySize指定，如果不指定，则默认与Java堆最大值(-Xmx指定)一样。 测试场景： 直接通过反射获取Unsafe实例，通过反射向操作系统申请分配内存： 设置JVM启动参数：-Xmx20M指定Java堆的最大内存，-XX:MaxDirectMemorySize=10M指定直接内存的大小。 DirectMemoryOOM.java 12345678910111213141516/** * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M */public class DirectMemoryOOM &#123; private static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception &#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while (true) &#123; unsafe.allocateMemory(_1MB); &#125; &#125;&#125; 测试结果： 测试结果分析： 由DirectMemory导致的内存溢出，一个明显的特征是Heap Dump文件中不会看到明显的异常信息。如果OOM发生后Dump文件很小，并且程序中直接或者间接地使用了NIO，那么就可以考虑一下这方面的问题。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA虚拟机系列","slug":"JAVA虚拟机系列","permalink":"https://ostenant.coding.me/categories/JAVA虚拟机系列/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://ostenant.coding.me/tags/JVM/"}]},{"title":"JVM系列(一) - JVM总体概述","slug":"JVM系列(一) - JVM总体概述","date":"2017-04-22T06:55:00.000Z","updated":"2018-08-02T09:34:58.826Z","comments":true,"path":"2017/04/22/JVM系列(一) - JVM总体概述/","link":"","permalink":"https://ostenant.coding.me/2017/04/22/JVM系列(一) - JVM总体概述/","excerpt":"前言JVM是Java Virtual Machine(Java虚拟机)的缩写，JVM是一种用于计算设备的规范，它是一个虚构的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。","text":"前言JVM是Java Virtual Machine(Java虚拟机)的缩写，JVM是一种用于计算设备的规范，它是一个虚构的计算机，是通过在实际的计算机上仿真模拟各种计算机功能来实现的。 JVM屏蔽了与具体操作系统平台相关的信息，使Java程序只需生成在Java虚拟机上一次编译，多次运行，具有跨平台性。JVM在执行字节码时，实际上最终还是把字节码解释成具体平台上的机器指令执行。 Java虚拟机包括一套字节码指令集、一组寄存器、一个栈、一个垃圾回收堆和一个存储方法区。 本文将简述以下内容: JVM是什么？ JVM能干什么？ JVM生命周期？ JVM组成架构？ 正文 JVM是什么JDK、JRE和JVM对比 JVM，JRE，JDK 都是 java 语言的支柱，他们分工协作。但不同的是 Jdk 和 JRE 是真实存在的，而 JVM 是一个抽象的概念，并不真实存在。 JDKJDK(Java Development Kit) 是 Java 语言的软件开发工具包（SDK）。JDK 物理存在，是 programming tools、JRE 和 JVM 的一个集合。 JREJRE（Java Runtime Environment）Java 运行时环境，JRE 是物理存在的，主要由Java API 和 JVM 组成，提供了用于执行 java 应用程序最低要求的环境。 JVMJVM是一种用于计算设备的规范，它是一个虚构的计算机的软件实现，简单的说，JVM是运行byte code字节码程序的一个容器。 JVM的特点 基于堆栈`的虚拟机 ：最流行的计算机体系结构，如英特尔X86架构和ARM架构上运行基于寄存器 。比如，安卓的Davilk虚拟机就是基于寄存器结构 但是，JVM是基于栈结构的。 符号引用 ：除了基本类型以外的数据 （类和接口） 都是通过符号来引用，而不是通过显式地使用内存地址来引用。 垃圾收集 ：一个类的实例是由用户程序创建和垃圾回收自动销毁。 网络字节顺序 ：Java class文件用网络字节码顺序来进行存储，保证了小端的Intel x86架构和大端的RISC系列的架构之间的无关性。 JVM字节码JVM使用Java字节码的方式，作为Java 用户语言 和 机器语言 之间的中间语言。实现一个通用的、 机器无关 的执行平台。 JVM能干什么基于安全方面考虑，JVM 要求在 class 文件中使用强制性的语法和约束，但任意一门语言都可以转换为被 JVM 接受的有效的 class 文件。作为一个通用的、机器无关的执行平台，任何其他语言的实现者都可将 JVM 当作他的语言产品交付媒介。 JVM 中执行过程如下： 加载代码 验证代码 执行代码 提供运行环境 JVM生命周期 启动：任何一个拥有main方法的class都可以作为JVM实例运行的起点。 运行：main函数为起点，程序中的其他线程均有它启动，包括daemon守护线程和non-daemon普通线程。daemon是JVM自己使用的线程比如GC线程，main方法的初始线程是non-daemon。 消亡：所有线程终止时，JVM实例结束生命。 JVM组成架构JAVA 代码执行过程如下： 1. 类加载器（Class Loader）类加载器 负责加载程序中的类型（类和接口），并赋予唯一的名字予以标识。 JDK 默认提供的三种 ClassLoader如下： 类加载器的关系 Bootstrap Classloader 是在Java虚拟机启动后初始化的。 Bootstrap Classloader 负责加载 ExtClassLoader，并且将 ExtClassLoader的父加载器设置为 Bootstrap Classloader Bootstrap Classloader 加载完 ExtClassLoader 后，就会加载 AppClassLoader，并且将 AppClassLoader 的父加载器指定为 ExtClassLoader。 类加载器的作用 Class Loader 实现 负责加载 Bootstrap Loader C++ %JAVA_HOME%/jre/lib, %JAVA_HOME%/jre/classes以及-Xbootclasspath参数指定的路径以及中的类 Extension ClassLoader Java %JAVA_HOME%/jre/lib/ext，路径下的所有classes目录以及java.ext.dirs系统变量指定的路径中类库 Application ClassLoader Java Classpath所指定的位置的类或者是jar文档，它也是Java程序默认的类加载器 双亲委托机制Java中ClassLoader的加载采用了双亲委托机制，采用双亲委托机制加载类的时候采用如下的几个步骤： 当前ClassLoader首先从自己已经加载的类中查询是否此类已经加载，如果已经加载则直接返回原来已经加载的类。 当前ClassLoader的缓存中没有找到被加载的类的时候，委托父类加载器去加载，父类加载器采用同样的策略，首先查看自己的缓存，然后委托父类的父类去加载，一直到Bootstrap ClassLoader。 当所有的父类加载器都没有加载的时候，再由当前的类加载器加载，并将其放入它自己的缓存中，以便下次有加载请求的时候直接返回。 小结 ：双亲委托机制的核心思想分为两个步骤。其一，自底向上检查类是否已经加载；其二，自顶向下尝试加载类。 ClassLoader隔离问题每个类装载器都有一个自己的命名空间用来保存已装载的类。当一个类装载器装载一个类时，它会通过保存在命名空间里的类全局限定名(Fully Qualified Class Name)进行搜索来检测这个类是否已经被加载了。 JVM 及 Dalvik 对类唯一的识别是 ClassLoader id + PackageName + ClassName，所以一个运行程序中是有可能存在两个包名和类名完全一致的类的。并且如果这两个”类”不是由一个 ClassLoader 加载，是无法将一个类的示例强转为另外一个类的，这就是 ClassLoader 隔离。 双亲委托 是 ClassLoader类一致问题的一种解决方案，也是 Android 差价化开发和热修复的基础。 类装载器特点Java提供了动态加载特性。在运行时的第一次引用到一个class的时候会对它进行装载(Loading) 、 链接(Linking) 和 初始化(Initialization) ，而不是在编译时进行。不同的JVM的实现不同，本文所描述的内容均只限于Hotspot JVM。 JVM的类装载器负责动态装载，Java的类装载器有如下几个特点： 层级结构：Java里的类装载器被组织成了有父子关系的层级结构。Bootstrap类装载器是所有装载器的父亲。 代理模式： 基于层级结构，类的代理可以在装载器之间进行代理。当装载器装载一个类时，首先会检查它在父装载器中是否进行了装载。如果上层装载器已经装载了这个类，这个类会被直接使用。反之，类装载器会请求装载这个类 可见性限制：一个子装载器可以查找父装载器中的类，但是一个父装载器不能查找子装载器里的类。 不允许卸载：类装载器可以装载一个类但是不可以卸载它，不过可以删除当前的类装载器，然后创建一个新的类装载器装载。 类装载器过程 加载（Loading） 首先，根据类的全限定名找到代表这个类的Class文件，然后读取到一个字节数组中。接着，这些字节会被解析检验它们是否代表一个Class对象 并包含正确的major、minor版本信息。直接父类 的类和接口也会被加载进来。这些操作一旦完成，类或者接口对象 就从二进制表示中创建出来了。 链接（Linking） 链接是检验类或接口并准备类型和父类接口的过程。链接过程包含三步：校验（Verifying）、准备（Preparing）、部分解析（Optionally resolving）。 验证 这是类装载中最复杂的过程，并且花费的时间也是最长的。任务是确保导入类型的准确性，验证阶段做的检查，运行时不需要再做。虽然减慢加了载速度，但是避免了多次检查。 准备 准备过程通常分配一个结构用来存储类信息，这个结构中包含了类中定义的成员变量，方法 和接口信息等。 解析 解析是可选阶段，把这个类的常量池中的所有的符号引用改变成直接引用。如果不执行，符号解析要等到字节码指令使用这个引用时才会进行。 初始化（Initialization） 把类中的变量初始化成合适的值。执行静态初始化程序，把静态变量初始化成指定的值。 JVM规范定义了上面的几个任务，不过它允许具体执行的时候能够有些灵活的变动。 2. 执行引擎（Execution Engine）通过类装载器装载的，被分配到JVM的运行时数据区的字节码会被执行引擎执行。 执行引擎 以指令为单位读取 Java 字节码。它就像一个 CPU 一样，一条一条地执行机器指令。每个字节码指令都由一个1字节的操作码和附加的操作数组成。执行引擎 取得一个操作码，然后根据操作数来执行任务，完成后就继续执行下一条操作码。 不过 Java 字节码是用一种人类可以读懂的语言编写的，而不是用机器可以直接执行的语言。因此，执行引擎 必须把字节码转换成可以直接被 JVM 执行的语言。 字节码 可以通过以下两种方式转换成机器语言： 解释器 解释器 一条一条地读取字节码，解释 并且 执行 字节码指令。因为它一条一条地解释和执行指令，所以它可以很快地解释字节码，但是执行起来会比较慢。这是解释执行的语言的一个缺点。字节码这种“语言”基本来说是解释执行的。 即时（Just-In-Time)编译器 即时编译器 被引入用来弥补解释器的缺点。执行引擎 首先按照 解释执行 的方式来执行，然后在合适的时候，即时编译器 把 整段字节码 编译成 本地代码。然后，执行引擎就没有必要再去解释执行方法了，它可以直接通过本地代码去执行它。执行本地代码比一条一条进行解释执行的速度快很多。编译后的代码可以执行的很快，因为本地代码是保存在缓存里的。 Java 字节码是解释执行的，但是没有直接在 JVM 宿主执行原生代码快。为了提高性能，Oracle Hotspot 虚拟机会找到执行最频繁的字节码片段并把它们编译成原生机器码。编译出的原生机器码被存储在非堆内存的代码缓存中。 通过这种方法（JIT），Hotspot 虚拟机将权衡下面两种时间消耗：将字节码编译成本地代码需要的额外时间和解释执行字节码消耗更多的时间。 这里插入一下 Android 5.0 以后用的 ART 虚拟机使用的是 AOT 机制。 Dalvik 是依靠一个 Just-In-Time (JIT)编译器去解释字节码。开发者编译后的应用代码需要通过一个解释器在用户的设备上运行，这一机制并不高效，但让应用能更容易在不同硬件和架构上运行。ART 则完全改变了这套做法，在应用安装时就预编译字节码到机器语言，这一机制叫Ahead-Of-Time (AOT）编译。在移除解释代码这一过程后，应用程序执行将更有效率，启动更快。 参考周志明，深入理解Java虚拟机：JVM高级特性与最佳实践，机械工业出版社 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"JAVA虚拟机系列","slug":"JAVA虚拟机系列","permalink":"https://ostenant.coding.me/categories/JAVA虚拟机系列/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://ostenant.coding.me/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://ostenant.coding.me/tags/JVM/"}]},{"title":"大型Web网站架构演变","slug":"大型Web网站架构演变","date":"2017-03-24T07:55:00.000Z","updated":"2018-06-18T01:56:34.926Z","comments":true,"path":"2017/03/24/大型Web网站架构演变/","link":"","permalink":"https://ostenant.coding.me/2017/03/24/大型Web网站架构演变/","excerpt":"前言我们以Java Web为例，来搭建一个简单的电商系统，看看这个系统可以如何一步步演变。该系统具备的功能： 用户模块：用户注册和管理 商品模块：商品展示和管理 交易模块：创建交易和管理","text":"前言我们以Java Web为例，来搭建一个简单的电商系统，看看这个系统可以如何一步步演变。该系统具备的功能： 用户模块：用户注册和管理 商品模块：商品展示和管理 交易模块：创建交易和管理 正文 阶段一、单机构建网站网站的初期，我们经常会在单机上跑我们所有的程序和软件。此时我们使用一个容器，如Tomcat、Jetty、Jboss，然后直接使用JSP/Servlet技术，或者使用一些开源的框架如Maven + Spring + Struts + Hibernate、Maven + Spring + Spring MVC + Mybatis。最后再选择一个数据库管理系统来存储数据，如MySQL、SqlServer、Oracle，然后通过JDBC进行数据库的连接和操作。 把以上的所有软件包括数据库、应用程序都装载同一台机器上，应用跑起来了，也算是一个小系统了。此时系统结果如下： 阶段二、应用服务器与数据库分离随着网站的上线，访问量逐步上升，服务器的负载慢慢提高，在服务器还没有超载的时候，我们应该就要做好准备，提升网站的负载能力。假如我们代码层面已难以优化，在不提高单台机器的性能的情况下，采用增加机器是一个不错的方式，不仅可以有效地提高系统的负载能力，而且性价比高。 增加的机器用来做什么呢？此时我们可以把数据库服务器和Web服务器拆分开来，这样不仅提高了单台机器的负载能力，也提高了容灾能力。 应用服务器与数据库分开后的架构如下图所示： 阶段三、应用服务器集群随着访问量继续增加，单台应用服务器已经无法满足需求了。在假设数据库服务器没有压力的情况下，我们可以把应用服务器从一台变成了两台甚至多台，把用户的请求分散到不同的服务器中，从而提高负载能力。而多台应用服务器之间没有直接的交互，他们都是依赖数据库各自对外提供服务。著名的做故障切换的软件有KeepAlived，KeepAlived是一个类似于Layer3、4、7交换机制的软件，他不是某个具体软件故障切换的专属品，而是可以适用于各种软件的一款产品。KeepAlived配合上ipvsadm又可以做负载均衡，可谓是神器。 我们以增加了一台应用服务器为例，增加后的系统结构图如下： 系统演变到这里，将会出现下面四个问题： 用户的请求由谁来转发到到具体的应用服务器？ 有那些转发的算法和策略可以使用？ 应用服务器如何返回用户的请求？ 用户如果每次访问到的服务器不一样，那么如何维护session的一致性？ 针对以上问题，常用的解决方案如下： 1、负载均衡的问题一般以下有5种解决方案： 1、HTTP重定向 HTTP重定向就是应用层的请求转发。用户的请求其实已经到了HTTP重定向负载均衡服务器，服务器根据算法要求用户重定向，用户收到重定向请求后，再次请求真正的集群 优点：简单易用； 缺点：性能较差。 2、DNS域名解析负载均衡 DNS域名解析负载均衡就是在用户请求DNS服务器，获取域名对应的IP地址时，DNS服务器直接给出负载均衡后的服务器IP。 优点：交给DNS，不用我们去维护负载均衡服务器； 缺点：当一个应用服务器挂了，不能及时通知DNS，而且DNS负载均衡的控制权在域名服务商那里，网站无法做更多的改善和更强大的管理。 3、反向代理服务器 在用户的请求到达反向代理服务器时（已经到达网站机房），由反向代理服务器根据算法转发到具体的服务器。常用的Apache，Nginx都可以充当反向代理服务器。 优点：部署简单； 缺点：代理服务器可能成为性能的瓶颈，特别是一次上传大文件。 4、IP层负载均衡 在请求到达负载均衡器后，负载均衡器通过修改请求的目的IP地址，从而实现请求的转发，做到负载均衡。 优点：性能更好； 缺点：负载均衡器的宽带成为瓶颈。 5、数据链路层负载均衡 在请求到达负载均衡器后，负载均衡器通过修改请求的MAC地址，从而做到负载均衡，与IP负载均衡不一样的是，当请求访问完服务器之后，直接返回客户。而无需再经过负载均衡器。 2、集群调度转发算法1、rr轮询调度算法 顾名思义，轮询分发请求。 优点：实现简单 缺点：不考虑每台服务器的处理能力 2、wrr加权调度算法 我们给每个服务器设置权值Weight，负载均衡调度器根据权值调度服务器，服务器被调用的次数跟权值成正比。 优点：考虑了服务器处理能力的不同 3、sh原地址散列算法 提取用户IP，根据散列函数得出一个key，再根据静态映射表，查处对应的value，即目标服务器IP。过目标机器超负荷，则返回空。 优点：实现同一个用户访问同一个服务器。 4、dh目标地址散列算法 原理同上，只是现在提取的是目标地址的IP来做哈希。 优点：实现同一个用户访问同一个服务器。 5、lc最少连接算法 优先把请求转发给连接数少的服务器。 优点：使得集群中各个服务器的负载更加均匀。 6、wlc加权最少连接算法 在lc的基础上，为每台服务器加上权值。算法为：（活动连接数 * 256 + 非活动连接数） ÷ 权重，计算出来的值小的服务器优先被选择。 优点：可以根据服务器的能力分配请求。 7、sed最短期望延迟算法 其实sed跟wlc类似，区别是不考虑非活动连接数。算法为：（活动连接数 +1 ) * 256 ÷ 权重，同样计算出来的值小的服务器优先被选择。 8、nq永不排队算法 改进的sed算法。我们想一下什么情况下才能“永不排队”，那就是服务器的连接数为0的时候，那么假如有服务器连接数为0，均衡器直接把请求转发给它，无需经过sed的计算。 9、LBLC基于局部性最少连接算法 负载均衡器根据请求的目的IP地址，找出该IP地址最近被使用的服务器，把请求转发之。若该服务器超载，最采用最少连接数算法。 10、LBLCR带复制的基于局部性最少连接算法 负载均衡器根据请求的目的IP地址，找出该IP地址最近使用的“服务器组”，注意，并不是具体某个服务器，然后采用最少连接数从该组中挑出具体的某台服务器出来，把请求转发之。若该服务器超载，那么根据最少连接数算法，在集群的非本服务器组的服务器中，找出一台服务器出来，加入本服务器组，然后把请求转发。 3、集群请求返回模式问题1、NAT 负载均衡器接收用户的请求，转发给具体服务器，服务器处理完请求返回给均衡器，均衡器再重新返回给用户。 2、DR 负载均衡器接收用户的请求，转发给具体服务器，服务器出来玩请求后直接返回给用户。需要系统支持IP Tunneling协议，难以跨平台。 3、TUN 同上，但无需IP Tunneling协议，跨平台性好，大部分系统都可以支持。 4、集群Session一致性问题1、Session Sticky Session sticky就是把同一个用户在某一个会话中的请求，都分配到固定的某一台服务器中，这样我们就不需要解决跨服务器的session问题了，常见的算法有ip_hash算法，即上面提到的两种散列算法。 优点：实现简单； 缺点：应用服务器重启则session消失。 2、Session Replication Session replication就是在集群中复制session，使得每个服务器都保存有全部用户的session数据。 优点：减轻负载均衡服务器的压力，不需要要实现ip_hasp算法来转发请求； 缺点：复制时网络带宽开销大，访问量大的话Session占用内存大且浪费。 3、Session数据集中存储 Session数据集中存储就是利用数据库来存储session数据，实现了session和应用服务器的解耦。 优点：相比Session replication的方案，集群间对于宽带和内存的压力大幅减少； 缺点：需要维护存储Session的数据库。 4、Cookie Base Cookie base就是把Session存在Cookie中，由浏览器来告诉应用服务器我的session是什么，同样实现了session和应用服务器的解耦。 优点：实现简单，基本免维护。 缺点：cookie长度限制，安全性低，带宽消耗。 值得一提的是： Nginx目前支持的负载均衡算法有wrr、sh（支持一致性哈希）、fair（lc）。但Nginx作为均衡器的话，还可以一同作为静态资源服务器。 Keepalived + ipvsadm比较强大，目前支持的算法有：rr、wrr、lc、wlc、lblc、sh、dh Keepalived支持集群模式有：NAT、DR、TUN Nginx本身并没有提供session同步的解决方案，而Apache则提供了session共享的支持。 解决了以上的问题之后，系统的结构如下： 阶段四、数据库读写分离化上面我们总是假设数据库负载正常，但随着访问量的的提高，数据库的负载也在慢慢增大。那么可能有人马上就想到跟应用服务器一样，把数据库一份为二再负载均衡即可。 但对于数据库来说，并没有那么简单。假如我们简单的把数据库一分为二，然后对于数据库的请求，分别负载到A机器和B机器，那么显而易见会造成两台数据库数据不统一的问题。那么对于这种情况，我们可以先考虑使用读写分离和主从复制的方式。 读写分离后的系统结构如下： 这个结构变化后也会带来两个问题： 主从数据库之间数据同步问题。 应用对于数据源的选择问题。 解决方案： 使用MySQL自带的Master + Slave的方式实现主从复制。 采用第三方数据库中间件，例如MyCat。MyCat是从Cobar发展而来的，而Cobar是阿里开源的数据库中间件，后来停止开发。MyCat是国内比较好的MySql开源数据库分库分表中间件。 阶段五、用搜索引擎缓解读库的压力数据库做读库的话，常常对模糊查找力不从心，即使做了读写分离，这个问题还未能解决。以我们所举的交易网站为例，发布的商品存储在数据库中，用户最常使用的功能就是查找商品，尤其是根据商品的标题来查找对应的商品。对于这种需求，一般我们都是通过like功能来实现的，但是这种方式的代价非常大，而且结果非常不准确。此时我们可以使用搜索引擎的倒排索引来完成。 搜索引擎具有的优点：它能够大大提高查询速度和搜索准确性。 引入搜索引擎的开销 带来大量的维护工作，我们需要自己实现索引的构建过程，设计全量/增加的构建方式来应对非实时与实时的查询需求。 需要维护搜索引擎集群 搜索引擎并不能替代数据库，它解决了某些场景下的精准、快速、高效的“读”操作，是否引入搜索引擎，需要综合考虑整个系统的需求。 引入搜索引擎后的系统结构如下： 阶段六、用缓存缓解读库的压力常用的缓存机制包括页面级缓存、应用数据缓存和数据库缓存。 应用层和数据库层的缓存随着访问量的增加，逐渐出现了许多用户访问同一部分热门内容的情况，对于这些比较热门的内容，没必要每次都从数据库读取。我们可以使用缓存技术，例如可以使用Google的开源缓存技术Guava或者使用Memecahed作为应用层的缓存，也可以使用Redis作为数据库层的缓存。 另外，在某些场景下，关系型数据库并不是很适合，例如我想做一个“每日输入密码错误次数限制”的功能，思路大概是在用户登录时，如果登录错误，则记录下该用户的IP和错误次数，那么这个数据要放在哪里呢？假如放在内存中，那么显然会占用太大的内容；假如放在关系型数据库中，那么既要建立数据库表，还要简历对应的Java bean，还要写SQL等等。而分析一下我们要存储的数据，无非就是类似{ip:errorNumber}这样的key:value数据。对于这种数据，我们可以用NOSQL数据库来代替传统的关系型数据库。 页面缓存除了数据缓存，还有页面缓存。比如使用HTML5的localstroage或者Cookie。除了页面缓存带来的性能提升外，对于并发访问且页面置换频率小的页面，应尽量使用页面静态化技术。 优点：减轻数据库的压力， 大幅度提高访问速度； 缺点：需要维护缓存服务器，提高了编码的复杂性。 值得一提的是： 缓存集群的调度算法不同与上面提到的应用服务器和数据库。最好采用一致性哈希算，这样才能提高命中率。 加入缓存后的系统结构如下： 阶段七、数据库水平拆分与垂直拆分我们的网站演进到现在，交易、商品、用户的数据都还在同一个数据库中。尽管采取了增加缓存和读写分离的方式，但随着数据库的压力继续增加，数据库数据量的瓶颈越来越突出，此时，我们可以有数据垂直拆分和水平拆分两种选择。 数据垂直拆分垂直拆分的意思是把数据库中不同的业务数据拆分到不同的数据库中，结合现在的例子，就是把交易、商品、用户的数据分开。 优点： 解决了原来把所有业务放在一个数据库中的压力问题； 可以根据业务的特点进行更多的优化。 缺点： 需要维护多个数据库的状态一致性和数据同步。 问题： 需要考虑原来跨业务的事务； 跨数据库的Join。 解决问题方案： 应该在应用层尽量避免跨数据库的分布式事务，如果非要跨数据库，尽量在代码中控制。 通过第三方中间件来解决，如上面提到的MyCat，MyCat提供了丰富的跨库Join方案，详情可参考MyCat官方文档。 数据垂直拆分后的结构如下： 数据水平拆分数据水平拆分就是把同一个表中的数据拆分到两个甚至多个数据库中。产生数据水平拆分的原因是某个业务的数据量或者更新量到达了单个数据库的瓶颈，这时就可以把这个表拆分到两个或更多个数据库中。 优点： 如果能克服以上问题，那么我们将能够很好地对数据量及写入量增长的情况。 问题： 访问用户信息的应用系统需要解决SQL路由的问题，因为现在用户信息分在了两个数据库中，需要在进行数据操作时了解需要操作的数据在哪里。 主键 的处理也变得不同，例如原来自增字段，现在不能简单地继续使用。 如果需要分页查询，那就更加麻烦。 解决问题方案： 我们还是可以通过可以解决第三方中间件，如MyCat。MyCat可以通过SQL解析模块对我们的SQL进行解析，再根据我们的配置，把请求转发到具体的某个数据库。我们可以通过UUID保证唯一或自定义ID方案来解决。 MyCat也提供了丰富的分页查询方案，比如先从每个数据库做分页查询，再合并数据做一次分页查询等等。 数据水平拆分后的结构如下： 阶段八、应用的拆分按微服务拆分应用随着业务的发展，业务越来越多，应用越来越大。我们需要考虑如何避免让应用越来越臃肿。这就需要把应用拆开，从一个应用变为俩个甚至更多。还是以我们上面的例子，我们可以把用户、商品、交易拆分开。变成“用户、商品”和“用户，交易”两个子系统。 拆分后的结构： 问题： 这样拆分后，可能会有一些相同的代码，如用户相关的代码，商品和交易都需要用户信息，所以在两个系统中都保留差不多的操作用户信息的代码。如何保证这些代码可以复用是一个需要解决的问题。 解决问题： 通过走服务化SOA的路线来解决频繁公共的服务。 走SOA服务化治理道路为了解决上面拆分应用后所出现的问题，我们把公共的服务拆分出来，形成一种服务化的模式，简称SOA。 采用服务化之后的系统结构： 优点： 相同的代码不会散落在不同的应用中了，这些实现放在了各个服务中心，使代码得到更好的维护。 我们把对数据库的交互业务放在了各个服务中心，让前端的Web应用更注重与浏览器交互的工作。 问题： 如何进行远程的服务调用？ 解决方法： 可以通过下面的引入消息中间件来解决。 阶段九、引入消息中间件随着网站的继续发展，的系统中可能出现不同语言开发的子模块和部署在不同平台的子系统。此时我们需要一个平台来传递可靠的，与平台和语言无关的数据，并且能够把负载均衡透明化，能在调用过程中收集并分析调用数据，推测出网站的访问增长率等等一系列需求，对于网站应该如何成长做出预测。开源消息中间件有阿里的Dubbo，可以搭配Google开源的分布式程序协调服务Zookeeper实现服务器的注册与发现。 引入消息中间件后的结构： 总结以上的演变过程只是一个例子，并不适合所有的网站，实际中网站演进过程与自身业务和不同遇到的问题有密切的关系，没有固定的模式。只有认真的分析和不断地探究，才能发现适合自己网站的架构。 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"架构学习系列","slug":"架构学习系列","permalink":"https://ostenant.coding.me/categories/架构学习系列/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://ostenant.coding.me/tags/Web/"}]},{"title":"HTTP协议详解","slug":"HTTP协议详解","date":"2017-02-25T14:14:00.000Z","updated":"2018-06-18T01:45:57.272Z","comments":true,"path":"2017/02/25/HTTP协议详解/","link":"","permalink":"https://ostenant.coding.me/2017/02/25/HTTP协议详解/","excerpt":"简介HTTP协议(超文本传输协议HyperText Transfer Protocol)，它是基于TCP协议的应用层传输协议，简单来说就是客户端和服务端进行数据传输的一种规则。","text":"简介HTTP协议(超文本传输协议HyperText Transfer Protocol)，它是基于TCP协议的应用层传输协议，简单来说就是客户端和服务端进行数据传输的一种规则。 注意：客户端与服务器的角色不是固定的，一端充当客户端，也可能在某次请求中充当服务器。这取决与请求的发起端。HTTP协议属于应用层，建立在传输层协议TCP之上。客户端通过与服务器建立TCP连接，之后发送HTTP请求与接收HTTP响应都是通过访问Socket接口来调用TCP协议实现。 HTTP 是一种无状态 (stateless) 协议, HTTP协议本身不会对发送过的请求和相应的通信状态进行持久化处理。这样做的目的是为了保持HTTP协议的简单性，从而能够快速处理大量的事务, 提高效率。 然而，在许多应用场景中，我们需要保持用户登录的状态或记录用户购物车中的商品。由于HTTP是无状态协议，所以必须引入一些技术来记录管理状态，例如Cookie。 正文HTTP URLHTTP URL 包含了用于查找某个资源的详细信息, 格式如下: 1http://host[&quot;:&quot;port][abs_path] HTTP请求下图是在网上找的一张图，觉得能很好的表达HTTP请求的所发送的数据格式。 由上图可以看到，http请求由请求行，消息报头，请求正文三部分构成。 HTTP请求状态行请求行由请求Method, URL 字段和HTTP Version三部分构成, 总的来说请求行就是定义了本次请求的请求方式, 请求的地址, 以及所遵循的HTTP协议版本例如： 1GET /example.html HTTP/1.1 (CRLF) HTTP协议的方法有： GET： 请求获取Request-URI所标识的资源 POST： 在Request-URI所标识的资源后增加新的数据 HEAD： 请求获取由Request-URI所标识的资源的响应消息报头 PUT： 请求服务器存储或修改一个资源，并用Request-URI作为其标识 DELETE： 请求服务器删除Request-URI所标识的资源 TRACE： 请求服务器回送收到的请求信息，主要用于测试或诊断 CONNECT： 保留将来使用 OPTIONS： 请求查询服务器的性能，或者查询与资源相关的选项和需求 HTTP请求头消息报头由一系列的键值对组成，允许客户端向服务器端发送一些附加信息或者客户端自身的信息，主要包括： Header 解释 示例 Accept 指定客户端能够接收的内容类型 Accept: text/plain, text/html Accept-Charset 浏览器可以接受的字符编码集 Accept-Charset: iso-8859-5,utf-8 Accept-Encoding 指定浏览器可以支持的web服务器返回内容压缩编码类型 Accept-Encoding: compress, gzip Accept-Language 浏览器可接受的语言 Accept-Language: en,zh Accept-Ranges 可以请求网页实体的一个或者多个子范围字段 Accept-Ranges: bytes Authorization HTTP授权的授权证书类型 Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Cache-Control 指定请求和响应遵循的缓存机制 Cache-Control: no-cache Connection 表示是否需要持久连接（HTTP 1.1默认进行持久连接） Connection: close Cookie HTTP请求发送时，会把保存在该请求域名下的所有cookie值一起发送给web服务器 Cookie: $Version=1; Skin=new; Content-Length 请求的内容长度 Content-Length: 348 Content-Type 请求的与实体对应的MIME信息 Content-Type: application/x-www-form-urlencoded Date 请求发送的日期和时间 Date: Tue, 15 Nov 2010 08:12:31 GMT Expect 请求的特定的服务器行为 Expect: 100-continue From 发出请求的用户的Email From: user@email.com Host 指定请求的服务器的域名和端口号 Host: www.zcmhi.com If-Match 只有请求内容与实体相匹配才有效 If-Match: “737060cd8c284d8af7ad3082f209582d” If-Modified-Since 如果请求的部分在指定时间之后被修改则请求成功，未被修改则返回304代码 If-Modified-Since: Sat, 29 Oct 2010 19:43:31 GMT If-None-Match 如果内容未改变返回304代码，参数为服务器先前发送的Etag，与服务器回应的Etag比较判断是否改变 If-None-Match: “737060cd8c284d8af7ad3082f209582d” If-Range 如果实体未改变，服务器发送客户端丢失的部分，否则发送整个实体。参数也为Etag If-Range: “737060cd8c284d8af7ad3082f209582d” If-Unmodified-Since 只在实体在指定时间之后未被修改才请求成功 If-Unmodified-Since: Sat, 29 Oct 2010 19:43:31 GMT Max-Forwards 限制信息通过代理和网关传送的时间 Max-Forwards: 10 Pragma 用来包含实现特定的指令 Pragma: no-cache Proxy-Authorization 连接到代理的授权证书 Proxy-Authorization: Basic QWxhZGRpbjpvcGVuIHNlc2FtZQ== Range 只请求实体的一部分，指定范围 Range: bytes=500-999 Referer 先前网页的地址，当前请求网页紧随其后, 即来路 Referer: http://www.zcmhi.com/archives/71.html TE 客户端愿意接受的传输编码，并通知服务器接受接受尾加头信息 TE: trailers,deflate;q=0.5 Upgrade 向服务器指定某种传输协议以便服务器进行转换（如果支持） Upgrade: HTTP/2.0, SHTTP/1.3, IRC/6.9, RTA/x11 User-Agent User-Agent的内容包含发出请求的用户信息 User-Agent: Mozilla/5.0 (Linux; X11) Via 通知中间网关或代理服务器地址，通信协议 Via: 1.0 fred, 1.1 nowhere.com (Apache/1.1) Warning 关于消息实体的警告信息 Warn: 199 Miscellaneous warning HTTP请求正文只有在发送POST请求时才会有请求正文，GET方法并没有请求正文。 HTTP请求报文 HTTP响应与HTTP请求类似，先上一张图： HTTP响应也由三部分组成，包括状态行，消息报头，响应正文。 HTTP响应状态行状态行也由三部分组成，包括HTTP协议的版本，状态码，以及对状态码的文本描述。例如： 1HTTP/1.1 200 OK （CRLF） HTTP响应状态码状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值： 1xx：指示信息 - 表示请求已接收，继续处理 2xx：成功 - 表示请求已被成功接收、理解、接受 3xx：重定向 - 要完成请求必须进行更进一步的操作 4xx：客户端错误 - 请求有语法错误或请求无法实现 5xx：服务器端错误 - 服务器未能实现合法的请求 常见状态代码、状态描述、说明： 200： OK - 客户端请求成功 400： Bad Request - 客户端请求有语法错误，不能被服务器所理解 401： Unauthorized - 请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403： Forbidden - 服务器收到请求，但是拒绝提供服务 404： Not Found - 请求资源不存在，eg：输入了错误的URL 500： Internal Server Error - 服务器发生不可预期的错误 503： Server Unavailable - 服务器当前不能处理客户端的请求，一段时间后,可能恢复正常 HTTP响应状态码说明 StatusCode StatusCode语义 中文描述 100 Continue 继续。客户端应继续其请求 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 200 OK 请求成功。一般用于GET与POST请求 201 Created 已创建。成功请求并创建了新的资源 202 Accepted 已接受。已经接受请求，但未处理完成 203 Non-Authoritative Information 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 204 No Content 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 205 Reset Content 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 206 Partial Content 部分内容。服务器成功处理了部分GET请求 300 Multiple Choices 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 301 Moved Permanently 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 302 Found 临时移动。 与301类似。但资源只是临时被移动。客户端应继续使用原有URI 303 See Other 查看其它地址。与301类似。使用GET和POST请求查看 304 Not Modified 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 305 Use Proxy 使用代理。所请求的资源必须通过代理访问 306 Unused 已经被废弃的HTTP状态码 307 Temporary Redirect 临时重定向。与302类似。使用GET请求重定向 400 Bad Request 客户端请求的语法错误，服务器无法理解 401 Unauthorized 请求要求用户的身份认证 402 Payment Required 保留，将来使用 403 Forbidden 服务器理解请求客户端的请求，但是拒绝执行此请求 404 Not Found 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面 405 Method Not Allowed 客户端请求中的方法被禁止 406 Not Acceptable 服务器无法根据客户端请求的内容特性完成请求 407 Proxy Authentication Required 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 408 Request Time-out 服务器等待客户端发送的请求时间过长，超时 409 Conflict 服务器完成客户端的PUT请求是可能返回此代码，服务器处理请求时发生了冲突 410 Gone 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 411 Length Required 服务器无法处理客户端发送的不带Content-Length的请求信息 412 Precondition Failed 客户端请求信息的先决条件错误 413 Request Entity Too Large 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 414 Request-URI Too Larg 请求的URI过长（URI通常为网址），服务器无法处理 415 Unsupported Media Type 服务器无法处理请求附带的媒体格式 416 Requested range not satisfiable 客户端请求的范围无效 417 Expectation Failed 服务器无法满足Expect的请求头信息 500 Internal Server Error 服务器内部错误，无法完成请求 501 Not Implemented 服务器不支持请求的功能，无法完成请求 502 Bad Gateway 充当网关或代理的服务器，从远端服务器接收到了一个无效的请求 503 Service Unavailable 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 504 Gateway Time-out 充当网关或代理的服务器，未及时从远端服务器获取请求 505 HTTP Version not supported 服务器不支持请求的HTTP协议的版本，无法完成处理 HTTP响应报文 HTTP协议详解HTTP的五大特点 支持客户/服务器模式。 简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。早期这么做的原因是请求资源少，追求快。后来通过Connection: Keep-Alive实现长连接 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 非持久连接和持久连接在实际的应用中，客户端往往会发出一系列请求，接着服务器端对每个请求进行响应。对于这些请求|响应，如果每次都经过一个单独的TCP连接发送，称为非持久连接。反之，如果每次都经过相同的TCP连接进行发送，称为持久连接。 非持久连接在每次请求|响应之后都要断开连接，下次再建立新的TCP连接，这样就造成了大量的通信开销。例如前面提到的往返时间(RTT) 就是在建立TCP连接的过程中的代价。 非持久连接给服务器带来了沉重的负担，每台服务器可能同时面对数以百计甚至更多的请求。持久连接就是为了解决这些问题，其特点是一直保持TCP连接状态，直到遇到明确的中断要求之后再中断连接。持久连接减少了通信开销，节省了通信量。 HTTP和HTTPSHTTP的不足 通信使用明文(不加密),内容可能会被窃听 不验证通信方的身份,因此有可能遭遇伪装 无法证明报文的完整性,所以有可能已遭篡改 HTTPS介绍HTTP 协议中没有加密机制,但可以通 过和 SSL(Secure Socket Layer, 安全套接层 )或 TLS(Transport Layer Security, 安全层传输协议)的组合使用,加密 HTTP 的通信内容。属于通信加密，即在整个通信线路中加密。 1HTTP + 加密 + 认证 + 完整性保护 = HTTPS（HTTP Secure ） HTTPS 采用共享密钥加密（对称）和公开密钥加密（非对称）两者并用的混合加密机制。若密钥能够实现安全交换,那么有可能会考虑仅使用公开密钥加密来通信。但是公开密钥加密与共享密钥加密相比,其处理速度要慢。 所以应充分利用两者各自的优势, 将多种方法组合起来用于通信。 在交换密钥阶段使用公开密钥加密方式,之后的建立通信交换报文阶段 则使用共享密钥加密方式。 HTTPS握手过程的简单描述如下： 浏览器将自己支持的一套加密规则发送给网站。 1服务器获得浏览器公钥 网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。 1浏览器获得服务器公钥 获得网站证书之后浏览器要做以下工作： (a). 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。 (b). 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码（接下来通信的密钥），并用证书中提供的公钥加密（共享密钥加密）。 (c) 使用约定好的HASH计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。 123浏览器验证 -&gt; 随机密码服务器的公钥加密 -&gt; 通信的密钥通信的密钥 -&gt; 服务器 网站接收浏览器发来的数据之后要做以下的操作： (a). 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。 (b). 使用密码加密一段握手消息，发送给浏览器。 1服务器用自己的私钥解出随机密码 -&gt; 用密码解密握手消息（共享密钥通信）-&gt; 验证HASH与浏览器是否一致（验证浏览器） HTTPS的不足 加密解密过程复杂，导致访问速度慢 加密需要认向证机构付费 整个页面的请求都要使用HTTPS 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"网络协议系列","slug":"网络协议系列","permalink":"https://ostenant.coding.me/categories/网络协议系列/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://ostenant.coding.me/tags/HTTP/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://ostenant.coding.me/tags/HTTPS/"}]},{"title":"TCP协议简介","slug":"TCP协议简介","date":"2017-02-25T03:59:00.000Z","updated":"2018-06-18T01:51:19.635Z","comments":true,"path":"2017/02/25/TCP协议简介/","link":"","permalink":"https://ostenant.coding.me/2017/02/25/TCP协议简介/","excerpt":"前言TCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。","text":"前言TCP（Transmission Control Protocol 传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议。 TCP的特性 TCP提供一种面向连接的, 可靠的字节流服务; 在一个TCP连接中，仅有两方进行彼此通信。广播和多播不能用于TCP; TCP使用校验和, 确认和重传机制来保证可靠传输; TCP使用累积确认 TCP使用滑动窗口机制来实现流量控制，通过动态改变窗口的大小进行拥塞控制 TCP三次握手与四次挥手三次握手 所谓三次握手(Three-way Handshake)，是指建立一个 TCP 连接时，需要客户端和服务器总共发送3个包。 三次握手的目的是连接服务器指定端口，建立 TCP 连接，并同步连接双方的序列号和确认号，交换 TCP 窗口大小信息。在Socket 编程中，客户端执行 connect() 时。将触发三次握手。 12345678910111213141516171. 第一次握手(SYN=1, seq=x); - 客户端发送一个 TCP 的 SYN 标志位置1的包, 指明客户端打算连接的服务器的端口，以及初始序号 X, 保存在包头的序列号(Sequence Number)字段里。 - 发送完毕后，客户端进入 `SYN_SEND` 状态。2. 第二次握手(SYN=1, ACK=1, seq=y, ACKnum=x+1); - 服务器发回确认包(ACK)应答。即 SYN 标志位和 ACK 标志位均为1。服务器端选择自己 ISN 序列号, 放到 Seq 域里, 同时将确认序号(Acknowledgement Number)设置为客户端的 ISN 加1, 即x+1。 - 发送完毕后，服务器端进入 `SYN_RCVD` 状态。3. 第三次握手(ACK=1，ACKnum=y+1) - 客户端再次发送确认包(ACK), SYN 标志位为0, ACK 标志位为1, 并且把服务器发来 ACK 的序号字段+1, 放在确定字段中发送给对方, 并且在数据段放写ISN的+1 - 发送完毕后，客户端进入 `ESTABLISHED` 状态，当服务器端接收到这个包时，也进入 `ESTABLISHED` 状态，TCP 握手结束。 三次握手的过程的示意图如下： 四次挥手TCP的连接的拆除需要发送四个包，因此称为四次挥手(Four-way handshake)，也叫做改进的三次握手。客户端或服务器均可主动发起挥手动作，在 socket 编程中，任何一方执行 close() 操作即可产生挥手操作。 123456789101112131415161718192021222324251. 第一次挥手(FIN=1, seq=x); - 假设客户端想要关闭连接，客户端发送一个 FIN 标志位置为1的包, 表示自己已经没有数据可以发送了, 但是仍然可以接受数据。 - 发送完毕后，客户端进入 `FIN_WAIT_1` 状态。2. 第二次挥手(ACK=1, ACKnum=x+1); - 服务器端确认客户端的 FIN 包，发送一个确认包, 表明自己接受到了客户端关闭连接的请求，但还没有准备好关闭连接。 - 发送完毕后，服务器端进入 `CLOSE_WAIT` 状态, 客户端接收到这个确认包之后，进入 `FIN_WAIT_2` 状态, 等待服务器端关闭连接。3. 第三次挥手(FIN=1, seq=y); - 服务器端准备好关闭连接时, 向客户端发送结束连接请求, `FIN` 置为1。 - 发送完毕后, 服务器端进入 `LAST_ACK` 状态, 等待来自客户端的最后一个ACK。4. 第四次挥手(ACK=1，ACKnum=y+1) - 客户端接收到来自服务器端的关闭请求, 发送一个确认包, 并进入 `TIME_WAIT` 状态, 等待可能出现的要求重传的 ACK 包。 - 服务器端接收到这个确认包之后, 关闭连接, 进入 `CLOSED` 状态。 - 客户端等待了某个固定时间（两个最大段生命周期, 2MSL, 2 Maximum Segment Lifetime）之后, 没有收到服务器端的 ACK, 认为服务器端已经正常关闭连接, 于是自己也关闭连接, 进入 `CLOSED` 状态。 四次挥手的示意图如下： SYN攻击 什么是 SYN 攻击（SYN Flood）？ 12345在三次握手过程中，服务器发送 SYN-ACK 之后，收到客户端的 ACK 之前的 TCP 连接称为半连接(half-open connect)。此时服务器处于 SYN_RCVD 状态。当收到 ACK 后，服务器才能转入 ESTABLISHED 状态.SYN 攻击指的是，攻击客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送SYN包，服务器回复确认包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN请求被丢弃，导致目标系统运行缓慢，严重者会引起网络堵塞甚至系统瘫痪。SYN 攻击是一种典型的 DoS/DDoS 攻击。 如何检测 SYN 攻击？ 1检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源IP地址是随机的，基本上可以断定这是一次SYN攻击。在 Linux/Unix 上可以使用系统自带的 netstats 命令来检测 SYN 攻击。 如何防御 SYN 攻击？ 123456SYN攻击不能完全被阻止，除非将TCP协议重新设计。我们所做的是尽可能的减轻SYN攻击的危害，常见的防御 SYN 攻击的方法有如下几种： - 缩短超时（SYN Timeout）时间 - 增加最大半连接数 - 过滤网关防护 - SYN cookies技术 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"网络协议系列","slug":"网络协议系列","permalink":"https://ostenant.coding.me/categories/网络协议系列/"}],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://ostenant.coding.me/tags/TCP/"}]},{"title":"WebSocket协议入门简介","slug":"WebSocket协议入门简介","date":"2017-02-23T07:47:00.000Z","updated":"2018-06-18T01:51:55.663Z","comments":true,"path":"2017/02/23/WebSocket协议入门简介/","link":"","permalink":"https://ostenant.coding.me/2017/02/23/WebSocket协议入门简介/","excerpt":"前言以前的网站为了实现推送功能，使用的方法都是轮询。所谓的轮询就是在特定的时间间隔（例如1秒），由浏览器向服务器发出一个 Http request ，然后服务器返回最新的数据给客户端浏览器，从而给出一种服务端实时推送的假象。由于 Http Request 的 Header（请求头）很长,而传输的数据可能很短就只占一点点，每次请求消耗的带宽大部分都消耗在 Header 上。从网上资料得知后来还有改进的轮询方法叫做 Comet ，使用 Ajax 。但这种技术虽然可达到双向通信，但依然需要发出请求，而且在 Comet 中，普遍采用了长轮询，这也会大量消耗服务器带宽和资源。","text":"前言以前的网站为了实现推送功能，使用的方法都是轮询。所谓的轮询就是在特定的时间间隔（例如1秒），由浏览器向服务器发出一个 Http request ，然后服务器返回最新的数据给客户端浏览器，从而给出一种服务端实时推送的假象。由于 Http Request 的 Header（请求头）很长,而传输的数据可能很短就只占一点点，每次请求消耗的带宽大部分都消耗在 Header 上。从网上资料得知后来还有改进的轮询方法叫做 Comet ，使用 Ajax 。但这种技术虽然可达到双向通信，但依然需要发出请求，而且在 Comet 中，普遍采用了长轮询，这也会大量消耗服务器带宽和资源。 正文所以 HTML5 定义了WebSocket 协议，以及相关的编程 API ，能更好的实现双向通信且节省服务器资源和带宽。 WebSocket原理 注意： WebSocket 实际上指的是一种协议，与我们熟知的 Http 协议是同等协议栈的一个网络协议。用网络模型结构来解释的话， WebSocket 和 Http 协议都属于 应用层协议，两者都基于传输层协议 TCP协议。 WebSocket与HTTP的联系简述：WebSocket 和 Http 一样，都是基于都 TCP，属于应用层的协议。 WebSocket并不是 HTTP 协议，WebSocket协议只是基于 HTTP 协议在客户端和服务器通过握手建立连接，连接建立以后就通过 TCP 协议发送和接收报文，与 HTTP 协议无关了。 WebSocket 协议和 HTTP 协议是两种不同的东西，它们的联系如下： 客户端开始建立 WebSocket 连接时要发送一个 header 标记了 Upgrade 的 HTTP 请求，表示请求协议升级。 服务器端做出响应的是，直接在现有的 HTTP 服务器和现有的 HTTP 端口上实现 WebSocket 协议，重用 HTTP 握手建立连接这一功能（比如解析和认证这个 HTTP 请求。如果在 TCP 协议上实现，这两个功能就要重新实现），然后再回一个状态码为 101 的 HTTP 响应完成握手，再往后发送数据时就没 HTTP 的事了。 WebSocket组件WebSocket通信架构HTML5 WebSockets规范定义了一个API,它允许web页面使用websocket协议与远程主机双向沟通。介绍了WebSocket接口,并定义了一个全双工的通信通道,通过一个套接字在网络上运行。相比不断客户端轮询的请求方式，HTML5 WebSockets长连接方式极大的减少了不必要的网络流量和延迟。 HTML5 WebSocketHTML5 WebSocket 规范定义了 WebSocket API , 允许用户在 Browser 使用 。WebSocket 协议为全双工通信,远程主机。基本原理是通过引入 WebSocket Endpoint, 定义一个 全双工 的通信通道, 通过一个 套接字 在网络上运行。HTML5 WebSocket 通过单个套接字长连接有效地降低网络上的开销。相比原有的的轮询和长轮询(Comet)方式来说，极大的减少了不必要的 网络流量 和延迟, 通常用于 推送实时数据 到客户端, 甚至可以通过维护两个HTTP连接来模拟 全双工连接 。 Proxy Server通常,代理服务器建立于内网和公网之间。代理服务器可以监控流量, 通过超时机制断开连接。HTTP 代理服务器——原本为文档转移——可以选择关闭或闲置 WebSocket 连接, 它会试图不断去call一个反应迟钝的 HTTP 服务器。对于长连接, 比如网络套接字, 这种行为是不合理的。另外, 代理服务器可能会缓存未加密的 HTTP 响应报文, 从而会给 HTTP 响应流带来巨大的延迟。 HTML5 WebSocket and Proxy Servers让我们看看 HTML5 WebSockes 是如何与代理服务器通信的。WebSocket 连接使用标准的HTTP端口 (80和443)。因此, HTML5 WebSocket 不需要新的硬件设备, 或新开放其他的网络端口。没有任何代理服务器 (代理或反向代理服务器、防火墙、负载平衡路由器等等), 浏览器和 WebSocket 服务器之间通信非常简单, 只要服务器和客户端都支持 WebSocket 协议。然而, 在生产环境中, 大量的网络通信都会穿透防火墙、代理服务器等。 HTML5 WebSocket and Proxy Servers之间的网络拓扑图 与常规的HTTP请求/响应，不断建立断开连接的方式相比, WebSocket 连接可以保持很长一段时间。代理服务器可能会对这种长连接的方式进行合理的处理, 但也可能带来不可预料的问题。 WebSocket示例Copy下面的代码,保存为 websocket.html。然后在浏览器中打开它。页面将自动连接到 ws://echo.websocket.org/ 服务器,发送一个消息，显示反应，关闭连接。参考链接：http://www.websocket.org/echo.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;!DOCTYPE html&gt;&lt;meta charset=\"utf-8\" /&gt;&lt;title&gt;WebSocket Test&lt;/title&gt;&lt;script language=\"javascript\" type=\"text/javascript\"&gt;var wsUri = \"ws://echo.websocket.org/\";var output;function init()&#123; output = document.getElementById(\"output\"); testWebSocket();&#125;function testWebSocket()&#123; websocket = new WebSocket(wsUri); websocket.onopen = function(evt) &#123; onOpen(evt) &#125;; websocket.onclose = function(evt) &#123; onClose(evt) &#125;; websocket.onmessage = function(evt) &#123; onMessage(evt) &#125;; websocket.onerror = function(evt) &#123; onError(evt) &#125;;&#125;function onOpen(evt)&#123; writeToScreen(\"CONNECTED\"); doSend(\"WebSocket rocks\");&#125;function onClose(evt)&#123; writeToScreen(\"DISCONNECTED\");&#125;function onMessage(evt)&#123; writeToScreen('&lt;span style=\"color: blue;\"&gt;RESPONSE: ' + evt.data+'&lt;/span&gt;'); websocket.close();&#125;function onError(evt)&#123; writeToScreen('&lt;span style=\"color: red;\"&gt;ERROR:&lt;/span&gt; ' + evt.data);&#125;function doSend(message)&#123; writeToScreen(\"SENT: \" + message); websocket.send(message);&#125;function writeToScreen(message)&#123; var pre = document.createElement(\"p\"); pre.style.wordWrap = \"break-word\"; pre.innerHTML = message; output.appendChild(pre);&#125;window.addEventListener(\"load\", init, false);&lt;/script&gt;&lt;h2&gt;WebSocket Test&lt;/h2&gt;&lt;div id=\"output\"&gt;&lt;/div&gt; 解读 创建一个 WebSocket 对象，参数是需要连接的服务器端的地址，同 http 协议使用http://开头 一样，WebSocket 协议的URL使用ws://开头，另外安全的WebSocket 协议使用wss://开头。。12var wsUri =\"ws://echo.websocket.org/\";websocket = new WebSocket(wsUri); WebSocket 对象一共支持 onopen , onmessage , onclose 和 onerror四个消息事件。 当Browser和 WebSocketServer 连接成功后，会触发 onopen 消息;12websocket.onopen = function(evt) &#123;&#125;; 如果连接失败，发送、接收数据失败或者处理数据出现错误，browser会触发 onerror 消息;12websocket.onerror = function(evt) &#123;&#125;; 当Browser接收到 WebSocketServer 发送过来的数据时，就会触发 onmessage 消息，参数evt中包含server传输过来的数据;12websocket.onmessage = function(evt) &#123;&#125;; 当Browser接收到 WebSocketServer 端发送的关闭连接请求时，就会触发 onclose 消息。12websocket.onclose = function(evt) &#123;&#125;; WebSocket报文下面给出 WebSocket 通过 HTTP 握手建立连接时发送的 request 和接收的 repsonse报文。 注意：下面的请求报文与响应报文中的内容不是完整的报文，而是 WebSocket 基于 Http 请求（响应）报文添加的内容。 客户端向 WebSocket 服务器发送 HTTP 请求，在请求头中加入Upgrade请求头，要求把连接从 HTTP 升级到 WebSocket，示例请求报文：12345678GET ws://echo.websocket.org/?encoding=text HTTP/1.1Origin: http://websocket.orgCookie: __utma=99asConnection: UpgradeHost: echo.websocket.orgSec-WebSocket-Key: uRovscZjNol/umbTt5uKmw==Upgrade: websocketSec-WebSocket-Version: 13 服务器发现客户端的请求是 WebSocket 协议，通过在在响应报文中添加Upgrade协议将连接从 HTTP 升级为 WebSocket，示例响应报文：123456HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: UpgradeSec-WebSocket-Accept: fFBooB7FAkLlXgRSz0BT3v4hq5s=Sec-WebSocket-Origin: nullSec-WebSocket-Location: ws://example.com/ 接下来，HTTP 连接断开连接，被底层同样依赖于 TCP/IP的 WebSocket连接所替换。对于WebSocket协议，默认情况下，同样是使用的 HTTP (80) 端口和 HTTPS (443) 端口。 WebSocket报文格式 欢迎关注技术公众号： 零壹技术栈 本帐号将持续分享后端技术干货，包括虚拟机基础，多线程编程，高性能框架，异步、缓存和消息中间件，分布式和微服务，架构学习和进阶等学习资料和文章。","categories":[{"name":"网络协议系列","slug":"网络协议系列","permalink":"https://ostenant.coding.me/categories/网络协议系列/"}],"tags":[{"name":"WebSocket","slug":"WebSocket","permalink":"https://ostenant.coding.me/tags/WebSocket/"}]}]}